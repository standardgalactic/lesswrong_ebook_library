
Best of LessWrong: February 2021
1. Making Vaccine
2. "PR" is corrosive; "reputation" is not.
3. RadVac Commercial Antibody Test Results
4. Your Cheerful Price
5. Utility Maximization = Description Length Minimization
6. Covid 2/11: As Expected
7. The Story of the Reichstag
8. The feeling of breaking an Overton window
9. Fixing The Good Regulator Theorem
10. Oliver Sipple
11. Unwitting cult leaders
12. Mentorship, Management, and Mysterious Old Wizards
13. How do you optimize productivity with respect to your menstrual cycle?
14. Covid 2/18: Vaccines Still Work
15. 2019 Review: Voting Results!
16. Reﬂections on the cryonics sequence
17. Covid 2/4: Safe and Eﬀective Vaccines Aplenty
18. Second Citizenships, Residencies, and/or Temporary Relocation
19. Quadratic, not logarithmic
20. Covid 2/25: Holding Pattern
21. Smuggled frames
22. The Prototypical Negotiation Game
23. Book review: The Geography of Thought
24. Curing Sleep: My Experiences Doing Cowboy Science
25. Promoting Prediction Markets With Meaningless Internet-Point Badges
26. Avoid Contentious Terms
27. Judging Our April 2020 Covid-19 Predictions
28. The 10,000-Hour Rule is a myth
29. How my school gamed the stats
30. The slopes to common sense
31. Current cryonics impressions
32. The Economics of Media
33. Overconﬁdence is Deceit
34. Distinguishing claims about training vs deployment
35. [Link] Sarah Constantin on RaDVaC
36. Intro to the Wedding Sequence
37. [Fiction] Lena (MMAcevedo)
38. Tournesol, YouTube and AI Risk
39. A No-Nonsense Guide to Early Retirement
40. The Kelly Criterion in 3D
41. Timeline of AI safety
42. Forecasting Prize Results
43. Support vs Advice & Holding Oﬀ Solutions
44. Killing the ants
45. Science Fiction
46. Suggestions of posts on the AF to review
47. Networking and Expert Consulting As Rationality Bottlenecks
48. Potential factors in Bell Labs' intellectual progress, Pt. 1
49. We got what's needed for COVID-19 vaccination completely wrong

50. Coincidences are Improbable

Making Vaccine
Back in December, I asked how hard it would be to make a vaccine for oneself. Several
people pointed to radvac. It was a best-case scenario: an open-source vaccine design, made
for self-experimenters, dead simple to make with readily-available materials, well-explained
reasoning about the design, and with the name of one of the world's more competent
biologists (who I already knew of beforehand) stamped on the whitepaper. My girlfriend and I
made a batch a week ago and took our ﬁrst booster yesterday.
This post talks a bit about the process, a bit about our plan, and a bit about motivations.
Bear in mind that we may have made mistakes - if something seems oﬀ, leave a comment.
The Process
All of the materials and equipment to make the vaccine cost us about $1000. We did not
need any special licenses or anything like that. I do have a little wetlab experience from my
undergrad days, but the skills required were pretty minimal.

One vial of custom peptide - that little
pile of white powder at the bottom.
The large majority of the cost (about $850) was the peptides. These are the main active
ingredients of the vaccine: short segments of proteins from the COVID virus. They're all <25
amino acids, so far too small to have any likely function as proteins (for comparison, COVID's
spike protein has 1273 amino acids). They're just meant to be recognized by the immune

system: the immune system learns to recognize these sequences, and that's what provides
immunity.
Each of six peptides came in two vials of 4.5 mg each. These are the half we haven't
dissolved; we keep them in the freezer as backups. 
The peptides were custom synthesized. There are companies which synthesize any (short)
peptide sequence you want - you can ﬁnd dozens of them online. The cheapest options
suﬃce for the vaccine - the peptides don't need to be "puriﬁed" (this just means removing
partial sequences), they don't need any special modiﬁcations, and very small amounts
suﬃce. The minimum order size from the company we used would have been suﬃcient for
around 250 doses. We bought twice that much (9 mg of each peptide), because it only cost
~$50 extra to get 2x the peptides and extras are nice in case of mistakes.
The only unusual hiccup was an email about customs restrictions on COVID-related peptides.
Apparently the company was not allowed to send us 9 mg in one vial, but could send us two
vials of 4.5 mg each for each peptide. This didn't require any eﬀort on my part, other than
saying "yes, two vials is ﬁne, thankyou". Kudos to their customer service for handling it.

Equipment - stir plate, beakers, microcentrifuge tubes, 10 and 50 mL vials, pipette
(0.1-1 mL range), and pipette tips. It's all available on Amazon.

Other materials - these are sold as supplements. We also need such rare and costly
ingredients as vinegar and deionized water. Also all available on Amazon.
Besides the peptides, all the other materials and equipment were on amazon, food grade, in
quantities far larger than we are ever likely to use. Peptide synthesis and delivery was the
slowest; everything else showed up within ~3 days of ordering (it's amazon, after all).
The actual preparation process involves three main high-level steps:
Prepare solutions of each component - basically dissolve everything separately, then
stick it in the freezer until it's needed.
Circularize two of the peptides. Concretely, this means adding a few grains of activated
charcoal to the tube and gently shaking it for three hours. Then, back in the freezer.
When it's time for a batch, take everything out of the freezer and mix it together.
Prepping a batch mostly just involves pipetting things into a beaker on a stir plate,
sometimes drop-by-drop.

Finally, a dose goes into a microcentrifuge tube. We stick the intake tube of a sprayer into
the tube, and inhale.

That's the process, at a high level. Multiple boosters are strongly recommended, so there's a
few iterations of this, though only the "take stuﬀ out of the freezer and mix it together" step
needs to be repeated. See the whitepaper for the full protocol details, as well more
information about each of the peptides and what the other ingredients do (summary:
chitosan nanoparticles).

The Plan
The key problem is how to check that the vaccine worked. If it were injected, that would be
easy: just get a standard COVID antibody test. Inhaling makes it a lot harder to hurt yourself,
but also complicates testing.
The whitepaper goes into more detail and half-a-dozen diﬀerent types of immune response,
but the basic issue is that immunity response in the mucus lining (i.e. nose, lung, airway
surfaces) can occur independently of response in the bloodstream. Commercial COVID
antibody tests generally check a blood draw. In principle one can run a similar antibody test
on a mucus sample, but <reasons>, so the commercial tests check blood.
(Side note: in many ways immunity in the mucus lining is better than in the blood, since it
blocks infection at the point where it's introduced. This is an advantage of inhaled vaccines
over injected. So why do most commercial vaccines inject? Turns out logistics are a major
constraint on commercial vaccine design, and injections are surprisingly easier logistically.
One of the major relative advantages of radvac is that it's intended to be prepared on-site
shortly before administration, so it can use techniques which work better but don't scale as
well. That largely balances out the constraints of readily-available materials and simple
preparation. As usual, the whitepaper goes into much more detail on this, including several
other logistics-related relative advantages - multiple boosters, custom peptides, frequent
design updates, etc.)
The whitepaper claims that "over a hundred" researchers have self-administered the vaccine
so far, but I have not been able to ﬁnd any data on test results from any of them. The paper
says that inhaled vaccine can induce immunity in the blood, but I don't have a quantitative
feel for how likely that is, other than the usual assumption that more dakka makes it more
likely. Meanwhile, I don't have a convenient way to test for immune response other than the
commercial tests.
So, the current plan is to search under the streetlamp. We'll just use the commercial tests.
Both of us got an antibody test before starting the project, and both came back negative.
My current model is:
If the vaccine induces an immune response in the blood, then it almost certainly
induces one in the mucus lining, but the reverse does not hold. So a positive blood
antibody test means it deﬁnitely works, a negative antibody test is a weak update
against.
There's some chance that a few doses are more than enough to induce a blood
response.
There's some chance that more dakka will induce a blood response, even if the ﬁrst few
doses aren't enough.
So, we'll do (up to) two more blood tests. The ﬁrst will be two weeks after our third (weekly)
dose; that one is the "optimistic" test, in case three doses is more-than-enough already. That
one is optimistic for another reason as well: synthesis/delivery of three of the nine peptides
was delayed, so our ﬁrst three doses will only use six of them. If the optimistic test comes
back positive, great, we're done.
If that test comes back negative, then the next test will be the "more dakka" test. We'll add
the other three peptides, take another few weeks of boosters, maybe adjust frequency
and/or dosage - we'll consider exactly what changes to make if and when the optimistic test
comes back negative. Risks are very minimal (again, see the paper), so throwing more dakka
at it makes sense.
Consider this a pre-registration. I intend to share my test results here.

Motivations
Why am I doing this?
I imagine, a year or two from now, looking back and grading my COVID response. When I
imagine an A+ response, it's something like "make my own fast tests, and my own vaccine,
test that they actually work, and do all that in spring 2020". We've all been complaining
about how "we" (i.e. society) should do these things, yet to a large extent they're things
which we can do for ourselves unilaterally. Doing it for ourselves doesn't capture all the
beneﬁts - lots of fun stuﬀ is still closed/cancelled - but it's enough to go out, socialize, and
generally enjoy life without worrying about COVID.
I've written a blog post about Benjamin Jesty, the dairy farmer who successfully immunized
his wife and kids against smallpox the same year that King Louis XV of France died of the
disease. I explicitly use this as an example of what Rationalism should strive to consistently
achieve. Yet when a near-perfect real world equivalent came along, on super-easy mode with
most of the work already done by somebody else, it still took me until December to notice.
The radvac vaccine showed up in my newsfeed back in July, and I apparently failed to
double-click. That level of performance is embarrassing, and I doubt that I will grade my
COVID response any higher than a D.
So I'm doing this, in part, to condition the mental motions. To build the habit of Doing This
Sort Of Thing, so next time I hopefully do better than a D.
Of course, the concrete beneﬁts are nice too. But at this point it's only ~4 months until I'd
get a vaccine anyway, so the price tag is only arguably worthwhile. It's still a fun project in
its own right, and it gets dramatically cheaper with more people (remember, $1000 bought
enough supplies for ~500 doses). Concretely, the largest beneﬁts are in risk reduction. If
there's big hiccups in commercial vaccine deployment, this becomes much more worthwhile.
If the South Africa strain turns out to evade commercial vaccines, this becomes much more
worthwhile - the radvac design is frequently updated based on the latest COVID research, so
we hopefully wouldn't need to wait around for approval of a new commercial vaccine.
Finally, I'm curious whether it will work - or whether we'll be able to tell that it works. It's a
data point as to just how often large bills are left sitting on sidewalks just a little ways oﬀ the
beaten path.

"PR" is corrosive; "reputation" is not.
This is in some sense a small detail, but one important enough to be worth write-up
and critique: AFAICT, "PR" is a corrupt concept, in the sense that if you try to
"navigate PR concerns" about yourself / your organization / your cause area / etc., the
concept will guide you toward harmful and confused actions. In contrast, if you try to
safeguard your "reputation", your "brand", or your "honor," I predict this will basically
go ﬁne, and will not lead you to leave a weird confused residue in yourself or others.
To explain the diﬀerence:
If I am safeguarding my "honor" (or my "reputation", "brand", or "good name"), there
are some ﬁxed standards that I try to be known as adhering to. For example, in Game
of Thrones, the Lannisters are safeguarding their "honor" by adhering to the principle
"A Lannister always pays his debts." They take pains to adhere to a certain standard,
and to be known to adhere to that standard. Many examples are more complicated
than this; a gentleman of 1800 who took up a duel to defend his "honor" was usually
not defending his known adherence to a single simple principle a la the Lannisters.
But it was still about his visible adherence to a ﬁxed (though not explicit) societal
standard.
In contrast, if I am "managing PR concerns," there is no ﬁxed standards of good
conduct, or of my-brand-like conduct, that I am trying to adhere to. Instead, I am
trying to do a more complicated operation:
1. Model which words or actions may cause "people" (especially media, or self-
reinforcing miasma) to get upset with me;
2. Try to speak in such a way as to not set that oﬀ.
It's a weirder or loopier process. One that's more prone to self-reinforcing fears of
shadows, and one that somehow (I think?) tends to pull a person away from
communicating anything at all. Reminiscent of "Politics and the English Language."
Not reminiscent of Strunk and White.
One way you can see the diﬀerence, is that when people think about "PR" they
imagine a weird outside expertise, such that you need to have a "PR consultant" or a
"media consultant" who you should nervously heed advice from. When people think
about their "honor," it's more a thing they can know or choose directly, and so it is
more a thing that leaves them free to communicate something.
So: simple suggestion. If, at any point, you ﬁnd yourself trying to "navigate PR", or to
help some person or organization or cause area or club or whatever to "navigate PR,"
see if you can instead think and speak in terms of defending your/their "honor",
"reputation", or "good name". And see if that doesn't make everybody feel a bit
clearer, freer, and more as though their feet are on the ground.
Related: The Inner Ring, by CS Lewis; The New York Times, by Robert Rhinehart.

RadVac Commercial Antibody Test
Results
Background: Making Vaccine
Results are in from the commercial antibody tests. Both my girlfriend and I came back
negative - the test did not detect any Spike antibody response in the blood. This post
will talk about how I'm updating based on these results, and the next steps.
Here's our timeline so far; more info on the vaccine is in the original post and the
radvac whitepaper:
We've taken ﬁve doses, spaced apart weekly (on Tuesdays).
The ﬁrst three doses only included six of the nine peptides, due to delays from
the manufacturer. (Spike 660, Spike 1145, and Orf1 5471T were the three
missing.)
The blood draw for this test took place the day after the ﬁfth dose. I expect this is too
soon to notice signiﬁcant impact from the last two doses; vaccines in general seem to
typically take 2-3 weeks to kick in, and that is my expectation for this one as well.
(Also, it was an "IgG antibody test", and WebMD says these antibodies typically take
about 2 weeks to show up after covid symptoms show from an actual infection.) This
is intended to mainly be a test of the ﬁrst three doses.
The test apparently used the "DiaSorin Liaison(R) SARS-CoV-2 S1/S2 IgG assay" (I
didn't know this until the results came in). According to the FDA, it has about 92%
sensitivity and 99% speciﬁcity. The "S1/S2" part indicates that it's testing for response
to the S1 and S2 subunits of the spike protein - together, these are essentially the
whole spike protein.
Important thing to notice: the test was looking for Spike antibodies, and two of our
three missing peptides were Spike peptides. Indeed, there were only 3 Spike peptides
among the full 9, so with two missing, we only had one Spike peptide in our ﬁrst three
doses. (The rest target other parts of the virus.) So that makes the test signiﬁcantly
less useful than it would otherwise be, and makes me more inclined to get another
test in 2-3 weeks when the doses with the other three peptides have had time to kick
in. 
How I'm Updating
In the original post, I called this test "searching under the streetlamp". It wasn't super
likely to come back positive even assuming the vaccine worked as intended, but it
was relatively cheap and easy to run the test, so it was our ﬁrst check. Given the
missing Spike peptides and the test only checking against Spike, it was even more
likely to come back negative than I originally estimated.
In Jacob's prediction questions, I gave roughly a 25% chance that a commercial
antibody test would pass for most people, given three doses and all 9 peptides. I gave
the vaccine about 75% chance of working overall, distributed over several diﬀerent

possible worlds. In this speciﬁc scenario, it's clear that the prior on test passing should
be even lower.
(Reminder on the possible worlds: the vaccine could induce antibody response in the
blood and mucus, only mucus, or not at all. It could induce T-cell response separate
from antibody response. It could work sometimes, much like how the ﬁrst dose of
commercial mRNA vaccines tend to work in 75% or 85% of people, and in that case I
expect more doses/more time to make it work more often.)
After updating on the results, I'm down to about 60-70% chance of working overall.
Unfortunately this test just didn't give us very much information - at least about the
vaccine working.
Aside from the test result, we do have one more small piece of information to update
on: I was quite congested for 1-2 days after the most recent three doses (and I was
generally not congested the rest of the week). That's exactly what we'd expect to see
if the vaccine is working as intended, and it's pretty strong evidence that it's doing
something. Updating on both that and the test results, I'm at ~70% that it works
overall.
Next Steps
There's a few directions to go from here.
First, we can take one more dose with all the peptides included, wait a couple more
weeks, and get another test to see if there's a blood antibody response against the
Spike protein. That would still be searching under streetlight - it's still cheap and very
useful if it passes, but most likely to not pass even if the vaccine works.
We could also speciﬁcally look for a commercial test which checks for both Spike and
Nucleocapsid antibodies, rather than just Spike, but I expect that to be diﬃcult - those
sorts of details are not particularly visible to consumers. Also, it would still most likely
be a blood test.
The most interesting direction to go from here is to order an ELISA assay kit and run a
test ourselves. Oﬃcial Best Person Anna Czarnotta suggested a protocol and gave a
bunch of helpful tips on this in the comments on the previous post. This would not
require waiting another 2-3 weeks, and would allow us to test mucus directly. It would
be a pretty direct test of whether the vaccine works, not a searching-under-the-
streetlight test. So that's probably what we'll try next; I need to do some reading to
ﬁgure out the details. Further results will be posted when they come in.

Your Cheerful Price
There's a concept I draw on often in social interactions.  I've been calling it the "happy
price", but that is originally terminology by Michael Ellsberg with subtly diﬀerent
implications.  So I now fork oﬀ the term "cheerful price", and specialize it anew.
 Earlier Facebook discussion here.
Tl;dr:
When I ask you for your Cheerful Price for doing something, I'm asking you for
the price that:
Gives you a cheerful feeling about the transaction;
Makes you feel energized about doing the thing;
Doesn't generate an ouch feeling to be associated with me;
Means I'm not expending social capital or friendship capital to make the
thing happen;
Doesn't require the executive part of you, that knows you need money in
the long-term, to shout down and override other parts of you.
The Cheerful Price is not:
A "fair" price;
The price you would pay somebody else to do similar work;
The lowest price such that you'd feel sad about learning the transaction
was canceled;
The price that you'd charge a non-friend, though this is a good thing to
check (see below);
A price you're willing to repeat for future transactions, though this is a
good thing to check (see below);
The bare minimum amount of money such that you feel cheerful.  It should
include some safety margin to account for ﬂuctuating feelings.
The point of a Cheerful Price, from my perspective as somebody who's usually
the one trying to emit money, is that:
It lets me avoid the nightmare of accidentally inﬂicting small ouches on
people;
It lets me avoid the nightmare of spending social capital while having no
idea how much I'm spending;
It lets me feel good instead of bad about asking other people to do things.
Warnings:
Not everybody was raised with an attitude of "money is the unit of caring
and the medium of cooperation" towards exchanges with an overt ﬁnancial
element.  Some people may just not have a monetary price for some
things, such that the exchange would boost rather than hurt their
friendship, and their feelings too are valid.  Not as valid as mine, of course,
but still valid.
"I don't have a cheerful price for that, would you like a non-cheerful price"
is a valid response.
Any time you ask somebody for a Cheerful Price, you are implicitly
promising not to hold any price they name against them, even if it's a
billion dollars.
If Tell Culture doesn't work for someone, Cheerful Prices may not work for
them either.
If a friend didn't already ask for your cheerful price, it may be good to
explicitly tell them when you're naming your cheerful price rather than

your minimum price.
Life does not promise us that we will always get our Cheerful Prices, even
from our friends.
Q:  Why is my Cheerful Price not the same as the minimum price that would make me
prefer doing the transaction to not doing it?  If, on net, I'd rather do something than
not do it, and I get to do it, shouldn't I feel cheerful about that?
As an oversimpliﬁed model, imagine that your mind consists of a bunch of oft-
conﬂicting desires, plus a magic executive whose job it is to decide what to do in the
end.  This magic executive also better understands concepts like "hyperbolic
discounting" that the wordless voices don't understand as well.
Now suppose that I don't want to hurt you even a little; and that I live in terror of
accidentally overdrawing on other people's senses of friendship or obligation towards
me; and that I worry about generating small ouches that your mind will thereafter
associate with me.
In this case I do not want to oﬀer you the minimum price such that your executive
part, which knows you need money in the long-term, would forcibly override your
inner voices that don't understand hyperbolic discounting, and force them to accept
the oﬀer.  Those parts of you may then feel bad while you're actually performing the
task.  I want to oﬀer you an amount of money large enough to produce an inner "Yay!"
loud enough that your executive does not have to shout down the other inner voices.
Q:  Say more about why you'd pay extra to make my balance of inner voices be very
yayful?
Some possible reasons:
Because I feel worried about the trade not getting around to taking place at all,
if you are reluctant to name a price high enough to make you feel cheerful.
Because I worry about you feeling a sense of ouchness about trading with me,
and I want to be sure you don't end up unconsciously avoiding trading with me
in the future.
Because I think you're otherwise likely to name too low a price compared to my
willingness to pay, and I'd feel bad about an unfair division of gains from trade.
Because my willingness to pay marginally more, for a marginally better thingy, is
high; so I'm eager to pay more in order to have you feeling better about doing
the thing, in hopes that I get a slightly better result.
Or I just don't want to hurt you even a little; either because I care about you, or
because I selﬁshly don't want to worry about the guilt of worrying I hurt
somebody.
Q:  Before we get too much further, is there anybody for whom this whole document is
diametrically the wrong advice?
For one, anybody who tends to already set their prices so high that they end up not
getting enough business to keep them busy, should not read things that they might
interpret as exhorting them to go set even huger prices.  For more on this, see Michael
Ellsberg's original cautions around the "happy price", and how it diﬀers from people
being exhorted to set ever higher sky-high prices on their seminars.
For two, anybody who already experiences a lot of negative emotion from ruminating
on how little they receive; or who feels sad and depressed about how little they have

to give; and who doesn't have any power to get more, or give more.  They should
maybe not be reading this at all?  They should maybe just stop reading this whole
essay immediately, because it may just make them feel sadder.  You need to have
Slack to beneﬁt from an essay about how to use Slack.
Q:  Thanks, back to other questions.  Why is a Cheerful Price not the same quantity as
"the least price that would make me feel sad and disappointed about the transaction
being cancelled"?
Because of loss aversion and inner multiplicity.  Once you're expecting to get some
money in exchange for doing something, even if you weren't cheerful about that price,
the part of you that did want the money will feel a sting of loss about losing the
money.  If you're setting the standard to "minimum price that leads to a feeling of loss
about losing the money" then, especially if you strongly need money, you may be
setting your price way too low and might not be capturing any of the gains from trade.
Also, since your strength of feelings may ﬂuctuate over time, you should not be trying
to cut a Cheerful Price very ﬁnely; you should name a price that includes some safety
margin.  If I was uncomfortable with you taking some safety margin, I wouldn't be
asking you to name your Cheerful Price in the ﬁrst place.  I'm ﬁne if I end up with a
little more social capital than when I started.  Nothing goes wrong if you end up
feeling slightly grateful about making the trade.
Q:  For several of your desiderata above, why not ask me instead for a price such that
I don't feel any ouchness about it?
Because I expect people to have a much harder time correctly detecting whether they
are feeling any tiny lingering ouches, compared to noticing a positive feeling of
cheerfulness.
Q:  Why is it better to ask somebody to name "a price that makes you cheerful" rather
than "a price that seems fair to you"?
Well, because those two things aren't interchangeable, and the thing that I actually
want is the Cheerful Price?
But in particular I'd worry that the notion of a "fair price" might lead people to name
prices-that-make-them-feel-bad.  
Suppose I want to pay somebody else to do my laundry this week.  If I ask them for a
fair price, instead of a cheerful price, to do my laundry, they may substitute some
other "fairness"-related question like:
"How much would I be willing to pay somebody else to do my laundry?"
And this presumes several symmetries that I think should not be symmetries.  My
willingness to pay is not the same as your willingness to pay.  The price you'd pay to
not have to do your own laundry this week, isn't the same as the price you'd accept to
do an additional load of laundry this week.
This may not seem fair, because it doesn't seem universal and symmetrical.  But to
me, in context, those seem like false symmetries and mistakenly substituted
questions, that might lead somebody into naming a price they didn't actually want to
take, and then feeling trapped into taking it.

So I'd see this as a case where the recipe "raise the price until the thought of
accepting it makes you feel a noticeable feeling of cheerfulness" may beat the recipe
"try to ﬁgure out what price would be 'fair'".
Q:  Hold on, technical objection to the above:  Isn't it suspicious from a coherent-
decisions perspective if the price you'd accept to do somebody else's laundry is much
higher or lower than the price you'd pay to not do your own laundry?  If you have a lot
of opportunities like this, it's a theorem that either you can be seen as placing some
consistent monetary price on your time and stamina, or you can rearrange your
choices to end up with strictly more money, time, and stamina.  I mean, suppose
somebody oﬀers you $40 to personally do their laundry that week, but you can pay
$20 to get a roommate to do your own roughly-equivalent amount of laundry -
When I ask you for your Cheerful Price, I'm asking what I need to pay to make your
current chorus of inner voices cheerful about taking the money, instead of them
feeling slightly resentful at me afterwards.  It's ﬁne and noble if you want to cultivate
your inner voices to make your life decisions more coherent; but please do that on
your own time rather than by expending my social capital.
Q:  Why is it better to name a "cheerful price" rather than "a price where both parties
beneﬁt"?  Don't we want trades to execute whenever both parties beneﬁt from them?
First of all, it's not always better.  It's better in those special cases when one or both
parties to the trade have particular desiderata, as listed above, that matter to them
equally or more than the variation in price.  This will not always hold true.
More generally, though:  Part of the great economic problem is ﬁnding trades that
beneﬁt both parties.  But even after we ﬁnd a trade like that, we then encounter a
further problem on top: the division of gains from trade.
Let's say I want to pay you to bake me a cake.  Suppose that $40 is the absolute most
I'd be willing to pay, if I had no other options, and that I wouldn't feel good about it
(the inner voices are then discordant and require an executive to shout them down
and accept the transaction).  Conversely, you'd accept a bare minimum of $10, and
wouldn't feel good about that price either.
Then the price should fall somewhere between $10 and $40, for the transaction to
occur at all.  But within that range, there's a zero-sum problem of dividing the gains
from trade, on top of the positive-sum interaction of having the trade occur at all.  At
a price point of $15 we're both better oﬀ, and at a price point of $35 we're both better
oﬀ; but I am better oﬀ, and you are worse oﬀ, at a price point of $15 compared to $35.
If many transactions like this are taking place, we have a third, positive-sum game on
top of the zero-sum second game: the game of supply and demand, the invisible
hand.  You set a price on your cakes that will cause you to sell as much of your cake-
baking time as you want to sell; and the more people want your cakes, the higher
your price goes; and if your price is high enough, that signals others to enter the
market and supply more cakes.  If we have a market price that balances a public
supply function and public demand function for interchangeable cakes, all is good.
 But not everything in life is exchangeable that way; and if not, there's a gains-division
problem between a unique buyer and a unique seller of a unique good.
The domain of the Cheerful Price is the pricing-of-the-trade issue.  Though indeed, one
of my potential reasons above for requesting a Cheerful Price was "Because I'm

nervous about the trade happening at all, so I want you to name a price that makes
you feel energized about getting around to it."
Q:  But if you ask somebody to name a Cheerful Price, doesn't that mean they might
name a price too high for the trade to take place, even if at a lower price the trade
would beneﬁt both sides?  Or what if they just name an astronomical price?
When I ask you to name a Cheerful Price, this often - not quite always - happens when
I have what I suspect is a relatively high willingness to pay.  But if your price goes so
high that I no longer feel cheerful, the transaction won't actually take place at that
price, and you won't get to feel cheerful about it.  So you still have some incentive to
keep your quoted price to "makes me feel cheerful at all, plus some safety margin in
case my feelings ﬂuctuate, but not too much higher than that".
Q:  What if my cheerful price feels very high and I'm too embarrassed to say it?
If I'm willing to pay it, you probably shouldn't feel embarrassed about accepting it?  I
wouldn't ordinarily advise other people to always directly confront their
embarrassment about everything.  But "accepting money that other people are happy
to pay you" is in fact an unusually good and important place to start overcoming your
embarrassed feelings.
Q:  But what if you're not willing to pay the price I name?  Wouldn't that be socially
awful?
Implicit in my asking you to name a Cheerful Price is a social promise that I will not
hold any price you name against you.
Your Cheerful Price is a fact about you and your feelings.  It's not a statement that you
think you're deserved something, or owed something, or that you expect to get that
price from me.  From one possible perspective, I'm asking you to do me the favor of
telling me that useful fact about your own state of mind, and you are doing me the
favor of telling me.  If Tell Culture doesn't work for one or both parties to a transaction,
the idiom of talking about Cheerful Prices may not serve them either.
If  I ask you "What price would make you feel cheerful about baking me a cake?" and
you are feeling generally horrible and it would take a life-changing amount of money
to make you feel good about kitchen work, you could say:  "Cheerful?  Probably a
hundred thousand dollars.  But I'd rather do it for ﬁfty dollars than not do it."  And that
would be ﬁne.
If your Cheerful Price makes me feel unhappy with the trade, I can tell you so.  And
then we could just not do it; or I, or you, could try to negotiate the price downward to
a non-cheerful but mutually beneﬁcial price.
Q:  If you're not promising to pay my Cheerful Price and we might end up negotiating
anyway, what's the point of asking me to name one?
Because there's no point in negotiating below your cheerful region, if your cheerful
price is already inside my comfortable-willingness to pay?
In some contexts you could think of it as me asking you to start oﬀ with an unusually
high opening bid, such that you'd feel quite cheerful if I just accepted that bid.  Which
I'd do because, e.g., I expect that, compared to my trying to save a fraction of the

price I'm guessing you'll name, your non-sadness and/or eagerness to deal with me
again in the future, will end up more important to me.
Q:  Wait, does that mean that if I give you a Cheerful Price, I'm obligated to accept the
same price again in the future?
No, because there may be aversive qualities of a task, or fun qualities of a task, that
scale upward or downward with repeating that task.  So the price that makes your
inner voices feel cheerful about doing something once, is not necessarily the same
price that makes you feel cheerful about doing it twenty times.
Also in general, any time you imagine feeling obligated to do something, you have
probably missed the point of the Cheerful Price methodology.
That said, you should probably check to see how how you would feel about repeating
the transaction - it might turn up a hidden sense of "I'll do this for you once because
I'm your friend", where your friend was hoping to pay you enough that they weren't
expending social capital at all.  Similarly, you might want to check "How much would I
charge this person if they weren't my friend?", not because your Cheerful Price for one
person has to be the same as your Cheerful Price for somebody else, but in case your
brain's ﬁrst answer was mostly the friendship voice glossing over real costs that the
other person is actively requesting to compensate you for.
Q:  I question the whole concept of a Cheerful Price between friends.  I don't think
that's how friendship works in the ﬁrst place.  If I'm willing to bake you a cake because
I'm your friend, bringing money into it would just make me feel icky.  If it was more
money I'd just feel ickier.
You have mentally arranged your friendships diﬀerently from how I arrange them!  But
your feelings are also valid, and you should clearly signal them to anybody who starts
talking about "cheerful prices" at you.  Tell them explicitly that's not how friendship
works for you!  They oﬀered you a Cheerful Price in the ﬁrst place because they
wanted you to be happy.  They don't want you to feel icky.
Q:  Just reading all this already made me feel icky.  When I bake you a cake, you're not
expending social capital, we're being friends -
In that case, you should not read the rest of this post.  It's a cognitive hazard to you.
 Leave immediately.
...
Uh, are they gone now?
Q:  Yeah, they're gone.
Really?
Q:  No, they're still reading, but now with an additional sense of oﬀense that you think
they're too low-status to withstand the weight of your words.  Obviously, only low-
status people could possibly be damaged by reading something.
Sigh.  There are many things I wish I could unread, cough-Gray-Boy-cough.  "Just stop
reading things that are damaging you" is an important life skill which has

commonalities with "Don't leave your hand on a hot stove-plate if that hurts you" and
"Speak up when people are touching you in ways you don't like."  
Q:  Fine, but there's nothing more you can do at this point to warn them oﬀ.  So, what
would you actually say to somebody who claims that, when they bake you a cake,
you're not "expending social capital" to get the cake, because them doing you a favor
can actually strengthen your friendship?
I'd try to explain that economics is about "limited resources" rather than, I don't know,
things that are easy to quantify, or things that are standard and interchangeable, or
whether people feel like they're losing something in the process of a trade.  The fact
that somebody won't willingly bake me an inﬁnite amount of cake is enough to call
that a limited resource, even if they didn't feel bad or lossy about baking one cake.
And that ﬁnite cake limitation is enough to make me worry about what I'm losing when
I ask a friend to bake me just one cake, even if they don't feel bad or lossy about it the
ﬁrst time.  Because I'm the kind of person who ends a computer RPG with 99 unused
healing potions, that's why.  And because I grew up relatively isolated, and I don't
have a good sense of how much I'm losing when I ask somebody to bake me a cake.  I
don't trust my ability to read someone's reactions if I ask them to bake me a cake.  I
don't trust my ability to judge whether that will strengthen the friendship or weaken it.
So in reality, I'm not very likely to end up friends in the ﬁrst place with somebody
who's made sad by my asking to quantify the cost to them of baking a cake.  I can't
tweak my state of mind far enough to encompass their state of mind, or vice versa.
Q:  Okay, but as you admit, some people, maybe even most people, would rather not
put ﬁnancial prices on things at all, in their friendships.  They'd rather just do favors
for each other without a felt sense of trying to keep track of everything.  Why did you
claim back up top that those feelings were valid, but less valid than yours?
I was speaking mostly tongue-in-cheek.  But in fact there are coherence theorems
saying that either you have consistent quantitative tradeoﬀs between the things you
want, or your strategies can be rearranged to get you strictly more of everything you
want.  I think that truly understanding these theorems is not compatible with being
horriﬁed at the prospect of pricing one thing in terms of another thing.  I think that
there is a true bit of mathematical enlightenment that you get, and see into the
structure of choicemaking, and then you are less horriﬁed by the thought of pricing
things in money.
Q:  Fine, but why is it not valid to let people go on feeling whatever they feel without
demanding that they be enlightened by coherence theorems right now at the cost of
doing violence to their emotions?  Who's to say they're not happier than you by living
more the life of a human and less the life of a paperclip maximizer, while both of you
are still mortals in the end?
Well, sure?  Hence it being "mostly tongue-in-cheek" rather than "slightly tongue-in-
cheek".
Q:  Despite your pretended demurral, I get the sense that you actually hold it against
them a bit more than that.
Fine, to be wholly frank, I do tend to see the indignant reaction "How dare you price
that in money!" as a sign that somebody was brought up generally economically
illiterate.  I mean, if somebody says, "Sorry, I haven't attained the stage of

enlightenment where explicitly exchanging money stops making me feel bad", I'm
like, "Your feelings are valid!  I'm still human in many ways too!"  But if they say,
"There are some things you can't put a price on!  How dare you!", I'm like, "This low-
decoupling indignation engine will probably have a happier childhood if I rudely walk
away instead of trying to explain how the notion of a 'price' generalizes beyond things
that are explicitly denominated in money."
Q:  On a completely diﬀerent note, I worry that the notion of a Cheerful Price is unfair
to people who start out poorer, because it will take less money to make them feel
cheerful.
Generally speaking, when I ask somebody to name a "cheerful price", I'm trying to
prompt them into naming a higher price so that I can avoid the fear of ouching them
and/or do more transactions with them in the future.  Giving people more money is
rarely less fair to them?  But if I try to probe at the implicit sense and worry of "unfair"
that you're raising as a concern, I might try to rephrase it as something like:
"If you tell somebody they have to accept as fair the least price that makes them
cheerful, they might accept a lower price than they could have gotten - a price that
would be an uneven division of gains from trade, or a price below the going market
rate - and this is more likely to happen to people who start out poorer."
And I agree that would be unfair.  If you can get more for your skills or your goods by
going above the lowest price that makes you comfortably cheerful, go for it.
That said, if I'm asking everybody in the room their Cheerful Price to do my laundry,
and the poorest person present names the lowest Cheerful Price, I think that's...
actually everything working as intended?  The eﬀect is that the person with the lowest
prior endowment is the one who actually gets the money and feels cheerful about
that; and the Cheerful part means they get more money (I hope) than if I asked
everybody present to name their price without specifying the Cheerful part.
My current cheerful price for "Please write me a short story about the following" might
be above $10,000 today.  In 2001 it might have been $100, back when $100 was
1/20th of the cost of the car I was driving.  The end result of this 10,000% increase in
how much money it takes to make me happy, as I've accumulated more money... is
that now people who'll write you a story for $100 get your money, instead of me.
 That seems a good phenomenon from the standpoint of ﬁnancial equality; it causes
money to ﬂow from people who have more money towards people who have less
money.
But on a more personal level, if I ask someone to name an amount of money that
makes them feel cheerful and energized, I expect and hope that this causes more
money to ﬂow from me to them.  If the technically deﬁned "cheerful price" is less than
the person otherwise thinks they can get from a payor, then by all means, they should
tell me:  "Don't worry!  I set my standard fee of $X high enough that I already feel
cheerful."  And then I won't feel worried about paying too little and everything will be
ﬁne.
Q:  Technical objection:  Surely if you're asking everybody in the room to name their
Cheerful Price for something, you should pay the lowest bidder the second-lowest bid,
not pay the lowest bidder their actual bid?
Uhhh... possibly?  I'm not actually sure that this logic works the same way when you're
asking people for Cheerful Prices - I think you're already asking them to nudge the

price upwards from "the lowest they'd accept", which means you don't have to give
them the second-price of the auction in order to ensure they get any gains from trade.
 It's a more friendly idiom in general - you're asking them and trusting them to tell you
the truth about what won't make them say "ow".  And despite that example of the
laundry, the whole thing seems more useful for individual interactions than auctions?
 But you may still have a point.  I'll have to think about it.
Q:  Now that I think about it, this whole document seems to be written like the
cheerful price is always something that the payor requests the payee to name.  Why
would it always be like that?
I wrote from that perspective because it's the perspective I usually occupy - at this
stage of my life, I'm usually looking for more ways to trade away money for what I
want, not looking for more ways to trade away other things for money.
And since not everybody can aﬀord to oﬀer us our Cheerful Price, in interactions
between friends, there's nonzero reason to not just rush ahead and name a cheerful
price before being asked.  Or to avoid misunderstandings and possible resentment
about you expecting too much, you should say "This is my cheerful price" rather than
"This is my price", if the other person didn't already explicitly say "Please name your
cheerful price."
But sure:  Some people who are in the habit of unilaterally underpricing themselves,
to the point where they're undertrading, even though they have pricing power to ask
for more, might do well to take the initiative on their side to think "What would I need
to be getting to make me cheerful about more interactions here?"  And this is true
whether the trade is for money, or not.
Or some people who are in the habit of underpaying, and not getting all the things
they want, even though they have more to oﬀer, might do well to think, "Would I still
feel cheerful about paying much more for X, if I got more or faster or better X?  Is
there some way to give more and get more?"  And this is true whether the trade is for
money, or not.
Some people may beneﬁt from switching perspectives to ask about cheerful prices
with respect to some internal bargains between the voices in their head; to apply the
same perspective to one-person transactions, not just two-person transactions.
But to repeat the warning from above:   If you have nothing more to give, or no pricing
power to ask for more; then thinking about what it would take to make the bargain
cheerful, may only make you sadder.  And this is true whether for outer bargains, or
inner bargains.
Life does not promise us that we will always get our Cheerful Prices, even from our
friends, and not even from ourselves.  Not every trade produces so much gain to
divide, even among many good trades worth making.

Utility Maximization = Description Length
Minimization
Crossposted from the AI Alignment Forum. May contain more technical jargon than usual.
There's a useful intuitive notion of "optimization" as pushing the world into a small set of states,
starting from any of a large number of states. Visually:
Yudkowsky and Flint both have notable formalizations of this "optimization as compression" idea.
This post presents a formalization of optimization-as-compression grounded in information
theory. Speciﬁcally: to "optimize" a system is to reduce the number of bits required to
represent the system state using a particular encoding. In other words, "optimizing" a
system means making it compressible (in the information-theoretic sense) by a particular model.
This formalization turns out to be equivalent to expected utility maximization, and allows us to
interpret any expected utility maximizer as "trying to make the world look like a particular
model".
Conceptual Example: Building A House
Before diving into the formalism, we'll walk through a conceptual example, taken directly from
Flint's Ground of Optimization: building a house. Here's Flint's diagram:

The key idea here is that there's a wide variety of initial states (piles of lumber, etc) which all end
up in the same target conﬁguration set (ﬁnished house). The "perturbation" indicates that the
initial state could change to some other state - e.g. someone could move all the lumber ten feet
to the left - and we'd still end up with the house.
In terms of information-theoretic compression: we could imagine a model which says there is
probably a house. Eﬃciently encoding samples from this model will mean using shorter bit-
strings for world-states with a house, and longer bit-strings for world-states without a house.
World-states with piles of lumber will therefore generally require more bits than world-states with
a house. By turning the piles of lumber into a house, we reduce the number of bits required to
represent the world-state using this particular encoding/model.
If that seems kind of trivial and obvious, then you've probably understood the idea; later sections
will talk about how it ties into other things. If not, then the next section is probably for you.
Background Concepts From Information Theory
The basic motivating idea of information theory is that we can represent information using fewer
bits, on average, if we use shorter representations for states which occur more often. For
instance, Morse code uses only a single bit (".") to represent the letter "e", but four bits ("- - . -")
to represent "q". This creates a strong connection between probabilistic models/distributions and
optimal codes: a code which requires minimal average bits for one distribution (e.g. with lots of
e's and few q's) will not be optimal for another distribution (e.g. with few e's and lots of q's).
For any random variable X generated by a probabilistic model M, we can compute the minimum
average number of bits required to represent X. This is Shannon's famous entropy formula
− ∑ X P [ X | M ] log  P [ X | M ]
Assuming we're using an optimal encoding for model M, the number of bits used to encode a
particular value x is log P[X = x|M]. (Note that this is sometimes not an integer! Today we have
algorithms which encode many samples at once, potentially even from diﬀerent
models/distributions, to achieve asymptotically minimal bit-usage. The "rounding error" only
happens once for the whole collection of samples, so as the number of samples grows, the
rounding error per sample goes to zero.)

Of course, we could be wrong about the distribution - we could use a code optimized for a model 
M2 which is diﬀerent from the "true" model M1. In this case, the average number of bits used will
be
− ∑ X P [ X | M 1 ] log  P [ X | M 2 ] = E [ log  P [ X | M 2 ] | M 1 ]
In this post, we'll use a "wrong" model M2 intentionally - not because we believe it will yield short
encodings, but because we want to push the world into states with short M2-encodings. The
model M2 serves a role analogous to a utility function. Indeed, we'll see later on that every
model M2 is equivalent to a utility function, and vice-versa.
Formal Statement
Here are the variables involved in "optimization":
World-state random variables X
Parameters θ, θ′ which will be optimized
Probabilistic world-model M1(θ) representing the distribution of X
Probabilistic world-model M2 representing the encoding in which we wish to make X more
compressible
An "optimizer" takes in some parameter-values θ, and returns new parameter-values θ′ such that
E [ − log  P [ X | M 2 ] | M 1 ( θ ′ ) ] ≤ E [ − log  P [ X | M 2 ] | M 1 ( θ ) ]
... with equality if-and-only-if θ already achieves the smallest possible value. In English: we
choose θ′ to reduce the average number of bits required to encode a sample from M1(θ′), using a
code optimal for M2. This is essentially just our formula from the previous section for the number
of bits used to encode a sample from M1 using a code optimal for M2.
Other than the information-theory parts, the main thing to emphasize is that we're mapping one
parameter-value θ to a "more optimal" parameter-value θ′. This should work for many diﬀerent
"initial" θ-values, implying a kind of robustness to changes in θ. (This is roughly the same
concept which Flint captured by talking about "perturbations" to the system-state.) In the
context of iterative optimizers, our deﬁnition corresponds to one step of optimization; we could
of course feed θ′ back into the optimizer and repeat. We could even do this without having any
distinguished "optimizer" subsystem - e.g. we might just have some dynamical system in which 
θ is a function of time, and successive values of θt satisfy the inequality condition.

Finally, note that our model M1 is a function of θ. This form is general enough to encompass all
the usual decision theories. For instance, under EDT, M1(θ) would be some base model M
 conditioned on the data θ. Under CDT, M1(θ) would instead be a causal intervention on a base
model M, i.e. M1(θ) = do(M, Θ = θ).
Equivalence to Expected Utility Optimization
Obviously our expression E[−log P[X|M2]|M1(θ)] can be expressed as an expected utility: just set 
u(X) = log P[X|M2]. The slightly more interesting claim is that we can always go the other way:
for any utility function u(X), there is a corresponding model M2, such that maximizing expected
utility u(X) is equivalent to minimizing expected bits to encode X using M2.
The main trick here is that we can always add a constant to u(X), or multiply u(X) by a positive
constant, and it will still "be the same utility" - i.e. an agent with the new utility will always make
the same choices as the old. So, we set
α u ( X ) + β = log  P [ X | M 2 ]  ⟹  P [ X | M 2 ] = e β e α u ( X )
... and look for α, β which give us a valid probability distribution (i.e. all probabilities are
nonnegative and sum to 1).
Since everything is in an exponent, all our probabilities will be nonnegative for any α, β, so that
constraint is trivially satisﬁed. To make the distribution sum to one, we simply set 
β = −ln ∑X eαu(X). So, not only can we ﬁnd a model M2 for any u(X), we actually ﬁnd a whole
family of them - one for each α > 0.
(This also reveals a degree of freedom in our original deﬁnition: we can always create a new
model M
′
2 with P[X|M
′
2] =
P[X|M2]α without changing the behavior.)
So What Does This Buy Us?
If this formulation is equivalent to expected utility maximization, why view it this way?
Intuitively, this view gives more semantics to our "utility functions". They have built-in
"meanings"; they're not just preference orderings.
Mathematically, the immediately obvious step for anyone with an information theory background
is to write:
E [ − log  P [ X | M 2 ] | M 1 ] = − ∑ X P [ X | M 1 ] log  P [ X | M 1 ] + P [ X | M 1 ] log  
 
1Z
P [ X | M 2 ]
P [ X | M 1 ]

= H ( X | M 1 ) + D K L ( M 2 . X | | M 1 . X )
The expected number of bits required to encode X using M2 is the entropy of X plus the Kullback-
Liebler divergence of (distribution of X under model M2) from (distribution of X under model M1).
Both of those terms are nonnegative. The ﬁrst measures "how noisy" X is, the second measures
"how close" the distributions are under our two models.
Intuitively, this math says that we can decompose the objective E[−log P[X|M2]|M1] into two
pieces:
Make X more predictable
Make the distribution of X "close to" the distribution P[X|M2], with closeness measured by
KL-divergence
Combined with the previous section: we can take any expected utility maximization problem, and
decompose it into an entropy minimization term plus a "make-the-world-look-like-this-speciﬁc-
model" term.
This becomes especially interesting in situations where the entropy of X cannot be reduced - e.g.
thermodynamics. If the entropy H(X) is ﬁxed, then only the KL-divergence term remains. In this
case, we can directly interpret the optimization problem as "make the world-state distribution
look like P[X|M2]". If we started from an expected utility optimization problem, then we derive a
model M2 such that optimizing expected utility is equivalent to making the world look as much as
possible like M2.
In fact, even when H(X) is not ﬁxed, we can build equivalent models M
′
1, M
′
2 for which it is ﬁxed,
by adding new variables to X. Suppose, for example, that we can choose between ﬂipping a coin
and rolling a die to determine X0. We can change the model so that both the coin ﬂip and the die
roll always happen, and we include their outcomes in X. We then choose whether to set X0 equal
to the coin ﬂip result or the die roll result, but in either case the entropy of X is the same, since
both are included. M
′
2 simply ignores all the new components added to X (i.e. it implicitly has a
uniform distribution on the new components).
So, starting from an expected utility maximization problem, we can transform to an equivalent
minimum coded bits problem, and from there to an equivalent minimum KL-divergence problem.
We can then interpret the optimization as "choose θ to make M1(θ) as close as possible to M2",
with closeness measured by KL-divergence.
What I Imagine This Might Be Useful For

In general, interpretations of probability grounded in information theory are much more solid
than interpretations grounded in coherence theorems. However, information-theoretic
groundings only talk about probability, not about "goals" or "agents" or anything utility-like. Here,
we've transformed expected utility maximization into something explicitly information-theoretic
and conceptually natural.  This seems like a potentially-promising step toward better foundations
of agency. I imagine there's probably purely-information-theoretic "coherence theorems" to be
found.
Another natural direction to take this in is thermodynamic connections, e.g. combining it with a
generalized heat engine. I wouldn't be surprised if this also tied in with information-theoretic
"coherence theorems" - in particular, I imagine that negentropy could serve as a universal
"resource", replacing the "dollars" typically used as a measuring stick in coherence theorems.
Overall, the whole formulation smells like it could provide foundations much more amenable to
embedded agency.
Finally, there's probably some nice connection to predictive processing. In all likelihood, Karl
Friston has already said all this, but it has yet to be distilled and disseminated to the rest of us.

Covid 2/11: As Expected
Nothing both unexpected and important happened this week, other than that we might be on
the verge of at least partially solving obesity.
There's plenty else to talk about, but everything was on trend. That doesn't mean my
predictions were perfect or the speed of trends didn't give us a few surprises, nor does it
mean I could have written this post a week ago. It does mean that long term expectations
haven't much changed. 
Vaccine eﬀorts continue to be far too slow to improve, but to still improve slowly, including
both distribution and approval. All current numbers continue to steadily decline, as they
should until the new strains threaten to reverse that, which should still be a few weeks
away. 
While we can hope for unexpected good news, the more realistic and modest hope is that
the lack of major news continues but things continue to steadily improve, and vaccine access
improves dramatically in March after the approval of Johnson & Johnson combined with
accelerating production across the board.
The Covid Tracking Project will be ending soon, and I still don't have an great alternative
source I love, so if you do have one (either for downloading data, for grabbing good data
manually slash copy/pasting into a spreadsheet, or both) please suggest it in the comments.
In the meantime, let's run the numbers.
The Numbers
Predictions
Last week: 7.7% positive rate on 12.7 million tests, and an average of 3,041 deaths per day. 
Prediction for this week: 6.9% positive rate and an average of 2,750 deaths. Current trends
should continue, with minimal impact yet from new strains, changed policies or increased
vaccinations. 
Results: 6.4% positive rate and an average of 2,968 deaths.
The 6.4% number isn't shocking and was deﬁnitely in my range of plausible outcomes, but
it's pretty great. It's even better than it looks, because our test counts are in rapid decline as
well, from 12.2 million to 11.3 million, which presumably reﬂects lower demand. Things are
improving rapidly, if not rapidly enough to stall the rise of the English strain, but things could
plausibly be 25% better week-over-week, and that's going to buy us time to improve further.
This is reason to be hopeful.
The 2,968 deaths are highly disappointing, as that's only a few percent less than last week.
The 14-day-delayed-from-diagnosis-to-deaths rolling 7-day CFR went up from 1.29% to
1.57%, but on the other hand the 21-day-delayed-from-diagnosis-to-deaths rolling 7-day CFR
went down from 1.34% to a new low of 1.25% (technically the low was 1.23% yesterday). 
When looking at regional totals, I noticed that Indiana added 1,507 deaths this week that
happened previously, as the result of an audit. 
When you take those away, that drops the average death rate down to 2,752 deaths per day.
Bullseye. 

Prediction: 5.7% positive rate and an average of 2,450 deaths. Things should still continue to
improve.
Deaths
Date
WEST MIDWEST SOUTH NORTHEAST TOTAL
Dec 10-Dec 16 3278 5324
4376
3541
16519
Dec 17-Dec 23 3826 5158
5131
3772
17887
Dec 24-Dec 30 3363 3668
4171
3640
14842
Dec 31-Jan 6
4553 4127
5019
4162
17861
Jan 7-Jan 13
6280 3963
7383
4752
22378
Jan 14-Jan 20
5249 3386
7207
4370
20212
Jan 21-Jan 27
6281 3217
8151
4222
21871
Jan 28-Feb 3
5524 3078
8071
3410
20083
Feb 4-Feb 10
4937 4194
7165
3429
19725
That's a very large uptick in the Midwest, so the question is what is going on there. There
certainly was never a corresponding jump in positive tests. Looking at the details, the
explanation is that more than all of it comes from February 4 in Indiana, with 1,518 deaths.
The Covid Tracking Project explains that these additional deaths come from a historical audit,
so they're not from last week at all. For this week's update I'll leave them in place, but will be
editing the extra 1,507 past deaths out of the weekly charts going forward. At that point,
things look normal.
Positive Tests

Date
WEST
MIDWEST SOUTH
NORTHEAST
Dec 31-Jan 6 428,407 251,443
494,090 267,350
Jan 7-Jan 13
474,002 262,520
531,046 306,604
Jan 14-Jan 20 360,874 185,412
452,092 250,439
Jan 21-Jan 27 260,180 158,737
386,725 219,817
Jan 28-Feb 3 191,804 122,259
352,018 174,569
Feb 4-Feb 10 144,902 99,451
255,256 149,063
Excellent progress. Not enough to overcome the new strain, but still very good, and even
better accelerating improvement.
Test Counts
Date
USA tests
Positive % NY tests
Positive % Cumulative Positives
Dec 17-Dec 23 13,363,172 11.1%
1,440,770 5.1%
5.60%
Dec 24-Dec 30 11,300,924 11.2%
1,303,286 6.0%
5.98%
Dec 31-Jan 6
11,649,640 13.3%
1,365,473 7.3%
6.45%
Jan 7-Jan 13
13,911,529 12.2%
1,697,034 6.6%
6.97%
Jan 14-Jan 20
14,005,720 9.7%
1,721,440 5.9%
7.39%
Jan 21-Jan 27
12,801,271 8.8%
1,679,399 5.3%
7.73%
Jan 28-Feb 3
12,257,123 7.7%
1,557,550 4.6%
8.02%
Feb 4-Feb 10
11,376,541 6.4%
1,289,603 4.2%
8.25%
Vaccinations

Last week there were signs the growth in vaccination rate might be stalling out. Fortunately
that has not happened, and supply continues to increase at a good clip. 
The current pace is not fast enough by any means, but if we can continue to grow at 20%
week over week with the Pﬁzer and Moderna vaccines alone, it won't be long before we get

where we need to be. 
It doesn't feel like things are accelerating, because eligibility was expanded suﬃciently that
there are no appointments anywhere and no one has any supply, but that will change. As
with many growing phenomena, more of the action takes place later in time than it would
seem to people who have been paying attention for a while. 
Globally things are mostly similar to last week, with Chile putting on a strong showing. 
Europe


It is clear that the United Kingdom has contained the English strain through its
countermeasures. The countermeasures in place elsewhere do not appear to be suﬃcient to
do that, but the existence proof of the option is deﬁnitive. Things are generally improving
everywhere, with Spain improving especially rapidly. As always, there are other countries
with things going on but I post the same list each week to remain consistent and avoid
cherry picking, with the USA on here as a comparison point. 
Covid Machine Learning Project
Eric Topel interview with Machine Learning Project sole creator Youyang Gu.
Waiting on the English Strain
Some good news this week (science link):
Max says this is obviously very bad news, but whether something is good or bad news
depends on your prior expectations. 
If you previously had your head in the sand and were trying to pretend that the English
Strain wasn't more infectious, this is indeed very bad news. 
If, however, you previously had accepted that the English strain was more infectious, and the
question was how much more infectious, then news of the answer could be good or bad. In
this case, it's good. 
This is an estimated 37% increase in infectiousness of the new strain versus the overall mix
of strains. My initial version got this calculation wrong and forgot that there's already a lot of
the new strain in Denmark, which pushes this into the 40s. Even that small diﬀerence is big,
although other oﬃcial estimates are still over 50%. Compared to 50%, even 45% is
eﬀectively much better. The diﬀerence is enough to give us somewhat of a puncher's chance
of things not being so bad, both buying us time and reducing how bad it is when the time
comes. 

This is roughly consistent with Kai's framing of the data today, as well, depending on beliefs
about the serial interval. 
This is a common pattern. For a while in March of 2020, the stock market was reliably
moving in the wrong direction on news. They'd see that things were shutting down and
update that things were worse than they thought, whereas from my perspective things
shutting down meant things were better than I thought, because I already knew that they
should shut down and now they were at least both aware of the situation and thus actually
shutting down. Which was good news.
So on that note, is this data point good news or bad news?
Vaccine Eﬃcacy
This is an attempted Bayesian analysis of various vaccines and their likely eﬃcacy against
various severities of disease and against various strains. I say attempted because it seems
like these take relatively generic prior distributions, and don't adjust them much based on
our understanding from other data points, including data from other vaccines. The result is
that these distributions are likely underconﬁdent, and in some cases biased, but it's still a
worthwhile  exercise.
Waiting on Johnson & Johnson
The good news is that Johnson & Johnson has applied for emergency use authorization, and
they are going to get it. There's going to be a sprint to review the data in which every second
will be used! Which started right after the oﬃcial application, because you can't review data
that hasn't been submitted in a completed application, that's physically impossible, what are
you even talking about. 
The bad news is that it's going to take three weeks to get to the meeting, likely with
additional time after the meeting before we can distribute the vaccine, but hey:

Last week I went over how we know the Johnson & Johnson vaccine is safe and eﬀective, and
there are millions of doses waiting to be distributed, and there's no good reason we can't
start that process yesterday. 
I do realize that there is a diﬀerence between, as Scott Alexander discusses, the FDA's need
to be legible and reliable, and follow proper procedures, versus my ability to apply Bayesian
reasoning. 
That doesn't mean this needs to happen three weeks after application, and attempts to
justify that timeline are obvious nonsense. 
Mostly, it's a call and response. You say 'why are we letting people die for no reason?' and
they say 'Thalidomide!' and 'people won't trust it.'
So basically, one time someone had a drug that wasn't safe. We didn't approve that drug
because our existing review process made it look unsafe, so in response to that we created a
more involved and more onerous process, as opposed to noticing that the previous process
actually worked in this case exactly as designed. Then we use this as a fully general excuse
to freak everyone out about everything that hasn't gone through this process, and then use
that freak out (that, to the extent it exists which it mostly doesn't, is directly the result of
such warnings) as our reason to force everything through the process. Neat trick. 
Oh, and did I mention that the 'safety data' that requires three weeks to review is, and I
quote it in its entirety, 'nothing serious happened to anyone at all, and no one was struck by
lightning.' Either J&J has created a safe vaccine, or J&J  is committing a fraud that will be
caught and get everyone involved arrested within three weeks, or they're committing a fraud
so eﬀectively that the review won't catch the fraud and won't help. Those are the only
possibilities. If the data isn't fraudulent then the drug is safe, period.

It's one thing to have Asymmetric Justice. I get that the FDA has to act as if damage from
permission is orders of magnitude more important than damage from lack of permission,
despite how awful that is for people's lives, but how many orders of magnitude are we
talking, and once you pick a number can you then show your work?
Do we already know the vaccine is going to be approved? Well, not quite, but...
Hang on, question incoming! Well, I'll be damned, that's not a 99 at all...
The question is actually kind of weird and terrible - if they move the meeting or issue the
EUA before the meeting it resolves to ambiguous and is cancelled, so the question it's asking
is 'conditional on having the meeting without approval do they then issue the EUA within 7
days' and that's not the thing we actually want to know. We want to know if the EUA will
eventually be issued one way or another, whereas this question is actually mostly measuring
whether they drag their feet so long it takes more than a week while they hash out the exact
minimum age and procedural guidelines, or something.
Also, I broke down and joined Metaculus for this question because 90% seemed crazy low,
and this is not how odds work this is not how odds work at all:
But then I checked another question, and hey, you know what gets one even more internet
points than good odds? 

Everything's made up and the points don't matter. No, I didn't lock in that second prediction,
and I believe I'm probably done with metaculus. I can't even. Change my mind.
On the actual J&J vaccine, I don't know what more there is to say. As with Moderna and
Pﬁzer, they've already done the actual approval process and conﬁrmed that it's going to get
approved before they applied, and now we're delaying in order to make it clear we are Very
Serious People who Follow Proper Procedure and are not In Bed With Industry and Putting
People At Risk or Destroying Trust in Vaccines by going 'too fast.' Or something like that. 
We have now done this three times. It's one thing to have the ﬁrst vaccine application point
out that there's weeks of lost time. It's another thing to not have ﬁxed the problem months
later.
Waiting on Novavax
From the USA article on Johnson & Johnson, we learn exactly what is holding up Novavax,
and the problem is a straightforward case of Not Clinically Trialed Here:
Waiting on AstraZeneca
If Novavax needs an American trial, I guess we have our answer on AstraZeneca. 
This cuts to the heart of how unserious, perverse and malicious non-approval is at this point:

Not counting implicit arguments from full-on anti-vax people, I have yet to see one single
person argue that we should undo the approval of AstraZeneca in the UK or EU. 
Nor did I see a single call for stopping the use of the AstraZeneca vaccine in South Africa.
That's presumably because this would be a really stupid move. There was a small and
therefore underpowered study of the AZ vaccine against the South African strain, which is
easy to misinterpret since it couldn't conclude anything deﬁnitively due to lacking suﬃcient
power. The AZ vaccine still clearly provides some protection against infection by the South
African strain, and likely greater protection against severe disease, and it's safe, so what's
the downside to continuing to give it out? 
Certainly if the choice is between 'some reduction in deaths, hospitalizations and severe
disease' and 'no thanks, we prefer the full quantity of deaths, hospitalizations and severe
disease' this choice should be clear enough. 
You would, of course, be wrong about that. South Africa did stop the use of the AZ vaccine
(WaPo), and again, I have not heard any experts point out how suicidal that decision is,
although shifting future vaccine purchases to other vaccines did make sense. 
This follows the pattern that 'expert opinion' on what to do is primarily defending following
elite decision making. I've been underestimating this eﬀect, but the pattern is increasingly
clear. If the properly respectful elites with the power (e.g. basically anyone powerful except
the Orange Man) decide not to do X yet, the 'experts' will talk about how we must follow
proper procedures before doing X or else risk catastrophe, or how X is damaging or unethical

or something. Once the properly respectful elites decide to do X, whether or not they
followed the procedures the 'experts' were defending earlier, the 'experts' might brieﬂy
decry the skipped procedure, but they will immediately pivot to defending X. There's
presumably some value of X suﬃciently awful that the 'experts' wouldn't do this, but we've
yet to prove that by example. 
So we have the same vaccine sitting in storage unused in Baltimore, while failure to secure
and deliver enough of that same vaccine for current use is a continent-wide scandal in
Europe.
And in case it wasn't suﬃciently clear last time, the reason AstraZeneca didn't apply is that
they've been told not to and that they'd be turned down. That's how the process works,
you're in constant communication and only apply when you have what is necessary.
Or in more detail:

Or, with the attitude the situation deserves:

Waiting on Demand Shortfall
First we had a shortage of eligible arms into which to put shots, resulting in lots of needless
delay. We were so obsessed with prioritization and what was fair that we threw doses away
while letting others sit on shelves.
Then we got to the current phase of the vaccine rollout, where there is an abundance of arms
and not enough shots to put in those arms. Now we are thankfully using all our doses, but
with a train wreck of a prioritization scheme that places lots of people at minimal risk (e.g.
anyone with a BMI of 30 in many places) in competition against seniors for shots, while
destroying the legitimacy of the prioritization system. It's worse than nothing, but far better

than too much, and the focus rightfully has shifted to ﬁnding more doses faster, increasing
production, cutting vaccine doses where we can and approving new vaccines quickly.
The question is how much and when to worry about the transition to the third phase, when
we have enough vaccine and the limiting factor becomes people's willingness to get
vaccinated.
Possible is not the strongest word, but the other part of this statement is claiming relatively
high conﬁdence. The key question is whether the 250M doses target is real and how much of
that is one-shot J&J doses. If we hit that mark, then our chances to get everyone in the 'eager
to get it' group done by April look reasonably good.
Peter Hotez, in the linked thread, has been hearing the other half of the news reports, and
also echoes the same range I have for how long we have before the new strains take over:
We can and should do our best to move the needle but the most important practical question
in so many of our lives is which of these two reports is right. Will we have suﬃcient doses for
'the eager' in April, or will it be waiting until at least June?
Shall we check in with the Good Judgement Project?

There continues to be very high conﬁdence that the necessary doses will be distributed by
the end of May. As usual, they are overconﬁdent and C is nothing like 90%, but the level of
conﬁdence still speaks volumes - Scott Gottlieb is making an explicit prediction of outcome
B, and Peter Hotez is soft expecting option D. 
Doing quick math, if Scott's other half of the equation is right and there's only 'deep'
demand for 50-75 million vaccinations, then compare that to our current pace of 1.5mm+
doses per day, or 750k people vaccinated per day with 44 million shots already
administered. Getting to 150 million shots from here would only be two months (mid-April)
even if we didn't accelerate from here. So it seems like the end of inﬁnite demand, and the
shift to a potential demand shortfall, is likely rather near. 
You know what isn't helping with that?


I could not be more contemptuous and sick of the 'nothing changes when you get
vaccinated' position. Or even this nonsensical 'we don't know' position. I took a graduate
level course in epistemology where it was called into question what it means to know that
some proposition P is true, and whether we can actually know anything at all, and that's all
quite interesting as philosophy, but for practical purposes yes we damn well know this stuﬀ. 
How bad is it? It's pretty bad:

My guess continues to be that this hesitation will fade with time. Wait for the people who
actively want the vaccine to get it, and then everyone who can't do their job without a
vaccine to get the vaccine, and then we'll have many months of tens of millions of people as
clear evidence that the vaccines work, and a lot more people will follow. Thus, I'd be inclined
to mostly wait on the public service campaigns until then, when people will be able to act if
convinced and we'll have an easier time convincing them.
I also notice that there is a large part of me that thinks, once it's easily and widely available,
you know what? Straight up, just f*** 'em if they don't want the vaccine. 
Suppose it is June 15, and there are open same-day appointments outside of work hours at
half the pharmacies in America. The good stuﬀ, too. Anyone who wants a free shot of
Moderna or Pﬁzer can get a free shot, no questions asked. 
Remember, we seem to have vaccines that are almost 100% eﬀective against death and
severe disease, and everyone's had the chance to get vaccinated, and can change their
mind at any time. 
Why not simply go back to normal? If the other half of America doesn't want the vaccine, all
right, ﬁne. Some of them can keep hiding in their houses for another year if it suits them.
Others can walk around vulnerable and shake everyone's hand. This large part of me really,
really doesn't care. Still do the PSAs and all that, sure, but it's their lives on the line. Either
we'll still contain the pandemic anyway, or the ones who are out there unvaccinated taking
big risks will infect each other, and that will burn itself out, and then either way we can all
move on with our lives. 
I don't endorse that position on reﬂection or anything, but it seems important to have the
courage to note that it is there. 
In particular, the whole 'we've told people that the vaccine won't stop them from getting
Covid or from passing Covid to others or let them resume their normal lives, so why the hell
should we expect them to take it?' counter-argument is getting stronger every time Zeynep
retweets another example, and her list is getting long. 
Vaccine Allocation By Politics And Power
New York joins the club letting those who technically have a 'comorbidity' of a BMI of 30 get
vaccine priority while seniors continue to be unable to book appointments. How the wheel
turns. Looks like the list at least excludes smokers. 

Americans are really fat. How fat are they? What say you, Wikipedia?
The National Center for Health Statistics estimates that, for 2015-2016 in the U.S., 39.8% of
adults aged 20 and over were obese (including 7.6% with severe obesity). Luckily in my ﬁrst
reading I'd mixed up which statistics are referring to BMI of 25 vs. 30 (they use the same
words in diﬀerent places to refer to both, but still totally my fault), and it's only that 39.8%
that are eligible in this fashion via the BMI threshold, if everyone is scrupulously honest and
doesn't game the system in any way.
Right away, the main mailing list I am on had one person note that he was four pounds short
of qualifying, and a plan was quickly formed (I believe and hope in jest but these days who
can know) to eat some carbs and put on a little water weight to get over the top. There
seems to be a lot of somewhat serious talk about putting on a few pounds to hit the cutoﬀ
point. 
Of course, a better strategy is to just lie, it's not like anyone is going to weigh you. This isn't
a boxing match.
I wonder how much long term damage this is going to do to people's health by demotivating
healthy lifestyle choices, the same way I worried earlier about the impact on smoking rates. I
don't think these impacts will be worse than the health eﬀects of the pandemic, but if you
think that kind of damage is impossible here, you have not done the math.
Meanwhile, in Georgia, health oﬃcials saw that a clinic was vaccinating teachers believing
them to be essential workers, who the state then decided were not yet eligible under local
rules because they are not 'essential workers,' and responded to this cartoon villainy by
raiding the medical center, conﬁscating the vaccine supply and promising not to deliver any
more doses for six months.
Meanwhile, in Boston, priorities are straight:
Meanwhile, in Harris County, a doctor gave out rapidly expiring doses, was ﬁred for it and is
now being prosecuted. Can't link to the story because NYT but it's easy to ﬁnd if you want
details.

While others get the vaccine because they run a microbrewery, which is classiﬁed as 
'essential manufacturing'.
You can't undo eligibility that's been granted. I mean, sure, you can, but it's pretty terrible.
What's done is done. We'd be better oﬀ without eligibility rules at all, and relying on people
to use their judgement and their willingness to invest time in the process as allocation
methods (despite the ability to do this being anti-correlated with actual need to get the
vaccine, both in terms of exposure and vulnerability), since we are unwilling to use price. 
For example, if you want to test how much people want to get vaccinated, you might give
them eight diﬀerent ways to book an appointment in the same county, and see who is willing
to try all of them. 
When people do start trying to use your systems, what happens? 
Occasionally someone gets this part right, and we're actively surprised:

You Should Know This Already (Inessential
Reminders)
If protests do anything at all, there should be pro-vaccine protests. 
The WHO is suddenly enamored with the 'frozen food' hypothesis for the origin of Covid-19,
which would claim that the virus didn't even originate in China, and I will leave interpreting
what is happening there as a (very easy) exercise for the reader.
If you've already had Covid-19, the second dose is likely not helpful to you. The ﬁrst dose will
have been enough. The second dose also knocks a lot of people on their ass for a day, so if it
isn't helpful one would actively want to avoid it for one's own sake, plus it gives that dose to
someone else who still needs it.
Immunity from old strains, study says, does still help against new strains.
Pﬁzer vaccine continues to post great results, in this case low viral loads.
There was a comment about Scott's article and my response to it that said that vaccines like
Johnson & Johnson's are always one dose, so my saying that it was good they didn't test a
second dose was evidence that I was incompetent and shouldn't get anywhere near the
CDC. That example looks rather interesting now a few days later, as they begin a two-dose
trial of the Johnson & Johnson vaccine in the United Kingdom. 
Exactly how good? In the way that counts the most for you, about 100% eﬀective:

And on transmission:

The best way to improve productivity and eﬃciency is to do the thing, in this case Pﬁzer
using their experience to double production. Which they could have done last year. It occurs
to me that if we had oﬀered to pay $100 per dose for mRNA vaccines all of last year and
then tossed them into the trash after testing their composition rather than even bother
storing them we'd be done with this pandemic by now.
An article writing up people's eﬀorts to create tools to help with booking vaccine
appointments.
The UK vaccine rollout is considered a success, and by the standards of other results, it is
indeed a success. This interview explains how they did it, which was essentially 'make deals
with companies and pay them money in exchange for doses of vaccines.' They still did much
less than a suﬃcient amount of that across the board, and it doesn't seem like anyone
involved grokked anything like the full speed premium or the need to overspend, but they at
least threw some eﬀort in the right directions. 
How do we know politics has returned to normal? "News stories" like this one on Fox News,
complaining that Biden was travelling by plane despite CDC warnings not to travel. That's

how you keep life, liberty and property relatively safe while the legislature is in session. 
As much as I go after the FDA, at least they did approve the most eﬀective vaccines,
whereas in India Pﬁizer has now withdrawn its application because of the need for 'additional
information.'
The army has now completed the process to issue the Combat Cloth Face Mask. The process
worked as designed and only took one year, at the low cost of $45 per cloth mask. The army
is congratulating itself on the "expedited timeline." 
Cases are declining across the world, here's an analysis of why that comes down to
behavioral changes combined with ~30% of people being immune due to prior infection and
that allowing us to turn the corner. He points out that temperatures of various places don't
much correlate with current trends. Of course, as the new strains take over, this progress will
by default be lost and reversed, and current levels overall remain quite bad.
If you don't believe that the bulk of infections come from people who are choosing to take a
lot of risk, that needs to be squared with people constantly taking lots of risk and announcing
they're taking lots of risk, like this 62 year old proudly shaking hands with whoever is willing.
Department of it can always get worse: Any month no one is vaccinated sure sounds like an
inauspicious month to me:

Still combined with remarkable amount of can-do spirit (article):

Ministry of Truth
There used to be a robust consensus that the right to free speech, both in law and in
practice, from threats both public and private, was one of our core values. I would argue it
was the core value. There is now an increasing consensus against the right to free speech.
This has progressed from the rapidly expanding umbrella of 'hate' speech (regardless of its
truth value), to speech in support of the political outgroup or against ingroup causes that the
Powers That Be have decided to proclaim as false or dangerous. 
Increasingly it also applies to health claims that are in conﬂict with Oﬃcially Recognized
Sources of truth. Like the WHO, FDA and CDC. 
Professional retaliation for speech in some cases has extended to merely having joined
(likely to reserve a preferred username) social networks that have arisen as alternatives to
this censorship, even the person in question ever having posted anything at all on such
networks. Why would you have access to a way to say something, if you didn't have
something to say?
We face increasing levels of Kolmogorov Complexity, and are told to say that thunder
proceeds lightning. More and more true facts are only stated privately in whispers, or
implicitly and esoterically within other statements.  
I write these posts on WordPress and they are reposted on LessWrong, which has strong
norms around front page posts, but a very strong commitment to not censor personal blog
posts, and which provides a robust backup in case someone tries to get my content taken
down. Ideally I'd fully self-host as well but I haven't put in the work. We live in times when
even outlining my model of the physical world of a pandemic makes it feel necessary to see
the entirety of my technology stack and where pressure might be brought to bear. A few
years ago such considerations wouldn't have occured to me at all.  
It has been my belief for a while that if I was posting my full content on Twitter, Facebook or
YouTube, that it is likely my content would have been taken down and censored.
It is not a helpful policy to take down information for not lining up with the oﬃcial
government position. That is not how one inspires conﬁdence and trust, or identiﬁes error

and discovers truth. There's also the small matter that the oﬃcial positions frequently
reverse themselves. 
Now it seems Facebook is expanding this policy...
The public approves and wonders why shutting down bad speech took so long:

Here is Zeynep explicitly violating Facebook's oﬃcial policy by stating true facts:
If a regular person says vaccines don't provide immunity, they'll be censored. If a newspaper
writes that we don't know that vaccines provide true immunity and therefore everyone
needs to keep social distancing and mask wearing forever even when everyone involved is
fully vaccinated, that's the mark of a Very Serious Person, and also the recommendation of
the CDC.

Shall we follow Zeynep's example, and violate this policy a bit more by making more true
statements about the physical world? Let's take a closer look at the policy and see what else
we can ﬁnd.
There were a lot of opportunities to violate this policy with true statements, so I'll limit
myself to two (a previous version had a third which I had misread).
The group of young children can potentially be infectious to others, but are eﬀectively
immune and cannot die from COVID-19.
The speciﬁc treatment of getting vaccinated or having previously been infected then
recovering results in immunity.
These aren't trivial gotchas. Both of these cases seem somewhat important.

The original source of Covid-19 infection was not human-to-human transmission. It is
generally believed to have been caused by consumption of an infected bat from a Chinese
wet market in Wuhan, but there are alternate theories as well, including the WHO's would-
hilarious-if-it-wasn't-real new 'frozen food' hypothesis, and also those who claim it escaped
from a lab (which is another claim explicitly prohibited by Facebook). I've chosen to consider
such questions of origin out of scope for these posts, but we know for sure it wasn't human-
to-human transmission. 
On the ﬂip side, love this exchange:
And also I wonder if they'll be enforcing this one against a lot of journalists and "experts":
I'm glad to hear that it's now oﬃcial that the vaccines are eﬀective in preventing Covid-19,
and I'm confused why Very Serious People keep telling everyone otherwise while also
wondering how to get more people to want to take the vaccines. Life is so weird.

It seems that all this is being directed by the WHO:
It is well-known that I am Against Facebook but these concerns have nothing to do with my
existing core objections to Facebook, other than taking 'Facebook decides what I see and
don't see, is manipulating me for its own proﬁt and I can't count on seeing anything or
having anything I say be seen' to an entirely new level.  
Since I am only on Facebook purely to exchange contact information for communication
elsewhere, plus the occasional messenger conversation that can't be avoided, I don't have a
read on the eﬀective level of enforcement of these rules, or whether such enforcement is
being done in a reasonable fashion. I do know that I continuously see reports of suspended
or even terminated Facebook and Twitter accounts with no explanation or one that makes
little sense, and no practical ability to appeal the decisions. 
I do think that being kicked oﬀ Facebook will often be a blessing in disguise, but that doesn't
make it right. If you value your Facebook account, please reconsider that position, but
meanwhile guard and bite your keyboard's tongue. 
I am thankful that I am in a position where I need not worry about retaliation, for the same
reasons I am in a position to devote time to writing this. Most others are not so fortunate.
To anyone who says 'this isn't the government doing it so it doesn't violate free speech' or
'there are plenty of other places to go all you have to do to have a platform is Create a Full
Alternative Stack (including your alternative to AWS, if not yet an ISP), think about the
practical implications of that. Does anything even need to be said?  
In Other News 
Video (3 minutes) on how to properly fold a surgical mask.
In case it wasn't clear yet, Zeynep Tufekci is doing great Covid-19 work, and I'm ﬁnally
following directly after far too long via the Twitter feed here. There's also a substack here.
Zeynep reports that the University of Berkeley has banned outdoor exercise. How do they
think that is going to go? Do you think students are going to obey your restrictions in ways
that make them take less risk? Do you think they're going to cooperate with your contact
tracing? 
Israeli hospital claims it might have a cure for Covid-19, dubbed EXO-CD24. They're saying it
helped 29 out of 30 patients in serious condition. I have no idea how promising things are at
this point, but ﬁgured I'd pass it along. They are coming out of Phase I and applying to begin
Phase II. 
A key part of the story of 2020 has been that life under social distancing is diminished life,
people's lives and livelihoods are hanging by a thread, and things are generally quite bad.
The most concrete illustration of this was supposed to be a higher suicide rate, which

seemed like it had to be true. Except, there's a claim that suicide wasn't up last year, despite
being up generally in recent years?
This shows a clear steady increase over the last two decades that is pretty alarming and
didn't get the attention it deserved, but a decline last year of 9.5%. 
Story checks out:

Paper and thread on seroprevalence in India.
Biden has not yet appointed an FDA commissioner. The key qualiﬁcation should be whoever
promises to get the vaccines approved quickly, the tests approved quickly, and also things
like ﬁlling in the vials of vaccine approved quickly. Once again, I suggest Solomon
Mowshowitz, or failing that, Scott Gotlieb is always available. 
CDC recommendations for how to do things relatively safely, with a remarkable lack of
ordering everyone to do nothing forever. I was amused by the following example of
accidental honesty, the classic reverse-no-evidence:

I mean, none of this is wrong or anything, on the margin this is good advice where available.
Now can we have a talk about what it means when there's 'no evidence' of something, and
why one might want to act as if that thing was probably true anyway?
Not Covid but exciting result of new potential weight loss treatment. As usual, I make no
claim that this is a legitimate result or that we should expect it to hold up, but this is the sort
of problem that could plausibly have a mechanical solution that simply works - weight loss is
up there in hardness with steel, diamonds and knowing thyself, but there's no reason that
has to be true. I've got the weight loss quest handled, but if there was a solution that also let
me eat three meals a day, or even reliably eat two, that would be awesome.
The early signs point to this being legit and super exciting, as Sarah Constantin is one of the
people I trust most on such matters:


I'd want to do a bunch more consideration before getting such a treatment, but Humanity,
Fuck Yeah! 

The Story of the Reichstag
When the Red Army was conquering Berlin, capture of Reichstag was seen as an
important symbolic act. For Russians, the Reichstag was a symbol of the Nazi Germany.
Nazis, however, never used the building, seeing it as a symbol of the despised
democracy.
When the building was ﬁnally captured Soviet soldiers ﬂew a ﬂag from the roof of the
building. The iconic photograph of the moment is not entirely truthful though. Rising
smoke in the background has been added a few days later. The editor has also noticed
that the soldier securing the soldier who was holding the ﬂag had watches on both
wrists. He corrected the error using a needle.
Soviet soldiers, as they were progressing westward through the Eastern Europe, were
notorious for looting watches. Some of them were wearing multiple on each wrist.
As the old joke goes: What did marshal Konev say when they were dragging the Prague
astronomical clock away? "Часы тяжелые." ("The times are hard." or, alternatively,
"The clock is heavy.")

When a footage from Yalta conference was shown in cinemas in Eastern Europe, the
sequence where Roosevelt shook Stalin's hand invariably elicited cries of "Mind your
watch!"
To veer oﬀ in completely random direction: When George W. Bush visited Albania, the
footage of him shaking hands with the crowd shows a watch on his wrist at one
moment but no watch few seconds later. Immediately, conspiracy theories sprang up.
They were, however, quickly debunked by the White House spokesperson: "The
President has not been robbed. He took his watch oﬀ."
Anyway, back to the Reichstag.
Red Army Soldiers covered the building with graﬃti.


These were simple inscriptions saying "Kiew - Berlin. Krasotkin." "From Moscow to
Berlin. Major Yakovlev." "Sergey was here." and similar.
When the building of Reichstag was being repaired after the war it turned out that
cleaning the walls would be too expensive. Those were poor times. The builders
therefore decided to build clean hallways just by raising a thin smooth walls covering
the original walls.
After the uniﬁcation of Germany, when the Reichstag was being repurposed to become
the seat of the parliament once again the builders drilled a hole into the outer wall and
discovered that the old Russian inscriptions were still there, untouched.

It was decided to remove the wall and leave the graﬃti at diﬀerent locations in place,
on public display.
I think the fact reveals something about the German political culture. I am having a
hard time imagining that, say, Americans would keep such a witness of their defeat in
the Capitol. That is, if the soldiers from Pearl Harbor were somehow able to get to
Washington and leave Japanese inscriptions behind.
What I, personally, like about it is its ambiguity.
The inscriptions can be interpreted in a crude way. As a message to German
parlamentarians: Mess it up and you'll see the Cossacks in the Reichstag again.
But there's also a much more subtle, even intimate, interpretation. Note how there's no
Stalin's declaration of victory in the building. But there are graﬃti from all those
Andreys and Georgiys, common boys dragged out of their villages, sent ﬁghting, killing,
being killed, seeing their freinds dying, looting and raping along the way until they
arrived in Berlin. Those inscriptions are a reminder that Germany is not an island for
herself. That those people, whether she wills or not, are part of her fate as much as
they are part of the fate of Russia.
February 5th, 2012

The feeling of breaking an Overton
window
Epistemic status: real but incomplete observations.
In late February of 2020, I went to the grocery store at 2am with my husband
(emptiest time), and we bought ~$1k of mostly canned or dry goods. We were the
only customers in line. The cashier seemed interested in our purchases, and I felt
myself stiﬀening as she looked. Then she asked me: "are you worried about that
virus?"
And... I found myself reaching for a lie, trying to compose a lie, moving my speech-
planning-bits as though the thing to do was to lie. I mean, not a technical lie. But I
found myself looking for a way to camouﬂage or downplay my model of the virus.
Oddly, it felt more like a thing happening in me ("I found myself") than like a chosen
thing. If you'll pardon the analogy, it somehow felt at least a bit like throwing up, in
that I remember once when I was trying not to throw up, and all of a sudden it was like
an alien process took over my consciousness and throat, reached for the bucket, got
my hair out of the way, and did the actual throwing up. And then returned my body to
me when it was over. The "alien process" sensation felt a bit similar.
With the cashier, I wondered at my impulse as it was happening, but I couldn't tell if
the impulse's source was "for the cashier's sake" (didn't seem to make sense); "to
prevent her from harming me" (didn't seem to make sense); or ... what exactly?
I forced myself to say "yes" to the cashier's question, and to elaborate a bit; to my
surprise, she seemed sincerely curious, and told me several people had been in doing
this and she would probably also prepare in some way. Even after this, my sentences
wanted to (sound soothing? ﬁt in? avoid disrupting others' "normal"? I'm still not sure
what), and it took me active eﬀort to partially not do this.
—
I am somehow quite interested in what precisely was happening there, and in any
related processes.
My guesses as to how to help with this puzzle-set, if you're so inclined:
Share observations (not theories) of any related-seeming things you've noticed
(the rawer the better);
Share observations (not theories) of what it's like to be you right now trying to
look at this stuﬀ. Do you have introspective access? Do you have sort of have
introspective access, and in what way? Do you kind-of-like identify with it? Kind-
of-like not-identify with it?
And okay, yes, also theories, I just hope the theory doesn't overwhelm the
observations at this confused stage.

Fixing The Good Regulator Theorem
Crossposted from the AI Alignment Forum. May contain more technical jargon than usual.
Conant & Ashby's "Every Good Regulator Of A System Must Be A Model Of That System" opens with:
The design of a complex regulator often includes the making of a model of the system to be regulated. The
making of such a model has hitherto been regarded as optional, as merely one of many possible ways.
In this paper a theorem is presented which shows, under very broad conditions, that any regulator that is
maximally both successful and simple must be isomorphic with the system being regulated. (The exact
assumptions are given.) Making a model is thus necessary.
This may be the most misleading title and summary I have ever seen on a math paper. If by "making a model"
one means the sort of thing people usually do when model-making - i.e. reconstruct a system's
variables/parameters/structure from some information about them - then Conant & Ashby's claim is simply
false.
What they actually prove is that every regulator which is optimal and contains no unnecessary noise is
equivalent to a regulator which ﬁrst reconstructs the variable-values of the system it's controlling, then chooses
its output as a function of those values (ignoring the original inputs). This does not mean that every such
regulator actually reconstructs the variable-values internally. And Ashby & Conant's proof has several
shortcomings even for this more modest claim.
This post presents a modiﬁcation of the Good Regulator Theorem, and provides a reasonably-general condition
under which any optimal minimal regulator must actually construct a model of the controlled system internally.
The key idea is conceptually similar to some of the pieces from Risks From Learned Optimization. Basically: an
information bottleneck can force the use of a model, in much the same way that an information bottleneck can
force the use of a mesa-optimizer. Along the way, we'll also review the original Good Regulator Theorem and a
few minor variants which ﬁx some other problems with the original theorem.
The Original Good Regulator Theorem
We're interested mainly in this causal diagram:
The main goal is to choose the regulator policy P[R|X] to minimize the entropy of outcome Z. Later sections will
show that this is (roughly) equivalent to expected utility maximization.
After explaining this problem, Conant & Ashby replace it with a diﬀerent problem, which is not equivalent, and
they do not bother to point out that it is not equivalent. They just present roughly the diagram above, and then
their actual math implicitly uses this diagram instead:

Rather than choosing a regulator policy P[R|X], they instead choose a policy P[R|S]. In other words: they
implicitly assume that the regulator has perfect information about the system state (and their proof does require
this). Later, we'll talk about how the original theorem generalizes to situations where the regulator does not
have perfect information. But for now, I'll just outline the argument from the paper.
We'll use two assumptions:
The entropy-minimizing distribution of Z is unique (i.e. if two diﬀerent policies P[R|S] both achieve
minimum entropy, they both produce the same Z-distribution). This assumption avoids a bunch of extra
legwork which doesn't really add any substance to the theorem.
Z is a deterministic function of (R, S). Note that we can always make this hold by including any
nondeterministic inputs to Z in S itself (though that trick only works if we allow R to have imperfect
information about S, which violates Conant & Ashby's setup... more on that later).
The main lemma then says: for any optimal regulator P[R|S], Z is a deterministic function of S.
Equivalently: all R-values r with nonzero probability (for a given S-value s) must give the same Z(r, s).
Intuitive argument: if the regulator could pick two diﬀerent Z-values (given S), then it can achieve strictly lower
entropy by always picking whichever one has higher probability P[Z] (unconditional on S). Even if the two have
the same P[Z], always picking one or the other gives strictly lower entropy (since the one we pick will end up
with higher P[Z] once we pick it more often).  If the regulator is optimal, then achieving strictly lower entropy is
impossible, hence it must always pick the same Z-value given the same S-value. For that argument unpacked
into a formal proof, see the paper.
With the lemma nailed down, the last step in Conant & Ashby's argument is that any remaining nondeterminism
in P[R|S] is "unnecessary complexity". All R-values chosen with nonzero probability for a given S-value must
yield the same Z anyway, so there's no reason to have more than one of them. We might as well make R a
deterministic function of S.

Thus: every "simplest" optimal regulator (in the sense that it contains no unnecessary noise) is a "model"
of the system (in the sense that the regulator output R is a deterministic function of the system state S).
The Problems
There are two immediate problems with this theorem:
The notion of "model" is rather silly - e.g. the system could be quite complex, but the regulator could be
an identity function, and it would count as a "model"
The regulator is assumed to have perfect knowledge of the system state (i.e. second diagram rather than
ﬁrst)
Also, though I don't consider it a "problem" so much as a choice which I think most people here will ﬁnd more
familiar:
The theorem uses entropy-minimization as its notion of optimality, rather than expected-utility-
maximization
We'll address all of these in the next few sections. Making the notion of "model" less silly will take place in two
steps - the ﬁrst step to make it a little less silly while keeping around most of the original's meaning, the second
step to make it a lot less silly while changing the meaning signiﬁcantly.
Making The Notion Of "Model" A Little Less Silly
The notion of "model" basically says "R is a model of S iﬀ R is a deterministic function of S" - the idea being that
the regulator needs to reconstruct the value of S from its inputs in order to choose its outputs. But the proof-as-
written-in-the-paper assumes that R takes S as an input directly (i.e. the regulator chooses P[R|S]), so really the
regulator doesn't need to "model" S in any nontrivial sense in order for R to be a deterministic function of S. For
instance, the regulator could just be the identity function: it takes in S and returns S. This does not sound like a
"model".
Fortunately, we can make the notion of "model" nontrivial quite easily:
Assume that S is a deterministic function of X
Assume that the regulator takes X as input, rather than S itself
The whole proof actually works just ﬁne with these two assumptions, and I think this is what Conant & Ashby
originally intended. The end result is that the regulator output R must be a deterministic function of S,
even if the regulator only takes X as input, not S itself (assuming S is a deterministic function of X, i.e.
the regulator has enough information to perfectly reconstruct S).
Note that this still does not mean that every optimal, not-unnecessarily-nondeterministic regulator actually
reconstructs S internally. It only shows that any optimal, not-unnecessarily-nondeterministic regulator is
equivalent to one which reconstructs S and then chooses its output as a deterministic function of S (ignoring X).
Minimum Entropy -> Maximum Expected Utility And
Imperfect Knowledge
I think the theorem is simpler and more intuitive in a maximum expected utility framework, besides being more
familiar.
We choose a policy function (x, r ↦P[R = r|X = x]) to maximize expected utility. Since there's no decision-
theoretic funny business in this particular setup, we can maximize for each X-value independently:

m a x ( x , r ↦ P [ R = r | X = x ] ) ∑ X , R , S , Z u ( Z ) P [ Z | R , S ] P [ R | X ] P [ S | X ] P [ X ]
= ∑ X P [ X ] ( m a x ( r ↦ P [ R = r | X ] ) ∑ R , S , Z u ( Z ) P [ Z | R , S ] P [ R | X ] P [ S | X ] )
Key thing to note: when two X-values yield the same distribution function (s ↦P[S = s|X]), the maximization
problem
m a x ( r ↦ P [ R = r | X ] ) ∑ R , S , Z u ( Z ) P [ Z | R , S ] P [ R | X ] P [ S | X ]
... is exactly the same for those two X-values. So, we might as well choose the same optimal distribution 
(r ↦P[R = r|X]), even if there are multiple optimal options. Using diﬀerent optima for diﬀerent X, even when the
maximization problems are the same, would be "unnecessary complexity" in exactly the same sense as Conant
& Ashby's theorem.
So: every "simplest" (in the sense that it does not have any unnecessary variation in decision distribution)
optimal (in the sense that it maximizes expected utility) regulator is a deterministic function of the
posterior distribution of the system state (s ↦P[S = s|X]). In other words, there is some equivalent
regulator which ﬁrst calculates the Bayesian posterior of S given X, then throws away X and computes its output
just from that distribution.
This solves the "imperfect knowledge" issue for free. When input data X is not suﬃcient to perfectly estimate
the system state S, our regulator output is a function of the posterior distribution of S, rather than S itself.
When system state can be perfectly estimated from inputs, the distribution (s ↦P[S = s|X]) is itself a
deterministic function of S, therefore the regulator output will also be a deterministic function of S.
Important note: I am not sure whether this result holds for minimum entropy. It is a qualitatively diﬀerent
problem, and in some ways more interesting - it's more like an embedded agency problem, since decisions for
one input-value can inﬂuence the optimal choice given other X-values.
Making The Notion Of "Model" A Lot Less Silly
Finally, the main event. So far, we've said that regulators which are "optimal" and "simple" in various senses
are equivalent to regulators which "use a model" - i.e. they ﬁrst estimate the system state, then make a
decision based on that estimate, ignoring the original input. Now we'll see a condition under which "optimal"
and "simple" regulators are not just equivalent to regulators which use a model, but in fact must use a model
themselves.
Here's the new picture:

Our regulator now receives two "rounds" of data (X, then Y ) before choosing the output R. In between, it
chooses what information from X to keep around - the retained information is the "model" M. The interesting
problem is to prove that, under certain conditions, M will have properties which make the name "model"
actually make sense.
Conceptually, Y  "chooses which game" the regulator will play. In order to achieve optimal play across all
"possible games" Y  might choose, M has to keep around any information relevant to any possible game.
However, each game just takes S as input (not X directly), so at most M has to keep around all the information
relevant to S. So: with a suﬃciently rich "set of games" (r, z ↦P[Z = z|R = r, S, Y ]), we expect that M will have to
contain all information from X relevant to S.
On the ﬂip side, we want this to be an information bottleneck: we want M to contain as little information as
possible (in an information-theoretic sense), while still achieving optimality. Combining this with the previous
paragraph: we want M to contain as little information as possible, while still containing all information from X
 relevant to S. That's exactly the condition for the Minimal Map Theorem: M must be (isomorphic to) the
Bayesian distribution (s ↦P[S = s|X]).
That's what we're going to prove: if M is a minimum-information optimal summary of X, for a
suﬃciently rich "set of games", then M is isomorphic to the Bayesian posterior distribution on S
 given X, i.e. (s ↦P[S = s|X]). That's the sense in which M is  a "model".
As in the previous section, we can independently optimize for each X-value:
m a x ( x , y , r ↦ P [ R = r | X = x , Y  = y ] ) ∑ X , Y  , R , S , Z u ( Z ) P [ Z | R , S , Y  ] P [ R | X , Y  ] P [ S | X ] P [ X ] P [ Y  ]
= ∑ X P [ X ] ( m a x ( y , r ↦ P [ R = r | X , Y  = y ] ) ∑ Y  , R , S , Z u ( Z ) P [ Z | R , S , Y  ] P [ R | X , Y  ] P [ S | X ] P [ Y  ] )
Conceptually, our regulator sees the X-value, then chooses a strategy (y, r ↦P[R = r|X, Y = y]), i.e. it chooses
the distribution from which R will be drawn for each Y  value.
We'll start with a simplifying assumption: there is a unique optimal regulator P ∗[R|X, Y ]. (Note that we're
assuming the full black-box optimal function of the regulator is unique; there can still be internally-diﬀerent
optimal regulators with the same optimal black-box function, e.g. using diﬀerent maps M.) This assumption is
mainly to simplify the proof; the conclusion survives without it, but we would need to track sets of optimal
strategies everywhere rather than just "the optimal strategy", and the minimal-information assumption would
ultimately substitute for uniqueness of the optimal regulator.
If two X-values yield the same Bayesian posterior (s ↦P[S = s|X]), then they must yield the same optimal
strategy (y, r ↦P ∗[R = r|X, Y = y]). Proof: the optimization problems are the same, and the optimum is unique,
so the strategy is the same. (In the non-unique case, picking diﬀerent strategies would force M to contain
strictly more information - i.e. M(X) ≠M(X′) - so the minimal-information optimal regulator will pick identical
strategies whenever it can do so. Making this reasoning fully work with many optimal X-values takes a bit of
eﬀort and doesn't produce much useful insight, but it works.)
The next step is more interesting: given a suﬃciently rich set of games, not only is the strategy a function of the
posterior, the posterior is a function of the strategy. If two X-values yield the same strategy 

(y, r ↦P ∗[R = r|X, Y = y]), then they must yield the same Bayesian posterior (s ↦P[S = s|X]). What do we mean
by "suﬃciently rich set of games"? Well, given two diﬀerent distributions (s ↦P[S = s|X]) and (s ↦P[S = s|X′]),
there must be some particular Y -value yp for which the optimal strategy (r ↦P ∗[R = r|X, Y = yp]) is diﬀerent
from (r ↦P ∗[R = r|X′, Y = yp]). The key is that we only need one Y -value for which the optimal strategies diﬀer
between X and X′.
So: by "suﬃciently rich set of games", we mean that for every pair of X-values with diﬀerent Bayesian
posteriors (s ↦P[S = s|X]), there exists some Y -value for which the optimal strategy (r ↦P ∗[R = r|X, Y ]) diﬀers.
Conceptually: "suﬃciently rich set of games" means that for each pair of two diﬀerent possible
posteriors (s ↦P[S = s|X]), Y  can pick at least one "game" (i.e. optimization problem) for which the
optimal policy is diﬀerent under the two posteriors.
From there, the proof is easy. The posterior is a function of the strategy, the strategy is a function of M,
therefore the posterior is a function of M: two diﬀerent posteriors (s ↦P[S = s|X]) and (s ↦P[S = s|X′]) must
have two diﬀerent "models" M(X) and M(X′). On the other hand, we already know that the optimal strategy is a
function of (s ↦P[S = s|X]), so in in order for M to be information-minimal it must not distinguish between X-
values with the same posterior (s ↦P[S = s|X]). Thus: M(X) = M(X′) if-and-only-if 
(s ↦P[S = s|X]) = (s ↦P[S = s|X′]). The "model" M(X) is isomorphic to the Bayesian posterior 
(s ↦P[S = s|X]).
Takeaway
When should a regulator use a model internally? We have four key conditions:
The regulator needs to make optimal decisions (in an expected utility sense)
Information arrives in more than one timestep/chunk (X, then Y ), and needs to be kept around until
decision time
Keeping/passing information is costly: the amount of information stored/passed needs to be minimized
(while still achieving optimal control)
Later information can "choose many diﬀerent games" - speciﬁcally, whenever the posterior distribution of
system-state S given two possible X values is diﬀerent, there must be at least one Y  value under which
optimal play diﬀers for the two X values.
Conceptually, because we don't know what game we're going to play, we need to keep around all the
information potentially relevant to any possible game. The minimum information which can be kept, while still
keeping all the information potentially relevant to any possible game, is the Bayesian posterior on system state 
S. There's still a degree of freedom in how we encode the posterior on S (that's the "isomorphism" part), but the
"model" M deﬁnitely has to store exactly the posterior.

Oliver Sipple
The other day I read Wikipedia arguably too much, and consequently came to know
the story of Oliver Sipple. Here's my summary of the story according to these two
Wikipedia pages and this page:
In the September of 1975, Oliver ('Billy') Sipple was an ex-marine of thirty-three,
injured in Vietnam and living in San Francisco. He was in and out of the veteran's
hospital, six years into civilian life.
One afternoon, he stood in a crowd of thousands of people to see the visiting
President Gerald Ford leave a San Francisco hotel from across the street. Ford stopped
to wave. Suddenly, a shot sounded, and Oliver saw a woman nearby adjusting the aim
of her revolver. He lunged and grabbed her arm, sending the second bullet into the
hotel, injuring a man inside.
Oliver was thanked for saving the president, and celebrated as a hero by the media. A
heroic veteran.
Soon the media learned that he was in fact a heroic gay veteran.
Oliver had shared his sexual orientation with with the San Francisco gay community—
or at least he had worked at a gay bar, paraded for gay pride, demonstrated for gay
rights, helped in the (LGBT) Imperial Court System, and worked on the campaign to
elect openly gay board of supervisors candidate Harvey Milk. But he hadn't shared it
with his family in Detroit, who had more old-fashioned impressions about the morality
of homosexuality. He also hadn't shared it with the world at large, who after all, lived
at a time when evidence of a gay person being a public hero was considered
fascinating news.
How did the media learn about this? Perhaps there were many sources, or would have
been eventually. But the morning after the shooting, two prominent gay activists each
outed Oliver to the San Francisco Chronicle. One was Reverend Ray Broshears, leader
of the 'Lavender Panthers'. The other was Oliver's own friend, Harvey Milk.
!
Harvey is reported to have explained privately to a friend, "It's too good an
opportunity. For once we can show that gays do heroic things, not just all that caca
about molesting children and hanging out in bathrooms."
The next day, Herb Caen, the San Francisco Chronicle reporter who received these
messages, reported to the world that Oliver was gay. He added that Oliver was friends
with Harvey Milk, and speculated that President Ford hadn't invited him to the White
House because of his sexual orientation.
Somewhere in here, Oliver asked that the media not report on the topic of his sexual
orientation, lest his family or current employer learn of it. It's not clear to me whether
this was in time for them to deﬁnitively know that he didn't want them to when they
ﬁrst did it, since apparently Caen 'couldn't contact him'.
At any rate, the topic was reported on thoroughly. Gay activists called for his
recognition as a gay hero. He was deluged by reporters, and hid at a friend's house, at

which point they turned to interviewing Harvey Milk. Harvey opined that President
Ford's gratitude would indeed have ﬂowed more generously had Oliver been straight.
Oliver's mother was purportedly harassed by her neighbors, and declared her intent
never to speak to him again. He was estranged from his family. His father at some
point instructed his brother to forget that he had a brother.
Oliver sued the reporter Caen and numerous newspapers and publishers for the
invasion of his privacy. The suit was dismissed, but he fought on. In 1984 a state court
of appeals held that he had become news, and his sexual orientation was part of the
story.
Oliver didn't do well after becoming a hero. He drank heavily, was diagnosed with
schizophrenia, put on weight, and needed a pacemaker. Over a drink, he was heard to
say that he regretted grabbing the gun.
It is said that he eventually reconciled with his family, but it is also said that his father
didn't let him come to his mother's funeral, so granting both stories it may have been
a late or mild reconciliation.
One February day in 1989, Oliver's friend found him dead in his San Francisco
apartment, alongside a bottle of Jack Daniels and a running television. He was 47.
Years later, journalistic ethics professors found this an instructive class discussion
topic.

Unwitting cult leaders
An insight that I'd kind of already had, but which this interview with Michael Taft
(relevant section starts at about 32 minutes) helped crystallize:
We tend to think of a "cult leader" as someone who intentionally sets out to create a
cult. But most cult-like things probably don't form like that. A lot of people feel a
strong innate desire to be in a cult.
In the podcast, Taft suggests that it's rooted in an infant's need to attach to a
caregiver, and to treat them as a fully dependable authority to ﬁx all problems - a
desire which doesn't necessarily ever go fully away. Once someone becomes a
teacher of some sort, even if they had absolutely no desire to create a cult, they will
regardless attract people who want to be their cultists.
There are people who want to ﬁnd a fully dependable authority ﬁgure to look up to,
and are just looking for someone who feels like a good ﬁt for the role. (I should note
that I have deﬁnitely not been immune to feeling this yearning myself.) To avoid
having cultists, "not intending to create a cult" isn't enough; you have to actively ﬁght
against people's tendency to idealize you, by doing things that force them to confront
the fact that you are actually just a human.
I'm reminded of something I recall Eliezer Yudkowsky once saying: "if you tell your
doting followers not to form a cult, they will go around saying 'We Must Not Form A
Cult, Great Leader Mundo Said So'."
Once people do start pulling you towards a cult leader role, it's going to feel very
appealing. What it feels like from the inside is "all of these people like me and say that
I've done a lot of good for them, so clearly I must be doing things right, and since they
also listen to me, I can use my position to help them out even more".
It's not just that the cultists are getting "brainwashed" by their leader; it's also that
the leader is getting brainwashed by their cultists to take the role that they want the
leader to take. Cults are said to use "love bombing" to attract new recruits, but in at
least some cases, it probably also happens that the cult leader is getting love bombed
by their followers.
And the temptation to take on that role is powerful not only because it feels nice
personally, but also because it does allow you to use your power for good. One
deﬁnition for a hypnotic trance that I've heard is that it's a state in which a person's
critical faculty is bypassed, which allows the hypnotist to directly make changes in the
mind of the person being hypnotized. And you can do a lot of good that way, such as
by implanting suggestions that help people overcome their addictions or phobias. 
Being someone's cultist (in this sense) is kind of like them having you in a hypnotic
trance. It is possible for to use that power in a way that's beneﬁcial, because the
critical faculty that might normally reject or modulate the leader's suggestions gets
partially bypassed.
But that same power makes it extremely dangerous, since people are not going to
think critically about what you say, and may take your words far more literally than
you intended, when you didn't think of adding the obvious-to-you caveats about how
it shouldn't be interpreted.

I've been feeling this myself. I've written various things that people like. And I've been
having a deﬁnite sense of some of my social environment trying to tug me more
towards a role as a teacher and as an authority, getting the sense that some people
are idealizing me. (And again, yes, there have been several times when I've had the
cult follower energy myself, too - both towards online writers and in some of my
romantic relationships.)
I'm reminded here again of Valentine's essay on the "Intelligent Social Web" and of
how people tend to take the kinds of roles that their social environment recognizes
and rewards... and how people try to tug others into the kinds of roles that they can
recognize and know how to interact with, and the collective power of everyone doing
this causes the social web as a whole to try to pull people into recognizable roles -
including the role of "charismatic leader". 
Here we come back to Taft's suggestion that many people have an instinctive desire
to get someone into a role that they recognize as a "trustworthy caretaker" one,
because the "child" role is one that feels very easy to play - just surrender your
judgment to the other person and do everything the way (you think that) they want
you to.
And I'm also reminded of siderea's analysis of kingship in Watership Down, and of how
Hazel never thought of himself as a leader originally in the novel, until the characters
around him started treating him as one - and how that might not be as good of a deal
as our society makes "kingship" sound like:
If you demonstrate a concern for the wellbeing of the people in your people, they
will start seeing their wellbeing as your concern. Start taking responsibility for how
things go in a group, and people will start seeing you as responsible for how
things go in a group.
This, right here, is what causes many people to back away from Kingship. Which is
their right, of course. It's totally legitimate to look at that deal and say,
"Oh, hell no."
Our society tells us that being King is awesome and everyone - well,
everyone normal - wants to be one. "Every body wants to rule the world." No,
actually, they don't. My experience tells me that most people are very reluctant to
step into the job of King, and this consequence of the role is a primary reason
why.
I don't know, but it strikes me at least plausible that prospective leaders themselves
getting partially deluded about what it is that they are up for, is what enables them to
actually step into the role rather than just saying "oh hell no".

Mentorship, Management, and
Mysterious Old Wizards
This is a linkpost for
https://forum.eﬀectivealtruism.org/posts/JJuEKwRm3oDC3qce7/mentorship-
management-and-mysterious-old-wizards
Followup to Dealing with Network Constraints
Epistemic Status: I spent some time trying to check if Mysterious Old Wizards were
important, and reality did not clearly tell me one way or another. But, I still believe it
and frequently reference it and ﬁgured I should lay out the belief.
Three bottlenecks that the EA community faces - easily mistaken for each other, but
with important diﬀerences:
Mentorship - People who help you learn skills, design your career, and gain important
context about the EA landscape that help you ﬁgure out how to apply those skills.
Management - Within a given org or existing hierarchy, someone who ﬁgures out what
needs doing and who should do it. This can involve mentorship of employees who are
either new, or need to train in new skills.
Finally, what I call Mysterious Old Wizards - Those who help awaken people's ambition
and agency.
I mention all three concepts to avoid jargon confusion. Mysterious Old Wizards are
slightly fungible with mentors and management, but they are not the same thing. But
ﬁrst, let's go over the ﬁrst two.
Mentorship and Management Bottlenecks
Mentorship and Management are (hopefully) well understood. Right now, my guess is
that management is the biggest bottleneck for EA (with mentorship a close second).
But this doesn't mean there's any obvious changes to make to our collective strategy.
The people I know of who are best at mentorship are quite busy. As far as I can tell,
they are already putting eﬀort into mentoring and managing people. Mentorship and
management also both directly trade oﬀ against other high value work they could be
doing.
There are people with more free time, but those people are also less obviously
qualiﬁed to mentor people. You can (and probably should) have people across the EA
landscape mentoring each other. But, you need to be realistic about how valuable this
is, and how much it enables EA to scale.
A top-tier mentor with lots of skills and context can help ensure someone thinks
through lots of relevant considerations, or direct them in the most useful ways. A
medium-tier mentor is more likely to be misguided about some things, or missing
some context.

A newcomer to the ﬁeld who's just read the obvious blogposts might be able to help a
newer-comer learn what to read, but there's going to be a lot of stuﬀ they don't know.
A lot of EA content is subtle and detailed, and easy to accidentally compress into
something misleading. (For example, 80k might write a nuanced article saying "You
should focus on talent gaps, not funding gaps", but this gets translated into "EA is
talent constrained", and then people repeat that phrase without linking to the article,
and then many people form an inaccurate belief that EA needs "pretty talented
people", rather than "EA needs very speciﬁc talents that are missing.")
I think the way to grow mentorship and management capacity involves longterm
planning and investment. There isn't free resources lying around we can turn into
mentorship/management. You can invest in mentoring people who grow into new
mentors later, but it takes awhile.
I think there is room to improve EA mentorship. But it's a fairly delicate problem, that
involves re-allocated resources that are currently being spent fairly carefully.
Mysterious Old Wizards
I'm looking for someone to share in an
adventure
In The Hobbit, Bilbo Baggins wakes up one day to ﬁnd Gandalf at his door, inviting him
on a quest.
Gandalf does not teach Bilbo anything. He doesn't (much) lead the adventuring party,
although he bales them out of trouble a few times. Instead his role in the story is to
believe in Bilbo when nobody else does, not even himself. He gives Bilbo a bit of a
prod, and then Bilbo realizes, mostly on his own, that he is capable of saving lives and
outwitting dragons.
In canon Harry Potter, Dumbledore plays a somewhat similar role. In the ﬁrst ﬁve
books, Dumbledore doesn't teach Harry much. He doesn't even give him quests. But a
couple times a year, he pops in to remind Harry that he cares about Harry and thinks
he has potential.
Showing up and Believing in You
Some people seem to be born ambitious and agentic. Or at least, they gain it fairly
early on in childhood.
But I know a fair number of people in EA who initially weren't ambitious, and then at
some point became so. And anecdotally, a fair number of those people seem to have
had a moment when Someone They Respected invited them out to lunch, sat them
down and said "Hey, what you're working on - it's important. Keep doing it. Dream
bigger than you currently are allowing yourself to dream."
This is often accompaniment with some advice or mentorship. But I don't think that's
always the active ingredient.

The core elements are:
The wizard is someone you respect. They clearly have skills, competence or
demonstrated success such that you actually take their judgment more seriously
than your own.
The wizard voluntarily takes time out of their day to contact you and sit down
with you. It might only be for an hour. It's not just that you went to them and
asked "do you believe in me?". They proactively did it, which lends it a costly
signal of importance.
They either tell you that the things you are doing matter and should invest a lot
more in doing them. Or, maybe, they tell you you're wasting your talents and
should be doing something more important. But, they give you some sense of
direction.
Network Bottlenecks
I think all three types of are in short supply, and we have a limited capacity to grow
the resource. But one nice thing about mysterious old wizards is that they don't have
to spend much time. Mentorship and management requires ongoing investment.
Mysterious Old Wizards mostly make you go oﬀ and do the work yourself.
In my model, you can only mysterious-old-wizard for people who respect you a lot. I
wouldn't go around trying to do it frivolously. It ruins the signal if it turns into a
formality that people expect you to do. But, I do think people should be doing it more
on the margin.

How do you optimize productivity
with respect to your menstrual cycle?
As the question asks, I am looking for productivity advice directly or indirectly related
to one's menstrual cycle. 
Motivation: This may seem like a gross or weirdly personal question but I think it's
actually quite important. For example, for the ﬁrst four hours of my period, I am
unable to do anything besides lie down, be in pain, and (sometimes) vomit for about 4
hours. Not accounting for all of the other ways my period negatively aﬀects me, this is
already 4 hours * 12 = 48 hours = 2 full days lost per year. That being said, there
can be menstruation related hormonal ﬂuctuations which positively inﬂuence
productivity. During ovulation, I can sometimes reach almost manic levels of mental
and social energy and (I'm less sure about this) I require a bit less sleep to function. 
What the question is asking: This is a very open-ended and personal question so I
am expecting similarly open-ended and personal answers. For example, stuﬀ I'm
interested in:
Generally speaking, how does your menstrual cycle aﬀect your productivity? 
What eﬀects has the pill had? Which kind of pill?
Have you experimented with varying your cycle length? (I had a 3 month cycle
some number of years ago, and enjoyed the decreased frequency and intensity
of my periods.)
Have you noticed ﬂuctuations in energy level caused by your menstrual cycle?
Any way to make the high energy phases longer and the low energy phases
shorter? Do phases of high energy correspond to a certain hormone which I
could get through the pill?
Are there dietary changes that mitigate the bad eﬀects of menstruation /
enhance the good eﬀects? (For example, is it "helpful" to give in to cravings?)
Are there sleep schedule choices that can be made which synergize with your
menstrual cycle?
Are there points in your cycle where you are best at detail-oriented work /
creative work / socializing / writing / anything else relevant?
It's possible that your answers to many of these questions are "my menstrual cycle is
irrelevant here because other inputs have way stronger eﬀects". Insofar as your
menstrual cycle has a sizeable eﬀect on any of these points (or other points I haven't
mentioned), I would be really interested in hearing your thoughts. 

Covid 2/18: Vaccines Still Work
This week the CDC released new guidelines for schools. I've spun my analysis of that oﬀ into
its own post. Scott Alexander also shared some good thoughts on Covid-19 in two new posts,
and I discuss both of those, and how our models and predictions diﬀer.
Also, as some combination of retaliation and its continued crusade against the evils of the
tech industry and the notion of freedom of speech, the New York Times ﬁnally published its
hit piece on Scott Alexander. I devote a brief section to it, the upside of which is that the
paper is now permanently banned from this space. 
Oh, right, you came here to learn about Covid-19 news. The short news is great. Infections
and deaths are down much faster than anticipated. The vaccine news is less great. The
process continues to accelerate, but that acceleration was slower than expected, and there's
still lots of FUD about what vaccinated people can and can't 'safely' do and little movement
yet towards saner policy in other ways, although there are signs of moving in that direction.
The new strains aren't here in force yet, but it seems likely that will happen soon.
One potentially big thing we learned is the study from infected NBA players, which suggests
that the English strain causes infections to play out over a longer period of time than the
classic strain, with all the implications of that.
 
Another was that it got even clearer than it already was that the Pﬁzer and Moderna vaccines
are highly eﬀective after only one dose, and that First Doses First would be a vast
improvement while we continue to have much less vaccine than we need.
The Numbers
Predictions
Results last week: 6.4% positive rate on 11.3 million tests, and an average of 2,752 deaths
after adjusting for Indiana.
Prediction: 5.7% positive rate and an average of 2,450 deaths. Things should still continue to
improve.
Result: 5.2% positive test rate on 10.4 million tests, and an average of 2,089 deaths. This is
after removing Ohio's adjustments that add additional deaths from previous months, similar
to Indiana's adjustments from last week. 
I'm straight up adjusting the results rather than listing both answers, because the
adjustment makes my prediction less accurate. When adjustments like this make predictions
more accurate, it seems necessary to list both results to keep oneself honest.
This is an extraordinarily good result. After several weeks of refusing to budge, deaths
plummeted, and the drop in infections continues to be rapid. With a 20%+ week over week
decline, we still aren't fully ready for the English Strain, but it's a great start and buys us
time. 
This will be the ﬁrst week that I am adjusting my prediction a bit to account for risk that the
English Strain is starting to take over, but it won't happen all at once. It would be very
surprising not to see a continued drop.
Prediction for next week: 4.6% positive test rate and an average of 1,800 deaths.

Deaths
Date
WEST MIDWEST SOUTH NORTHEAST
Dec 17-Dec 23 3826 5158
5131
3772
Dec 24-Dec 30 3363 3668
4171
3640
Dec 31-Jan 6
4553 4127
5019
4162
Jan 7-Jan 13
6280 3963
7383
4752
Jan 14-Jan 20
5249 3386
7207
4370
Jan 21-Jan 27
6281 3217
8151
4222
Jan 28-Feb 3
5524 3078
8071
3410
Feb 4-Feb 10
4937 2687
7165
3429
Feb 11-Feb 17 3837 2221
5239
2700
Once we take out the adjustment in Ohio, we see steady advancement across the board. 
Positive Tests

Date
WEST
MIDWEST SOUTH
NORTHEAST
Jan 7-Jan 13
474,002 262,520
531,046 306,604
Jan 14-Jan 20 360,874 185,412
452,092 250,439
Jan 21-Jan 27 260,180 158,737
386,725 219,817
Jan 28-Feb 3
191,804 122,259
352,018 174,569
Feb 4-Feb 10
144,902 99,451
255,256 149,063
Feb 11-Feb 17 97,894
73,713
185,765 125,773
Once again improvement is steady all around, although slower in the Northeast and
especially slower in New York, which I'm personally not too thrilled about. 
Test Counts
Date
USA tests
Positive % NY tests
Positive % Cumulative Positives
Dec 24-Dec 30 11,300,924 11.2%
1,303,286 6.0%
5.98%
Dec 31-Jan 6
11,649,640 13.3%
1,365,473 7.3%
6.45%
Jan 7-Jan 13
13,911,529 12.2%
1,697,034 6.6%
6.97%
Jan 14-Jan 20
14,005,720 9.7%
1,721,440 5.9%
7.39%
Jan 21-Jan 27
12,801,271 8.8%
1,679,399 5.3%
7.73%
Jan 28-Feb 3
12,257,123 7.7%
1,557,550 4.6%
8.02%
Feb 4-Feb 10
11,376,541 6.4%
1,473,454 4.1%
8.25%
Feb 11-Feb 17 10,404,504 5.2%
1,552,555 3.5%
8.41%
As a point of comparison, these rates are similar to what we saw late in October. 
Also worth noting that we've never seen a rolling 7-day average below 4%, so we could get
that to an all-time low within the next two weeks. Exciting stuﬀ.

Vaccinations

This was a deeply disappointing week on the vaccine front, with the 7-day average declining
over the last few days, and on net almost no progress week over week. Our rate of progress
has stalled out. Weather and the holiday I am sure contributed to this, and increased supply
is still in our future, but it's still disheartening. 
Europe


Overall news is good, but nowhere near as good as in America.
Covid Machine Learning Project
As with other sources, the infection numbers look good but the vaccine numbers are
disappointing. He has us at 27.7% infected as of February 4, versus 27.2% a week earlier. 
The English Strain

The NBA once again delivers us reliable data on the things we care about.
Clustering means that this can't be presumed to be a random sample, but 7/65 for
December and January is such bad news it could be seen as potentially turning the corner
into becoming good news again. If we were at 10%+ new strain over that period, then that
means at least 20% by the end of January, and it's now two weeks later than that which
should take us at least close to 50%. 
If we interpret that as the new strain about to become impactful and take over, it's bad
news. But, if we interpret it as the new strain is already here in force then it gets more
ambiguous and could even be good news! If the new strain is 25%, or even 50%, of new
cases, and cases are still going down, then that's amazing. It means we've somehow
managed to do so much additional prevention work that we're still making rapid progress. So
that would be pretty great. 
The timing of the transition between strain, however, wasn't what was being studied here at
all. Here's the paper. Instead, the paper is studying the timing for when people are infectious
with each strain, using the frequent NBA testing to generate a robust data set. That's pretty
great, since it informs all sorts of decision making.
These charts seem super useful, with red being the English strain and blue being classic:


Note, before we go any further, that these are in some ways highly atypical cases. NBA
players are not representative of the population, and these could be highly correlated in

various ways. It's entirely possible that these results don't mean much because of those
issues, and it would be super nice if we could run similar tests on a population that wasn't so
exceptional and unusual.
Together, these charts tell a story of the typical infected person with the classic strain being
acutely infectious for a brief period, whereas the new strain makes them sick and infectious
over a longer period. This would then presumably also be the reason the new strain is
deadlier, although I don't have a good understanding of why it has that eﬀect and wouldn't
have been surprised if this pattern had gone along with a less deadly strain rather than a
more deadly strain. 
This means that the infection cycle (the serial interval) of the English strain is longer than
that of the old strain. That means that it will grow slower, relative to its increased
infectiousness, than the old strain. If we weren't doing any mitigation at all, it's possible that
the English strain could have a higher R0 than the old one yet end up not becoming (at least
at ﬁrst) the dominant strain, because the old one would grow faster. This means that we
should expect the English strain to arrive in numbers somewhat slower than its level of
infectiousness would otherwise indicate, buying us more time to prepare, but also means
that if the strain arrives in force at a given time, we should estimate it being a bigger jump in
infectiousness than we would have previously since it will have had fewer cycles in which to
get that far.
This also means that if the English strain is a major factor, and this data is accurate,
quarantine periods will have to get longer. Whatever was being done before won't be
enough, and anything that would be enough now was previously overkill. 
There also won't be one number to represent the increase in infectiousness, because the
relative R0 will diﬀer based on people's behaviors. 
Due to the origin of the sample take all this with a bunch of salt, but it's a bunch of
interesting updates. 
The South African Strain
It is clear that antibodies from our current vaccines are less eﬀective against the South
African strain. The question is how much less eﬀective, and what that translates to in
practice in terms of protection. When one shows antibody response levels, it is traditional for
a reason to use a logarithmic chart. The immune system doesn't produce exactly enough
antibodies, it does its best to massive overkill when that makes sense.
Also, there's the continuous risk that one will confuse the diﬀerent measures of
'eﬀectiveness' and reach a nonsense conclusion by doing math that isn't valid. I worry about
the interpretation of things like this but trust my readers to handle it: 

There are plenty of people who read that and interpret it very incorrectly as 'whelp, we were
95% protected, but this is two thirds less protection, so that's about 1/3 protected.' That
would be rather alarming, but it's not the case. Cutting antibody eﬀectiveness by 2/3rds is
going to reduce vaccine protection, and the 'no evidence' statement here is obvious
nonsense the way such statements usually are, but we also have no reason to expect a
2/3rds drop in antibody protection levels to translate to anything like a 2/3rds drop in how
eﬀective the vaccine will be at preventing infection or death. 
Here's the chart from the preliminary report, click through to get their explanations:

#YouHadOneJob (to Appoint Someone To Fill)

President Biden continues not to have named his new head of the FDA (WaPo). The two top
candidates continue to be Janet Woodcock and Josh Sharfstein. 
It seems from a brief investigation that Sharfstein's primary mission would be to stop evil
drug companies from potentially earning a proﬁt. Such villains would need to be stopped
immediately. On the plus side, he has earned the ire of anti-vaccine groups, and that has to
count for something.
Janet Woodcock is the current acting commissioner, and thus directly responsible for our
failure to approve vaccines. You gotta love this being front and center on her Wikipedia
page: 
In the context of opioids that certainly does not seem great, but we do need that same
energy now in other matters, and also there's this:
Not that it's working all that well, or anything, based on what we observe, but that doesn't
mean it couldn't be much worse. At least Janet Woodcock is moving on the margin to
produce more innovation and get things to move faster, as opposed to stopping things and
slowing them down. So if those are the only choices, I'd have no choice but to go with Janet
Woodcock.
Vaccines Work
(And yes, you should know this already.)
Somehow, we constantly get articles and new studies that are framed as surprising, saying
that yes, the vaccines that we know work, work. 
And thus, 'No evidence' for the obvious conclusion all the Bayesians reached weeks or
months ago becomes evidence that counts in newspapers and journals. 
Which is important! Even when one trusts, one should verify. Even if one did not need to
verify, one can still learn more and in more detail. Every little bit helps.
It's best not to get too worked up about the failure to use words like 'conﬁrms' and instead
call such results 'game-changing.' What matters now is that our beliefs, and what we're
willing to do with those beliefs and say out loud, have now converged. 
Yet, even when the write-ups clearly point to the correct response (ﬁrst doses ﬁrst), it still
pains me to see things like this...

I say this points to First Doses First because otherwise this isn't a game-changer in pursuit of
herd immunity. If you always give everyone their second dose two weeks after the ﬁrst, this
new ﬁnding at most puts you two weeks ahead of schedule. The only real 'game-changer'
would be to use this to do First Doses First.
(In good news, there's reports that the CDC is in technically conﬁdential discussions about
recommending a move to First Doses First.)
And here we are, back to Very Serious Person framing, complete with 'may' and 'partial':
Another similar article on the topic is here, with the same framing that this is news.
The problem is, we all want to directly measure infectiousness, since it's genuinely unclear
exactly how much protection against this various vaccines oﬀer at various points:

But how are you going to do that? The only practical option that would actually work, that I
can think of, would be a challenge trial, which is super illegal, so the next best thing
anyone's come up with so far is what this study did, which was to measure viral load in the
infected. 
The result of 75% lower average viral loads in vaccinated people, conditional on infection at
all, reinforces our previous understanding. First, it conﬁrms that, conditional on infection at
all, vaccinated people are less infectious even after one dose. Second, it conﬁrms that severe
disease, hospitalization and death should be much reduced in vaccinated individuals, again
after only one dose, even conditional on infection. 
Since one dose also does a remarkably strong job of preventing infection, we can now
multiply these eﬀects. The only downside is that, with less viral load and less serious
infection, those who are vaccinated are more likely to have a case and be undetected, so the
"% eﬀective" number on infected-at-all is going to be lower than the "% eﬀective" number
measured by those who test positive. Testing often happens in response to a reason, and
also suﬃciently light cases generate more (technically false) negatives.
Practical Model of Vaccine Eﬀectiveness
Basically, my current model is that the vaccines all improve your chances at each step of the
illness, cumulatively. This ﬁts the data and also my understanding of immunology.
Think of being infected kind of as: 
1. First you get exposed and you roll to see if you get infected at all.
2. Conditional on getting infected at all, roll to see if you get mild symptoms. 
3. Conditional on getting mild symptoms, roll to see if you get moderate I'm-sick-this-sucks
level symptoms.
4. Conditional on getting moderate symptoms, roll to see if you get a severe case.
5. Conditional on severe, roll to see if you need hospitalization.
6. Conditional on hospitalization, roll to see if you die.
If you pass a roll, you recover, and then you roll again based on how bad it was to see if you
get some form of Long Covid. The further down the chart you get before you stop, the more
infectious you are for longer, ratios unknown. And the worse your case, the higher the viral
load you pass to someone you infect, which makes their chances at each stage worse as
well.
Being young and healthy helps you at each step, and so does vaccination, as does being
exposed in step 1 to a low initial viral load, with the diﬀerence that vaccination helps
relatively more at steps 1-2, and being young and healthy is relatively more eﬀective at

stages 3-6, and I don't know where viral load helps more, but it all helps at least some at all
steps.
When we measure vaccine eﬀectiveness, diﬀerent studies are measuring diﬀerent places on
the chart - most are checking how many people test positive as primary endpoint, which is
closest to #3, but others test everyone periodically, which is more like a mix of #1 and #2 (if
you're barely positive, the test won't be positive for as long and might miss it entirely). We
also measure #5 and #6 and report those, because people notice they're important.
What we notice in every vaccine study is that #6 comes out to 100% protection, and #5 at
least comes damn close. Two weeks ago there were 5 vaccine studies released, quite large,
with zero hospitalizations and zero deaths in any of the treatment groups. As far as I have
seen, for every vaccine anyone is considering oﬀering to anyone, there has not been a single
death from Covid-19 in the treatment group of any vaccine trial. 
Call the dominant strain in America the 'Classic' strain to contrast it with the South African,
Brazillian or English strains. 
My current prior on Pﬁzer/Moderna vs. Classic is that they're something like 90% vs.
infectiousness (step #2 or so), 95% vs. moderate symptoms (#4), 99%+ versus death. To
the point where we've fully vaccinated several percent of the population across many
countries and have one report of a fully vaccinated person dying of Covid-19, versus what
would otherwise be over a hundred per day. 
Similarly, J&J was measured at 66-72% vs. Classic as the headline number, but is clearly
95%+ and plausibly 99%+ against hospitalization and death, we don't know the full number
because again zero cases in the treatment group. 
The other vaccines follow similar paths. They all oﬀer strong protection versus hospitalization
and death.
Even in the worst case, where the AZ vaccine is not so eﬀective against the SA strain in
terms of infection and transmission, it's more eﬀective than nothing at all even against
infection and transmission, doesn't block getting a second vaccine later, and it would still
prevent a lot of deaths. So the SA decision to not use AZ only makes sense if they can trade
their AZ supply for someone else's supply of a diﬀerent vaccine, which could still be a
win/win.
You want to know how eﬀective the Pﬁzer vaccine is? This eﬀective:

It's too early to draw ﬁrm conclusions about impact on the IFR (infection fatality rate) from
this alone, since my prior for the baseline number is something like 0.2%-0.6%, which means
we'd expect 1-3 deaths by now if they were detecting every case from 544 infections, or a
few times that if we assume the majority of infections continue to be missed. The
hospitalization rate is similar to the overall USA hospitalization rate for cases, but the
American death rate is about half our hospitalization rate, so even if hospitalized but
vaccinated patients are somewhat less likely to die than hospitalized unvaccinated patients,
I'm guessing the hospitalization threshold in Israel is lower. 
Also worth remembering that Israel focused on vaccinating its elderly. 
Winning all ﬁfteen coin ﬂips does happen by accident, but rarely on one's ﬁrst attempt.
Combine that with winning all the coin ﬂips in all the vaccine trials. 
Or to put it another way, vaccines are so good that mild cases after vaccination are clickbait
news items (hence I won't direct link):
Or, in summary, this:

This study covers our own results in practice, and also ﬁnds the vaccines highly eﬀective
(pdf). Numbers here were actually somewhat disappointing compared to what we've seen
elsewhere. Sharing the chart below because the data is the thing, but note that these are
very small samples in terms of number of infections in many cases, so don't take the exact
numbers all that seriously.

Once again wasn't suﬃciently powered to measure everything we want, but once again
reduced severe outcomes, and a zero on deaths.

Vaccine Work So Well We Can Vaccinate More
People
Shout it from the rooftops (study). Moderna half doses illicit robust immune response in
healthy adults, including those over the age of 55.  
This is a huge boost to our vaccine supply, if only we are willing to take it. Given the physical
mechanisms it isn't quite a doubling of Moderna doses, but it's close. 
A letter to the editor reanalyzing the Pﬁzer data on the ﬁrst dose only. 



I wouldn't want to hang my hat on a sample of size n=29, but the pattern keeps repeating
itself, and the math isn't remotely close. 
There is no lower hanging fruit available than this.  
The logistical hurdles are many. What would it mean if we put so many doses into each vial?
Well, good news, the FDA only took a few weeks to give their sign-oﬀ on that one:
It's pretty great when there's a painfully obvious thing to do, you hold it up for weeks, then
you allow it and everyone gives you credit for the huge boost provided by your approval.
 
Celebrate, good times, come on, also look at those reporters doing math:

Presumably the 20% number comes from a 40% increase in Moderna vaccine doses, and
Moderna being about half of our supply. That implies that there will still be a shortage of
vials, and that if we could ﬁnd a way to produce more vials we could deliver more vaccine
doses. We may not be quite the can-do country we used to be, but 'produce more vials
faster' still seems like an ask that should be within our reach. 
In good news, France is recommending only one dose for those previously infected.
The data seems very clear that if you've already had Covid you need at most one vaccine
dose.

Linked studies are here, here and here. The real question is whether such a person needs the
ﬁrst dose of vaccine, or whether the prior infection was suﬃcient. As I told a commenter last
week, my position on that is that there's no real downside to getting the ﬁrst dose so you
should get it, but I wouldn't ﬁght for a scarce appointment and go way out of my way if I'd
already been infected, and for now let them go to those who need them more.
 
A proposal to change our method of vaccine administration. Huge if true and implemented,
deﬁnitely won't be implemented in time to matter even if true. Thus did not do the research
to determine if true, but good brainstorming so ﬁgured I'd pass along.
Bubble Bursting
What to make of this story from the conference organized by Peter Diamandis? 
I'd encourage comparison to this analysis of what a Covid test tells you, at Aceso Under
Glass. 
Diamandis attempted to create an immunity bubble via PCR testing.

Masks were encouraged between venues, but not required. 
There was one positive test prior to day one. That person was not admitted, and participated
virtually. All other test results were negative, but afterwards...

If you go from testing negative one day to highly infectious the next day, at least one of
those tests almost certainly gave the wrong answer, even if you're only or primarily
interested in infectiousness.
He links to this article, noting that people with Type B or AB blood are more likely to test
positive than those with Type O blood but not more likely to get sick, and that he is Type O.
But a lot of people are Type O, so interpreting this as 'tests don't work on Type O' would be
saying they don't work on almost half the population, which unless you knew a particular
person's blood type would cash out as straight up 'doesn't work.' 
Sounds like everyone is going to recover, which is great. Concrete speciﬁc data is always
highly useful, and it's great to have a detailed report. What can we conclude from this?
Masks work, and not using masks was a mistake, but I think the mask data here is being
misinterpreted. If one group was isolated in one area and none of them got Covid, and
another group was in a diﬀerent area and many of them did get Covid, the presumed
explanation is that the isolated group, even if large, didn't have any Covid cases to begin
with, and they wouldn't have caught Covid even without masks. Again, that doesn't make
the masks unnecessary or not a good idea, but it could easily have gone the other way.
Mostly what I see is a badly designed protocol. 
You can't have a bubble without an initial quarantine period.
Tests are great for reducing risk. Testing at the rate this group tested, if practiced by the
general population, would end the pandemic in a month or two.
But the requirement for a bubble isn't reducing risk. The goal is to all but eliminate risk, and
this protocol obviously didn't do that given the timing involved. Rapid tests don't reliably test
positive before symptom onset. 
A 14-day quarantine period before starting is deﬁnitely suﬃcient. A 7-day period before
starting, combined with multiple tests on everyone, would in practice be good enough for a
bubble of this size. A 0-day quarantine doesn't make any sense and won't get it done. 
This stuﬀ is complicated, and people are not explaining it well. As a result, even super smart
people like Peter Diamandis are often getting it importantly wrong. 
Again, that doesn't mean that what they did wasn't highly useful. The protocol helped by
catching one infected person, and on average I would expect it to stop a large majority of
potential outbreaks in such a group. Missing someone (or multiple someones) required
having bad luck. 
What it doesn't do, under current conditions, is provide enough safety to form a true bubble
where people can ignore transmission risk between those in the bubble. It doesn't let you

ignore masks, distancing and ventilation entirely. 
No, Really, Andrew Cuomo Is The Worst
The Washington Post is among many calling for the removal of Cuomo from oﬃce. It seems
clear now that not only did Cuomo put Covid-19 positive nursing home residents back into
nursing homes where they could infect other residents, he also covered up the resulting
deaths. 
New York Times Is Permanently Banned 
It is a great sorrow to see the paper I grew up thinking of as the paper of record, with the
motto "All The News That's Fit To Print," engage in such brazen libel and retaliation,
insinuation of guilt by association so brazen it should be used as an example in textbooks,
and condemnation of the very idea of freedom of speech. 
Due to its recent remarkably disingenuous retaliatory hatchet job hit piece on Scott
Alexander, together with the paper's growing general amount of malice (as Eliezer points out
it's not obvious that this piece was even unusually disingenuous for the NYT), The New York
Times is now permanently banned from my blog. There will be no links of any kind to NYT
and I will not speak to anyone associated with the paper or provide them any information for
any reason, other than to inform them of this decision and its cause. I will share information
from NYT sources if there is no alternative, without linking.
As further proof of its principled opposition to free speech, The New York Times took this
position to its logical conclusion, and also warned us this week about the nefarious
Clubhouse and its dangerous potential for 'unfettered conversation.'
If you're reading this, you almost certainly read Scott (if not, that's a serious mistake that
you should ﬁx, so go do that now, I'll wait.) Remember that this is how they conduct
themselves in the arena you know. Why would you think they do any diﬀerently elsewhere?
For now, I am not extending this ban to avoiding information from individual NYT reporters
on Twitter. A remarkably large number of people providing information on Twitter turn out
when you check to be NYT reporters. I could be persuaded that I should take this step, and
block all of them on principle. 
Beyond that, and urging everyone else to follow suit (or at least to cancel any subscriptions
and not talk to their reporters) on pain of me thinking less of you, I consider the matter
closed.  
Scott Alexander Predictions on Covid-19
Scott Alexander is out with a post on Covid-19. I provided feedback on an earlier draft, and
think both versions were quite good. When writing on a weekly basis, it's easy to forget to
step back and look at the longer term picture more broadly. I've done it somewhat, but
haven't focused enough on the longer term, so this is a welcome reminder. Scott is doing
what so many do not, creating a physical world model full of gears, trying to ﬁgure out how
those gears function, and thus ﬁgure out how things work and what is likely to happen. Then
he even makes probabilistic predictions. It's what you'd expect from the consensus number
one pick. 
Let's take a look at the predictions:

The threshold for this prediction is not so high. Right now we are more than 50% down from
peak in terms of positive tests and hospitalizations, so this wouldn't require us to get
anywhere near the previous peak. The prediction also requires that the new peak be in
March or April; technically if it's in May then this resolves to no, no matter how high the
peak. I still expect this to happen, because math, because the threshold is low, and because
while we've exceeded expectations in vaccination we likely haven't exceeded them by
enough to make a March deadline once you account for all the lags.
The most promising thing is that the fourth-wave narrative has  become fully accepted by
the Very Serious People in advance, which is plausibly why we're seeing such strong declines
in cases now - the control system may be partially working to act on the future rate of
growth rather than the current one.
With us at R0~0.83 at the moment, we're deﬁnitely not there yet, but we're not that far from
there especially if the English strain isn't fully 50%+ more infectious and is only 30-40%
more infectious.
Combine all those eﬀects including the timing involved, and I'm at something like 60% here
if measured in the 7-day average positive test count. 
Given this says 'or new strains with similar dynamics' this seems hard to avoid. A majority
could end up being not that many cases, but that doesn't change what we have to do to
prevent case growth, nor does it change the odds here. Our containment plans for the new
strains are terrible, and we're seeing convergent evolution towards things that would count. I
think this is low and I would be closer to 80%. A full year is a long time.
I'm interpreting this purely on an individual risk level. I worry that our knowledge generation
systems and our vaccine approval systems are so broken that we'll never 'know' for sure the
way this question implies we will know, but let's say that this question is asking about our
best guess looking back on 2021. I am much more optimistic here. AstraZeneca is the one
that might fail this test against some strains, but if I hadn't seen Scott's number I'd have
been at least around 85% for this, because 80% reduction isn't that high a threshold. Given
Scott looked and said 55%, I'll revise that down to 70% on the basis of there being multiple
'all' clauses in this, and it being dangerous to get too optimistic about claims that are worded
like that. 

Note that this threshold is an order of magnitude or more stronger than the one that says
vaccinate anyone anywhere with anything you can get, at any existing price, and I predict
that all vaccinations listed here will have been worth getting for the general population
regardless of which strains are dominant with a probability of 95%, except insofar as it
prevents people from being given access to another vaccine soon thereafter (e.g. if you can
get Moderna next week or AZ right now, but the government won't let you have both, it
makes sense to wait). The remaining 5% mostly involves the vaccines somehow interfering
with each other and some being vastly better than others plus widely available relatively
quickly.
I'm interpreting this prediction as being agnostic as to the framing involved, and assuming it
resolves to Yes if and only if the CDC issues guidelines saying many of those previously
vaccinated should get an additional shot some time in 2022. With that wording, I'd be around
50% for this, so rough agreement. The diﬀerence is more that I don't think this is that likely
to portent a big problem, and more likely to be a similar annoyance to the ﬂu shot, where it's
totally worth doing but not a big deal for healthy people if you end up forgetting.
The long term mutation rate of Covid-19, and how impactful those future mutations are likely
to be, is unknown, although we can guess. I agree with Scott that this is the big physical
unknown for long run outcomes, but within the range of plausible answers I think our choice
between plausible decisions as a civilization matters far more. 
The link Scott provides here is very welcome news. The FDA seems to be on the verge of
getting this one at least mostly right. 
The probability here depends on exactly how formal this has to be. If it needs to be an
explicit announcement of such a lane for a particular company or group of companies, then I
think 50% is a good prediction. If all that's required is a general understanding by Pﬁzer or
Moderna and those observing them that they could get approval within three months in a
future emergency, then I think this is closer to 80%. 
I'm optimistic here because there's an existing example of this process (the ﬂu) that
everyone agrees upon, and because this involves essentially repeating a similar thing to an

already done thing, which is what organizations like the FDA deal with best, and also
because of how terrible it would look (and be) to hold this up in that situation were it to arise.
I'm going to be less conﬁdent on this prediction, and bring it down to 80%, because 10% is
not a lot of people, and it wouldn't take that big a cultural shift to exceed that rate of mask
wearing semi-permanently even if there wasn't a strong physical need for it.
The core question to be decided is, are we going to emerge with a new appreciation for life
into a new roaring 20s, or are we going to do to adults what we've already done to
childhood, and extend life-crippling restrictions indeﬁnitely because of a recalibration of risk
and new cultural norms? Will we bring another promise to Mother Earth with a bounty and
mercy, or will we hide from her within walls of stone at the barrel of a gun?
It's great that moving forward we'll have improved our infrastructure for providing remote
services and doing video calls and such, but it would be a supreme tragedy if we let our way
of life permanently end in a new wave of disease paranoia. That outcome seems entirely
plausible but also entirely preventable. 
There will be rock concerts and music festivals once again. There will be more than there
have ever been, because there have to be.
You Gotta Fight For Your Right to Party.
All your other rights as well. Covid could well end up being used as a framework for the
denial of our basic rights. If elites can break the rules in an emergency they will create an
emergency in order to break the rules, and thank you for coming to this Ted Talk. It could also
do the opposite, and embolden people to not listen to elites the next time they try something
like this, given their performance record. 
We need to go several steps further than reversion to the old norms. As I discussed in the
School Daze section, we need to take this opportunity to undo previously instituted insane
safety concern trolling, and let life exist. Covid-19 safety is a group eﬀort where we must
contain spread, so safety concerns are at least understandable, but the overarching reach of
most such concerns are about blameworthiness, liability and people's inability to do or
intuitively understand or appreciate statistics and math. Free the children. Also free
everyone.
Metaculus Redux
I got a bunch of pushback from people involved with Metaculus on my comments on
Metaculus from last week. There was a lot of discussion in the LW comment section, and
some talk on Twitter as well. I continue to be very happy Metaculus exists (and that Good
Judgment Project exists) which is why I am willing to discuss them and why I am sad that
they are not better. I've written extensively about prediction markets, and these aren't
prediction markets. They also aren't entirely not prediction markets, of course, but it's true
that they're diﬀerent and it's not obvious the incentives can or should be the same as in
prediction markets themselves.
If you are motivated to make predictions in such places, and are putting in the time such that
your predictions are net helpful, then you are doing a public service, so please keep doing
that. And a big thank you to those helping run and improve such places, even if I don't agree
with all your decisions and don't choose to participate.

My other request for such places is that I ﬁnd them next to impossible to usefully navigate
for the questions I care about, whether I'm looking to view results or make predictions, and
more and better curation and organization of the markets seems high value. So does
ensuring that the most important questions exist and are in good form, and get the extra
attention they deserve. 
At some point I hope to write up my thoughts in more detail.   
Vitamin D As It Ought To Be
New study claims that it conﬁrms that Vitamin D is very important for Covid and is highly
eﬀective even when administered at the hospital. Alas, it looks like the methods and
statistics they used were highly suspect to say the least. They didn't randomize patients,
they did the treatments in some wards but not others, then didn't even assign patients
randomly to wards, then didn't cluster their errors. 
That doesn't change the fact that everyone should be supplementing Vitamin D, and it's
plausible I should be talking about this way more often lest people forget. The new data isn't
compelling (at least, it isn't in the form it's been presented) but it's also deﬁnitely not
evidence against Vitamin D. 
Then there's Scott Alexander's latest article on the subject, Covid/Vitamin D: Much More
Than You Wanted To Know, which is in some sense a very accurate title (as in, the ﬁrst
paragraph tells you what you wanted to know, take Vitamin D regardless), but in another
sense not true at all, since if anything he can tell us less than I would want to know, since I
want to know more than is known, again even though it doesn't directly impact behavior
today. His thoughts deﬁnitely ﬁt right in with 'Vitamin D study looks good but turns out to be
deeply ﬂawed and thus it tells us nothing new.' 
I understand where Scott's analysis is coming from here, but I don't agree with it. I do
acknowledge that it is possible that all the gigantic correlations are a big coincidence that
results from intermediation from some combination of otherwise poor health, other sunlight
eﬀects and socioeconomic status, and failing to control for such matters. It's possible, sure,
despite the eﬀect sizes in the 'damn check out this chart' area. I also think there's a bunch of
dialectic thought going on here, where it's eﬀectively about Whose Study Is Right and so
when two disagree we have it out see whose was better, or something, with negative
ﬁndings needing to be defeated in a righteous battle. I also think Scott is going with a big
"yeah, yeah, the boy is crying Vitamin D again and I'm not about to go chasing after this
non-existent wolf yet again.' 
That's making his prior a lot diﬀerent than mine, perhaps entirely fairly. If I was informed I'm
making an epistemic mistake, my ﬁrst guess would be that I need to better appreciate the
degree to which there's been wolf-crying and the dynamics involved, and that this should be
moving my estimates.
Scott makes three probabilistic assessments (they're not predictions exactly) at the end:

Tyler Cowen notes that he is even more skeptical than Scott. 
The ﬁrst curious thing here is the matching 25% numbers. I can imagine Vitamin D helping if
taken as a regular supplement while not helping, or helping less or only helping when
administered early or the right way, in the hospital. I can't imagine it working in the hospital,
but not working as a regular supplement. That would blow my mind. These two numbers
being identical thus suggests Scott doesn't see it that way, and in particular that he's
thinking that if it doesn't work in a hospital (or doesn't work in a hospital for any given
reasonable dosing method) it also doesn't work as a supplement. 
I still think Vitamin D supplementation in advance of infection is a favorite to signiﬁcantly
decrease the risk of getting Covid and give that maybe a 60% chance. I've been persuaded
that it's not obviously true and that taking Vitamin D deﬁnitely doesn't mean you can laugh
oﬀ Covid risk or anything. I ﬁnd it reasonably plausible that if you try to make up for a
deﬁciency in the hospital, it's too late to do much about it, and the chance drops to maybe
45%. 
Can you hear Eliezer Yudkowsky in the background saying "Bet! Bet! Bet!"? I hope you can!
The problem is that we both agree on the correct course of action - give everyone Vitamin D
supplements now, and give every Covid patient more intense ones in the hospital - because
there's so little downside to doing that. And I believe we both agree that this issue probably
isn't going to be deﬁnitely settled, regardless of who is right. If Vitamin D supplementation
doesn't do anything about Covid-19, some studies will keep ﬁnding correlations because they
aren't controlling for enough of the right things. If Vitamin D does do something, a lot of
studies will still be deeply ﬂawed because scientists and doctors mostly run ﬂawed studies
and there's a lot of correlations to dodge here and people trying to prove a point are
especially bad about controlling for such things properly, and other studies will lack suﬃcient
power or use the wrong protocols or control for things twice or whatever and end up ﬁnding
no eﬀect. There will never be a challenge trial or other deﬁnitive answer.

Maybe if there were a particular future study happening where we could both see the
protocol, we could bet on what that study will ﬁnd. That sounds like it might work, and if
someone has a good candidate, please share. 
Because we agree on the course of action, in many ways the more interesting questions are
epistemic ones. How should one evaluate the evidence in this situation? Which things should
move our priors how much? An in depth discussion of that with an eye on general principles
of evaluation of evidence seems like it would be generally useful.
I'd also note that the third line says equal or outweigh, not outweigh. The word equal either
is or is not doing work here. Does this include the case where Vitamin D supplements do
nothing for most people but are at least marginally helpful if you're suﬃciently deﬁcient
(42% of Americans are deﬁcient, Google says)? If so, then I ﬁnd this number strangely low
and wonder why it isn't starting with a 9 (or at least an 8) even if we ignore Covid entirely. If
the word equal isn't doing work and the question is about whether this is worth the cognitive
opportunity cost of taking up an action slot that could be used for something else, then I
could accept 75% conditional on the Covid-related skepticism being very reasonable.
A ﬁnal note is that no one is denying that Vitamin D deﬁciency is very highly correlated with
bad Covid-19 outcomes. The world in which Vitamin D supplementation doesn't help is the
world in where there holds some combination of (A) Vitamin D supplementation doesn't
provide Vitamin D in a useful way, (B) Vitamin D levels are a proxy for other sunlight eﬀects,
(C) Vitamin D levels are a proxy for age or other health eﬀects or (D) Vitamin D levels are a
proxy for socio-economic status. 
Thus, if you go to the doctor and they measure your Vitamin D levels as suﬃcient, that
deﬁnitely is very good Covid-risk news for you personally. If they measure your levels as
insuﬃcient, that deﬁnitely is very bad Covid-risk news for you personally. Thus, there's a
weirdly Calvinist perspective on all this that one could take, that I do not endorse, where
those with high Vitamin D are The Elect who are low risk and are saved, even if one is saved
via an entirely diﬀerent method. Again, not endorsing that, but I do ﬁnd it amusing and
interesting to think about.
In Other News
Monthly reminder that I have a Patreon if you have the desire to give me money to support
my writing. While I ﬁnd this motivating, I do not need the money even a little bit.
Contributing earns you my silent thanks to you, but that's it. If you want to contribute
enough to matter, contact me privately to minimize the costs involved.
We're ﬁnally doing a challenge trial. Even at this late date, it's super valuable for its results,
and even more valuable for the precedent it sets:

Stimulus plan wants to spend $500 per person on distribution alone, and The Grumpy
Economist asks why it costs so much. For all things vaccines I prefer to ask why we are
spending so little rather than pinch pennies. One can reasonably raise an eyebrow here, but
vaccine distribution is so valuable that the concern should be corruption and theft. If the
money is eﬀectively being stolen that would be bad. If the money is being used ineﬃciently
but with any good eﬀect at all, such as by massively increasing payments to those who give
the shots, I'm totally ﬁne with that. Cost beneﬁt analysis checks out.
This piece by Zeynep on how to think critically and interpet oﬃcial communication is
fantastic. Not for those who are old hats at this, but great for those getting up to speed.
Some unusually good non-Covid content recently on LessWrong: Anna Salamon observes
that PR is corrosive whereas reputation is not, and Eliezer Yudkowsky discusses the concept
of Cheerful Prices, the amount of money that would cause one to happily do a thing.
There's an online event coming up on February 25 about pandemics, biowarfare and the
future of human health called Going Viral, if you're interested you can register at the link,
and they asked me to pass it along.
I am curious what changed Dr. Fauci's timeline here, I haven't heard an explanation of what
caused the update:
The alternate hypothesis, of course, is that Fauci is telling people the timeline he thinks will
cause the most responsible behavior rather than his actual estimate (or, in other words,
lying.)
Medical students are at risk more from socializing than from treating patients, in one study in
Denmark. This matches priors.

Your periodic reminder (in this case from Bryan Caplan) that bioethicists are mustache-
twirling villains and without them we wouldn't have a pandemic. Also, did you know that if
you want to know if your experiment is allowed, you have to ask bioethicists and ﬁnd out
their answers? That sure sounds like an experiment on human subjects. Shouldn't we ask
bioethicists if that's permitted before we ask bioethicists if that's permitted? 
Your periodic reminder that rapid tests would end this pandemic and could be had en masse
for about $5 each, but we don't allow them to be sold, so what few exist languish in places
where the people involved don't want them. 
Thread about how we measure the eﬀectiveness of ﬂu vaccines.
Story about a private service to help with vaccine distribution in Oregon. Sadly not about a
way to spend more money to get more vaccines, but still helpful.
In WaPo, Alex Tabarrok tells us how to get on with it and vaccinate faster via some of the
usual completely obvious minimal-downside strategies we should deﬁnitely do. Nothing new
here.
It's fun to think about what might be good to do with the J&J vaccine if we could do whatever
we anted, but that doesn't make such ideas remotely practical or plausible. 
Department of it could always be worse: A current hypothesis that China is holding oﬀ on
vaccinating more widely until it can have suﬃcient supply for the whole country. There's
concerns about equity, and then there's full on anti-escapism. 
Biden team announced vaccine deliveries sooner than they were oﬃcially previously
expected:
That is of course excellent news, although how good the news really is depends on what our
true previous expectations were and how much this updates those expectations. Biden's goal
of 100 million doses in 100 days was never in doubt, and it seems plausible that all the

oﬃcial timelines have been chosen in a similarly conservative fashion to ensure they can't
fail. Underpromise and overdeliver. 
Germany doesn't have much vaccine supply, but is managing to actually target its most
vulnerable with what supply it does have. Comments suggest Sweden is doing this as well. I
too am curious to see how the case fatality rates shift a month from now in such places
versus our own.
FDA refuses to authorize rapid tests, so we ship 60mm of them overseas. Sigh. 
We ran an experiment to see people's willingness to pay for less crowded planes (MR linking
to WSJ), and it was low. The implication is that people's willingness to pay to avoid Covid risk
may be low in general, and we should consider that (while keeping in mind that much risk is
not private). One complicating factor is that the people who value Covid safety a lot mostly
either aren't ﬂying at all, or think the plane itself is mostly safe. I've noted before that the
ventilation of the planes themselves seems rather good, and I'd be more worried about the
taxi and getting through the airport, and also I haven't ﬂown at all anyway. I also expect a
psychological eﬀect where once a person decides they must ﬂy or is willing to ﬂy, often they
don't properly factor in marginal risk when making decisions, because they're in the context
of a bigger baseline risk and people's brains don't handle that very well. 
Even more than that, I think that the way we shop for plane tickets is designed to cause this
result. Everyone goes to an internet site and everything is sorted by price, price and price,
with ﬁlters for airlines and times and stopovers to the extent you use those. But mostly the
whole system is about getting the best price, which gives you visibility and makes you the
default choice on multiple levels. I don't see why plane safety via less people on the plane
should be any diﬀerent - people won't think about it or won't be aware of the diﬀerences, or
won't be willing to actively give up cheaper prices to get the thing even if they'd also never
make the opposite trade, and so on. So I think this is interesting and worth pondering, but
doesn't prove as much as one might think.
A thread arguing the UK should go for Covid elimination, and that such suggestions have
eﬀectively been censored and considered non-options. It uses a lot of the 'no evidence' lines
of reasoning, although in ways that are less terrible than normal. I think the way you get to
zero is ﬁrst you vaccinate and then you go for zero rather than locking down ﬁrst, but yes
everyone should absolutely go for zero Covid by the end of the year by getting the contact
tracing systems ready for that. I'm actively confused that this isn't obvious.
Let's check in on our model of Dr. Fauci, and see how it does on some events from last year:


Weekly Tom Friedman update for additional perspective, nothing new here.
Regulatory hold-ups are worse than you thought. Ada Poonawalla of the Serum Institute of
India reports that they have 70 million doses that exist but can't be shipped because the
countries that have purchased them haven't approved them, and they are already four

months old and expire in April. It doesn't sound like he's optimistic that, if the countries
involved still haven't approved them, he'll be able to redirect those vaccine doses to other
places. He's already making 70mm doses a month, so one would hope he'd be able to ship
the older doses out and replace them with new ones, so at least nothing spoils unused, but I
no longer count on such sanity to prevail. Also worth noting that Ada got the majority of his
funding from the Gates Foundation, so they did end up helping build useful capacity in at
least one case. 
Part of this 'vaccine nationalism' seems obviously good to me. If every country decides it
needs its own manufacturing suﬃcient to make everything it needs, that seems great,
because then we might have something approaching enough overall manufacturing capacity.
If everyone says 'no exporting vaccines until we have enough for everyone domestically'
that's not the ideal distribution mechanism but it is highly motivating for capacity, which in
the long term matters more. Whereas restrictions on importing vaccines, requiring one's own
regulatory hurdles everywhere, is pure downside. Even if you want to 'support' your own
candidate, why not simply pay for the vaccine doses later from your own factories even if
you end up not using or exporting them? The amount of pound foolishness, from almost all
angles, is staggering. 
Not Covid, but we should be rather worried about our failure to reliably keep the lights on.
Literally. 

Non-Covid Weight Loss Drug Update takes a look and ﬁnds the results most promising,
against a backdrop of historical money incineration that suggests continued need for
caution. 
Non-Covid Civilization Watch: Large parts of Texas continue to be without power under
dangerously cold conditions. Now there are reports of lots of people losing water as well.
Explosions shut oﬀ power to large parts of Portland. California's power grid is increasingly
unreliable each year. We should be alarmed about this. It is perhaps the best concrete test of
whether our civilization can maintain its physical infrastructure, it can't be faked, and it is
very much not going well. Any given incident can usually be explained away, extreme
weather events have always caused temporary power loss, but when it happens more often
on larger scales for longer periods, we need to ask ourselves what's going on. 
Thus, we must ask ourselves: What still works?

2019 Review: Voting Results!
You can see the full voting results here: 1000+ karma voters  (All voters)
The 2019 Review votes are in!
This year, 88 voters participated, evaluating 116 posts. (Of those voters, 61 had 1000+ karma, and will be weighted more highly
in the moderation team's decision of what to include in the Best of 2019 Books)
The LessWrong Moderation team will be reﬂecting on these results and using them as a major input into "what to include in the
2019 books." 
Top Results
The top 15 results from the 1000+ karma users are:
1. What failure looks like by Paul Christiano
2. Risks from Learned Optimization: Introduction, by evhub, Chris van Merwijk, vlad_m, Joar Skalse and Scott Garrabrant
3. The Parable of Predict-O-Matic, by Abram Demski
4. Book Review: The Secret Of Our Success, by Scott Alexander
5. Being the (Pareto) Best in the World, by Johnswentworth
6. Rule Thinkers In, Not Out, by Scott Alexander
7. Book summary: Unlocking the Emotional Brain, by Kaj Sotala
8. Asymmetric Justice, by Zvi Mowshowitz
9. Heads I Win, Tails?—Never Heard of Her; Or, Selective Reporting and the Tragedy of the Green Rationalists, by
Zack Davis
10. 1960: The Year The Singularity Was Cancelled, by Scott Alexander
11. Selection vs Control, by Abram Demski
12. You Have About Five Words, by Raymond Arnold
13. The Schelling Choice is "Rabbit", not "Stag", by Raymond Arnold
14. Noticing Frame Diﬀerences, by Raymond Arnold
15. "Yes Requires the Possibility of No", by Scott Garrabrant
Top Reviewers
Meanwhile, we also had a lot of great reviews. One of the most valuable things I found about the review process was that it looks
at lots of great posts at once, which led me to ﬁnd connections between them I had previously missed. We'll be doing a more in-
depth review of the best reviews later on, but for now, I wanted to shoutout to the people who did a bunch of great review work. 
The top reviewers (aggregating the total karma of their review-comments) were:

Some things I particularly appreciated were: 
johnswentworth, Zvi and others providing fairly comprehensive reviews of many diﬀerent posts, taking stock of how some
posts ﬁt together.
Jacobjacob and magfrump who stuck out in my mind for doing particularly "epistemic spot check" type reviews, which are
often more eﬀortful.
Complete Results (1000+ Karma)
You can see the full voting results here: 1000+ karma voters ( All voters )
To help users see the spread of the vote data, we've included swarmplot visualizations.
Only votes with weights between -10 and 16 are plotted. Outliers are in the image captions.
Gridlines are spaced 2 points apart.
Concrete illustration: The plot immediately below has 18 votes ranging in strength from -3 to 12.

Rank
Title
Visualization
1
What failure looks like
2
Risks from Learned
Optimization: Introduction
3
The Parable of Predict-O-
Matic
4.5
Being the (Pareto) Best in
the World
4.5
Book Review: The Secret
Of Our Success
6
Rule Thinkers In, Not Out

Rank
Title
Visualization
7
Book summary: Unlocking
the Emotional Brain
Outlier: +20
8.5
Asymmetric Justice
8.5
Heads I Win, Tails?—Never
Heard of Her; Or, Selective
Reporting and the Tragedy
of the Green Rationalists
10
1960: The Year The
Singularity Was Cancelled
11.5
Selection vs Control
11.5
You Have About Five Words
13
The Schelling Choice is
"Rabbit", not "Stag"
14
Noticing Frame Diﬀerences
15
Yes Requires the
Possibility of No

Rank
Title
Visualization
16
"Other people are wrong"
vs "I am right"
17
Rest Days vs Recovery
Days
18.5
Seeking Power is Often
Robustly Instrumental in
MDPs
18.5
The Forces of Blandness
and the Disagreeable
Majority
20.5
The Costs of Reliability
20.5
Chris Olah's views on AGI
safety
22
Reframing
Superintelligence:
Comprehensive AI Services
as General Intelligence
23.5
Humans Who Are Not
Concentrating Are Not
General Intelligences
23.5
The strategy-stealing
assumption
26.5
Reframing Impact

Rank
Title
Visualization
26.5
Understanding "Deep
Double Descent"
26.5
Moloch Hasn't Won
26.5
Integrity and
accountability are core
parts of rationality
30.5
Gears-Level Models are
Capital Investments
30.5
In My Culture
30.5
Make more land
30.5
Forum participation as a
research strategy
33
Unconscious Economics
34.5
Mistakes with
Conservation of Expected
Evidence
34.5
Bioinfohazards

Rank
Title
Visualization
36
The Tale of Alice Almost:
Strategies for Dealing With
Pretty Good People
37
Excerpts from a larger
discussion about simulacra
38
human psycholinguists: a
critical appraisal
40
AI Safety "Success Stories"
40
Do you fear the rock or the
hard place?
40
Propagating Facts into
Aesthetics
42
Gradient hacking
44
The Amish, and Strategic
Norms around Technology
44
Power Buys You Distance
From The Crime
44
Paper-Reading for Gears

Rank
Title
Visualization
48.5
How to Ignore Your
Emotions (while also
thinking you're awesome
at emotions)
48.5
The Real Rules Have No
Exceptions
48.5
Coherent decisions imply
consistent utilities
48.5
Alignment Research Field
Guide
48.5
Blackmail
48.5
The Curse Of The
Counterfactual
52.5
The Credit Assignment
Problem
52.5
Reason isn't magic
54
Mental Mountains
56.5
Simple Rules of Law

Rank
Title
Visualization
56.5
Utility ≠ Reward
56.5
Is Rationalist Self-
Improvement Real?
56.5
Literature Review:
Distributed Teams
59
Steelmanning Divination
60
Book Review: Design
Principles of Biological
Circuits
61
Building up to an Internal
Family Systems model
62
Evolution of Modularity
63
[Answer] Why wasn't
science invented in China?
64
How Much is Your Time
Worth?
65.5
Book Review: The
Structure Of Scientiﬁc
Revolutions

Rank
Title
Visualization
65.5
Everybody Knows
68.5
Sequence introduction:
non-agent and multiagent
models of mind
68.5
From Personal to Prison
Gangs: Enforcing Prosocial
Behavior
68.5
Some Ways Coordination is
Hard
68.5
Circle Games
71
Why Subagents?
73.5
Healthy Competition
73.5
Where to Draw the
Boundaries?
73.5
Does it become easier, or
harder, for the world to
coordinate around not
building AGI as time goes
on?
73.5
Six AI Risk/Strategy Ideas

Rank
Title
Visualization
76.5
Thoughts on Human
Models
76.5
Classifying speciﬁcation
problems as variants of
Goodhart's Law
79
Book Summary:
Consciousness and the
Brain
79
Gears vs Behavior
79
Strategic implications of
AIs' ability to coordinate at
low cost, for example by
merging
82
Book Review: Secular
Cycles
82
Some Thoughts on My
Psychiatry Practice
82
Coordination Surveys: why
we should survey to
organize responsibilities,
not just predictions
84.5
The Hard Work of
Translation (Buddhism)
84.5
[Part 2] Amplifying
generalist research via
forecasting - results from a
preliminary exploration

Rank
Title
Visualization
86.5
Soft takeoﬀ can still lead
to decisive strategic
advantage
86.5
Total horse takeover
88.5
Complex Behavior from
Simple (Sub)Agents
88.5
Less Competition, More
Meritocracy?
90.5
Megaproject management
90.5
But exactly how complex
and fragile?
92.5
Trauma, Meditation, and a
Cool Scar
92.5
Turning air into bread
95
AlphaStar: Impressive for
RL progress, not for AGI
progress
95
Dishonest Update
Reporting

Rank
Title
Visualization
95
What are the open
problems in Human
Rationality?
97.5
Integrating the Lindy
Eﬀect
97.5
mAIry's room: AI reasoning
to solve philosophical
problems
99
S-Curves for Trend
Forecasting
100.5
Partial summary of debate
with Benquo and Jessicata
[pt 1]
100.5
The Power to Teach
Concepts Better
102.5
Instant stone (just add
water!)
102.5
Autism And Intelligence:
Much More Than You
Wanted To Know
104
Relevance Norms; Or,
Gricean Implicature Queers
the
Decoupling/Contextualizing
Binary
105
Rationality, Levels of
Intervention, and
Empiricism

Rank
Title
Visualization
106
The Zettelkasten Method
107
Two explanations for
variation in human abilities
108
No, it's not The Incentives
—it's you
Outlier: -11
109
Firming Up Not-Lying
Around Its Edge-Cases Is
Less Broadly Useful Than
One Might Initially Think
110
The Power to Demolish Bad
Arguments
111
Neural Annealing: Toward a
Neural Theory of
Everything (crosspost)
Outlier: -20
112
Dual Wielding
113
Approval Extraction
Advertised as Production
Outlier: -15
114
The AI Timelines Scam
Outlier: -13

Rank
Title
Visualization
115
Debate on Instrumental
Convergence between
LeCun, Russell, Bengio,
Zador, and More
What does this mean, and what happens now? 
(This section written by habryka, previous section written by Ray)
The goals of this review and vote were as follows: 
1. Create common knowledge about how the LessWrong community feels about various posts and the progress we've made.
2. Improve our longterm incentives, feedback, and rewards for authors.
3. Help create a highly curated "Best of 2019" Sequence and Book.
Over the next few months we will take the results of this vote and make it into another curated collection of essays, just as we did
with last years results, which turned into the "A Map that Reﬂects the Territory" essay collection. 
Voting, review and nomination participation was substantially greater this year than last year (something between a 30% and 80%
increase, depending on which metrics you look at), which makes me hopeful about this tradition living on as a core piece of
infrastructure for LessWrong. I was worried that participation would fall oﬀ after the initial excitement of last year, but I am no
longer as worried about that. 
Both this year and last year we have also seen little correlation with the vote results and the karma of the posts, which is an
important sanity check I have for whether going through all the eﬀort of this review is worth it. If the ranking was basically just the
same as the karma scores of the post, then we wouldn't be getting much information out of the review. But as it stands, I trust the
results of this review much more than I would trust someone just pressing the "sort by karma" button on the all-posts page, and I
think as the site and community continues to grow, the importance of the robustness of the review will only grow. 
Thank you all for participating in this year's review. I am pleased with results, and brimming with ideas for the new set of books
that I am looking forward to implementing, and I think the above is already a valuable resource if someone wants to decide how to
best catch up with all the great writing here on the site. 

Reﬂections on the cryonics sequence
Three months ago, I had a dream my mom died while cryocrastinating, and I decided
to ﬁnally start the process. I quickly found that it was ridiculously hard to ﬁgure out
what the process even was, and I thought, "huh, someone should really write a guide
on how to do this." And lo, I just spent the past three months writing that guide. It is
24,000 words long and took up about 90% of my working hours for the past three
months.
I knew very little about cryonics before starting the sequence. It took me about ﬁve
years after ﬁrst encountering the idea on LessWrong to feel comfortable enough with
it that I wanted to sign up. I still think it's an incredibly long shot, and I'm probably just
using it the way many people use religion - to stave oﬀ my crippling fear of death. I'm
just some random person, not an 'oﬃcial expert' or even someone who's that deeply
invested.
But I've already said everything I want to say about cryonics itself. This post is about
the other things I've learned.
First, I learned that I have a really great intellectual support community. Most of my
questions were ﬁelded by former housemates, coworkers, and erstwhile
acquaintances. Mati Roy was super helpful - he's a knowledgeable and committed
cryonicist who's embedded in all of the relevant conversations. My mom and sister
(both writers and editors in their own right) helped with last-minute proofreading. And
Habryka was a real sport all the times I got so confused about life insurance that I was
on the verge of tears (which happened periodically throughout the entire three
months); he even let me call him about it in the middle of the workday once.
But more importantly for me, I learned that I am capable of ﬁguring things out and
building an understanding of new areas. The skill of "research" always seemed to me
like a total black box, and I was told repeatedly it was a skill I didn't have - ﬁrst when I
washed out of the GiveWell Research Analyst application process at the ﬁrst step
(right after college), and later when I was put in a role where I was supposed to do
research and was repeatedly given frankly hurtful negative feedback that amounted
to little more than "you are bad at this, why aren't you better?" I ﬁgured that the
people around me who were doing "research" knew some magic secret that I didn't,
and I felt paralyzed and fell further and further behind.
But it turns out that "research" just means googling things, reading the relevant
results, and writing and talking through things until you understand them. You don't
need to have a fancy title or major in anything speciﬁc; you can just open your
computer and do research, any time you want. If anyone had explained that to me
back in that role, I probably wouldn't have failed so hard. 
Relatedly, in a recent job, my boss and I both decided I wasn't good at working on
large, loosely structured projects with no externally imposed deadlines. This was
partly a matter of choice (I wanted bite-sized assignments so that I'd never have to
take my work home with me), but it was also based on a time when my boss asked
me to do a thing due in two months and I basically completely forgot and didn't ever
make a real eﬀort. So, it was really cool, while working on the cryonics sequence, to
destroy the part of my self-narrative that said I was bad at large, self-directed projects.

I also grew up quite ﬁnancially illiterate, in an activist environment, with parents who
kept all of their assets in cash because they thought "investing is just gambling." So
I'm particularly proud of having gotten such a good grasp on the life insurance
landscape, even if my understanding is imperfect. That's the type of thing I was raised
to be afraid of - and I totally was afraid of it - but I kept going anyway. Pretty cool.
I am super done with writing for today, so, the end.

Covid 2/4: Safe and Eﬀective Vaccines
Aplenty
The vaccine data is in. It's pretty great.
We now have six known safe and eﬀective Covid-19 vaccines: Pﬁzer, Moderna, AstraZeneca,
Novavax, Johnson & Johnson and Sputnik.
Pﬁzer and Moderna are amazingly safe and eﬀective. They have been approved and are
being distributed. The problem is that due to our unwillingness to properly fund the process
of scaling up, we are stalling out at about 1.3 million doses per day for a population of 330+
million people each of whom needs two doses. That won't do, the vaccine rollout is going
about the way you would expect if you've been paying attention so far, and the English and
other variant strains are rising fast.
The other vaccine approvals are not in. It's pretty terrible.
Johnson & Johnson and Novavax are also safe and eﬀective, far better than we need them to
be. They both held onto their data longer than they would have in a sane world, and took
longer to collect it than they would have in a sane world, but there's nothing other than
bureaucratic delays now standing in our way. Johnson & Johnson is expected to get its
approval at some unspeciﬁed date, presumably this month. Yet there is no sense of urgency. 
AstraZeneca is even more egregious. There are doses ready to go, it has been approved by
major regulatory agencies elsewhere, and the main objections seem to be "the data isn't
from Americans" and "we're mad at you about previous mistakes so we need to punish that
somehow." We are still going to wait until April or so for the American data, plus the delays
after that, unless something changes and the new administration and/or the FDA see
themselves as suﬃciently blameworthy for not approving the vaccine. This badly needs more
outrage. There's an increasing amount, but so far it's nowhere near enough.
Sputnik is the least egregious. Not using it is going to get a lot of people killed, but it's a
Russian project largely motivated by national pride, that never held out any hope of
convincing us to trust it and always planned to distribute its doses in Russia and then the
third world, so I can sort of understand this one. I'll settle for the other ﬁve.
The short term situation is clearly headed in a positive direction. Death counts are being
remarkably stubborn, but are on their way down along with hospitalizations, case counts and
positive test percentages. By all metrics, every day we are a percent or two safer than the
day before, with politicians hard at work to bring the control systems back online. The
problem is that in the medium term, the English strain is coming fast and our current pace of
vaccinations isn't going to make much impact. 
The news on those strains is very much not the best possible news. It looks like the English
strain is more virulent than the old one, and also it seems to be picking up the mutations
that allow the other new strains to partially escape immunity from previous infections. If we
don't get our act together quickly, things could turn quite ugly quite fast.
Things should still have a few weeks of improvement left before that next crisis hits us, but
we'll have to pick up the vaccination pace a lot if we want that next crisis to not happen or
not be so bad. It's likely going to be close.
We'll also be losing the Covid Tracking Project soon. I hope that they'll guide me to
alternative data sources that do the job, but it could get considerably harder to stay on top
of things. 

Let's run the numbers.
The Numbers
We have a complication. The Covid Tracking Project has changed the way their data is
presented. This forces a choice between using a set of test percentages that is obviously too
high, or one that is substantially lower than the one I previously thought was most accurate.
I'll be using the smaller numbers. Presumably this is a diﬀerence like counting somewhat
duplicative tests instead of not counting them, but I'm not sure.
Thus, the numbers that use Covid Tracking Project need to be recalibrated. I've copied the
old sheet so we still have it, but the new sheet backﬁlls all data with the new numbers. 
Also, I looked at the data downloads I used to use to calculate regional positive test
percentages, and there's enough uncertainty and missing data points that I don't think it
makes sense to try and ﬁx it with the site going down in a month. I'll keep an eye out for
another source of that data that's in reasonably nice form, if you know of one please drop a
line in the comments.
In the meantime, one can rest assured that test percentages on the regional level are
roughly moving with test counts, as the testing situation seems to have stabilized as far as I
can tell. It's ﬁne to ignore this issue for a while, but I wouldn't want to ignore it for months on
end, so we'll need a ﬁx.
Predictions
Using the previous scale of test percentages:
Last Week's Number: 11.9% positive rate on 11.3 million tests, and an average of 3,043
deaths.
Last Week's Prediction: 10.5% positive rate and 2,900 deaths per day.
Using the new scale of test percentages:
Last Week's Number: 8.8% positive rate on 12.8 million tests, and an average of 3,257
deaths.
Last Week's Implied Prediction (using same ratios week over week): 7.8% positive rate and
3,103 deaths per day.
Results under the new system: 7.7% positive rate on 12.7 million tests, and an average of
3,041 deaths per day. 
Thus, once you recalibrate, we are on the scheduled path. 
Prediction for next week: 6.9% positive rate and an average of 2,750 deaths. Current trends
should continue, with minimal impact yet from new strains, changed policies or increased
vaccinations. 
Deaths

Date
WEST MIDWEST SOUTH NORTHEAST
Dec 3-Dec 9
2437 5508
4286
2744
Dec 10-Dec 16 3278 5324
4376
3541
Dec 17-Dec 23 3826 5158
5131
3772
Dec 24-Dec 30 3363 3668
4171
3640
Dec 31-Jan 6
4553 4127
5019
4162
Jan 7-Jan 13
6280 3963
7383
4752
Jan 14-Jan 20
5249 3386
7207
4370
Jan 21-Jan 27
6281 3217
8151
4222
Jan 28-Feb 4
5524 3078
8071
3410
There was quite the storm in the Northeast but I don't think that was driving the drop in
deaths that much but it likely contributed a little due to delayed reporting. Mostly I think this
is all real and even the South has now peaked.
Positive Tests

Date
WEST
MIDWEST SOUTH
NORTHEAST
Dec 17-Dec 23 439,493 271,825
419,230 236,264
Dec 24-Dec 30 372,095 206,671
373,086 225,476
Dec 31-Jan 6
428,407 251,443
494,090 267,350
Jan 7-Jan 13
474,002 262,520
531,046 306,604
Jan 14-Jan 20
360,874 185,412
452,092 250,439
Jan 21-Jan 27
260,180 158,737
386,725 219,817
Jan 28-Feb 3
191,804 122,259
352,018 174,569
We see clear improvement all around. One needs to remember that things remain at a very
high level even with the drops so far, and will continue to do so for a while. It's easy to
mistake improvement for being at a good level, and we're not at a good level. We should
continue to see another few weeks of improvement along similar lines, at the end of which
we still won't be at comfortable overall levels, but it will be substantially better than now.
Test Counts
Date
USA tests
Positive % NY tests
Positive % Cumulative Positives
Dec 10-Dec 16 13,438,613 11.1%
1,444,725 4.9%
5.14%
Dec 17-Dec 23 13,363,172 11.1%
1,440,770 5.1%
5.60%
Dec 24-Dec 30 11,300,924 11.2%
1,303,286 6.0%
5.98%
Dec 31-Jan 6
11,649,640 13.3%
1,365,473 7.3%
6.45%
Jan 7-Jan 13
13,911,529 12.2%
1,697,034 6.6%
6.97%
Jan 14-Jan 20
14,005,720 9.7%
1,721,440 5.9%
7.39%
Jan 21-Jan 27
12,801,271 8.8%
1,679,399 5.3%
7.73%
Jan 28-Feb 3
12,257,123 7.7%
1,557,550 4.6%
8.02%

Note the change in the old numbers, and recalibrate what the numbers mean going forward.
This is good news, but it isn't great news or as good as it looks, and it isn't enough to
overcome the new strain. Previously we measured the peak at 16.4%, now it's being
measured at 13.3%.
Covid Machine Learning Project
The model sees the control system kicking in and edging our R0 back up to 0.92 by January
20. It seems clear it's still below 1, but not that much below 1. We see the stalling out of ﬁrst

vaccine doses, as the number of available doses is scaling up painfully slowly and more
doses get diverted to second doses. 
As of January 20 this sees 26.6% of the population as having been infected, up from 25.7%
on January 13. 
Vaccinations

The average is up to 1.34 million doses per day versus 1.21 million doses per day last week,
but the increase is in second doses many of which were held back in various places (despite
instructions not to do this, I'm conﬁdent this was frequently ignored). Even worse, the
averages have stalled out over the past few days. We should expect things to pick up in
March and April for multiple reasons, but the near term outlook isn't great.
Europe


The United Kingdom's case counts started declining on January 9, so we're ﬁnally starting to
see the corresponding improvement in deaths. Everything seems to be a continuation of
previous trends.
South African Strain
It looks increasingly like the South African strain reduces, but does not eliminate, eﬃcacy of
vaccines and of previous infection. Here's a thread discussing, which links to another few
good threads as well. The Novavax vaccine's eﬀectiveness dropped oﬀ substantially but less
than half, and we see similar results from Pﬁzer and Moderna. 
Worth keeping in mind that in all these cases, eﬀectiveness versus severe disease,
hospitalization and death is higher than eﬀectiveness against all reinfections.
There were a lot of reinfections in the South African study. This thread does a good job going
over the details but misses the obvious interpretation:


The obvious thing that Crotty is missing here, which I keep having to point out because
everyone constantly ignores it, is that people do not get infected with Covid-19 at random.
People get infected proportional to the amount of risk they take. The people who previously
got Covid-19 both were previously taking more risk as a group, because that's how they got
infected, and also were likely taking even more risk now, because they had multiple reasons
to think themselves relatively safe. 
So if we get equal rates of infection between the previously infected and the previously not
infected, that is entirely consistent with 50% protection. What we actually learned here is
that the two eﬀects likely have similar size. The chance of reinfection by the South African
variant is roughly the same ratio as the risk proﬁle of people who were previously infected
versus previously not infected. If we can solve for one, we can solve for the other, which
seems pretty exciting actually.
From Crotty's thread, we know that from antibodies alone we might estimate 50% protection
is retained against the SA strain from previous infections, but we also should expect
mediation by T Cells and other methods, so we should expect more than 50% protection to
remain. That also jives with any reasonable estimate of relative risk-taking, since both have
to give the same answer. It would shock me if the ratio of risk between the infected and non-
infected wasn't more than 2:1.
One reasonable prior for the actual ratio is that the J&J vaccine's relative eﬀectiveness
should apply. Thus, against symptomatic infection, we have 72% eﬀective in America versus
57% eﬀective in South Africa, for immunity being 79% as eﬀective. That would imply
somewhat under a 4:1 risk ratio for the infected versus non-infected (since they should
match the asymptomatic risk ratio, which should show less eﬀectiveness), which also makes
sense to me and if anything seems a little low. 
Also, the South African strain is here, and there's community spread, identiﬁed in South
Carolina (WaPo).
English Strain
More evidence that it's more virulent, although the overall virulence on display here is not
high:

Even worse, it looks like it's acquiring the mutation from the South African strain, because
that mutation is inevitable under current conditions...

In Denmark they have a lockdown that is rapidly bringing down cases, and thanks to
frequent sequencing we know that it is almost good enough to stop the English Strain (B117)
but not quite, with estimated R at 1.06, again Kai in this thread from this Science article.
Given that it's still the heart of winter and we can get help from more vaccinations, it seems
like Denmark should be able to 'win' the endgame, but at the cost of months of additional
hard lockdown.  
The Pﬁzer and Moderna Vaccines
There's more data coming out of Israel, because Israel collects data. It looks highly
disappointing, likely because there's a lot of asymptomatic cases being picked up, where
eﬀectiveness is lower, but also lots of confounding stuﬀ going on in all directions:


There's a big push by everyone, and I am no exception to this, to boil down the eﬀectiveness
of a vaccine to one number. It increasingly looks like it does not work that way. The vaccines
are better thought of as being protective at each stage of the disease. Thus, they protect you
from being infected, then if you are still infected they protect against symptoms, then
against severity, then against hospitalization, then against death. You're in a better position
the whole way. 
That means that you are personally very very protected from the worst outcomes and
vaccinated people are going to be at minimal risk themselves, but their chance of being
infected won't improve as much. What about infecting others? That will be somewhere in the
middle. All infections are not created equal, and any given infection of someone who was
vaccinated is less likely to be symptomatic, and so almost certainly similarly less likely to be
infectious slash likely to be less infectious, at any given time. 
This does update me against acting as if fully vaccinated people don't pose risk to not-yet-
vaccinated others, so precautions in those situations look more sane, as does the case for
continuing mask wearing and social distancing in general until things are suppressed. If all
parties involved are vaccinated, that's another story.
If you're running out of vials in which to put your vaccine, you should put as much as
possible into each vial, and also yes more money would have accelerated vaccine production
and more money still could do so. Moderna is therefore asking the FDA permission to put
more doses in the vials, which somehow they need to do, and also the answer wasn't 'yes of
course do that I know technically you had to ask but this really, really isn't a question.' The
contrast with Pﬁzer's 'I know you're using that sixth dose so we don't have to give you as
much vaccine' is rather stark.
We'll get right on that request, Moderna!

I think this is being too charitable. The correct timeline involves not having to check at all,
and correct timeline where approval is necessary to avoid other stupid cases doesn't waste
the day conﬁrming and you get a yes during the call. Also, note that this is saying the FDA
could approve it within weeks, but also might not. We're supposed to think this is fast and
praiseworthy for literally 'put more of the same liquid into the same vials.' That's the
standards we're judging ourselves against these days.
Also, this anecdote is not exactly comforting:

This is also food for thought:
The AstraZeneca Vaccine
At least Europe has approved the vaccine, even if they didn't look at all the data, and took
way too long to look at the data, while ﬁghting in public about not getting their fair share for
a vaccine they hadn't even approved yet and which they delayed by months haggling over
pennies, and with the potential hesitations to use it on people who need it most because 'no
evidence' in older people. 
But, seriously, good decision.
On the issue of pregnancy, they issue this stark warning:

Yes, I agree. We should only consider doing things when the beneﬁts outweigh the risks.
The beneﬁts outweigh the risks. 
The news is great all around:

Delaying the second dose appears to actively make the second dose more eﬀective. Which is
common for vaccines.

Thus, the admission that delaying it is 'reasonable.' If we were considering switching to
faster second doses, rather than the other way around, 'experts' would consider it reckless
and irresponsible.
In the meantime, the single dose alone is 76% eﬀective, presumably against symptomatic
infection (WaPo) and was found to be 67% eﬀective against further transmission. Because
we need a study to generate headlines or quotes like these:
What the hell is up with the word "may" in these sentences, anyway? I'm pretty sure we
don't need a study to know that vaccines "may" prevent transmission.
Unless AstraZeneca is committing outright fraud, the data shows the AstraZeneca vaccine is
safe and eﬀective, and every day that we do not approve it will cost lives for no reason
whatsoever.
AstraZeneca has not applied for emergency use authorization, because it has been told not
to do so. If told to apply, they would doubtless quickly apply. Or you could of course approve
it without an application. The regulatory norms were made for man, not man for the
regulatory norms.
The good news is that the factory is running despite our failure to act. We are sitting on tens
of millions of doses of a proven safe and eﬀective vaccine. They're sitting around in
Baltimore waiting for approval. 

How long it takes us to approve this vaccine is a major test of the Biden administration.
A test they have clearly already failed, and continue to fail. We must make it clear how
unacceptable this is. The only way to give the people involved a path to doing the right thing
is to let them point to how blameworthy they would be for not doing the right thing, within
the next two weeks. To that extent, I am interested in assigning blame. 
So I'm in favor of such true and culturally heartwarming summarizes as:
To that end, there's even a planned protest at the FDA building to call for vaccine approvals.
Whether or not anyone shows up or listens, it's a great idea. 
The Johnson & Johnson Vaccine
As always, every headline writer has a choice to make.
Option one is to point out that the Johnson & Johnson vaccine is inferior to the Pﬁzer and
Moderna vaccines. One can say something based on "J&J Vaccine 66% Eﬀective Against
Moderate to Severe Covid-19."
Which, while a hell of a lot better than 0%,  is deﬁnitely not 95%. This sets up a deeply silly
'should we approve it?' debate and a (slightly less silly given you could potentially hold out
for something better personally) 'should you want this vaccine?' debate. As a bonus, one
gets to set up permanent fear, uncertainty and doubt, so you can demand indeﬁnite
Sacriﬁces to the Gods despite vaccinations.
Another option is to take sides and lead with the takeaway conclusion despite not
understanding how good the J&J vaccine is, because a much worse version would still be
good enough:

Or, you could go with something like this Bloomberg headline instead (twitter link, data):
Not only no deaths but also no hospitalizations in the treatment group is pretty great. If you
get this vaccine and wait a month, you deﬁnitely have to worry that you might then infect
other non-vaccinated people, but you do not have to worry about dying from Covid-19. 
I'd pay a substantial amount to get Pﬁzer or Moderna instead of J&J if I could get either one
today, but given the choice between waiting and taking what's available, I will happily accept
the J&J vaccine now rather than hold out for Pﬁzer or Moderna. 
Thus, as something we can give to the whole population, as a one dose vaccine that only
requires regular refrigeration and can be produced in massive quantities - J&J is promising
100 million doses by April and a billion within the year - this will do nicely.
It is worth noting that the one dose Johnson & Johnson vaccine shows similar beneﬁts to the
ﬁrst shot from Pﬁzer or Moderna. The diﬀerence is that Pﬁzer and Moderna then give you a
second shot. 
Thus, Johnson & Johnson has done us the valuable service of not testing their vaccine with a
second shot, thus allowing us to do First Doses First and get on with vaccinations twice as
fast. If we decide later that we should double back and give a second shot  to make it more
eﬀective, once we have suﬃcient supply, that's great. 
Given our current 'medical ethics' regime, it is important to test exactly those options that it
would be good to enact, and to not test anything that else. Whenever you have another
option, that option can create ethical obligations, and also choices are bad because they
make you blameworthy for all opportunity costs. Better to only have the one good option. 

Of course, if had turned out that J&J's vaccine worked with a second shot but didn't with only
one shot, and we only tested one shot, that would have been quite bad. The good news is
that early phase trials are very good at testing for antibody response, so we already knew
the answers before we started the test.
The bad news of course is that thanks to the FDA, we (once again) had to wait for the test
anyway, and then wait for the evaluation, which we are (once again) still waiting for, despite
'hot damn look at this chart' and meaningful side eﬀects best described as 'none
whatsoever.' Despite that, I'm writing this section on Sunday, and I would be shocked if I
have to go back and edit it. 
While we wait, the FDA is doing its usual thing of not releasing its information yet. It typically
releases two days before the meeting.
Moderna scientist who worked on their vaccine agrees that J&J's vaccine is 'darn good' and
warns to let the perfect be the enemy of the good. 
Eric Topol looks at the results and reaches similar conclusions, that J&J vaccine might have
issues with continued asymptomatic transmission but oﬀers great protection to the person
vaccinated and is a 'very eﬀective' vaccine. 
Unless Johnson & Johnson is committing outright fraud, the data shows the Johnson &
Johnson vaccine is safe and eﬀective, and every day that we do not approve it will cost lives
for no reason whatsoever.
How long it takes us to approve this vaccine is a major test of the Biden administration.
The Novavax Vaccine
Let's not forget that there was another vaccine that came out with results this past week.
Novavax was found to be 89.3% eﬀective for preventing symptomatic Covid-19, which as
we've learned presumably means less than that against asymptomatic Covid, but far more
eﬀective against hospitalization and death. A post-hoc analysis found 95.6% eﬀective versus
old variant and 85.6% eﬀective versus the new strain, and there was only 60% eﬃcacy
against the South African strain in the South African leg of the study. It seems clear that the
SA variant partially escapes, but does not fully escape.
Did anyone else notice that the South African leg's headline was "90% of cases attributed to
escape variant" to make people think about 90%, then in the non-bold print it mentions the
60% eﬃcacy? 
Alas, there is a major problem, which is that the study wasn't conducted in the United States.
Therefore, they are 'in talks' with the FDA about asking for emergency use authorization, but
it has yet to announce that it will even seek approval before its 'Prevent-19' American study
is complete. But that study is still recruiting patients, so it'll presumably be a few months, at
which point the vaccine will be mostly unneeded here (but will still do a lot of good
elsewhere). You see, last year the FDA graciously said that outside data could be submitted,
but you need to talk to the FDA ﬁrst on a case by case basis. 
The lack of reciprocity in approvals between the US and UK/EU or other ﬁrst world nations is
senseless and costs lives and money and stiﬂes innovation, but at least I understand it. You
don't want to trust your regulatory decisions to another country. Easy thing to get. But it's
worth periodically pointing out that this thing where we don't have data reciprocity is
completely insane. 

First we mandate detailed three-step data collection. Then we ban any eﬃcient method of
data collection. Then we ban any method of data collection that isn't done here in the United
States, out of some bizarro FUD that Our Humans Are Diﬀerent or something. Which sort of
makes sense for Japan under normal circumstances, if you don't do cost-beneﬁt analysis, but
enforcing it here on English data during a pandemic is something else. 
Then, of course, we mandate where the vaccines are made. Even more vaccine nationalism. 
Unless Novavax is committing outright fraud, the data shows the Novavax vaccine is safe
and eﬀective, and every day that we do not approve it will cost lives for no reason
whatsoever.
How long it takes us to approve this vaccine is a major test of the Biden administration.
When we see an article called "Biden's Latest Move Just Handed The Vaccine Market To
These Two Companies" it should be about how they won't approve anyone else's vaccine,
not about how Biden wisely is buying enough doses from those two companies alone to
vaccinate everyone if necessary. We should do that several times over to be safe.
The Russian Vaccine
Beep. Beep. Sputnik works too. Data source here. 


That chart sure looks familiar. 90%+ eﬀective against detected infections (at this point, I
expect eﬀectiveness versus all infections to be somewhat lower, but for a bunch of
asymptomatic and largely not so infectious infections to get missed and for those to be
prevented less often, slash more infections are contained before they become detected.) 
And once again, prevents all cases of severe disease. Nice.
There's also a New Yorker article on Sputnik's development. 
That article explains that we must deny approval to this vaccine because the people involved
did not Follow Proper Procedure, and therefore must be punished:

Don't get me wrong. There are some details that are indeed rather suspicious, and some
process decisions that are highly suspicious. Putin and company are highly, and highly
suspiciously, motivated to show good results quickly. Timing in several cases seemed
motivated by getting there ﬁrst, or not being outdone, or modifying eﬀectiveness to match
others' results; see the full post for details. 
And suspicious one should therefore be. All of this must be veriﬁed. Which won't happen, in
part because given that we wouldn't approve things anyway, they're not about to give us
that ability. 
But also the author is completely correct on this:

That's the test. Would you put it in your arm rather than do nothing? And if the answer here
is no, then, please, show your work.
I'm fully aware of the reality that we'd never use a Russian vaccine no matter how good the
evidence and likely neither will Europe, purely because it is Russian, but there's nothing
stopping us from doing so, and there being no chance of actually approving the vaccine (to
the extent that there won't be an application) doesn't make the words any less true, so...
Unless the Russians are committing outright fraud, or there are side eﬀects of which I'm
unaware or that they are hiding (in this case, that caveat does seem necessary), the data

shows the Sputnik vaccine is safe and eﬀective, and every day that we do not approve it will
cost lives for no reason whatsoever.
How long it takes us to approve this vaccine is a major test of the Biden administration.
The Amazing Race
We had another episode this week (WaPo), as a lucky late-night freezer failure in Seattle sent
hundreds into a frenzy. 
By morning, they'd used all their vaccine shots. It doesn't always quite work out that way,
but it is the default result, despite people not planning for such situations and engaging in
what is clearly full improvisation. 
For those who don't think we'd get up in the middle of the night to get a vaccine shot, not
only would we do that, some of us will get up in the middle of the night to look for an
appointment for a vaccine shot:
Also, they want to make it clear that this is not the hospital's fault, it's our fault because
everyone was 'getting used to' the requirements:
Overall, I strongly approve of the conclusion:
Except I would then, you know, have them implement it anyway.
Vaccine Allocation By Politics And Power

When you allocate by politics and power, you also allocate technological contracts and
logistics the same way. Some places were so foolish they decided to use the CDC's software
to schedule appointments, that it paid $44 million to create.  That turned out about as great
as you'd expect.
You see, there is only one company responsible enough (read: connected enough slash
paying enough bribes) to be able to do this job:

The whole article is full of failure, so kind of read the whole thing but also kind of no need.
As usual, when something fails a lot of people, that is cited as an 'equity' concern rather
than a 'failing lots of people' concern.
This is all business as usual. I'm not exactly surprised or outraged, but I want to make it clear
that this is business as usual so maybe don't give these people our business:

They let counties set their own additional requirements, on top of anything from the states.
Some counties decided to engage in vaccination nationalism, excluding anyone from outside
the county, putting pressure on others to follow suit. There's also outrage about people
travelling within counties, such as between parts of Manhattan, where all vaccination sites
are now scrambling to promise they'll prioritize the way the powerful people want rather
than by which eligible people attempt to get appointments.  
There's also the issue that counties in New York aren't allowed to vaccinate seniors or
anyone not on their particular priority list, even if those people are eligible. That's a diﬀerent
department.
My grandparents are getting told that they can't make appointments outside their county,
but their own county allows outside appointments, so there aren't any appointments
available in their own county either. A prisoner's dilemma that everyone saw coming. 
This was the report this week from Arnold Kling:
So little text, so many failures. First, we let him make the appointments, then we cancelled
them over a spat between counties. I wonder how often such cancellations get replaced in
time.
Then we managed to downsell the vaccine and botch the distribution and stories about
distribution so much that he's not even feeling sad about it. Let alone outraged. He's under
the impression that the vaccine is maybe 90% eﬀective, when it's 95% eﬀective against
symptomatic Covid, and more eﬀective than that against hospitalization and death. But even
relatively attention-paying people don't realize.
Then there's the story he linked to, about a Maryland couple waiting hours indoors on a line
to get their shots. This is not par for the course, but it's scary to even hear about, and given I
haven't heard that many vaccine stories, someone I read reporting back this way is a pretty
bad sign.

If you don't have the connections or savvy to get an appointment or on the approved lists,
you try whatever you can think to do, which results in having to tell people to stop calling
911 for a vaccine appointment.
Or you can sit there clicking over and over, hoping for the best:
Or, if you're a senior who lacks strong computer skills, you're eﬀectively out of luck and
behind others who are at much less risk but who have the ability to navigate such problems. 
Covid Tracking Project Calls It Quits
I've relied on them as my source of data all the way through, so it's pretty scary to suddenly
see this:

This was their post explaining their decision. At core, they say this is a government job, and
now that the government will actually do it, they can stop. I wish I shared their conﬁdence.
They'll be spending the next few weeks telling people like me where to go to ﬁnd the data
elsewhere, which hopefully will work out.
A big thank you to everyone involved in the project. You've been invaluable over this past
year, and you've done it all on a volunteer basis. I'm sure it has cost many of you dearly, and
I can't be at all upset about the decision on ﬁnally hanging up the hat.
Still, if we can take up a collection and change the answer, I'm deﬁnitely up for contributing. 
Your Periodic Reminders (You Should Know This
Already)
The Pﬁzer and Moderna vaccines are super duper eﬀective, in practice much more than 95%.
We should at most give those who already got infected one vaccine dose, for reasons that
should be obvious. Now we have a study backing that up, for those who deny knowledge
outside of studies can exist. 
We should give Dolly Parton her vaccine shot. This waiting until other people to get it ﬁrst
despite being instrumental in funding the vaccine thing might seem noble but she's 75 years
old, and also people who are instrumental in funding the vaccine need to get ﬁrst crack and
if we don't give them that then we really don't deserve her. Especially if her shot in arm
could help get people to accept the vaccine. What we actually deserve, it seems on every
front, is a Super Bowl ad about having a gig economy side job for which she re-recorded her
hit song as "working 5 to 9." Therefore, that's what we are going to get. Go Chiefs. 
We should approve more vaccines and vaccinate more people faster (MR).
We should work to expand vaccine manufacturing capacity by spending more money
(paper).
We should do human challenge trials and not doing so is a massive fail.
We should at least not let trivial issues massively slow down the world's most important
activity. From the New Yorker article on Sputnik, on how one incident cost us over a month on
the only AZ trial the FDA will accept because it's the only American one:

We should approve the Lilly antibody cocktail.
We should let people make a proﬁt oﬀ vaccine distribution, rather than shutting them down
when we notice them claiming the ability to do so.
We should be doing more rapid testing and almost everyone arguing against them is either
deeply confused about what matters and/or is arguing in bad faith. They work wonders. Also
the arguments keep repeating and I don't want to write the same thing each week.
We should consider that the FDA's current actions are likely government in America at its
theoretical best. Anything else you ask it to do, it will probably do worse than this. 
We shouldn't do what the link does and make our headlines and top cares about who is and
isn't blameworthy, but we totally should let Merck and anyone else without a working
vaccine manufacture the approved vaccines. And put in large orders. If any of the original
developers objects, pay them full price and also pay Merck full price. I really, really don't
care about that, any more than I care about who is to blame or whether they would have
backed these proposals three months ago. And also they oﬀer support for approving (and
even better, for subsidizing) any and all rapid tests.
Not that it would be that easy. There's a bottlenecked step, the creation of Lipid
Nanoparticles (LNPs) for the mRNA vaccines, which the other companies can't obviously help
with. At least, not right away, but I'm betting they could help scale up, although you could
also just pay Pﬁzer and Moderna more money. Also, this week we learned that Moderna
literally is out of vials and is asking the FDA permission to ﬁll them higher, and is waiting
around for a few weeks on that, so yes a little help might be in order. As a fallback, the
pharma companies whose candidates failed don't need to produce the mRNA vaccines from
Pﬁzer and Moderna, if they can't do that, but I strongly suspect that if they had the right to

produce the Oxford vaccine, or the Johnson & Johnson or Novavax vaccines, that would go
rather smoothly, because that's a more standardized process.
Then again, the person saying it cannot be done should never interrupt the person doing it:
You can go to a pharmacy or other location doing vaccinations, and oﬀer to take a dose
that's going to be otherwise thrown away. Sometimes this works. The media and other Very
Serious People, of course, will call you a 'vaccine hunter' and 'line jumper' who isn't being
'fair.' What those people should have done, these experts say, is let those doses get thrown
into the garbage. Much better, and you deﬁnitely totally shouldn't get vaccinated with an
otherwise-to-be-discarded dose, because that would be very unethical and inequitable, and
that stuﬀ matters so much more. You selﬁsh bastard.
If you require papers in order to travel, criminals will sell travellers fake papers, even if those
papers are negative Covid-19 tests. 
If you tell college students not to party and follow the rules, they will break the rules and
party anyway. 

This was actually a case of a failure to zero out. Physicists tried to model everything that
happened on campus, the distances between students, and dangers of each activity. They
made an insanely complicated model, which they thought had room for error. The problem is
that once your model tries to model something, if you miss any components or mess up any
components, now you get the wrong answer. One ludicrously wrong input - in this case
assuming everyone would follow the rules, despite everyone being college students - and
your results are meaningless. 
That's why I try to stick to much simpler models that allow us to take into account the factors
that we can't model directly, by using inputs that incorporate those factors. It's the only way.
Even if they hadn't made this particular dumb mistake, they doubtless had lots of other
mistakes, and lots of other places where they had to guess because we banned experiments
and don't know the answer.  
All the modeling eﬀorts talked about in the write-up are doomed because they don't
understand the role of the control system, and I couldn't bring myself to read the whole thing
because it's very long and boring.
Those taking mass transit need to wear masks. The CDC has now caught on and announced
a mandate, and only about a year late and after the President signed an explicit executive
order.
(Tweet, Link):

A reasonable case against Dr. Fauci. It is a good question what would have happened if he
hadn't tried to 'handle' Trump and instead spoken out using his authority in his ﬁeld. The
weird thing about this case is portraying Fauci as 'truth teller who compromised to keep his
job' instead of 'strategic liar who knows the truth, who compromised that approach to keep
his job' which I think is closer to accurate. Either way, there are reasonable arguments for
and against Fauci's tactical decisions.
And ﬁnally, never forget that it can always, always, always get so much worse:

No, really, it can always get worse (from my Bloomberg daily Covid update email):

We Can Still Agree: Andrew Cuomo Is The Worst
Credit where credit is due, I don't want to defend him either but it's only fair, sometimes
stopped clock successfully tells time, I don't trust them either:
Then again, in practice this means he scorned the people explicitly in charge of planning
distribution of a vaccine in exactly this situation, and instead improvised something new

based on those closest to him on the ﬂy (NYT so no link), which doesn't seem like it would be
expected to be better.
Cuomo is reopening indoor dining, despite conditions being worse than when he banned
indoor dining, and there being a higher payoﬀ to staying safe now than before due to
vaccination progress, and despite the new variant coming soon that's easier to transmit:

To justify this, he's distorting data in a way that would shock even psychiatric researchers. 

If you don't want to call this fraud or lying, what would you like to call it instead?
When called out on it, he issued this "corrected" graph:

The green circles are a hint, as is that the graph starts lower than it ﬁnishes. Huh. 
I leave 'spot all the other ways this graph is wrong' as an exercise to the reader.
In Other News
A report this week of someone making their own vaccine. The question is whether it will work
(and of course, whether it is entirely safe). This is pretty great in the context of doing it For
Science. Plausible experiments are almost always positive expected value given how they
can scale. In terms of whether it's a good idea to do this for your own beneﬁt, it seems like
it's rather late in the game for that, but I'm not going to attempt to render a verdict.
Biden continues to do some of the obvious things pure wins we weren't doing before, even if
they're not the most important ones:

In context I can't tell if this is talking about the constrained supply of vaccine doses, or
referring to the real actual shortage of vials to put vaccine doses into, which is awaiting the
FDA hopefully agreeing only a few weeks from now to let Moderna put more doses into each
vial. 
Also we're ﬁnally doing this:
Here's the scope of what to expect, looks like CVS can't quite do our entire current pace on
its own, we'd need to also use RiteAid and/or Walgreens:

Teachers' unions in many areas continuing to ﬁght for the right to not teach children:

As always I'm torn because I consider school as it existed in 2019 in America a prison and a
dystopian nightmare, but somehow remote learning has managed to be much worse, and it
might never end, or at least go on for years, for those who can't aﬀord private school. The
kids are not going to be alright.
There's a disturbing pattern of people who get Covid-19 also getting diabetes, both Type I
and Type II (WaPo). Unclear how often those people remain diabetic, but it's one more reason
to not want to get Covid. 
Canada doesn't seem to be following up that often to check on whether travellers are
quarantining. But of the 3% or so they do follow up with, they claim that over 99% are
complying with the rules. Would they like to buy a bridge, or perhaps Niagara Falls?
Pasteur Institute abandons its eﬀort to create a vaccine after disappointing test results.
Presumably it was too late to matter anyway, better to scale up what we have. Story seems
to mostly be about French national pride and how they no longer have any.
Far right anti-vaccine protesters blocked access to the mass vaccination site at Dodger
Stadium, forcing it to shut down for a day. Somehow we did not simply physically remove
them. Instead, major news outlets are asking what sites helped organize it (in this case, it
seems, Facebook) so they can demand censorship. 
Global forecast for who will get vaccines this year. Thread discussing it here. 
I'd like to thank Scott Sumner of The Money Illusion, author at EconBlog, writer of the
excellent Great Depression gold standard book The Midas Paradox and top relentless
advocate of the obviously correct Fed policy of NGDP targeting that I wouldn't know about if
not for him, for sending people over to my posts. He's worth reading if his interests are
relevant to your interests. He should also know that I've been unable to load The Money
Illusion for months now but still read it through my RSS feed. His econLog posts are on
average better anyway, as he readily admits. Some highlights of his on Covid are Selective

Outrage, Markets Are Good At Allocating Resources and Regulation It's Much Worse Than You
Think. The titles say it all but the details are solid if you want them.
Curative is providing massive amounts of testing, and wants to test asymptomatic people
because it's called testing. The FDA is pushing back and warning against this, because there
is a 'risk of false negatives' which is concentrated on weeks-old infections. It's not even clear
whether these 'false negatives' are an advantage or disadvantage, since detecting that
someone was infected two months ago mainly shuts down activity without reducing risk
much. What matters is active Covid. The FDA certainly seems from this reading to be
demanding that the tests become so sensitive that they detect completely inert quantities of
virus left over from old infections, and force such people into needless isolation, on pain of
not allowing people to learn about their status at all. The good news is, as the article notes,
lots of asymptomatic people are getting these tests anyway, despite the FDA's best eﬀorts to
get us all killed.
It's important to make disaster movies so that people only act as dumb as the stupid people
in disaster movies, becuase otherwise they don't realize they're not supposed to be even
stupider:
Matt Levine continues to be on ﬁre, it's important to remember there's life outside of Covid-
19, and I continue to recommend subscribing to his newsletter. In addition to coverage of the
entire GameStop saga, this was an example yesterday of "Matt says thing Zvi frequently
says, but incidentally says it better when covering today's ﬁnancial news":

The news allowed me to scale things back a bit this week, a trend that will hopefully
continue. I do not expect many surprises over the next few weeks. Then again, that's often
how surprises work. 

Second Citizenships, Residencies,
and/or Temporary Relocation
EDIT (4/20/21): I am occasionally updating this post at this
linked Google Doc with new information. You may wish to
instead read this post there.
Introduction
Over the past few years, I've gained an interest in securing options for residency
outside of my home country, in particular via second citizenship.
There are a number of potential beneﬁts that can arise from having a second
residency option. These include professional and education opportunities, other
economic opportunities, the ability to mitigate a variety of potential risks via
relocation, travel beneﬁts, and the potential extendability of these beneﬁts to a
spouse, descendants, or in rare cases friends and colleagues.
In this post I:
1. Share the reasons I've identiﬁed for securing a second residency
2. Provide thoughts on planning for a soon upcoming, largely unexpected
departure
3. Describe long-term options for alternative residency
4. Share my knowledge and experience toward securing a second citizenship
5. Provide the lessons I've learned in pursuing genealogy for the purposes of
securing a second residency
6. Share some other related topics I may write about in the future as an extension
of this post and oﬀer to help or connect people interested in securing second
residencies
Notes and Disclaimers
1. The original version of this post was written in early October 2020 and
commissioned by the Center For Applied Rationality (CFAR). It has been
somewhat reorganized for publication on this forum.
2. This document is written nearly entirely oﬀ memory. As a result, it is likely that
there are signiﬁcant mistakes. It's worth validating anything in here that you
plan to act on.
3. It is also written as a ﬁrst-pass, optimizing for sharing the information with
minimal time-investment. There may be cases of imprecise language, and
inconsistencies in presentation or organization, as a result.
4. I've pursued this topic out of personal interest, without an expectation that I
would end up sharing my knowledge of it. As a result, I typically only looked into
things to the degree necessary for my personal interest. I therefore expect this
document to not be comprehensive and for there to be a high level of

subjectivity in my account. Many opportunities are limited on the basis of
current citizenship or ancestral background.
5. You may want to navigate to sections of interest using the outline on the left
rather than read the post as a whole. The options that I've found most exciting,
because they are not well-known and can confer citizenship without relocation or
large ﬁnancial outlay, are Panama and the Ancestry Options. Unfortunately,
these won't be available to all readers. Luckily, you may ﬁnd other options
compelling.
Why Second Citizenships May Be
Useful
Second citizenships can...
1. Enable the counterfactual acquisition of desirable jobs:
1. Positions in the country of second citizenship that are not available (or not
available without signiﬁcant friction) to those without existing right-to-work
2. Positions in other countries that extend a right-to-work to the citizens of a
country in which second citizenship is secured (e.g. other EU countries)
3. National country government positions are sometimes reserved for
citizens.
4. The United Nations (UN) has some sort of system by which a person's
citizenship plays a large role in the possibility of their working for the UN,
even in unrelated positions. I don't know a lot about this, but I've been told
by many people that it is much more diﬃcult to enter the UN as an
American citizen than it is as a citizen of other countries. I've also been
told it's much easier if you hold citizenship of a country in which there's
less competition for positions, and most target countries for second
citizenships are likely to have less competition than most EA hubs. I am
uncertain to what extent this may or may not apply to other
intergovernmental (or nongovernmental) organizations.
2. Enable potentially valuable work-visitation ability:
1. Many countries, such as the US and UK, limit the length of work visitations
as well as the activities that may be done. If a citizen of a country you'd
like to visit for work purposes, you will not be subject to such limitations.
2. Some countries can be more easily visited as a citizen of one country over
another. For example, each citizenship I've investigated oﬀers visa-free
access to at least 5 countries that US citizens otherwise require visas for. In
particular, a few countries (Bhutan, Russia (possibly no longer), Brazil (no
longer)) have sometimes charged sizable daily fees for visitors from some
countries, while others can visit for free.
3. Provide access (or access at a much-reduced tuition) to Universities that were
otherwise inaccessible
1. In particular, low-cost universities for citizens are more available in Europe
than the US
4. Enable eligibility for various grants and scholarship programs
5. Provide access to social services (welfare, health care, maternal support, etc.)
that are superior to those in the country of ﬁrst-citizenship
6. Enable the ability to reduce risks, in particular in times of crisis, from a variety of
threats such as:
1. Authoritarian rule (by going to country of 2nd citizenship)

2. Nuclear events (relocation as either as a preventative or response)
3. Biorisks (relocation to a location that is better managed, in which the
threat is not present, that has earlier/easier access to drugs or vaccines of
interest, etc.)
4. Air quality (e.g. leaving urban China or India, or other locations that may
have a sudden decrease in air quality)
5. Natural disasters (preventative relocation or in response)
6. Escaping violence
7. Escaping false imprisonment
8. Leaving area of ﬁnancial or economic collapse (personal or systemic, as
long as one country provides superior opportunity)
9. Violence, imprisonment, restrictions on movement or activities while
visiting a country that is hostile (or has factions that are hostile) to your
country of origin
7. Provide economic opportunities
1. Lower cost of living via relocation
2. Lower taxes via relocation and dual taxation agreements
3. Cheaper access to key resources (University, prescription drugs, etc.)
4. Access to banking and investment opportunities reserved for citizens
8. Increase access to resources
1. Prescription drugs are often more readily available and less inexpensive in
non-U.S. countries
2. Some drugs (e.g. in cases of pandemic) may not be available to the public
in the US as early as elsewhere
3. Nuclear bunkers in countries that are more isolated
9. Provide opportunities for inﬂuence of additional national governments
10. Improve awareness and understanding of other cultures and value systems
11. Increase opportunities for enjoyment via visitation or residence in an area that
would otherwise be harder to visit or have restrictions on the length or type of
presence
12. Some of these beneﬁts may be extendable to spouses, descendents (ad
inﬁnitum), and (more rarely) friends or colleagues via inheritance or
sponsorship.
13. Some of these beneﬁts may become more pronounced if many in the
community secure the same second citizenship. For example, they could allow
for the creation of a new EA hub, group purchasing (e.g. a bunker in a country
that's less at-risk), group decision making to start EA-relevant programs at
accessible less expensive universities, etc.
Example beneﬁts someone may have had in
the current pandemic:
1. I know of a person on the Diamond Princess cruise ship that had an early COVID
outbreak who was able to leave it earlier as a result of his second citizenship. He
was a U.S. and Panamanian citizen, had pursued Panamanian citizenship solely
for the beneﬁts listed above, and Panama negotiated for his departure from the
ship and chartered a plane for him signiﬁcantly earlier than the U.S. did.
2. A friend was working for the UN in Nigeria when the COVID outbreak occurred.
The country was in lockdown, and she was unable to leave it. She is a dual
citizen of Germany and the U.S. Germany oﬀered her a chartered ﬂight to depart
Nigeria a month earlier than the U.S. did.

3. The US and UK are two countries that have particularly high case rates of COVID.
A second citizenship could have allowed relocation to a country with a lower
case rate (and better management).
4. Some COVID treatments are more readily available in some countries. For
example, Fluvoxamine may be a highly promising preventative of
hospitalization-worthy COVID. Many doctors seem quite hesitant to prescribe it
in the U.S., and a clinical trial includes a placebo arm, but I believe it is freely
and easily purchasable in some other countries. A number of drugs (primarily
those that have previously been used to treat other conditions) fall under this
category.
5. Many countries have provided greater social services (in particular direct
payments) to those who are unemployed during this pandemic than have others.
6. Health care for COVID, in particular should you be hospitalized, may be much
less expensive in some countries than in others.
7. The ability to search for jobs in multiple locations can be particularly valuable
during this time of mass unemployment.
Leaving the US in the Next 1-4 Months
(written Oct. 2020)
Short-Term Stays
There are a number of countries still allowing US citizens to enter as tourists.
1. The UK & Ireland may be particularly appealing, because they are English
speaking, have strong healthcare, and are in/near the EU.
2. Mexico is currently allowing US citizens to enter (via ﬂight only) as well.
Long-Term Stays
Most places will have limits to how long you can stay in them (e.g. 90 days for the UK
or EU). (1) (<- See footnotes) There are some options for more long-term stays, in
particular:
Estonia
Estonia has launched a 1-year visa for remote / digital workers. Though it was planned
for some time, that it launched during the pandemic is seemingly indicative of their
willingness to accept applications during this time.
1. The last time I looked, Estonia was not allowing anyone residing in the US to
enter. A reasonable plan seems like it may be to travel to the UK/Ireland and
then enter Estonia from there. (2)
1. I believe the UK & Ireland require a 2 week quarantine upon entry, and you
must have negative covid tests before exiting quarantine.
2. Estonia seems like a great option because it is in the EU. Presumably, one could
go to any other EU country once this visa is secured (although they may e.g.
require an Estonian permanent address or something... I'm not sure how or to
what extent Estonian residence may or may not be veriﬁed or required).

3. I expect this visa to be renewable, so this option may not be time-bound.
4. There are some EA connections to Estonia that may make this more appealing or
may be worth reaching out to if you have any issues.
5. I'm uncertain of the application & visa price; my guess is somewhere between
$500 and $4000.
Bermuda
Bermuda (overseas territory of the UK) has launched a 1-year remote worker visa as
well; particularly for the pandemic.
1. Bermuda may be particularly appealing because it is well-developed, English-
speaking, and close to the US.
2. You can go straight to Bermuda from the US; there's no need to e.g. go to the UK
ﬁrst like there is for Estonia.
3. I believe you need a negative test or two prior to your ﬂight in order to enter.
4. Reports on the quality of Bermuda's healthcare vary. I saw general descriptions
of it being strong while I also read speciﬁc instances of patients being
transported to the US for care.
5. I'm uncertain of the application & visa price; my guess is somewhere between
$1000 and $9000.
6. I somewhat suspect that Bermuda will accept applicants more readily than
Estonia, since this visa's creation is seemingly in direct response to the loss of
tourism revenue due to covid.
St. Lucia
St. Lucia has also launched a 1-year remote worker visa.
1. Like Bermuda, I expect St. Lucia may accept applicants more readily than
Estonia, given the program's creation is inspired by making up for lost tourist
revenue.
2. St. Lucia may be appealing for its weather and proximity to the US; I expect it's
healthcare to be worse than other presented options.
3. I'm uncertain of the application & visa price; my guess is somewhere between
$1000 and $9000.
UK & EU Tourism
You can spend 3 months in the UK and 3 months in the EU (e.g. via Ireland) to get a
total of 6 months abroad, which may be suﬃcient for most (or suﬃcient to plan
another option).
Germany
Germany has long had an independent contractor/entrepreneurship visa; I'm unsure if
it has been aﬀected by the pandemic. I secured this visa around 2011/2012. At that
time, the requirements to secure the visa were not too onerous and mainly involved
proof that you were staying in Germany, had suﬃcient funds, and were an
independent contractor or entrepreneur. I believe it was renewable indeﬁnitely.

One of the most diﬃcult aspects of securing it was that the required documentation
was a moving target; online sources conﬂicted with one another and each reviewer of
your application seemingly applied their own new criteria as well. As a result, one of
the most successful strategies was insistence; arguing with your reviewer and
demonstrating how you did in fact have suﬃcient documentation and that they were
wrong. Hopefully, this has now changed to be more straightforward and less
dependent on having a willingness to be highly insistent.
Portugal
I know little about it, but I believe Portugal has a visa you can secure with proof that
you plan to establish residency in Portugal and that you have a stable and regular
source of signiﬁcant income from abroad (enough to easily live oﬀ of).
Notes on How to Prepare and Leave
1. Refundable international ﬂights are available through United Airlines, American
Airlines, Southwest Airlines, and a few others. These are typically much more
expensive than normal tickets.
1. These may be appealing to book now; I can imagine that in a situation in
which a number of people want to leave the country, ﬂight tickets may
either sell out or rise greatly in price.
2. It may make sense to book tickets from multiple airports, to multiple
countries, and on multiple airlines, should you be able. This helps provide
options in case of diﬃculty getting to any speciﬁc airport, a country closing
down to US tourists, etc.
3. It may make sense to book tickets throughout the time of concern, e.g. if
you are worried about election-related violence you could consider tickets
throughout the November-January (inauguration) timeframe (or even
after).
2. Long-term visas should likely be applied for as soon as possible; although it may
be the case that the Estonian visa should not be applied for until you've moved
to another country.
3. If your passport expires prior to 6 months after your latest potential entry date
into another country, you may want to see if you can get it renewed and
returned in time. Many countries do not let people enter on passports that have
less than 6 months remaining validity.
Longer-term Options for Alternative
Residency
Residency can refer to citizenship, permanent residency, temporary (short- or long-
term, renewable or nonrenewable) visas, or visa-free visits.
Citizenship vs. Permanent Residency vs. Visas
vs. Entering as a Tourist
1. Citizenship: I ﬁnd gaining citizenship in another country to be highly appealing.

1. Pros:
1. Permanent, nearly irrevocable right to live and work in another
country. (3)
2. Provides access to social services (e.g. healthcare, welfare)
3. Provides access to consular services (e.g. protection in their
embassies, negotiation on your behalf)
4. Provides a passport
1. This can make it easier to enter some third countries; for
example, US citizens require sometimes-expensive visas to
enter Russia while citizens of many other countries do not.
2. Many have said that they feel like they're less vulnerable / less
of a target when traveling in countries where the government
or some citizens may be hostile to the US.
5. Typically inheritable by your oﬀspring and often makes citizenship
much easier for your spouse
6. Can be helpful for gaining international employment
7. May have social, emotional, or mental health beneﬁts as well.
1. Many say they feel more connected once they gain citizenship,
that they have rediscovered their heritage, they have more
conﬁdence since they have an escape plan, etc.
2. Cons
1. You're subject to the laws of that country. In practice, this seems to
rarely have a downside.
1. The most likely probably relates to taxation; most countries tax
only those citizens living in the country, but some (like the U.S.
and Israel) tax citizens living anywhere in the world. That said,
this then can get waived if the two countries have an
agreement not to double tax (the U.S. does with most
developed countries, Israel does with most as well, although I
think they're currently negotiating with Australia and it may not
be in-place yet).
2. If you break a law in your second country, your ﬁrst may be
unwilling to help you, since you're a citizen of that second
country.
1. (There are mixed reports about whether or not this is or is
not the case.)
2. You may need to maintain two active passports (a small ﬁnancial
cost). Most countries will not let their citizens enter on a foreign
passport.
3. A few countries require you to renounce your other citizenships upon
receiving theirs, or will disavow your citizenship if you acquire
another afterward. Sometimes this is speciﬁc to a certain country;
e.g. I believe Slovakia and Hungary are not on good terms and do not
allow dual citizenship with one another. This is rare but worth
verifying for your countries of interest.
4. Dual citizenship could potentially be detrimental to a political career.
2. Permanent Residency: The is one-step below citizenship, and is sometimes a
prerequisite toward obtaining citizenship.
1. Pros
1. Permanent right to live and work in another country, although it is
much more revocable than citizenship
2. Typically provides access to social services (e.g. healthcare, welfare)
2. Cons

1. Most (if not all) permanent residencies need to be 'maintained'
through physical presence in the country. The nature of this
requirement varies from country to country, although it is typically
quite signiﬁcant (e.g. 6 months+ in the country for 3 of the 5
preceding years).
3. Visas: These signify temporary permission to be in a country. Sometimes they
provide the right to work, while others only provide the right to be there as a
tourist.
4. Tourist: Usually when you enter a new country, you typically enter as a 'tourist',
whether or not that is your intention (e.g. most attendees to academic
conferences will typically enter the country as a 'tourist'). Some countries
require a visa for this, while others will provide a period of time under which you
can remain visa-free (e.g. the EU and UK provide 90 days). When you enter as a
tourist (whether visa-free or not), you do not have the right to work in the
country. (4)
Comparing Options Against One Another (5)
Generally, it is not necessary to limit your number of applications for residency or
citizenship. (6) That said, you may choose to prioritize on the basis of a number of
diﬀerent factors.
1. Ease of applying
1. Language requirements
1. Some citizenship programs require you speak the local language, to
varying degrees. For some you seemingly need to be B1 (7) or B2
conversational, while others only require an A1 or A2 level of
language ability (or no language requirement at all).
The way in which this is assessed varies as well. I've seen all of the
following as language assessment tools depending on the country
and program:
1. Oﬃcial language tests
2. Conversations in the language when submitting the application
3. Proof that you've taken a language course
4. Signed statement by two citizens that you know the language
5. Submitting your application in the language
2. Documentation requirements
1. Each citizenship program has quite varied requirements for
documentation. Any or all of the following documents may potentially
be required (though some programs require very little
documentation):
1. Birth certiﬁcates (for you and potentially some of your
ancestors) (8)
2. Your passport
3. Marriage certiﬁcates (if applicable, for you and potentially some
of your ancestors)
4. Death certiﬁcates (if applicable, for potentially some of your
ancestors)
5. FBI background check
6. Miscellaneous other documentation

You may choose to apply or not apply to  a program on the basis of which documents
you have available (e.g. which ancestors you have records for). It may be worth
applying even with a low likelihood of success if you have all the required
documentation to submit an application, while other programs that would very likely
be successful may not be worth applying to until the necessary documents can be
obtained.
The form in which these need to be provided may range quite a bit as well. The
following are the potential possibilities: 
1. Apostille: This is an internationally recognized seal that certiﬁes that a
document is genuine. It is typically provided by the government. You would
submit your document to the government in which it is issued to get it
apostilled, prior to submitting your application.
2. Original: Some programs ask for you to send the original documents. In most
cases, with the notable exceptions of passports, it seems apostilled and/or
oﬃcial copies are accepted even when the programs do ask for originals.
3. Oﬃcial copies: Governments can issue oﬃcial copies of documents at your
request.
4. Casual: Some governments aren't picky at all; I think because they expect to
verify the information via another method anyway. In these cases, you can e.g.
make your own copy of a document (rather than obtaining one from a
government) and submit it.
5. Reference: Some governments will look up the information or validate it
anyway, so you don't necessarily need to provide any copy of a document, just
information. For example, you might provide your date and place of birth rather
than a birth certiﬁcate.
6. (Oﬃcially) Translated: Some places are happy to accept documents in
whatever language they are in, others will accept documents in English or their
country's language only, and some will only accept documents in their own
country's language. Some will let you source the translation in any way that
works for you, but most seem to require an 'oﬃcial translation'. Oﬃcial
translation providers also vary by country; some require that their own
government translate the documents for a fee, while others have a large
network (including in the US) of oﬃcial translation services that they allow.
I track the documents required for each place I'm applying with something similar to
this linked sheet.
1. Cost
1. Purchasing citizenship can be very expensive ($35,000-$10M), and while
most other options for procuring citizenship are generally aﬀordable
($0-$350), some other programs can have fees that are quite prohibitive.
For example, 1-year work visas in Australia seemingly often cost in the
range of $3,500-$10,000. 
There may be other costs that are less obvious that are worth
consideration as well. For example, programs in Panama and Israel require
your physical presence in the country. Some programs require apostilled
copies of oﬃcial translations of a number of documents, which each have
low fees but can add up quickly. If you pay for genealogy assistance to
search for and obtain records, those costs can add up quite easily as well.
2. Ties to the country

1. Some countries require you demonstrate ties to the country and/or culture.
The two instances of this I've seen have been poorly speciﬁed and involve
signiﬁcant discretion in their assessment. I think these are often easy to
build, and may involve activities such as attendance at cultural events or
travel to the country of interest.
3. Likelihood of application being successful
1. While sometimes it can be very clear whether or not you'll successfully
receive citizenship or residency if you apply, I've more often found that
there's a level of ambiguity. This ambiguity can arise from:
1. New programs that aren't fully speciﬁed and are largely untested
(Austria's new citizenship via ancestry program announced Sep
2020)
2. Diﬀerences in program wording, implementation, or standards for
evaluation by individual or consulate
3. Discretion on questions of suﬃcient documentation, language ability,
etc.
4. Desirability of citizenship
1. Passport strength
1. There are three passport desirability rankings I'm aware of:
1. Passport Index Score
2. Henley Passport Score
3. Sovereign Man Passport Rankings (likely paid access only)
2. I've built this linked spreadsheet to identify what countries' passports
provide advantaged access to which others, compared to your home
passport. The visa requirements for every country combination from
Wikipedia articles can be pasted in, and then the formula extended
for new results. (9)
2. IHDI (Inequality-adjusted Human Development Index), Fragile States Index,
English speaking percentage of population
1. I use these metrics as ﬁrst-pass proxies for the country's personal
appeal and stability.
3. Other access (EU, Latin America group, East African group)
1. An EU passport tends to be highly valued due to the number of
countries to which it provides access. There's some sort of common
Latin American work & residency group as well, and I believe there's
one in East Africa.
1. In some cases these may provide the permanent right to live
and work, while others just make it much easier to do so.
4. Ease of citizenship for spouse and/or descendants
1. In many cases, you may value a citizenship more if it can be acquired
by a spouse and/or oﬀspring. The ease with which these happen can
vary.
5. Personal connections & feeling
1. I've found that I may in some cases have a higher likelihood of being
able to obtain citizenship to some countries to which I don't feel
connected, while there are others to which I do feel I have a stronger
ancestral or modern-day connection.
Options for Gaining Citizenship or Permanent
Residency

I've been surprised to ﬁnd that there are a number of options for second residency
and citizenship; they're often more accessible than I'd anticipated, though usually still
time-intensive and potentially diﬃcult to get. There are four categories of ways to get
a second citizenship / residency:
1. Miscellaneous: Some countries will grant residency or citizenship on the basis
of your religion, your current citizenship, and/or your educational and
professional achievement. Asylum may be a possibility in more extreme
circumstances.
2. Ancestry: A number of countries may grant you citizenship or residency if you
have ancestors from those countries. Some examples are: Italy, Ireland,
Lithuania, Latvia, Hungary, Czechia, Germany, Poland, Ukraine, Slovakia, and
Austria
3. Purchasing: A number of countries may grant you citizenship if you make a
large investment in the country or pay the government for it. This includes EU
countries (I think Malta and Albania). In most cases the cost is over $100,000,
but St. Lucia has a citizenship scheme that returns most of the money to you
after 5 years, with a net cost that is much cheaper.
4. Naturalization: Most countries will grant citizenship if you live there for a
period of time.
Miscellaneous Options for Residency or Citizenship (10)
Panama 
Panama oﬀers a "friendly-nations visa" that provides permanent residency. This is
instantly obtainable (no residency requirement), if you're a citizen of one of ~50
countries that they have selected. This is particularly appealing for a few reasons:
1. Instant access to permanent residency
2. This permanent residency is much easier to maintain than others
1. You are required to spend one day in Panama out of every two years to
maintain it. If you fail to, if you return within 6 years, they'll reinstate it
pretty easily.
3. This permanent residency takes you on a somewhat-easy path to citizenship.
You need to have permanent residency for 5 years, speak Spanish, and
demonstrate a connection to Panama. Given the ease with which you can
maintain permanent residency in Panama, you could be in the country 3-4 times,
for a total of ~2 weeks, and obtain your Panamanian citizenship (although you
may want to stay longer to better demonstrate a connection to Panama; some
citizenship applications that are technically valid do get denied).
4. I estimate the total cost to be $2-4k all-in to do this.
5. Miscellaneous beneﬁts
1. Panamanian citizenship is supposedly excellent for ﬁnancial security and
alleviating U.S. taxes as well.
2. A number of people report that Panama is very enjoyable to be in.
3. Panama outperformed the US in at least one instance with regard to
consular assistance after the coronavirus outbreak.
COFA: Palau, Micronesia, and the Marshall Islands
COFA stands for "The Compact of Free Association". It is an agreement between the
US and Palau, Micronesia, and the Marshall Islands. The summary of this agreement
that I've read states that in exchange for the US being able to maintain military bases

in these countries, the US provides nearly all social services for them (e.g. roads,
welfare, etc.). Additionally, the citizens of these countries have the permanent right to
live and work in the US, and citizens of the US have the permanent right to live and
work in these countries.
1. Pros:
1. Permanent right to live and work in these countries.
2. It seems you can enter each of these countries for 1 year visa-free (e.g.
without notice.) Then it seems you apply for a visa that they are obligated
to grant allowing you to stay longer.
2. Cons:
1. There is very little available information about the right for Americans to
live and work in these countries. I would not be surprised if some of this
information is wrong; I would not rely on this without verifying it ﬁrst.
1. I also have spent less time learning about this agreement than most
other things on this document. I could particularly be mistaken about
aspects of this one.
2. These are micronations; they likely are not used to new people moving to
them, probably don't have great healthcare, and likely are not very
economically developed.
3. Given the US's presence and inﬂuence in these countries, going to these
may not alleviate your concerns.
Israel
People who can demonstrate that they are Jewish (e.g. a letter from a synagogue,
ancestors' gravestones showing they were Jewish, etc.) are permanently entitled to
obtain citizenship.
1. Pros:
1. Citizenship can be instantly obtained upon arriving in Israel
2. Israel is a developed country with a strong economy and social services.
3. Upon obtaining citizenship, there are a number of beneﬁts provided
1. Waived taxes for 10 years!
1. (These may not be fully waived; maybe they're just reduced. I
recall being very impressed though).
2. Given Israel's agreement with the US, this can give you 10
years of lower taxation if you reside there.
3. If you were to e.g. inherit a lot of money in one year or realize a
large amount of capital gains, perhaps obtaining citizenship
and spending that one year in Israel would be highly ﬁnancially
valuable.
1. In that case, you may potentially delay your acquisition of
citizenship until that time.
2. A monthly payment for a number of years if you reside in Israel
1. (I think for a single individual this was about $300 a month; it
scales by family size and I may be wrong about the amount.)
3. Assistance ﬁnding a place to live
4. Free Hebrew classes
5. Probably quite a bit more
2. Cons:
1. While many countries allow you to obtain citizenship through your heritage
without ever visiting that country, for Israel you must go there and you

must demonstrate that you intend to move there for the foreseeable
future.
1. It may be the case that you are genuinely interested in trying-out
living in Israel, but you are worried you'll get in trouble if it doesn't
work out and you leave or change your mind soon after arrival.
From what I've been able to determine, the intention to move there is
all that is needed, and leaving pretty quickly after doesn't seem to be
an issue (although I'd want to further verify this before relying upon
it).
It seems you only need to show that you've rented a place and have
some way you plan to make money in order to demonstrate that you
intend to live in Israel.
2. Israel has worldwide taxation, and while it has agreements with most
countries so that you are not double-taxed, its negotiation with Australia is
ongoing and a double taxation treaty was seemingly not in place when I
looked in September 2020.
3. Israel has mandatory conscription into its military if you are under 28 years
old and residing in the country.
3. Notes
1. Citizenship is typically granted 3 months after arrival; you can ﬁll out a
simple form to waive this waiting period, however.
Canada
Canada is one of few countries to oﬀer instant permanent residency. To obtain
permanent residency, you must get a suﬃcient number of 'points' according to a
formula that will ask about things like your age, education level, work experience,
marriage status, whether you have a job oﬀer in Canada, etc.. If you apply and are
above the points threshold they reset every 3 months, you're oﬀered permanent
residency (and I think you have a year to accept and move there, but I may be
wrong.)
1. Notes
1. I think it's moderate diﬃculty to meet the points threshold. It's not at all
unobtainable but many may not have suﬃcient proﬁles. Others may meet
the points threshold even without a Canadian job oﬀer.
2. Canada is surprisingly easy to obtain citizenship in as well. You can gain
citizenship after just 3 years of living in Canada as a permanent resident.
Citizenship through in-country birth of a child (Brazil, Argentina, Chile)
1. Many countries reduce the naturalization requirement for those who have
children in those countries (and typically these countries provide those children
with citizenship instantly.)
1. In particular, Brazil will grant instant citizenship to the parents of a baby
born in the country. Argentina and/or Chile (I don't fully recall), reduce the
residence requirement to 1 year in order to obtain citizenship if you have a
child in that country.
Portugal

Spain and Portugal had programs for granting citizenship to Sephardic Jews. Spain's
recently ended; I've heard Portugal's is still in place. I don't know much else about it.
Digital Nomad Visas 
See this linked section above
Ancestry Options for Residency or Citizenship
Unless you already have documentation of your family history, it is likely that you'll
need to engage in at least a little genealogy. I have a section on this below.
There are a number of countries that oﬀer citizenship through ancestry (most often
European countries). Wherever your ancestors are from, it is likely worth Googling if
they oﬀer citizenship through ancestry and also reaching out to the embassy to ask as
well (I emailed the consulate of a country that did not say they oﬀer citizenship
through ancestry anywhere I could ﬁnd online, and they still said if I submitted
documentation of my ancestry they'd consider granting citizenship). Most lists I've
found of which countries oﬀer citizenship through ancestry are very incomplete.
Additionally, it seems the rules regarding citizenship through ancestry are often not
well-determined. I've seen multiple instances of the regulations being written
diﬀerently on diﬀerent government websites, I've heard of successes & failures that
don't align with the regulations, and many countries do leave the decision about your
citizenship up to the discretion of whoever happens to be reviewing your application.
General advice for pursuing citizenship through ancestry
1. Engage with genealogy. It's been my personal experience (and I've heard
many anecdotes of this as well) that the story I'd been told of my ancestry was
very incomplete and with some inaccuracy. Genealogy seemingly becomes more
and more rewarding the more I engage with it, both from a citizenship and
personal interest perspective.
2. Find and talk to others pursuing citizenship. Facebook groups have been
invaluable in providing a wide range of guidance and information regarding the
pursuit of citizenship. Search for one for your desired country. Some that I'm
aware of are:
1. Lithuania Dual Citizenship, Lithuanian's Citizenship Assessoria Lituana E
Traduçoes
2. Latvian Dual Citizenship
3. Slovak Living Abroad Certiﬁcate & Slovak Citizenship
4. HUN Citizenship Journey
5. Austrian Citizenship Holocaust Descendants
6. Ciudadania Checa/Czech citizenship
7. Irish and Wannabe Irish, Dual Ireland/US Citizenship
8. Dual US-Italian Citizenship, Italian Dual Citizenship, Italian Dual Citizenship
Social Club
There's typically additional genealogy focused groups as well. Some
examples: Genealogy in Ukraine - Research and Ancestry, Hungarian
Genealogy Group, Lithuania & Latvia Jewish genealogy, New York City
Genealogy
3. Reach out to oﬃcial sources. Embassies and consulates can be surprisingly
interested and willing to answer questions and assist with your application.

Some countries have central archives that will do extensive genealogy work on
your family for a minimal fee. Oﬃcial sources have multiple times saved me a
lot of time and eﬀort vs. pursuing questions or research on my own.
Citizenship (or Residence) Through Ancestry Programs I've Heard Of (not at
all exhaustive): 
Hungary
Hungary has one of the most commonly used citizenship through ancestry programs. I
think it's decently liberal, but I could be mistaken. The ways in which I think (with low
conﬁdence) that it is liberal is that:
1. I think you can apply if you have ancestors that lived anywhere in the historic
Austria-Hungary.
2. I think you can go back any number of generations.
Certainly, if you have ancestors up to the fourth generation who lived in the "Kingdom
of Hungary" borders of Austria-Hungary, you are eligible for citizenship. There are two
diﬀerent programs, one in which you must demonstrate Hungarian language
proﬁciency, and another in which you do not need to do so.
I don't fully recall what determines whether you need to demonstrate you can speak
Hungarian or not, but I think it has to do both with the timing of your ancestors
leaving Hungary and whether or not they were from the Kingdom of Hungary proper
or not.
If you do need to speak Hungarian for your application, it is assessed informally via
the short (10 min) conversation you have when submitting your application in person
at the embassy or consulate. Two teachers who have prepared students for this
conversation in the past estimated students can learn suﬃcient Hungarian in 4
months, with 2 hour long lessons per week. It seems a reasonable cost-eﬃcient and
well-tested method of preparing for this conversation is via teachers on
https://www.italki.com/. I estimated my total cost (not accounting for opportunity cost
of time) would be $641, based on an hourly pay rate to the teacher of $19. If you're
more adept at language learning than the average individual or want to select a less
expensive teacher, this could perhaps be less. Alternatively, it does seem many
people learn Hungarian to an extent that seems beyond this amount, and some of
them seem to think it was necessary for their application to be accepted.
Some embassies are known for being more or less lenient than others, and regardless
of the embassy you select, you will have a certain amount of luck based on the
strictness with which the person you submit your application to assesses your
Hungarian. You can apply again if you do not pass.
Hungary requires oﬃcial copies of birth and marriage certiﬁcates going back to your
ancestor who lived in the relevant geography.
Latvia
Latvia oﬀers citizenship by descent under its "exiles" program to those whose
ancestors were presumably Latvian citizens at the time of World War II beginning and
who left Latvia prior to its regaining independence in 1990. In order to substantiate
the former, typical guidance is that you must ﬁnd documentation implying Latvian
citizenship that is from 1933-1940, although some claim that documents as early as

the late 1920s are sometimes accepted as suﬃcient proof. Unless you are already in
possession of suﬃcient proof, the likely best step is to reach out to the Latvian
Archives. The Latvian Archives are particularly great to work with compared to those
of other countries; they will perform a complete genealogical search on your family for
under $100 and are highly communicative (though the process does take months). In
at least my case, they found a lot of documentation that was not only helpful for
citizenship applications, but also was informative of my family's history.
Latvia requires Apostilles for most foreign-originating documents that may be
submitted for your application.
There is a second Latvian citizenship program "Latvians and Livs" of which I have
more limited knowledge. My understanding is that you must demonstrate a genetic
Latvian heritage, as well as a strong understanding of Latvian (e.g. at the C1 level), in
order to secure Latvian citizenship under that program.
Lithuania
It is possible to secure Lithuanian citizenship by descent, though some of the
qualiﬁcations to do so are unclear. There are signiﬁcant discrepancies between what
oﬃcial sources list as qualifying, and what those in Facebook groups say works:
Oﬃcial Sources 
Facebook Word-
of-Mouth 
You must provide proof that is suggestive of an
ancestor being a Lithuanian citizen
You must provide
deﬁnitive proof an
ancestor was a
Lithuanian citizen
Proof can come in a variety of forms, such as
documents indicating life in Lithuania (school
enrollment, paystubs, etc.), foreign documents
showing place of birth or citizenship, etc.
The only
acceptable proof is
documents issued
by the Lithuanian
archives
I assign an approximately 50/50 likelihood to the oﬃcial sources vs. Facebook
providing better guidance. The Facebook community (which is overwhelmingly
Brazillian) predominantly hires a small number of providers to complete the
application process for them, so it doesn't feel as though the limits of acceptable
documentation are as likely to have been explored as they would be with a large
group of applicants applying more independently. Conversely, I've often found that the
implementation of citizenship programs can be quite diﬀerent than how they're
described on oﬃcial websites, so I do think Facebook communities often provide
relevant valuable information.
Additionally, there are conﬂicts between oﬃcial sources, with some saying that a
great-grandparent (or more recent ancestor) must have been Lithuanian, while others

say you can go up to great-great-grandparents, and at least one other saying 'any'
direct ancestor is acceptable. In this case, I expect the sources saying 'any' direct
ancestor is acceptable to be correct.
Lithuania has not been an independent state very long or very often. To apply for
citizenship, you must substantiate an ancestor who (plausibly?) had citizenship while
Lithuania was independent. I'm uncertain of the exact dates considered to be
acceptable, but they're approximately from 1918-1939. You also must show that this
ancestor left Lithuania prior to it regaining its independence in 1990.
Securing documentation to support an application may be diﬃcult (see table above). I
found the Lithuanian archives to be both of limited utility and diﬃcult to communicate
with. They will perform document searches, and in my case they did ﬁnd a couple that
were relevant, but these searches are highly abbreviated and not comprehensive. To
more thoroughly search the Lithuanian archives, you will likely want to hire someone,
and the cost of these searches seemingly range from €300-500, with no guarantee of
any success. (11) You may want to consider searching the Latvian archives; they seem
to hold many documents originating from Lithuania and will perform comprehensive
searches.
Most foreign-originating documents need to be Apostilled and oﬃcially translated to
Lithuanian for the application.
I expect to apply for this citizenship sometime in 2021, which may provide some
additional information as to acceptable documentation.
Austria
Austria has a brand new program that was passed into law in September 2020. It is
most clearly intended for those whose ancestors were Austrian citizens and were
persecuted, primarily by the Nazis. As a result, if your ancestors meet that deﬁnition,
you have the most straightforward case.
That said, the deﬁnitions around the program are written broadly enough that it may
be the case that many more people are eligible. It may be that if your ancestors ever
considered themselves Austrian (or Austro-Hungarian), and were ever persecuted, you
may be eligible. Since this is a brand-new program, we don't really have data on what
will or won't be acceptable (and the consulates don't either; they're providing varied,
inconsistent information).
As a result, a number of people are currently applying to this program without a clear
idea on whether or not they're eligible. Applying for the program is easier and more
straightforward than most; there is no language requirement and you are only
required to provide personal copies of any ancestor documentation. You do need to
provide an apostilled copy of your birth certiﬁcate and an apostilled FBI background
check, however.
I suspect that there may be an advantage to applying now; I could see Austria being
liberal now but tightening the requirements later on once it sees how many applicants
there are.
Slovakia

Slovakia oﬀers a status of being designated a "Slovak Living Abroad". If you apply for
and successfully receive this status, you'll receive the permanent right to come to
Slovakia and easily obtain permanent residency.
To become a Slovak living abroad, you need to demonstrate ancestral ties to Slovakia,
some form of proof that you speak some Slovak, and some form of proof that you're
culturally tied to Slovakia. 
Slovakia has a particularly wide range of strictness with regard to the administration
of this program. I've seen some accounts of successful applications with very little to
substantiate them; proof of having enrolled in a Slovak course (without having started
it), for example, was suﬃcient for one applicant. I've also seen accounts of seemingly
well-qualiﬁed individuals trying for years and being denied this status. The method for
certifying language ability and cultural ties that Slovakia seemingly most recommends
is to have two others with "Slovak Living Abroad" status sign a statement attesting to
your language ability and cultural belonging.
A Facebook group was just recently formed for this (~August 2020), so I've seen much
less discussion of this program than most others I've investigated. The group seems
popular and should provide signiﬁcant new data in the upcoming year. 
A bill has been introduced in Slovakia to allow citizenship via ancestry as well. This
would be near-automatically granted to those who are already designated "Slovaks
Living Abroad". But for those who haven't gained that designation (which may be
eliminated if the bill is passed), a language test would be required. Therefore it may
be beneﬁcial to apply for this status sooner rather than later.
Other European Options
1. Czechia: Czechia has a citizenship by descent program; though I've learned
very little about it thus far. I've gotten the impression that it is likely more strict
than some others.
2. Ukraine: Ukraine oﬀers citizenship by ancestry, but you must renounce your
previous citizenships. There is a bill under consideration to not only eliminate
this requirement, but also to ease the process by which citizenship by ancestry
can be obtained. I plan to periodically check-in on this.
3. Germany: I'm unsure if a German citizenship by descent program exists. I did
read at least one website that said German citizenship by descent is available,
while others have not included it in their list. After research I found out that my
family actually didn't have German ties, so I didn't look into this any further.
4. Poland: I haven't looked into this because I found out after research that my
family's Polish ties are quite minimal, if they exist at all. I've heard that Poland
does oﬀer a citizenship by descent program and that it is quite strict and diﬃcult
to pursue.
5. Ireland: Ireland has a citizenship by descent program, and it has a reputation
for being liberal, easy, and one of the most used. I know very little else about it.
6. Italy: Italy also has a citizenship by descent program, and it has a reputation for
being liberal, easy, and one of the most used. I know very little else about it.
Financial Options for Residency or Citizenship
A number of countries will let you either directly purchase citizenship or gain
citizenship via investment in the country. As far as I know, all of these require over

$100,000 in order to gain citizenship. Due to my ﬁnancial status, I have not looked
into these much at all. I have noticed that there exist multiple options in the EU and
Caribbean; I'm unsure to what extent this option exists elsewhere (though it does
seem widespread).
St. Lucia
St. Lucia has the only program I've found to be notable based on my interests. The
reason it is notable is that most of the money can be returned to you after a 5 year
period. If I recall correctly, the initial outlay is over $100k, and it sits with the St.
Lucian central bank for 5 years. After 5 years, they'll return it to you minus fees, and
the total cost (not accounting for opportunity cost, inﬂation, interest, etc.) can be
something like ~$15,000 for a single person and ~$35,000 for a family of 4. This
includes a potentially temporary COVID price reduction and a refund of some of the
fees by using a broker with whom you split commission. (12)
Naturalization Options for Residency or Citizenship
Nearly all countries grant those who live there for enough time citizenship. There's a
few of these that have shorter time requirements than others that are worth
mentioning.
Spain
Typically it takes 10 years of residency to become a Spanish citizen. If you have
citizenship of a Latin American country, however, this requirement is reduced to just 2
years.
Interestingly, they recognize Puerto Rico in their list of Latin American countries.
Puerto Rico does grant "citizenship" to those who are born or live there. I think this
typically does not have any legal beneﬁt or meaning, but it is helpful for reducing your
time until Spanish citizenship. Notably, it takes only 1 year of residency in Puerto Rico
to become a Puerto Rican citizen. So with 3 years of residence, you can become a
Spanish citizen (1 year in Puerto Rico, 2 years in Spain).
Netherlands
I believe I've read that they have the shortest residency requirement in Europe, at 3
years until citizenship.
Canada
Included in the miscellaneous section because permanent residency is instant;
citizenship itself can be obtained with 3 years residence.
Belgium, Chile, Argentina, Panama
I've read each of these have appealing naturalization programs, but I haven't looked
into them (I likely did very brieﬂy and decided that I wasn't personally interested).
Genealogy

Acquiring citizenship by ancestry is often most appealing; it typically doesn't require
you to make any major changes in your life, such as relocating or spending a lot of
money, but you can receive all the beneﬁts of having a second citizenship.
In order to pursue citizenship by ancestry, you need to know about your family
history, and typically, have documentation of it as well. Here's how to get started with
genealogy. (13)
1. Start a (feature-rich) family tree; it will be the basis for all your
genealogy
1. A family tree is the basis for tracking your family and recordkeeping. The
best service on which to do this is Ancestry.com. An alternative is the
software Family Tree Maker, which has two-way sync with Ancestry.com
(and is nice to have to ensure you have a local copy of things).
1. For each person in the tree, these can each store a number of facts,
documents, stories... really anything you'd like.
2. Ancestry.com will automatically ﬁnd worldwide records that may
match the people in your tree and suggest new ancestors / relatives.
It can be extremely helpful; on very limited initial information I've
sometimes tracked a family back to the 1500s.
1. The records that are digitized tend to be from Western,
developed countries. If your family has mainly been in the US &
Europe, you are much more likely to locate family records than
those from other locations.
3. It will also match those in your tree with other family trees on the
Ancestry.com service, and suggest records and relatives on the basis
of what others have added. I've discovered extended relatives that
are quite distant (e.g. 5th cousins), but had an amazing amount of
info about my family (including e.g. pictures and items of my great
great great grandfather).
1. There's a messaging service, and I've been somewhat
surprised to ﬁnd that messaging those who have made family
trees including my ancestors has yielded a lot of information
that those users didn't store on the family trees themselves. I
highly recommend it.
This seems more common with older generations, who maybe
build basic family trees but may not be as interested in or
adept at digitizing paper records.
2. This feature can also be a bug; it is very easy for one person to
make a mistake or guess on Ancestry.com, and for that to then
proliferate across all the trees and almost seemingly become
'fact'. By locating new records others hadn't found, I've
discovered multiple instances of others' trees having incorrect
information that I'd added to mine.
2. The best way to build a tree is ﬁrst through your own family history /
knowledge.
1. One of the most proliﬁc maxims within genealogy is to focus as much as
possible on gathering every piece of family history directly from your
family before doing much other work. I've found that this advice is sound.
1. It is surprisingly easy to ﬁnd a record that really looks like it belongs
to your family, but that doesn't. For example, Ancestry.com may
recommend a record as applying to your family, and the record may
be for someone with the same ﬁrst and last name, same year of

birth, same spouse's name, etc. It can be very easy and reasonable
to believe that this record is for your ancestor. But there are times
that this happens, and the information is for another person.
Unfortunately, you may then spend hours building your family tree
on the basis of this irrelevant document, and it can be quite diﬃcult
and time-intensive to ﬁgure out that mistake and undo all of the
mistaken decisions made as a result.
2. Working oﬀ of your own family history is the best way to prevent this
sort of mistake, to the extent possible. Start with your knowledge,
and then interview any living relatives that you have;
especially those older than you (make sure to record the information
all down somehow). Ask them for any information they may have;
ancestor's names, place names of birth, death, or where they lived,
anecdotes of how many children person X had, when they
immigrated to a new place... most anything and everything can end
up being helpful. I've found that those relatives I don't know well...
such as extended family, can have much more information about the
family history than I ever would have expected.
3. Be very willing to learn about genealogy options speciﬁc to your family.
1. While Ancestry.com is a powerful tool, there are a number of specialized
ways to locate records depending on your situation. For example,
JewishGen is a great service for locating European Jewish records. Many of
its databases are synced with Ancestry.com, but many others aren't.
2. The best way I've found to learn about what tools may be relevant to you
is to ask questions or read posts in relevant Facebook groups.
3. FamilySearch is probably the most valuable, general genealogy service
after Ancestry.com. They have a quite helpful wiki that can also point you
to a number of sources of records for your family's context. For example,
here's a wiki on Latvian records.
1. FamilySearch has a number of records that it has scraped (often with
inaccuracies) but hasn't publicly digitized. Typically you would go to a
FamilySearch History center to see the digitized version of the
record, but during the pandemic you may not want to. You can
always wait until you are comfortable going to one, but I've also
found two (potential) solutions:
1. The NYC Genealogy FB group regularly has threads where
people post the record numbers that they need looked up. One
person will go and do a number of searches at once; this
potentially helps minimize the amount of exposure occurring
through less people visiting.
2. I found places with no cases (e.g. southern NZ in early
September 2020) and posted a 'gig' on Craigslist. I did receive
responses, but I ended up getting my record via a diﬀerent
method.
4. Consider paid genealogy; at least for locating local records that aren't
digitized
1. There are a number of records that are only available on-location; too
often, these are the most important records to your citizenship application.
For example, only one of all of my great great grandparents' birth records
has been digitized, while others are likely to be available if I hire someone
locally.
2. Paid genealogy work is often very expensive, but I've found two ways to
make it more aﬀordable:

1. Reaching out to national archives can be a low-cost, valuable way to
get a lot of genealogy work done for a low fee. They also may have
access to records that no other provider can search for, and they
may be able to provide oﬃcial certiﬁcations that can be used for
citizenship applications.
1. My most successful experience with this has been with the
Latvian archives. I've (so far) had less experience with some
other country's archives, but the success I've had with Latvia
outweighs the minimal fees I've paid for less successful
searches elsewhere.
2. Facebook groups have sometimes found a low cost provider that
they'll all use. For example, for locating records on the ground in
Hungary, one service provider is much lower cost than all others I've
been able to locate, and he seemingly solely works for those who
have found him on the Facebook group (and now has his own FB
group as well). He has great reviews,
3. If you are time-constrained but not ﬁnance-constrained, there are a
number of people who will do nearly all the relevant genealogy work for
you. I've contacted a large number of them, but due to cost I haven't
proceeded with any of them (just the two examples above).
5. DNA tests typically don't seem to be useful. I've primarily heard of these
being helpful for those who were adopted or otherwise don't know as much as is
typical about their family history (e.g. those who don't know their parents'
names, or perhaps who don't know their grandparents' names). That said, they
can be quite inexpensive ($49 when on sale at Ancestry.com) and perhaps can
help with your research.
Moving Forward
1. If you found this post helpful and are interested in applying for citizenship,
please contact me at josh@derisked.org. I may be able to oﬀer help (possibly for
free, depending on funding) and can also connect people who are interested in
applying for citizenship to the same country.
2. In the future I may update this post or create a sequence by:
1. Improving the linked spreadsheets so that they're easier for others to use
2. Clearing up my areas of uncertainty or inaccuracy by referencing relevant
materials
3. Adding references for those who would like to learn more
4. Writing up step-by-step instructions for some programs
5. Investigating other citizenship by ancestry programs and/or learning more
about those which I don't know much about.
6. Learning more about available naturalization, ﬁnancial, etc. citizenship
programs
7. Writing about relocation tax strategies
8. Writing about economic residency and related ﬁnancial derisking
opportunities
I currently don't expect to write these additions in the next 6 months.
Footnotes (added Feb 19)

(Footnotes dropped oﬀ while transferring my draft from Gdocs to LW; I only realized
this now, 5 days after posting)
(1) Column V in this passport comparison sheet has the Wikipedia information on this
(from late 2019 I believe).
(2) This linked doc, in particular this section, seemingly validates this plan.
(3) I have read anecdotes of citizenship being taken away; typically in autocratic
countries and/or in response to politics or signiﬁcant levels of crime (e.g. murder).
Even in these situations it's quite rare though.
(4) Although the deﬁnition of 'work' can be worth investigating. E.g. in the UK, there
are some work activities you can perform, and others that you can't, when entering as
a tourist.
(5) Here's a partially redacted copy of a spreadsheet I've made to track potential
citizenship options. It hasn't been edited much for others' ease of use, and some
information may be outdated or incorrect. Numeric information is more likely to be
accurate than is written.
(6) For a potential exception see the third con in this section containing a description
of Slovakia and Hungary.
(7) More about these levels:
https://en.wikipedia.org/wiki/Common_European_Framework_of_Reference_for_Langua
ges#Common_reference_levels
(8) This is elaborated on further in the "Ancestry Options for Residency and
Citizenship" and "Genealogy" sections.
(9) I built this for myself and have not customized this at all for others' use. It is likely I
can make it more user friendly if widely desired. It is a bit hacky and may not work
perfectly, additionally, the source Wikipedia info may be inaccurate or out of date.
(10) At some point I found this linked spreadsheet of options. I do not recall the source
of it, and I'm uncertain of when it was created and its level of accuracy. I only have
explored it brieﬂy, but some may ﬁnd it quite valuable.
(11) I have found one person oﬀering €150 upfront, with €150 due upon success,
though I don't have any supporting references for them or other reasons to have
much belief that they are legitimate or would be successful.
(12) Sovereign Man has a broker with whom they have an agreement to split
commission.
(13) FWIW, I've found genealogy to be much more interesting and enlightening than
expected. I knew a decent amount about human history anyway, but via learning
about my personal history I've learned quite a bit more about human history as well.

Quadratic, not logarithmic
I recently realized a very simple, almost obvious bias, that I had because I never
thought more about it. Moreover, quite a lot of people have this bias too.
What is worse in time of pandemic - to increase the number of your contacts from 0 to
1 or from 99 to 100? Intuitively, since we perceive many quantities on a logarithmic
scale, the ﬁrst thing is much worse. I heard multiple times something like: "I am
already doing this and this and that because I have to, so it does not make sense for
me to decrease my shopping", or "My roommate (spouse, child...) does not care about
this at all, so it does not make sense for me either". 
However, this is simply not true. If I care solely about myself, increasing the number of
contacts increases the probability to get sick linearly - no logarithmic scale. But if I
also care about other people (my contacts, yes), then we have linear growth of
probability to become a spreader, and linear growth of the group to whom I can
spread, thus leading to quadratic growth of the total expected damage to society.
So, if I have quite a lot of contacts already, I should be much more cautious about
adding more than if I have almost none. It sounds so trivial right now - yet so many
times I have heard the opposite advice. 

Covid 2/25: Holding Pattern
Scott Alexander reviewed his Covid-19 predictions, and I did my analysis as well. 
It was a quiet week, with no big news on the Covid front. There was new vaccine data, same
as the old vaccine data - once again, vaccines still work. Once again, there is no rush to
approve them or even plan for their distribution once approved. Once again, case numbers
and positive test percentages declined, but with the worry that the English Strain will soon
reverse this, especially as the extent of the drop was disappointing. The death numbers
ended up barely budging after creeping back up later in the week, presumably due to
reporting time shifts, but that doesn't make it good or non-worrisome news.
This will be a relatively short update, and if you want to, you can safely skip it.
If anyone knows a good replacement for the Covid Tracking Project please let me know. Next
week will be the last week before they shut down new data collection, and I don't like any of
the options I know about to replace them.
Let's run the numbers.
The Numbers
Predictions
Last week: 5.2% positive test rate on 10.4 million tests, and an average of 2,089 deaths.
Prediction: 4.6% positive test rate and an average of 1,800 deaths.
Result: 4.9% positive test rate and an average of 2,068 deaths.
Late prediction (Friday morning): 4.5% positive test rate and an average of 1,950 deaths
(excluding the California bump on 2/25).
Both results are highly disappointing. The positive test rate slowing its drop was eventually
going to happen due to the new strain and the control system, so while it's disappointing it
doesn't feel like a mystery. Deaths not dropping requires an explanation. There's no question
that over the past month and a half we've seen steady declines in infections, and conditions
are otherwise at least not getting worse. How could the death count be holding steady?
One hypothesis is that weather messed with the reporting, but Texas deaths went down and
the patterns generally do not match. Virginia saw a giant jump in the death rate and I've
adjusted them down by 475 deaths to account for that, which seem to be holiday-related
catchup even though it seems super late for that. Nothing else stood out in the charts. As
per my rules, since the Virginia adjustment improves my accuracy and there's a non-zero
amount of ambiguity, I'm not including it in the results section. If included, that would move
us to 2,001 deaths per day, which still feels too high.
Added Friday 9am: I realized this morning I hadn't made a prediction, so I'm making one
now, after seeing Thursday's results that include a high death count (3138, 800 of which are
a backlog from California), and a lot of tests (1.8mm) with only a 4.1% positive rate. I expect
some continued improvement for now, but there are signs that improvement is slowing
dramatically. 
Deaths

Date
WEST MIDWEST SOUTH NORTHEAST
Dec 31-Jan 6
4553 4127
5019
4162
Jan 7-Jan 13
6280 3963
7383
4752
Jan 14-Jan 20 5249 3386
7207
4370
Jan 21-Jan 27 6281 3217
8151
4222
Jan 28-Feb 3
5524 3078
8071
3410
Feb 4-Feb 10
4937 2687
7165
3429
Feb 11-Feb 17 3837 2221
5239
2700
Feb 18-Feb 24 3652 2433
4782
2427
Using the Wikipedia numbers we do see continued declines in death rates, but still highly
disappointing ones. The English Strain might be substantially more deadly, but it's too early
for that to account for this. It's deﬁnitely odd and I not only see no explanations and lack a
good one to oﬀer, I don't see anyone noticing that it is odd.
Positive Tests
Date
WEST
MIDWEST SOUTH
NORTHEAST
Jan 14-Jan 20 360,874 185,412
452,092 250,439
Jan 21-Jan 27 260,180 158,737
386,725 219,817
Jan 28-Feb 3
191,804 122,259
352,018 174,569
Feb 4-Feb 10
144,902 99,451
255,256 149,063
Feb 11-Feb 17 97,894
73,713
185,765 125,773
Feb 18-Feb 24 80,625
64,857
150,493 110,339

Continued improvement, but slower than one would like especially given the continued drop
in testing. We may not have much more time to see declines before counts start increasing
again.
Test Counts
Date
USA tests
Positive % NY tests
Positive % Cumulative Positives
Jan 7-Jan 13
13,911,529 12.2%
1,697,034 6.6%
6.97%
Jan 14-Jan 20 14,005,720 9.7%
1,721,440 5.9%
7.39%
Jan 21-Jan 27 12,801,271 8.8%
1,679,399 5.3%
7.73%
Jan 28-Feb 3
12,257,123 7.7%
1,557,550 4.6%
8.02%
Feb 4-Feb 10
11,376,541 6.4%
1,473,454 4.1%
8.25%
Feb 11-Feb 17 10,404,504 5.2%
1,552,555 3.5%
8.41%
Feb 18-Feb 24 9,640,109
4.9%
1,502,741 3.2%
8.55%
New York continues to test robustly, but many other places are not following suit. This
continues to mean that the positive test rate is dropping slower than the true rate of new
infections, but it's also worrisome that we are getting out of the habit of testing people. This
is nowhere near enough testing.
Vaccinations
This is very much not great.


It is hugely disheartening to see our weekly rate decline from 1.61 million per day last week
to 1.3 million per day now, with no signs yet of a full recovery let alone getting back on our
previously accelerating path. I do hope that will happen soon, and slow progress is still
progress in the meantime, but it's all scary.
How are we doing vaccinating nursing homes? About this well:

A line for only those not in nursing homes would make this contrast even more stark. We
botched this job, but even with that botching it was hugely impactful.
Pﬁzer and Moderna claim to have solved their bottlenecks and pledge massive boost to US
supply (WaPo). They are promising 140 million doses over the next 5 weeks, more than
double the recent pace of vaccinations. 

If we do get to that pace, we will be back on track to be able to give vaccine shots to
everyone who actively seeks them out by the end of April, even if we don't get our act
together on half doses or ﬁrst doses ﬁrst or get any help from Johnson & Johnson or our other
known safe and eﬀective vaccine options. 
On the ﬁrst doses ﬁrst front, yet another group of experts is out in favor of this obviously
correct approach:
What I ﬁnd most interesting is the explanation that this is motivated by the English strain:

The English Strain didn't change the right answer. Instead, it puts additional pressure on the
answer to be correct, giving a suﬃciently short time-horizon problem slash scary downside
scenario to allow 'experts' to come out in favor of the better answer over the worse answer.
Whatever prevents the most infection, hospitalization and death is the right answer either
way, and that's far and away ﬁrst doses ﬁrst. 
What would a country actually using its vaccine doses look like? I'm guessing something like
this:

At a minimum, it would look like this:
Europe


You can see Europe's situation mostly holding steady here, and you can see America's death
rate having climbed back up in the last few days (even adjusting for Virginia). It's deﬁnitely
troublesome.
UK vs. EU vaccine eﬀorts, looks like a tie, oh wait:
Covid Machine Learning Project

Yet another place to see the drop in vaccinations recently, especially in ﬁrst doses. Other
than that, the lines continue to move in the same directions previously expected. He now has
us up to 28.1% ever infected as of February 11, and 13.8% having at least one vaccine dose
as of today.
The English Strain
Some hard data from NYC (full report):

This seems like very good news given our priors. If we are only up to 6.2% now versus 2.7%
for all of January, then the variant isn't on pace to take over for another few months. That
would be enough time to oﬀset the increased infectiousness via additional vaccinations. 
Alas, data elsewhere in the country is not as promising. This is another data source, this one
covering sequencing in the United States, showing us in the 15-20% range.
Kai's latest update on Denmark, where new strain is now 57% of cases, and cases are rising
despite the lockdown.
Some hard data from a variety of countries, this website seems great. Doesn't paste well, so
click on the link. In the USA it has the English strain up into the low double digits, which is
closer to my overall prior and still importantly better than I'd feared.
A Youyang Gu thread looks at various possible scenarios, and noting that new variant
takeover need not mean we get a gigantic wave.
The South African Strain
A well-deserved break from insanity is now oﬃcial:
A thread goes over the key passages:

This looks like an eminently sensible system. One age group, one week to assess safety,
eﬀectiveness judged straightforwardly based on immunogenicity. 
Also good is that South African cases have fallen dramatically down, which should lower our
worries about this strain on multiple levels.

Also, Moderna is testing an updated vaccine designed for the South African variant. It's good
news to conﬁrm this but it was so inevitable it almost isn't news.
Johnson & Johnson
The FDA has announced that the Johnson & Johnson vaccine meets the requirements for
emergency authorization. You might think this would mean it is now authorized for
emergency use. You would be wrong. You can't rush meetings.
You might think that would mean we have a plan for what to do when it is so authorized.
You'd be wrong again. Remember when Biden complained that Trump didn't have a plan?

WTF, indeed. Taking three weeks to approve the vaccine is bad enough, but I can sort of
understand it. Not using that time to make a distribution plan (this should not even be
necessary, the plan should already have existed long ago) is a whole diﬀerent level of
sabotage. Rumors of the new administration's ability to administrate seem greatly
exaggerated. 
Vaccines Still Work
Latest conﬁrmation that vaccines work, in this case one shot of AstraZeneca:
Meanwhile, America continues to sit on a massive unused supply of AstraZeneca doses.
What is the right way to describe that FDA decision?
Chinese data reports their vaccine also works, with eﬀectiveness levels similar to Johnson &
Johnson. Note that I say their data reports, rather than that it is true. Watch who gets
vaccinated. 
People continue to treat conﬁrmation that vaccines work as news. It is not news. 
We know vaccines work. They are highly (but not fully) eﬀective in preventing infection and
the spread of disease. They are even more eﬀective at preventing severe disease,
hospitalization and death. 

That doesn't mean that getting the exact numbers right isn't valuable. Getting it right is
valuable.
But those who imply, or outright say, that this is the 'ﬁrst information' we have or that it is
the 'ﬁrst evidence' or anything like that, shame, shame, shame, shame on you.
Shame!
Shame!

No shame here, only facts (some shame further down thread but let's ignore that):

If anything I ﬁnd this a little disappointing, as I was very much enjoying the straight 100%s.
Still, don't get me wrong, I'll take it.
Then there are those that are still going with the 'no evidence' line somehow. Note the date. 

Shame.
This leads us to your periodic reminder:
There are no CDC guidelines for what vaccinated people should do.

After what happened with the schools, I'm not optimistic about what those CDC guidelines
are going to say. The good news is that people are not schools, and can more easily hit
ignore.
The attitude goes like this:

What the hell, Dr. Fauci? You were supposed to be lying to get better outcomes...

Who cares if you're vaccinated, same energy, f*** everything, we're doing ﬁve blades. 

What happens when your messaging is all about how vaccination priority is the most
important thing and also how vaccines can't be relied upon in any way: Many NBA players
reluctant to promote vaccine, largely out of concern that getting the vaccine too soon would
look bad, but also because many of them don't trust the vaccine.  
You also get reactions like this:
I am not claiming that 'tell the truth' is always the correct simulacra-level-2 play, but
blatantly lying to the public to their faces, in order to scare them and warp their perceptions
of physical reality to get them to do what you want, is a strategy that keeps getting tried by
elites and media, and keeps blowing up in their faces. 
Good news, in the UK you'd at least be able to travel:

The continued FUD around whether previous infection protects people continues to be
insane, as is forcing those already infected to compete for limited vaccine supply. The people
I know (or secondhand know) who got Covid mostly then got the vaccine anyway, and
worries about being punished for not having done so are a lot of the reason for that. Great
strategy. 
When is it time to go back to normal? Youyang Gu oﬀers one perspective, the graph seems
optimistic but the curve seems mostly reasonable:

There will come a day when there is once again a pivot, from everyone must take
precautions to everyone must do their part to restart the economy. It probably won't be as
bad as the UK's payments for dining in and only dining in during a pandemic that paid more
if you had a larger group. It should still be expected to be perverse, because the system
selects for perversity. 
People like Dr. Fauci will instantly transform from 'even fully vaccinated you can't see a
movie' to 'it's important for our economy and mental health for us to get back to our regular
lives.' 
And then, if necessary, they'll transform back, as many times as necessary. 
This week we saw one of the ﬁrst signs. Cuomo is proposing a $5,000 reopening tax credit
per employee for restaurants (max 10 per restaurant). 
So, let me get this straight. Restaurants are in danger of closing, so we'll hold oﬀ on paying
them for a year, then pay them money if and only if they reopen, exactly at the moment
they're not in as much danger of permanently closing. So if you managed to survive without
payments, congratulations, you deserve a reward check? But only if you open now? It's as if
we wanted to transfer funds to restaurants, but held oﬀ until now because doing it earlier

would have been helpful. If we do it now, it's in the name of Economic Recovery, so giving
preferred interests cash is now ﬁne.
In Other News
Somewhat unfair, but still...
From The Onion, on Cuomo, but don't tell me you think it didn't happen.
Meanwhile, in Florida, this is how the news covers...


...prioritizing the most vulnerable citizens (the elderly) for vaccination.
They also continue to use outdoor events as their go-to blame totems and cite them as
superspreader events, despite this consistently proving not to be the case. Our continued

closing of outdoor spaces and preventing outdoor activity is actively counterproductive on
every level, so doubtless it will continue until this is fully over.
In other Fauci news:
Thread by Youyang Gu of the Machine Learning Project, on whether in-person instruction at
universities impacted Covid-19 rates. He concludes that, while there was a short-term bump
in cases when classes began, there was no clear long-term rise in cases. 
Marginal Revolution reminds us that "medical ethics" has no interest in beneﬁting humans or
making the world a better place, is instead actively working to make the world a worse place
and ensuring that humans suﬀer, and the ﬁeld is proud of this. 
MR also highlights some related liquid ﬁre from its comments section, speciﬁcally on ﬁrst
doses ﬁrst.
Welcome to 2021:
Via same account, same energy:

Meanwhile in North Dakota, a ban on mask mandates. Gotta love the detail that the
legislature uses a mask mandate themselves.
More data on who thinks we should wait until teachers are vaccinated, I continue to ﬁnd it
interesting that we rarely ask if they should fully reopen or not once all teachers who want
the vaccine have received it, which is the question I'd be most curious about:

The Eyes Have It: Study suggests wearing glasses could reduce Covid risk by more than half.
Proposed mechanism is that this avoids rubbing and touching the eyes, because everyone
has to constantly use their purity instincts and blame touching things instead of the obvious

explanation that glasses shield the eyes from airborne particles the same way masks shield
your nose and mouth. Either way, this suggests eyes might be a more important infection
vector than we'd realized, and provides even more emphasis for what you do mattering
more than people realize. The other alternate explanation is that wearing glasses correlates
with a bunch of other things, and those things reﬂect lower risk, which also seems highly
plausible. I wouldn't read too much into this but yes I would try to wear non-prescription
glasses or sunglasses if I had that option. Lucky for me my eyes are terrible and this is well-
covered.
Adding daily tests to border quarantines into zero-Covid areas like New Zealand seems like it
more than passes every possible cost-beneﬁt test, but even there, nope, not testing. They're
only now even testing those working the border on a daily basis. Meanwhile, Austria is now
testing all schoolchildren twice a week. 
Looks like drinking is actually down over the past year, although not for those 50+?
The right thing: Still available! Congratulations, Connecticut.
Even if things start to get worse again before they resume getting better, I'm hopeful that
we're getting close in general, and that we're close to getting everyone who wants one a
vaccine. In the meantime, Xkcd is at long last on top of my cutting edge pandemic-beating
strategy. 

Smuggled frames
Cross-posted from my blog .
Status: I think the described concept would be more useful if I applied it more often — or at
least noticed when I do apply it. Right now it's thinking out loud + "I wonder what will
happen if I post on LW".
Intro
I think that "critical thinking" is way too often taken to mean roughly "checking the facts and
logical inferences you are presented with".
In addition to focusing on facts — "what people claim to be true" — it seems useful to focus
on a certain cluster of claims that are very often left implicit. These claims are related to the
process of how humans make decisions in the wild, which involves mushy categories like
"legitimacy" and "importance". I will call them "frames".
Those claims can be categorized as:
existence claims — by mentioning a thing or a category (e.g. "Supreme Court's
liberal wing"), you are claiming that it exists and makes sense and can be used
productively for thinking; How An Algorithm Feels From Inside is a post-length
exploration of that for categories speciﬁcally;
importance claims — by mentioning a thing, you are claiming that it should be taken
into consideration;
legitimacy claims — building on a premise that a certain authority is legitimate in
some domain (thus automatically making it more legitimate);
and likely more.
For example, whenever somebody start talking about "the best way to solve a problem X",
you might disagree with their solutions — alright! — but you will update slightly towards
"problem X exists" and perhaps "problem X is important". These might be very contentious
claims, but they get smuggled in without an argument.
(Unless you have a strong emotional reaction, in which case they might rejected wholesale.
Think of anything from the domain of politics, for instance.)
Example: Merriam-Webster
A lot of people believe that a) that it's important for the category of "correct spelling" to
exist, and, simultaneously, b) that objective rules of spelling don't exist, i.e. grammar (and
language in general) is deﬁned by social consensus.
This has a lot of consequences. For instance, people get genuinely upset that Merriam-
Webster lists "irregardless" as a word. They also spend a ton of time arguing about spelling,
the logic of it, precedents, and so on.
Of course, there are many other reasons to care about spelling, such as "learning to spell,
and learning to argue about spelling well, is a somewhat costly way to join certain tribes".
They are more important than the beliefs I listed above.

However, I want to talk exclusively about the Merriam-Webster situation for a moment. Why?
Because noticing smuggled frames is an incredibly eﬀective way to snap yourself out of
caring about unimportant things and being in a love-hate relationship with certain
authorities. Sometimes it's useful. Sometimes it's very useful.
Going back to the actual spelling now:
What would happen if people didn't believe that it was important for the
category "correct spelling" to exist? Well, they wouldn't be having arguments in
the ﬁrst place. Why have arguments about something unimportant?
What would happen if people believed that objective, non-social rules for
spelling did exist? They would go and ask linguists for advice, and not
lexicographers. They would ask questions like "what is better?" or "what is more suited
for our brains?" (or "what did God intend?" etc) rather than frantically pulling the
blanket of social consensus. Going beyond spelling — they would be interested in
things like the acoustic adaptation hypothesis, about diﬀerent languages being better
suited for diﬀerent terrains (literally!).
Another example: great works
Thought experiments like these are an easy way to get rid of otherwise unsolvable emotional
patterns that prevent people from thinking clearly, optimizing the right things, and achieving
good lives. Here is a longer example.
You are an aspiring ﬁlmmaker.
When you were growing up, your dad was constantly referring to certain movies as "great
works" and others as "eh, it's a good movie". You heavily disagreed with him about which
movies are great works and which aren't, but adopted the position that the category itself is
valid — some movies are great and timeless works, and some aren't.
Naturally, you feel very bad about not creating great works. You don't start any projects that
don't have any chance of becoming a great work.
Counterintuitively, you would even ﬁnd some consolation if you successfully argued that no
movies are great works — because it would free you up from the obligation to create great
works, and you could instead do what you like. Filmmaking-speciﬁc nihilism, so to speak.
However, it is very hard to argue that no movies are great works, because the category does
not have a good deﬁnition. But many other categories don't have good deﬁnitions either! You
can't abandon all categories that don't have good deﬁnitions, because then you wouldn't
know how to make any decisions at all.
This is where smuggled frames come into play. Once you clearly see where you got the
notion of "great works" from, it is much easier to discard it without having to explicitly refute
it, and think: "what alternative categories could exist, and which of them do I like?".
Is art a way to say old truths in a way that would be viscerally understood by a
particular (and perhaps very small) group of people?
Is art an attempt to make the world a more diverse and interesting place?
Is art self-expression, useful for its own sake even if nobody else cares?
Is art's purpose to entertain people?
Note that here I am going slightly beyond How An Algorithm Feels From Inside. The point is
not to decide "oh, okay, art is everything at once, I will just optimize some mix of these".
Don't! Good things come out of choosing a deﬁnition and sticking to it, temporarily at least,

even if this deﬁnition is "fake" in some way — see In praise of fake frameworks. You can
always choose another deﬁnition later if you want.
One more example: evil people
You might have grown up with a category of "good people" and "bad people". Then
somebody told you: don't anthropomorphize humans. Everybody thinks they are the good
guy. Evil behavior is caused by [reasons]. Etc, etc.
They have robbed you of a category. And it's good! You have been able to empathize with
people more, and you've also had a blast arguing on Twitter about not anthropomorphizing
people.
However, eventually you notice that this category was useful, so you consciously (or semi-
consciously) bring it back. You say things like "I realize there are no evil people, but fuck you
and I'm going to block you anyway". You are able to use "don't be evil" to guide your life. And
so on.
"All frames are initially smuggled frames" does not necessarily mean "all frames are bad".
The Economist?
Here is The Economist telling you some facts about things that happened in the summer of
2020:
https://www.economist.com/united-states/, July 8, 2020
In order for these headlines to make sense, you must accept a number of assumptions. What
are those assumptions?
"Justice John Roberts joins the Supreme Court's
liberal wing in some key rulings"
Let's start with the Supreme Court headline.
EXISTENCE/IMPORTANCE CLAIM: "The Supreme Court has a liberal wing"
EXISTENCE/IMPORTANCE CLAIM: "Some rulings are particularly important"
EXISTENCE CLAIM: "And it's possible to know which (and we know which)"

Under the guise of a simple fact, three other claims have been smuggled into your brain. The
ﬁrst claim is the easiest to debate, so I'll go with it.
"The Supreme Court has a liberal wing".
You are invited to believe that there is a framework for analyzing how the Supreme Court
operates (divide the justices into wings), and that it is a useful analysis tool.
What if it's not a useful analysis tool?
What if the justices don't particularly follow the ideology lines?
What if you should care about how experienced or smart or [whatever] the appointed
justices are, rather than sigh and go "oh well, Trump got another judge of his own in
the Court"? What if some Supreme Court decisions are bad because some justices are
shit at interpreting the Constitution, and should not have been appointed in the ﬁrst
place? Has the quality of the Court's legal output declined over the past years?
What if the real ﬁght is between, say, originalists and adherents of the living
Constitution approach, and you should be much more concerned about that?
Etc, etc, etc.
This single implicit claim about the existence of "the liberal wing" is shaping the kinds of
discussions you are inclined to have about the Supreme Court. Brick by brick, your worldview
is being built out of others' worldviews.
"Cutting American police budgets might have
perverse eﬀects"
I think the implicit claim in this headline is that by talking about the police budgets, people
might change something. It's an existence claim, in a way, though it tells you what's possible
and not what exists.
Why would The Economist talk about cutting police budgets if there was no point in talking
about them? And indeed, if The Economist believed it was impossible to change anything,
the headline would look diﬀerent, e.g. "What will happen after American police budgets are
cut".
Let's go further: imagine if The Economist ran a headline in 2016 that went "Accepting
Trump's election as legitimate might have perverse eﬀects". That wouldn't be wrong. But
they would never phrase it like that—because it'd mean suggesting that there was a serious
choice whether to accept the election as legitimate. Not a "hear my radical idea" suggestion
in the opinion column, but an actual sober choice.
And there was a choice! You could just say: no, Trump is not a legitimate president. It was a
thing you could do, and 23% of Clinton voters did, on the day after the election. If The
Economist was, year after year, suggesting to its readers that they had a choice whether to
accept the election as legitimate—and, importantly, also implying (by virtue of being
discussed in The Economist!) that this choice mattered — that percentage would probably be
higher.
This is how The Economist tells you what is possible and what isn't; what is worth taking
seriously and what isn't. You might completely disagree with its opinions, but as long as you
assume that The Economist is not being irrelevant, some of its worldview is still rubbing oﬀ.
Where to go from here?

This has a chance to grow from a sketch into a viable, life-applicable mechanism in several
months of observations. So — see you in a few months.

The Prototypical Negotiation Game
Suppose you want to meet up with someone in New York City. You did not arrange a
time and place beforehand, and have no way to communicate. Where and when do
you go to maximize your chances of meeting? Empirically, the most popular answer is
the Empire State Building, at noon. (Does that change your answer?)
This is the explanation of Schelling points which I hear most often: there are games
where the main goal is for everyone to coordinate on the same answer, but it doesn't
really matter which answer. So, we look for points with some symbolic signiﬁcance -
"Schelling points".
The message of this post is that this is not the prototypical form of a Schelling-style
coordination game which actually comes up most often in the real world. In practice,
Schelling points come up when coordinating on the same answer is the most
important thing for each player, but they still have diﬀerent preferences for which
answer is chosen. This leads to negotiation - indeed, we could call this the deﬁning
property of a negotiation problem. (Abram's Most Prisoner's Dilemmas Are Stag Hunts,
Most Stag Hunts Are Schelling Problems says something similar, although the
emphasis will be diﬀerent here.)
The Game
As before, you and a friend want to meet up in New York City. This time you do have a
communication channel: you each have a cell phone and the other's number. BUT
you're both lazy and don't want to move very far from wherever you happen to be -
let's say you're at central park zoo and your friend is in chinatown. Successfully
meeting up is still far more important than the location chosen, but given a successful
meetup, you both disagree on preferred location.


Source. Chinatown is near the bottom, central park zoo
is in the lower right of the big park in the center, and
the Empire State Building is in the Garment District
between the two.
Here's a few ways this could play out.
Story 1: you and your friend agree to meet at the midpoint of your locations. But in a
ﬁt of laziness-inspired brilliance, you lie and claim to be at the far end of central park,
rather than the zoo. As a result, the supposed "midpoint" is much closer to you.
Story 2: Same as the previous story, but your friend also lies about their location.
Story 3: Same as previous story, but each of you correctly anticipates that the other
will lie and does not believe anything they say. You will both ignore whatever the other
says. And so, despite being able to talk to each other, you are eﬀectively unable to
communicate. Suddenly, Schelling points like "the Empire State building at noon"
become relevant again. It's relevant precisely because it's trustworthy - if you both
know in advance that the Empire State Building at noon is the natural meetup point,
then there's no room to lie about it.
This is the sort of game where Schelling points typically become relevant in the real
world. It's a negotiation game: both players care more about reaching an agreement
than about which speciﬁc agreement is reached. But they still have diﬀerent
preferences about which possible agreement is reached, so there's competition over
it. The relevance of Schelling points comes in, not from a lack of communication
channels, but from a lack of trust. If nobody believes what the others say, then we can
only coordinate on "natural" agreements in which there's no degrees of freedom
which could be shifted by strategically lying.
Let's look at a couple other ways this could play out.
Powerless Underlings: Intentionally
Destroying Communication Channels
Suppose a merchant is selling an "I ❤ NY" t-shirt, and you want to buy it. The
maximum price you'd be willing to pay is higher than the minimum price they'd be
willing to accept, but you still generally prefer a lower price and they generally prefer
a higher price. It's a prototypical negotiation game: you both care most about
reaching an agreement on the price, but you have diﬀerent preferences about which
price is agreed upon.
So, you haggle. The prototypical negotiation game leads to a prototypical negotiation.
Round-number prices likely serve as Schelling points, but there are other moves one
can make as well.
One of the most common moves in this kind of game is to intentionally destroy a
communication channel.
In our "meet up in NYC" example from earlier, you could text your friend "phone
dying, meet at central park zoo" and then turn oﬀ your phone. You've declared a
meetup point, and destroyed their ability to negotiate it by destroying the
communication channel.

The analogous move for a t-shirt merchant is to hire an underling to run the store. The
underlying has no power to negotiate prices - indeed, that's exactly the point. If
someone tries to haggle, they say "sorry but I'm not allowed to change the prices". If
someone asks to speak to the owner, they say "sorry but the owner won't be here
until this evening", or better yet "sorry but I've never even met the owner, this is a
huge national chain".
Of course, the trade-oﬀ of this strategy is that the merchant will miss the opportunity
to sell a t-shirt to someone who's willing to pay just a bit less than the merchant's
listed price. No haggling means few opportunities for price discrimination. But as long
as customers aren't too price-sensitive, the underling is a useful strategy.
... and that's why you can't haggle with store clerks. In another world, where oﬀering
diﬀerent prices to diﬀerent customers is more proﬁtable than always charging a high
price (and sometimes missing out on sales), maybe store clerks would haggle and get
paid based on how high a price they can get, much like car salesmen.
Moving The Schelling Point
Imagine that the "meetup in NYC" game happened a lot more often, between a lot
more people. People from one end of the city were constantly meeting up with people
from the other end, and a negotiation game played out every time. Then there'd be a
lot of incentive to move the Schelling point.
Physically moving the Empire State building would be one way to do this, in principle,
though very diﬃcult. (In other games, physically moving an existing Schelling point is
more plausible - see e.g. Parable Of The Dammed.)  Alternatively, a bunch of people
could fund construction of an even taller building closer to their end of the city. In an
extreme case, we could get a runaway arms race of people from both ends of the city
building ever-taller buildings closer to their end.
Another strategy would be to put up a billboard saying "Meet up here!", and run
advertisements for the new meetup point, and have everyone on your end of the city
put up social media posts about how Everyone Should Meet At The Meetup Billboard
Or They Are Terrible.
... which brings us to norms and culture wars.
Norms are a many-player negotiation problem. Disagreements over norms are
unpleasant for everyone involved: you violate something I thought was a norm, I
punish you for it, you respond with righteous indignation at this unfair punishment for
violating something you did not think was a norm, punish me back, quite possibly the
whole thing escalates... unpleasant for everyone. Most people most of the time want
to agree on norms, whatever they happen to be, and move on with their lives. But we
still have diﬀerent preferences over what the norms should be. For instance, what
things should or should not be considered "acceptable" to say in public (i.e. what
speech will or will not be punished, or which punishments will or will not themselves
be punished)?
The resulting norms are Schelling points: people follow the norms which everyone else
follows. And they can be moved around the same way one normally moves around
Schelling points.

... so when you see someone posting on social media about how People Who Don't
Follow Norm X Are Terrible, that is actually a substantive move in the game. It's just
like running an ad for a particular meetup point. And of course, people who want some
other norms to be the Schelling point will run opposing ads, and sometimes the whole
thing will turn into an arms race.

Book review: The Geography of
Thought
This is a linkpost for
http://www.bayesianinvestor.com/blog/index.php/2021/02/06/geography-of-thought/
Book review: The Geography of Thought: How Asians and Westerners Think
Diﬀerently... and Why, by Richard E. Nisbett.
It is often said that travel is a good way to improve one's understanding of other
cultures.
The Geography of Thought discredits that saying, by being full of examples of cultural
diﬀerences that 99.9% of travelers will overlook.
Here are a few of the insights I got from the book, but I'm pretty sure I wouldn't have
gotten from visiting Asia frequently:
There's no Chinese word for individualism - selﬁsh seems to be the closest equivalent.
Infants in the US are often forced to sleep in a separate bed, often in a separate room.
That's rather uncommon in Asia. Does this contribute to US individualism? Or is it just
a symptom?
There are no Asians in Lake Wobegon. I.e. Asians are rather reluctant to rate
themselves as above average.
Westerners want contracts to be unconditionally binding, whereas Asians want
contracts to change in response to unexpected contexts.
Asians are likely to consider justice in the abstract, by-the-book Western sense to
be rigid and unfeeling.
Chinese justice is an art, not a science.
Origins of Western Culture
Those cultural diﬀerences provide hints about why science as we know it developed in
the West, and not in Asia.
I read Geography of Thought in order to expand my understanding of some ideas in
Henrich's WEIRDest People.
Nisbett disagrees somewhat with Henrich about when WEIRD culture arose, writing a
fair amount about the Western features of ancient Greek culture.
Nisbett traces some of the east-west diﬀerences to the likelihood that the Greeks met
more apparent contradiction than did Asians, via trade with other cultures. That led
them to devote more attention to logical thought. (Here's an odd claim from Nisbett:
ancient Greeks were unwilling to adopt the concept of zero, because "it represented a
contradiction").

Nisbett agrees with Henrich that there was some sort of gap between ancient Greek
culture and the Reformation, but believes the gap came later than Henrich does.
These two quotes are about all that Nisbett has to say about the gap:
As the West became primarily agricultural in the Middle Ages, it became less
individualistic.
The Romans brought a gift for rational organization and something resembling the
Chinese genius for technological achievement, and - after a trough lasting almost
a millennium - their successors, the Italians, rediscovered these values ... The
Reformation also brought a weakened commitment to the family and other in-
groups coupled with a greater willingness to trust out-groups
Neither Nisbett nor Henrich convinced me that they know much about any such period
of reduced individualism - they don't seem to consider it important.
Reductionism and Categorization
I used to interpret attacks on reductionism as attacks on a valuable aspect of science.
I now see an alternate understanding: a clash of two cognitive styles, reﬂecting
diﬀering priors about how much we can usefully simplify our models of the world.
The Western goal of ﬁnding really simple models likely helped generate the study of
physics. I'm guessing it also contributed a bit to the West's role in eradicating
infectious diseases.
However, it may have been counter-productive at dealing with age-related diseases.
Let's look at the example of Alzheimer's.
Western researchers have been obsessed with the simple model of beta amyloid being
the sole cause of the disease. Drugs targeting beta amyloid have been failing at a rate
that is worse than what we should expect due to random chance if they were
placebos. Yet some researchers still pursue drugs that target beta amyloid.
Some of that focus on single causes is due to the way that medical research depends
on patents, but don't forget that patent law is a product of Western culture.
Meanwhile, outside of the mainstream, there are some signs of progress at treating
Alzheimer's using approaches that follow a more holistic cognitive style. They posit
multiple, overlapping factors that contribute to dementia, and entertain doubts about
how to classify various versions of dementia.
I also see some hints that traditional Asian medicine has done better than mainstream
Western medicine at treating Alzheimer's. The results still seem poor, but the
risk/reward ratio seems good enough that I'm trying a few of them.
High modernism, combined with excessive reiﬁcation of categories, may have led the
medical establishment on some dead-end paths.
In addition, Western medicine has been much more eager to adopt surgery than China
- presumably due to an expectation that cutting out "the cause" of a disease will cure
it. I'm moderately conﬁdent that Western medicine does too much surgery. I don't
have any guess about whether Asian cultures do too little.

Chuang Tzu is quoted as saying, "Classifying or limiting knowledge fractures the
greater knowledge."
it's been suggested that the distinction between "human" and "animal" insisted
upon by Westerners made it particularly hard to accept the concept of evolution.
... Evolution was never controversial in the East because there was never an
assumption that humans sat atop a chain of being and had somehow lost their
animality.
Westerners needed to overcome the habit of classifying humans and animals as
categories with diﬀerent essences. Asians are much less comfortable with attaching
importance to categories and essences, so evolution required less change in their
worldviews.
Doesn't the Western lead in reductionist science conﬂict with the evidence of Asian
students doing well at math and science? Nisbett says that's partly explained by
Asians working harder:
due at least in part to the greater Western tendency to believe that behavior is the
result of ﬁxed traits. Americans are inclined to believe that skills are qualities you
do or don't have, so there's not much point in trying to make a silk purse out of a
sow's ear. Asians tend to believe that everyone, under the right circumstances
and with enough hard work, can learn to do math.
There's some important tension between this and the message of The Cult of Smart.
Nisbett tells us that American math-teaching isn't as good as the Asian version. But
that can't be the full answer - Cult of Smart indicates that schools rejected key
elements of Western culture in the past few decades. Key parts of that trend
happened just before Geography of Thought was published.
So the US seems to be adopting parts of Asian culture that make schools more cruel,
and more eﬀective at producing excellent graduates. But that trend seems unstable,
due to the delusion that it's promoting the Western ideal of equality.
IQ
For a long time, I believed that the Raven's Progressive Matrices Test was culture-
neutral.
Nisbett compares an example from a CFIT test (like Raven's, but with "culture fair" in
the name) with an example from an IQ-like Chinese test. The Chinese test is more
focused on relationships between parts. It was easy for me to see that the two tests
were optimized for mildly diﬀerent notions of intelligence, so I was unsurprised when
Nisbett reported that Chinese subjects showed higher scores on the Chinese test, and
Americans showed higher scores on CFIT.
I'm a bit frustrated that Nisbett is vague about the magnitude of the diﬀerences, and
that he cites only an unpublished manuscript that he co-authored. Publish it now,
Nisbett!
Both notions of intelligence seem quite compatible with common notions of
smartness, diﬀering only in which skill subsets ought to be emphasized most. So this
isn't like the usual commentary on bias in IQ tests that's looking for an excuse to
reject intelligence testing.

Intentions
I previously wrote:
I'm surprised to ﬁnd large diﬀerences in how much various cultures care about
distinguishing intentional and accidental harm, with WEIRD people caring the
most, and a few cultures barely distinguishing them at all.
Nisbett hints that some of that is due to the WEIRD expectation that actions have a
single cause, and can't result from a combination of intentional and accidental factors.
Some of it might also be due to Westerners doing more causal attribution in general.
Virtue Ethics
I wonder how cultural diﬀerences aﬀect attitudes toward ethics?
In particular, I wonder whether Asian cultures care less about virtue ethics, due to less
inﬂuence from Fundamental Attribution Error?
Some hasty research suggests that the answers are controversial.
The Stanford Encyclopedia of Philosophy says:
What makes the characterization of Confucianism as a virtue ethic controversial
are more speciﬁc, narrower senses of "virtue" employed in Western philosophical
theories. Tiwald (2018) distinguishes between something like the broad sense of
virtue and a philosophical usage that confers on qualities or traits of character
explanatory priority over right action and promoting good consequences. Virtue
ethics in this sense is a competitor to rule deontological and consequentialist
theories. There simply is not enough discussion in the Confucian texts, especially
in the classical period, that is addressed to the kind of questions these Western
theories seek to answer.
There are other narrower senses of "virtue" that are clearly mischaracterizations
when applied to Confucian ethics. Virtues might be supposed to be qualities that
people have or can have in isolation from others with whom they interact or from
their communities, societies, or culture. Such atomistic virtues could make up
ideals of the person that in turn can be speciﬁed or realized in social isolation. ...
inﬂuential critics of the "virtue" characterization of Confucian ethics ... seem to be
supposing that the term is loaded with such controversial presuppositions.
Conclusion
Geography of Thought is a great choice if you want to understand the cultural
diﬀerences between the US and China. It complements WEIRDest People fairly well.
Geography of Thought is mostly about two sets of cultures, with little attention to
cultures other than those of eastern Asia and the West.
Nisbett seems a bit more rigorous than Henrich, but Henrich's cultural knowledge
seems much broader. Geography of Thought doesn't quite satisfy the "and Why" part
of it's subtitle, whereas Henrich makes an impressive attempt at answering that
question.

Curing Sleep: My Experiences Doing
Cowboy Science
Epistemic status: Subjective report describing youthful exuberance. The actual
experimentation part of this was very badly executed.
 
In light of the recent homemade peptide vaccine, this is a writeup of my experiences in
insuﬄating internet chemicals. 
This happened during a period of my life when I was very bored, kinda rich, and getting
really into darknet libertarian culture. This is cowboy science, and upon reﬂection, I was
insuﬃciently concerned about either of legal troubles or brain damage. 
 
Background
Orexin (aka hypocretin-α) is a neuropeptide which promotes wakefulness, weight loss, and
happiness. Damage to the orexinergic system seems to cause Type 1 Narcolepsy—comorbid
with sleepfulness, obesity, and depression.
Deadwyler et al attempted to prove a causal relationship, by sleep-depriving rhesus monkeys
and having them insuﬄate orexin. It appears that sleep-deprived monkeys snorting orexin
perform as well on cognitive tests as the non-sleep-deprived monkeys. 
So there I was, a graduate student reading through this paper, and you can hear the gears in
my head turning. 
1. Orexin insuﬄation appears to promote wakefulness in sleep-deprived primates.
2. I am a sleep-deprived primate.
3. ...
 

 
Transhuman Greed
Will this cause some kind of...anti-narcolepsy? Have I found a cure for sleep itself
?? 
I was properly embracing More Dakka. But this Kerbal Space Program-tier science thought
wasn't as nuts as it seemed. This was 2012, the orexin research was fresh, and my
neuroscience professors were still touting the party line of "perhaps the only purpose of
sleep is to keep humans indoors and conserving calories during the night, because their
comparative advantage is day. We don't even know why, or even if, we really need sleep!" 
(We didn't know about sleep-as-memory-post-processing, or that, during sleep, the brain
lobes spread apart to let the CSF pressure-wash away all of the metabolite byproducts. We
just thought sleep was one of those no-longer-adaptive biological quirks inﬂicted by
evolution, which, in defense of past neuroscientists, happen all the time.)
And so, at the thought of no longer needing to sleep, I was ﬁlled with a transhuman greed...
 
The Experiment
So I ordered a vial of primate-brain orexin from the internet, and got to snortin'. 

(Did you know that places selling chemicals "for research purposes only" don't check to
make sure you're a real researcher? As far as I can tell, it's just enough veriﬁcation for them
to maintain defensibility when you do something stupid with their chemicals. This has
problematic implications for biosecurity and should be patched immediately, but is great
when you want to do something stupid with chemicals.)
I asked my friends which of them were willing to go on this journey of discovery with me.
Perhaps predictably, most of them took issue with deliberately putting a little-researched
internet chemical into their brains, "to see what happens".
But I did ﬁnd one volunteer. And so we began to do science. Or, at least, SCIENCE!!
Our experimental design was as such: 
We will establish baseline tests for our subjects—reaction speed, serial sevens, short-
term memory recall, and whatever else comes up when you google "cognitive test
online". We will establish baselines for ourselves both in sleep-deprived states, and
non-sleep-deprived states.
I will unfreeze and measure out the appropriate doses of this powder into some distilled
water, and put it in insuﬄation syringes.
We will give the orexin syringe to our sleep-deprived subject, and they will SNIFFF
 
Results
Our scores on the tests during conditions of sleep deprivation improved to be commensurate
with baseline. 
We still felt sleepy, though. 
However, the reason why I didn't take to the streets shouting about my cure for sleep was
because the experiment was so sloppy that I didn't even trust those results. See below. 
 
Experimental Design Flaws, Any One Of Which
Would Get It Thrown Out, tbh
Although my confederate experimenter/subject was blinded to whether the spray was
orexin or placebo, I was not. I guess I intended to compensate for the placebo eﬀect by
"trying real hard".
Because orexin was expensive, I only bought enough for four doses, which put an
upper limit on how many trials we could run.
n=2, y'all.
 
Now, Take to the Streets and Do A Science
Thus concludes my tale. And although for a few years afterwards I puttered about trying to
recreate this experiment, I got distracted by life and romance and cryptocurrency, as is
always the case. 

If you feel like studying this area and perhaps curing sleep, I am cheerfully available as a
consultant.  

Promoting Prediction Markets With
Meaningless Internet-Point Badges
Intro
( x-post )
I'd like to live in a world where prediction-market use is common and high-prestige.
The easiest way for this to happen is for prediction markets with money to be legal.
In the absence of this, there might nevertheless be some potential low-hanging fruit
for a point-based prediction market -- Metaculus, or some unidentiﬁed contender -- to
promote the wide acceptance of prediction markets. The same action might also
improve the general quality of journalism, potentially.
Proposal
The prediction market creates a new feature. The feature allows a user of the market
to create a small badge, displayable on the user's blog, Medium, Substack, or
elsewhere, that displays the person's username and a score measuring the accuracy
of their predictions.
The score could be an absolute measure such as Brier score, or a relative measure
such as the percentile that the person occupies within the market. It could also be
colored according to the number of predictions the person has made; or it could have
a tag indicating that this accuracy only obtains within a particular subject or ﬁeld; or it
could indicate the time horizon with which they typically make predictions; generally,
there are numerous addendums that could be added.
All of the above details are important, but for the moment I put them to the side.
The badge could be displayed at the head of every article by the author, potentially.
Codewise, this would work similarly to any front-end widget managed by another
server, i.e., like a commenting system, like a Twitter embed, and so on and so forth.
So of course it would update live as the predictions by the author came true / did not
come true, even on older articles.
(This badge could be supplemented, of course, by embedded questions from
prediction markets, which could be placed in articles. Metaculus already has these.)
Possible Points in Favor
People are tired of shitty media. There's an enormous groundswell of media distrust
from many angles, as far as I can tell. A measure like this is easy to understand, at
least in the basics, and provides clear evidence of credibility for those who use it,
entirely independent of trust.

It also evens the credibility playing-ﬁeld between individuals and large agencies,
which could be popular.
People like little badges if they grant status. If the ﬁrst users of this are suﬃciently
high-prestige, or if predictions / articles made by users of this badge gain fame, then
many people will want this. (After all, people wanted to get the Twitter veriﬁed badge,
right?) This could lead more people to the prediction market, which would be good.
Tying narrative to numbers helps broad acceptance of prediction markets. Prediction
markets are great, but prediction markets are not stories, and people love stories.
Having people write journalist-y narratives within the context of their personal
predictions could then make prediction markets more popular, while also constraining
said people to attend more carefully to the truth.
Possible Points Against
Writers don't want auditability. This is true; a lot of writers do not. If enough writers
start using this, though, ideally the lack of such a badge would be considered strong
evidence the writer does not take truth seriously, and it would therefore become in
the interests of writers to include it.
People just won't start using it. I think the most diﬃcult part, here, is getting an initial
quantity of writers to start using such a badge. A prediction market could help this by
enlisting some famous people to start using it. But I freely admit early acceptance is
the trickiest part. I'm not sure what the best approach is.
There's a host of generic objections that also apply equally well to all prediction
markets, which I will not here address.
Honestly, not sure if this would work or not.  But I think there's a possible world where
it could help a lot.

Avoid Contentious Terms
A succinct term for a concept is great, but only if everyone involved views it similarly.
If you're trying to write something persuasive, controversial terms are traps that can
derail discussion and make ﬁnding common ground harder. Consider limiting yourself
to well understood terms to avoid distracting from your core argument.
One of my favorite comments I've received was "you're really good at talking about
the patriarchy without talking about the patriarchy," on a post about dividing tasks in
marriage. I didn't use terms like "emotional labor", "sexism", or, as noted,
"patriarchy". This typically involves slightly longer phrasing, but it's not too bad; that
post has "not everyone wants to be or will be in a male-female couple" instead of
bringing in "heteronormative". Similarly, a version of the post I wrote about tickling
kids that used "consent" or "rape culture" would have been worse.
There are two main ways people bounce oﬀ terms:
Aﬃliation. A piece mentioning "emotional labor" will lead readers to one set of
inferences about the author; one mentioning "traditional marriage" will bring
diﬀerent inferences to mind. This can be useful if you are trying to strengthen
the views of people who already agree with you, but not if you're trying to bring
in new people.
Confusion. Your audience may not know what your terms mean, or, worse, may
think they mean something diﬀerent than you do. In discussions with your
friends a broad understanding of "racist" may be implicit, but if you use the term
to describe credit scoring many readers will take it as a claim that the system
was maliciously and intentionally designed to disadvantage people on the basis
of their race, and perhaps that credit scores explicitly consider an applicant's
race.
There are some downsides to this approach: it can make it harder to ﬁnd your piece
through searching and it can feel somewhat detached from the broader conversation
on the issue. It's probably not for everyone, but it's a pragmatic approach I've found
works well.
Comment via: facebook

Judging Our April 2020 Covid-19
Predictions
Scott Alexander has given his verdict on our predictions for Covid from April 2020. 
This seems like an excellent opportunity to reﬂect on those predictions. I'll also attempt to
render my verdict on the predictions, based on the principles I discuss in Evaluating
Predictions in Hindsight under Hard Mode, as Scott's already done the Easy Mode work. 
Afterwards, I'll give my take on the Assorted Links from that post as well.
Note on Methodology
This post is where I gave my predictions. Note that I don't give my fair probabilities here.
Instead, I give what prices I'd be willing to wager at. This is an important distinction. 
The coward's method of proposing a wager is to say 'Bob, you think this is 90% likely, I think
that's too high, so surely you will give me 9:1 odds.' That's nonsense, of course, because
Bob previously thought those odds were fair, and now someone wants to bet against him.
Why should Bob let someone pick which predictions of his someone bets against at fair
odds?
The epistemic hero's method would be to give your own fair probability, and oﬀer to meet in
the middle via the Green Knight test (you'd do the math and combine into one wager). Thus,
'Bob, you think this is 90% likely, I think it is 10% likely, so let's bet at even odds.' 
The gambler's method is to consider the prediction as if it were an initial value for a
prediction market, and reveal how far you'd be willing to move the odds while still being
comfortable wagering. That doesn't mean you would then think the odds were fair, or that
you'd be comfortable if someone wanted to bet against you on your own side at those new
odds. Thus, you say something like "Bob, you say 90%, I'm willing to bet against that at 80%
odds" which means you think it's at most 80%, so you're willing to place bets ﬁrst at 90%,
then 85%, then 80%, so long as cumulative size isn't too large, but then you'll stop and
won't place the one at 75%. If Alice comes along and says "You stopped at 80% odds, I want
to bet against this at 75% odds" you might or might not accept her wager. Often you
wouldn't.
It's not a ﬁrst-best solution to (at least sort of) keep two sets of books in your head, where
the odds on the game say 50%, you're willing to bet up to 55%, but your gut tells you your
side will win 70% of the time. It is still often a very good practical solution to keep both sets
of books, and mostly avoid placing wagers inside the 55%-70% window. One way to think of
that is you'd be at 70% as fair value if you hadn't seen the market, but you respect the
market and know you're often wrong. But if the market wanted to move higher, you'd oﬀer
no objections.
In this case, looking at the gambler's limit prices improves my calibration score, because I
was overconﬁdent in the overall arc of the pandemic and our reactions to it, which is why my
log score was highly unimpressive. In Hard Mode, we consider everything including
reasoning, so such calculations are mostly set aside either way.
I encourage you to follow along by reading my previous thoughts in the original post as you
go down the list of questions, to get the full explanations, as for space reasons I'm cutting
them short here.

Questions
False. The biggest mistake I made in this pandemic was vastly underestimating the strength
of the control system. My explanation on this question makes that very clear. I thought it
wasn't likely that people would be willing to continue containment that didn't make progress
even until June, and I was very wrong. Should have been higher than 60%. I consider this
prediction a rather large error.
False on Scott's grading. They did relax things somewhat in between, so I'd view this as
ambiguous. Under my read at the time I think there was a major (but far from total)
relaxation that was then rescinded. Despite this, 10% was a really bad prediction here no
matter the interpretation, there clearly was a plausible path for fully sustained lockdowns
thanks to the control systems and the way California was choosing its risk tolerance levels.
This needed to be at least 25%.
False. This one comes out looking correct. By the time the prediction was made this was sub-
1%.

False. This was closer than I would have expected, seasonality helped a lot and I
underestimated it. My guess is the right guess was a little higher than this, something like
35% or 40%.
True. I essentially say 'I think this is higher than 90% but for various reasons it's tough to bet
things up higher than 90%.' In hindsight this is so high a threshold it's essentially a Can't
Happen, but given information at the time I don't think 90% is crazy low - it's plausible 95%
is a better prediction but I don't think more than that would have been wise.
True. I did win this one but again feels overconﬁdent given what we knew at the time, and I
bet this one up a bit too high, although China's presumed willingness to fudge numbers
matters. 85% would have been a better stopping point.
True. On reﬂection, giving a full 10% to 'China has the worst death toll but oﬃcially denies it'
seems crazy high, and I'm ﬁne with this one at 80% with only a 5% diﬀerence between the
two numbers. I didn't think hard enough about that question at the time.
True, I got this overturned 'on appeal' via a Twitter poll. My logic at the time goes on to
explicitly say that I expect this to remain the narrative even if it's no longer true, rather than
being a prediction that almost never does another city end up getting hit harder. On
reﬂection, indeed do many things come to pass, narratives shift in strange ways and 90%
was the better prediction.

False. This was either damn close (95,963!) or not close at all because China cares about
round numbers and was only going to let it cross 100k if they had no choice, and they had
plenty of choice. I was surprised to see China's case count had risen this much, and it's kind
of suspiciously close to 100k given that a lot of people have incentives not to report cases
and China doesn't want to cross round thresholds. I'm going to say that 40% was a pretty
good prediction.
True! Vaccine timelines being so fast was a huge outlier. We succeeded here, but only by a
few weeks, despite things going mind-blowingly right and seeing much better results than
anyone expected. AstraZeneca messed up their trials but that was the only major thing that
went wrong, and it's hard to see where things could have gone much better short of some
small country going rogue. I'm not sure whether 40% or 50% was the better prediction here,
but that seems like a good range.
11. Best scientiﬁc consensus ends up being that hydroxychloroquine was signiﬁcantly
eﬀective: 20%
Sell to 15% or so, while noting that I think the chance of it actually being eﬀective is much
higher than that.
False. I like this assessment in hindsight. We now more fully understand the extent to which
The Narrative pushes hard on things like this, and would have made it exceedingly diﬃcult
for HCQ to be accepted as eﬀective even if it was eﬀective. It would have needed to be a
game changer. 
12. I personally will get coronavirus (as per my best guess if I had it; positive test not
needed): 30%
Sell to 20% at least, and also what the hell? 
False. Yeah, I didn't sell enough of this, no way he was at 20% risk to catch this and his
prediction here seems even siller now.
13. Someone I am close to (housemate or close family member) will get coronavirus: 60%
Sell to 40%.

False. This seems like a more reasonable place to have stopped than the 20% from #12. I
want to say still a bit high, but room here for some people who might not take good
precautions. Note that the 2:1 ratio here between these two questions is deﬁnitely silly and
selling them both down a third indicates a mistake somewhere.
14. General consensus is that we (April 2020 US) were overreacting: 50%
15. General consensus is that we (April 2020 US) were underreacting: 20%
"General consensus will be that we were reacting stupidly. We reacted wrong. That's an easy
call. The question is, will that be widely seen as an underreaction, an overreaction,
something that's neither, or will there be a lack of consensus? What does it take to get a
'consensus'? Who counts?
My guess is that there ﬂat out won't be consensus.  
...so I'm going to sell the overreacting contract down to 30%, but stop there because people
are bad at such things and ﬁnd ways to rewrite history to suit their narratives. I'm going to
hold the 20% on underreacting"
False on both, as expected there's no consensus apart from the consensus that we were
acting stupidly. Which is hard to avoid as a conclusion, given we did contradictory things in
diﬀerent places and at diﬀerent times, and also dropped some rather important balls. But
even then I'm not super conﬁdent you'd call it a 'consensus.' By only going down to 30% and
20%, I seem to be implying I'm not that conﬁdent in a lack of consensus, so this seems like I
should have been somewhat bolder.
16. General consensus is that summer made coronavirus signiﬁcantly less dangerous: 70%
True. Again consensus can be tough, so 70% seems reasonable or even a bit high. I don't
think we could be super conﬁdent in this at the time.
17. ...and there is a catastrophic (50K+ US deaths, or more major lockdowns, after at least a
month without these things) second wave in autumn: 30%
True. I stand by this being a substantial underdog for exactly the reason I noted, which is that
this is a parlay of several things that each must happen - we need to go under the bar, then
back over the bar, on multiple fronts. There were Major Lockdowns each month, but it's not
clear there were 'more major lockdowns' each month, so I do think technically this evaluates
to true as written, but as far as intent it's not clear to me this fully happened because it's not
clear lockdowns suﬃciently lifted. Parlays are hard to win!
18. I personally am back to working not-at-home: 90%

False. Seeing this as diﬀerent from the lockdown percentage seems clearly right in hindsight,
and the reason I'm still too high on this is that I got the lockdown probability wrong. If we
compound that 25%+ with another 10% here we get that this can be at most around 65%,
and also other things can always happen so 60% seems like a more reasonable maximum.
19. At least half of states send every voter a mail-in ballot in 2020 presidential election: 20%
False. I don't think this was ever close to happening, exactly for the reasons I laid out. Not
moving markets too far when you're anchored, especially betting on a big favorite, is always
good policy.
20. PredictIt is uncertain (less than 95% sure) who won the presidential election for more
than 24 hours after Election Day. 20%
True. Thinking about all the right things here, still getting to the wrong answer. Seeing
accusations of fraud as unlikely looks silly in hindsight, especially given the extended
willingness of the market to stay insane long after the verdict was in. You can say it should
have been under 95% for 24 hours, but you can't say that for a month out. So that reasoning
wasn't great. The question is how close the election had to actually be in terms of tipping
point margin of victory, in order to allow it to be thrown into question, in each direction, and
thus how likely such a result was. The tipping point state was Biden+0.6%. My guess is that
Biden+3% or Trump+1% would have settled things quickly. That range seems more like a
30% shot than a 10% or 20% shot, but also we got a very large amount of fraud accusation
versus reasonable priors in April even given that we should have expected a lot more fraud
accusations than people did expect. I think 20%-25% seems like the right range in hindsight. 
I also looked at Scott's non-Covid predictions, but we'll postpone looking at those until Scott
grades them.
Appendix: Metaculus Monday Links Thoughts
1. Hypermind looks promising at ﬁrst glance.
2. Vitalik Buterin talks about his adventures winning $50,000 betting against Trump on
Ethereum prediction market Augur.

My takeaway from Vitalik's journey is that it took $50,000 worth of time and technical
expertise to make that $50,000, and the only reason it made sense for Vitalik to do it was
because of the value of reporting on the results and in learning by doing. Essentially this is a
start-up style operation to see if things can scale, and even with the completely insane
market and uniquely huge event the opportunity size wasn't great. Perhaps in 2024 such
things will be ready for prime time but for now I would treat the operational risks involved as
bigger than the proﬁt margins oﬀered. 
What's most weird to me is that the various prediction markets stayed in line with each
other, despite very diﬀerent participation restrictions and costs of doing arbitrage. My guess
is that a lot of people involved were not thinking about real costs and eﬀective odds, rather
thinking about whether the market prices lined up and were 'fair' in some sense.
3. This week on Metaculus: will a third-party candidate win 5%+ of the popular vote in
2024? Users say 15% chance
Scott is betting against. I'm not. Not only Perot in '92 and '96 but Anderson in '80 broke this
barrier for 3 of the last 11, there are plausible known routes to this in '24 (e.g. Trump as 3rd
party, Trump (or someone in his image) as Republican causing a third party run, Libertarians
running Amash or Romney, or a proper run somehow by Kanye West or another billionaire, or
even a Warren/Sanders style scorched earth campaign on the left if Biden runs again). Hell,
the way things are weirding who knows who will run. If anything I'd be at 20% rather than
15%. 
4. Also, will Bitcoin outperform the US stock market over the next ﬁve years, at 51%. I
started out thinking - of course it's 50-50! By the eﬃcient market hypothesis, if any
asset was obviously going to do better than another, people would change the price
until it wasn't. But on second thought that's wrong - stocks have a higher than 50%
chance of beating treasuries over the same period because of a risk premium. Maybe
there's no intuitive way to think about this, you have to have opinions on the
underlying fundamentals, and it's only 51% by coincidence?
It's at exactly 50/50 now! I quoted Scott in full above to ensure I fully represent his thinking
here. Looking at this market tricked me into trying to put in a prediction, despite that then
putting a burden on me (in theory anyway) to update that prediction continuously or lose
points, but it said I was Forbidden to do that, so I didn't.
This does not reﬂect well on Metaculus. The 50% number is crazy, or at a minimum, it
represents a very strong rejection of the Eﬃcient Market Hypothesis, and would make Bitcoin
what is known as a Screaming Buy. 
This comes up every time I see Bitcoin price distribution predictions. Bitcoin can only go as
low as $0. Bitcoin could, in theory, go up not only to $100k but to $1 million or more. 
If the Bitcoin distribution centers on the same place as the stock market, it is a screaming
buy compared to the stock market, and you should put a substantial portion of your net
worth into BTC. 
If Bitcoin is priced eﬃciently now, then that implies it is more likely to fall than rise, even
with a substantial risk premium, because that's the only way for the math to come out even.
The alternative is to both think BTC is priced fairly and that almost none of that value is the
potential to rocket to the moon, which doesn't seem right to me at all. If you think BTC can't
rocket, BTC is a bad buy.
Perhaps Metaculus thinks Bitcoin is indeed a screaming buy. That's not a crazy thing to think.
But if it does think that, it seems like an awfully big coincidence that this landed on exactly
50%. 

There's no trade, since (as many people reminded me) Metaculus is not a prediction market
and you can't trade on its values, but there's still a big contradiction with market prices
here. 
None of this is investment advice in any way, but: My model of BTC at the moment is that
expected returns for holding BTC are positive, in excess of its fair risk premium, but that in a
large majority of worlds it will be outperformed by the stock market, often that involves very
large declines, and also you have to account for tax liability and the chance someone will
steal your bitcoins.
The weekly Covid update will be posted on Thursday as per usual.

The 10,000-Hour Rule is a myth
This post appeared ﬁrst on the EA Coaching blog .
The 10,000-Hour Rule for expertise popularized by Malcolm Gladwell is a funny case of
citation telephone. Basically, the rule claims that anyone can become an expert if
they spend ten thousand hours practicing. In other words, ten thousand hours of
practice is necessary and suﬃcient to become an expert. It's attributed to research by
Anders Ericsson, the psychologist who pioneered the study of deliberate practice. 
An interpretation which Ericsson published a three-page paper refuting. (You can read
the whole thing here.)
The best violinists averaged ten thousand hours of practice, compared to their less
accomplished counterparts who "only" averaged ﬁve thousand. (Keep in mind that
Ericsson studies expert performance - he wants to know what makes people excel, so
he's not studying average populations.) 
According to Ericsson, Gladwell claimed that 10,000 hours was the "magic number for
true expertise" based on Ericsson's work. This misrepresentation won popular appeal
and spread. In internet mythos, the average is now misrepresented as a threshold
after which people magically become experts. (I pity the poor stats professors
weeping into their pillow at people abusing averages.) 
This is another example of why you should take pop sci stuﬀ with a grain of salt. The
10,000-Hour Rule was coined and popularized based on a game of citation telephone
tracing back to a misunderstanding of a statistic. The guy it's attributed to denies that
he ever said or intended to convey that message. That should be enough to warrant a
dollop of skepticism for the next bright claim to come along. 
Still, if the 10,000-Hour Rule is an urban myth, is there still anything to learn here? I
think so. 
1. 
Becoming world class takes a heck of a lot of time. Ten thousand hours is twenty hours
of practice a week for ten years. That's how much the best violinists averaged by the
time they were twenty, and it's not like they stopped there. They probably continued
that rate of practice during their actual career. In another example, winners of
international piano competitions had around twenty-ﬁve thousand hours of practice
under their belts.
Even assuming signiﬁcant heterogeneity, it will probably take a lot of time to compete
at the highest levels in a standardized ﬁeld such as sports or music. If you can ﬁnd
niches where the competition doesn't practice as much, you might be able to stand
out with much less eﬀort. For example, Ericsson found that students reached world
class levels for memorizing long strings of numbers after only ﬁve hundred to a
thousand hours of practice.
Either way, you should probably expect to measure your success across years. I've
only spent about four hundred hours blogging, so I shouldn't be surprised that I have

oodles of room for improvement left. So don't be disheartened if you only see tiny
motes of progress on the scale of weeks. 
2.
Raw time also isn't suﬃcient. You also need to use that time eﬀectively, which
Ericsson claims is best done via deliberate practice. As someone who half-heartedly
practiced piano for two years to appease my mother, I can attest that just putting in
hours does not promise results. Deliberate practice tries to maximize learning per
eﬀort invested.
Importantly, deliberate practice commonly involves learning new and better methods,
rather than repeating what you already know how to do. For example, one study
subject started out able to remember a string of seven numbers. By learning better
memorization techniques he got that number up to 18, more than doubling his original
length. But then he struggled to continue learning. He had to learn even more
memorization methods before he could break that plateau - and remember up to 79
numbers! 
Deliberate practice is a slippery term, but tends to be characterized by:
Focused practice on a speciﬁc subskill within the larger skill you want to
improve. E.g., Ben Franklin improved his writing by transforming essays into
poems to expand his vocabulary.
Feeling pushed near the edge of your capabilities. You usually need to think hard
about how to improve, learn challenging new material, or carefully practice
something outside your comfort zone. E.g., practicing a tricky piano ﬁngering
until you can do it ﬂuidly.
Clear, rapid feedback on how well you did and what you need to improve. This
can be self-directed, but ideally comes from a 1:1 instructor. E.g., an
experienced cook telling a beginner cook what spices their dish is missing.
I suspect that both the expert instruction and intense focus beneﬁt deliberate practice
by helping you see ways to improve that would have slipped by unnoticed otherwise.
Note, deliberate practice isn't just about ﬁnding new methods - you also need to
deliberately practice those methods until they become routine and your whole process
works better. 
Similarly, by focusing on one small skill at a time, you can give it the attention needed
to ﬁnd and practice ways to improve that piece of the overall skill. For example, I'm
experimenting with Obsidian right now, because, for some people, a great note taking
system acts as external working memory and brings new insights to their writing. If it
works out, I might see a sudden jump in writing quality. Whereas I expect that just
writing more will have a gradually diminishing learning curve. (Unless, of course, I
learn new methods for writing.)
3.
In his paper, Ericsson addresses an interesting debate. Basically, some critics accused
him of denying that genetics had any eﬀect on success. Ericsson responds that he

never argued genetics play no role, just that you can improve a lot with practice,
particularly if you begin as a child. 
What's surprising here is how strong a claim Ericsson is still making. He believes you
can change virtually every aspect of the human body and nervous system (except
height and body size) with sustained intense training. 
I actually had the chance to talk with Ericsson and some other positive psychology
researchers about this topic a few years ago. The message I walked away with was
that no one there denied that a ceiling probably exists on how good a particular
person can become at something. They all accepted this was true. 
It just didn't matter.
They didn't care about ceiling eﬀects because it was like someone complaining that
they could never beat Michal Phelps, so they never learned to swim. Sure, there is a
ceiling there that they probably can't beat. But they are so far from that ceiling that it
just seems silly to care. If instead they focused on what they could do, they could
probably become a pretty good swimmer.
Ericsson also writes about multiple domains where there seemed to exist a learning
plateau, and then the person overcame it by learning new methods. E.g. people
learning Morse code seemed to hit a limit, but better teaching methods were able to
help them overcome it. 
From that perspective, even the experience of feeling like you've hit a ceiling is
suspect. A better teacher or new method could unblock even an already skilled person
from improving. 
Within eﬀective altruism speciﬁcally, the ceiling people seem to worry the most about
is intelligence. 
I speculate that this is a backlash against IQ deniers. The internet spits out articles
about how IQ is a myth and anyone can succeed if they just try. This causes people
like Scott Alexander to write a bunch of articles defending IQ. Eﬀective altruists see all
this evidence -- and care about believing true things-- so this is really convincing. (It
probably doesn't hurt that our monkey brains also notice these beliefs signal ingroup
solidarity...) 
This has the unfortunate side eﬀect of pushing some eﬀective altruists toward
worrying that they aren't smart enough. Then they obsess over a ﬁxed trait and
scramble for nootropics. (The resulting depression and anxiety also aren't helpful.) 
Which is rather strange. Scott has the excellent analogy that we'd look at someone
funny if they said height didn't matter one bit for becoming a professional basketball
player or if they said that practice didn't matter one bit for the tall person becoming a
professional basketball player. Similar, intelligence has a ﬁxed genetic component and
your experience of intelligence is malleable in response to eﬀort. 
I'm particularly interested in the experience of plateaus that we attribute to limited
intelligence. For example, when I asked Scott Alexander about his writing process a
while back, he said that he composes the post in his head until writing is "a little
harder than just transcribing the way I imagine it, but not *much* harder" (at least for
short posts - like the length of this post). 

I can't do that. I frequently ﬁnd that I can't hold more than a couple paragraphs worth
of an essay in mind at once. After that, they slip away and I lose the chain of thought. 
Should I toss up my hands and despair of ever being a good writer? Well, if blogging is
only worthwhile if my blog will be described as a "national treasure," then it's worth
thinking about what this means for how much eﬀort and time it would take to get to
that level. .
If, however, I just care about being able to build out useful thoughts? Then this
probably doesn't I say much, because the amount I can hold in mind at one time is a
constraint on working memory. Fortunately, writing things down is itself a way around
this problem. I can write down multiple threads of thought and address each one in
turn. Writing is eﬀectively a method for expanding working memory. 
I expect many other cases that feel like limits in intelligence may actually be plateaus
in working memory or processing speed or learning techniques. What do we actually
experience that hints at lower intelligence? Slower learning? Less creative problem
solving? Worse grades? Less work output? 
These experiences are probably related to intelligence, but you will see an
improvement in your learning speed and grades if you improve your note taking or
learn better study techniques. That points to deliberate practice playing a role even in
areas that we might traditionally attribute to intelligence. 
And yes, there are some instances where it probably does matter if you're in the top
.01% of the population. If you need to succeed at that level for it to be worthwhile, it's
worth testing if you are likely to meet that threshold. 
But in general, if you want to improve and are willing to invest eﬀort ﬁnding the best
methods to do so, you probably can. 
Special thanks to Nora Ammann for her feedback.
Enjoyed the piece? Subscribe to EA Coaching's newsletter to get more posts delivered
to you.

How my school gamed the stats
I was reading the Slate Star Codex review of The Cult of Smart. Part of it discusses
charter vs state schools and the allegations of fraud of various kinds undermining
charter schools record of better achievement. Reading it, I realized that I took for
granted that public schools engage in systematic fraud in a variety of ways. I don't
think this is something everyone understands, hence this post.
I went to a state school in the UK. State schools are rated on a 1 - 4 scale from
unsatisfactory to outstanding. My school was rated good, meaning a 3. A few
memories which stand out. During my ﬁrst week I saw one of the boys in my class
who was 11 at the time held up against the wall in a corridor while a 16 year old put a
shiv to his throat and robbed him. He handed over his wallet and keys. A year or two
later and I remember seeing a small boy who struggled with depression held up by the
throat against a locker and slapped in the face by a troublemaker from the same class
in front of everyone just before we went in to the classroom. I remember classes
which were ﬁlled start to ﬁnish with people shouting and talking. Neither of the ﬁrst
two events were common but they also weren't uncommon. No one was surprised to
witness them. It's worth emphasizing again that my school was above average, in fact
quite far above average, and in a middle class area. It's also worth noting that I was
mostly in top ability streamed classes, meaning my classroom experience was likely
far better than average.
There were many ways in which the school and teachers gamed the system to boost
their measured performance. One way was to do exams for students. I was on a
bottom set language class for French. After two years I literally couldn't speak a single
sentence in french and maybe knew 20 words in total. I still passed my exams. How?
We did the tests in class. Often the teacher would go through them with us. Literally
giving us the test and then going through each question on the whiteboard and telling
us what to write. A diﬀerent year and a diﬀerent teacher, this time the teacher would
sit next to us and write the answers down. Why sit next to us? It was the bottom set
so people often wouldn't even bother to write down the answer if they were told it.
This kind of thing was normal, so much so that I, and I think most people there, didn't
realize anything unusual was happening.
Another way schools game metrics is to cheat inspections. A major component of how
schools are judged in the UK is through independent inspections carried out by an
independent quasi-governmental organization called Ofsted. Now, you may imagine
that these inspections would be unannounced, so as to best get a real image of how a
school works. Not the case. They're scheduled well in advance. Before every
inspection, a few things would happen in my school:
The worst troublemaker kids would be taken aside and put in a special room
where inspectors wouldn't see them. Either that or they would just be told not to
come into school at all on that day.
All of us were told in assembly that an inspection was coming and to be on our
best behavior on that day. Often teachers would have conversations with less
serious troublemakers and impress on them that they would behave on that day
or face consequences afterwards.
Teachers would put a great deal more eﬀort into their lesson plans than was
normal. Classroom behavior management would also be far stricter. Because of
these and other measures my school during an inspection was utterly diﬀerent

than my school on a normal day. On some level this isn't surprising. If teachers'
promotions and management's jobs depend on good inspection results and
inspections are easy to game, people will game them. Incentives drive behavior.
But it's still sad.
Another way the stats were gamed was by not recording bad behavior. When a school
gives a detention or suspends/expels a student, there's a record of it. This is especially
true of suspensions, students being sent home or expulsions. The more of these you
have, the worse you look as a school. The solution then is obvious, don't punish
people or punish them in non-recorded ways. Again, in my school it was completely
normal for students in lower sets to swear at the teacher, talk over them or disrupt
the class for everyone else. It was normal for someone to be aggressive and abusive
towards others and to face at most a 40 minute detention, but even getting a
detention would be unusual.
I realize that one data point is not enough to draw solid general conclusions. My own
perception is that this kind of fraud wasn't speciﬁc to my school. My cousin went to a
state school fairly nearby. He's 4 years younger than me. During one of my winters
back from undergrad we discussed his school and his experiences mirrored mine. His
exact words regarding inspections were "I learned 4 times more that day than any
other day that year. It was amazing". I talked to a few British students at university,
although speciﬁcally the not middle/upper class ones who would have gone to public
schools. They had gone to schools similar to mine in diﬀerent parts of the country and
their stories were similar and often worse. Two particularly funny examples from my
friends' experiences stand out. A teacher in year 9 walked up to a student who was
talking, picked them up and threw them out of an (open) ﬁrst ﬂoor window. My friend
sitting in class noticed two boys making fun of him and then proceeded to get up in
the middle of class while the teacher was talking, walk to their table, ﬂip the table
upwards to hit them in the face before going to sit down again when the teacher told
him to. (Remember, my friend was a studious, sporty Asian kid and not a
troublemaker. This kind of thing is normal in that environment). Comedic stories aside,
my experiences in school, while not universal, seem fairly common in the UK and from
what I've read of the statistics, bad US schools are far, far worse.
I'm unsure what my point here is. I think I have two:
Charters may cook their books in various ways. In the UK, State schools do too. I
would be surprised if it wasn't also the case in the US.
I think that I feel like a lot of commentators on places like SSC have fairly middle
class experiences of fairly good schools and that bleeds into how their
comparison between state vs charter schools. It's just good to remember that
it's not those nice middle class schools that charters typically replace.
Crossposted to my blog at https://dissent.blog/2021/02/20/how-my-school-gamed-the-
stats/

The slopes to common sense
This is a linkpost for https://cerebralab.com/The_slopes_to_common_sense
The slopes to common sense
Usually, I try to outline the thing I'm talking about ﬁrst. But in this case, it's best to start with
an example.
i - Why we sleep
In 2017 the book "Why We Sleep" was published. This book was essentially trying to muster
a very strong scientiﬁc argument for why one should sleep 8 (self-reported) hours a night. In
that, it argued the health and cognitive beneﬁts of sleep are so great that sleeping less than
8 (self-reported) hours a night is insane from a cost-beneﬁt analysis perspective.
Two years later, Alexey Guzey stumbled upon the book and wrote a pretty stark rebuttal of
the ﬁrst chapters, essentially showing that the epidemiological evidence does not exactly
support the author's conclusion and some of the smaller claims that reinforce it. It should be
noted that in some cases "Why We Sleep" doesn't only ignore the evidence on the subject,
but outright engages in data manipulation.
To me this seems like a fairly clear case of "chunk the book in the junk science bin, try to tell
people not to read it and move on". So was that the internet's reaction? Well, that's hard to
say, the top discussion threads around the article as shown by Google are:
Hacker News
/r/ssc
/r/sleep
/r/sleephackers
I ﬁnd it very interesting that in all 4 discussion threads it seems like the consensus opinion is
something like "yeah, but the book is still pretty good" plus a bunch of people upvoting
comments that criticize the rebuttal without having read it (i.e. the answer to their criticism
is found in the rebuttal itself).
It should be noted here that /r/sleephackers and /r/sleep are supposed to be specialized
communities, i.e. the kind that would care about even minor factual errors regarding this
topic. And /r/ssc, as well as HN, should boast an audience that's educated enough not to
confuse science with a new global religion.
So why is everyone still agreeing with the core thesis of the book?
I don't know, but I can speculate it stems from a line of thought that goes something like
this:
Yeah, ok, maybe it's not proven that 8-hours of self-reported sleep is the ideal. Maybe
there are +/-3 hr variations depending on the individual and environmental factors.
Maybe short sleep is not correlated with that many negative things, or not that strongly.
Still, the general point that it's cautious to try and sleep as much as you feel you need
to, and not set an alarm sooner than 8 hours after bed, seems sound.
This is fair... except for the fact that you are not agreeing with the book in making the above
statement, you are agreeing with literally every single mother and grandmother in the world.

The general idea that you shouldn't force yourself to sleep less than you feel like and that 8
hours a night is a rough guideline for a good amount of sleep if you have to set a clock is... I
assume, at least as old as ﬁxed-schedule jobs and alarm clocks. I won't go around digging for
citations now, but quickly browsing through some 19th-century novels should be all it takes
to prove my point.
The pattern above has as its ﬁrst ingredient a commonly accepted view (why it is so is
irrelevant, it might be true or not, it might also be so deeply embedded into society that
questioning its truth value is pointless.) In our case, that view is:
Sleep however long you feel like you need to, try sleeping during the night, as a general
rule of thumb (e.g. if you have to set an alarm clock) aim for 8 hours a day. If you're
sleeping less than 5 or more than 11 hours something is probably oﬀ, so just in case, go
see a doctor.
But you can pull that commonly accepted view in diﬀerent directions. For the sleep claim, for
example, I could pull a bit towards the "less sleep" direction:
Sleep however long you feel like you need to, try sleeping mostly during the night, as a
general rule of thumb (e.g. if you have to set an alarm clock) aim for at least 6 hours a
day, but you can go up to 8 if that feels better. If you're sleeping more than 10 hours
something is probably oﬀ, so just in case, go see a doctor.
Or, as "Why We Sleep" does, I can pull it towards the "more sleep" direction:
Sleep however long you feel like you need to, always sleep during the night, sleep at
least 8 hours a day, but 9 might be better. If you're sleeping less than 7 hours something
is probably oﬀ, so just in case, go see a doctor or review your sleep habits.
Now, you might not be perfectly on-board with me on what the "commonly accepted" view of
sleep is, so feel free to construct your own deﬁnition here and then construct 2 alternative
deﬁnitions, one higher and one lower on the "amount of sleep" axis.
Done? Ok
ii - Directions of common sense
Hopefully, you'll note an interesting phenomenon here. Or at least some of you will. The
"more sleep" variation of the common-sense view probably sounds more reasonable to you.
As in, the burden of proof for "more sleep" is probably less than for "less sleep". It's true that
neither are as convincing as the common-sense view, otherwise, it would lose its namesake,
but it's obvious that the common-sense view doesn't glide in a "linear" way. Indeed, any
argument for not improving sleep quantity and quality (you shouldn't care about your
mattress, PJs are overrated, room temperature doesn't matter, feel free to use your phone
before bed, you don't need a fancy pillow, always set an alarm clock) sound much ickier than
any argument for improving sleep quantity or quality (reverse the above list).
Basically, a common-sense view on any axis can be thought of as a local-minium, but the
slop on one side (e.g. sleep less) can be much steeper than the slope on the other side (e.g.
sleep more).
In other words, there's a steep direction in which you can try taking a common-sense view,
where you'll encounter more opposition and a ﬂat direction in which you will encounter less.
Granted, I don't think this applies to every common-sense view, but I really like the model.

Going back to my original question about "Why We Sleep": So why is everyone still agreeing
with the core thesis of the book?
In principle, I think it's because "Why We Sleep" unintentionally pulls a dirty trick:
Align yourself with the common-sense view.
Argue for shifting the common-sense view towards the ﬂat side.
What happens then is that anyone arguing against you seems to be arguing for shifting the
common-sense view towards the steep side. Even if this is not true.
The takeaway from the rebuttal of "Why We Sleep" is not "sleep less", it's just "change your
opinion about sleep's health beneﬁts to back where it was before you read the book".
In case this is not obvious, think about it the following way: Telling anyone anything will
create some opposition, some anger because now they have to adjust their model of the
world. But the amount of anger generated is asymmetrical depending on the direction you
tell them to shift their view towards:
 
So tell someone that they should shift that view towards the ﬂat direction, e.g people should
sleep more, and they might get a bit annoyed, but they will weight in the potential utilities,

your credentials, the empirical evidence (just kidding) and they might suppress that tiny
annoyance and turn it into interest and gratitude or even agreement with the new
information.
But tell them that they should shift that view towards the steep direction and they will very
quickly become very pissed oﬀ at you.
iii - Broader phenomenon
I swear I don't have a bone to pick with "Why We Sleep" more than I have with 99% of
popsci. I am giving it as an example here since it's the only thing I can think of where this
gradient issue is obvious, that most people will be familiar with, and that isn't very politically
involved.
The problem with this steep/ﬂat distinction is that it often applies to issues that are heavily
politicized, indeed, I think having a very ﬂat and a very steep direction of change might be
the very thing that makes an issue get into politics, to begin with.
Think about it, you pick an issue "A" and argue for shifting common sense towards the ﬂat
side. Some people might grumble a bit, but overall, whatever, at most nobody care, at best a
lot of people agree. But politics involves opposition, if your opponents agree with you they
are made to seem dumb for not having ﬁgured it out ﬁrst... and if they disagree with you,
well, you can now paint them as arguing for going in the steep direction, and suddenly they
go from mild-mannered politician to "literally the devil".
At most your opponent has to add a lot of disclaimers, like:
Yes, I know the steep direction exists, I'm not arguing for going that way, all I'm saying is
that the common-sense view as it is right now is best and my opponent wants to shift it.
I'm not arguing we shift it the other way, I'm just arguing we leave it be as it is. Yes,
where it was is indeed closer to the steep part of the curve but it is a minimum, and
nobody is forcing us to push it the other way...
And as we all know, the more someone is forced to talk about something, the more they are
being aﬃliated with that thing. You on the other end, are going in the ﬂat direction, you
needn't care about being associated with anything bad, even if you are saying "let's go x in
the ﬂat direction" and the opposition paints it as "let's go 2x in the ﬂat direction", you are
still safe, 2x in the ﬂat direction is still not as bad as 0.01x in the steep direction.
The worrying acceptance selectively taking some of the things someone says out of context
as gestalt psychology, instead of taking them at face value, probably also fuels this whole
thing more.
In this model, political polarization comes from groups of people disagreeing about which
directions are ﬂat and which are steep.
It's also a model that allows for a worldview where people are mostly in agreement since
they all hold common-sense views. But can be polarized very quickly by a politician trying to
instigate their opponents into seeming to argue the steep side of an issue.
And this model ﬁts my understanding of people much better than other models of politics I
saw, which require heavily agentic behaviour from the voters, something I never see IRL. It
also moulds very well on the consensus making social dynamics in friend groups, or at work
and so on.
iv - The diﬃculty with scepticism

Finally, one thing I often noted is that, whenever I try to argue for a sceptical viewpoint on an
issue, i.e. argue that we know nothing about the subject, I fall into this problem where people
think I am taking "the other side".
For example, I might say something like:
The scientiﬁc method was not designed for or tested at the kind of scale where it can
make speculations about the origins of the universe. The models which got stretched to
create theories about the origins of the universe have never functioned without the
scientiﬁc method to back them up with the experiments whenever they stretched a few
inferential steps away. But the origin of the universe is essentially an inﬁnity of
inferential steps away given the sheer scale of the issue.
By which I mean:
While one can speculate about the origin of the universe for fun, the speculations remain
empty and even hinting that they fall under the umbrella of science is wrong. We can't
make any meaningful factual claims about the origin of the universe. We are too limited
to understand an event like this.
... Which seems to be the common-sense view. Most people in principle seem to agree they
have no fucking idea about why things are instead of not being and that the very question is
stretching the limits of language/reason.
But for some reason, a few people will hear me say something like:
Well, fuck this physics bullshit, I think superstitions are a much better model for
explaining the origin of the universe.
I expect I'm making the same fallacy myself in regards to other views, I'm not patting myself
on the back for being "wise and sceptical" here, I probably just have sharp/ﬂat distinctions
for subjects that other people don't and vice versa.
Scepticism might be an ability to recognize sharp/ﬂat distinctions in order not to be pulled
towards the "ﬂat" side for fear of taking the "sharp" way.
Or maybe scepticism is an ability to view something in enough detail to ﬁgure out someone
is arguing for the "common sense" minimum rather than being a few short steps away on the
sharp side.
At any rate, I think that this might be a good model for introspecting on my sceptical model
of the world, how I convey it to others, and in which situations I might be using it to make
isolated demands for rigour.
v - The rest
On the whole, this model is overly simplistic, the main things I'm glancing over are:
Common sense may not really exist regarding some issues.
Common sense might not mean the same thing for diﬀerent people on diﬀerent issues.
The function deﬁning ease of acceptance is not composed of two lines intersecting at
"common-sense", it can have a very complex shape. For example, a short "sharp" area
might be followed by a rather long ﬂat one, or even by a dip leading to a new
minimum.
The sharp/ﬂat distinction should probably be done in an n-dimensional space (n =
numerically quantiﬁable elements of a view), not a 2d one. But I think scaling this up
keeps everything intact, I'm not sure though.

Thinking of most beliefs as numerically quantiﬁable in a somewhat linear fashion is
probably wrong. However, most beliefs to have "goals" associated with them, and
those goals are usually sequential (e.g. a belief in communism might be: revolution ->
abolish private property -> abolish money -> abolish government), so really it might be
that "sharp" or "ﬂat" is really a distinction regarding the next goal on the axis of a
particular belief once we shift away from the commonly held view.
Does this leave me with a model that can be of any use?
I don't know, time will tell. I'm not "big enough" to use my own models in my own works, at
least not those that I hope to be coherent for a new audience.
If I ﬁnd this model allows me to generate a few interesting conclusions I might expand on it
and those conclusions in a future post. If not, maybe somebody ﬁnds it useful. At most I'll
ﬁnally be able to sleep more soundly, having potentially resolved some confusion, and
common sense tells me this will improve my health.

Current cryonics impressions
People around me often sign up for cryonics, and say that it is very important. My
guess is that this argument for it, heavily inspired by Waitbutwhy's much longer piece,
as well as years of talking to people around me and reading their blogs, is correct:
1. One day people will probably live much longer than they do now.
Probably we will work out how to beat the diseases of aging, as we have many of the
infectious diseases. Eventually dying at age 90 of heart disease will seem as much of
a needless tragedy as dying of an infection at age 45 does to us now.
2. One day we will probably be able to 'freeze' and usefully thaw organs like
brains using vitriﬁcation.
We can already do this with other organs. For instance a rabbit kidney can apparently
already be vitriﬁed then warmed up and put back in a rabbit and work.
3. People can start to successfully evade the diseases of aging as soon as
science reaches the freezing part of 2, even if it hasn't got to the thawing
part or to 1 yet.
Because once you are vitriﬁed, you can wait quite a long time for further
developments.
There is a decent chance that we are already at the freezing part of 2. For instance, a
defrosted vitriﬁed rabbit brain apparently appeared to be in good order, though I
assume we don't know how to reattach brains to rabbits, alas.
The chance that we are there on the freezing is high enough that people dying soon
(by our current standards of irrevivability) should generally be vitriﬁed instead of
burned or buried, if the chance to survive longer is worth the price to them.
You can sign up for something like this at the cost of a not-super-expensive life
insurance policy, though I think the more promising techniques at the moment aren't
available yet to purchase.
I haven't actually signed up for this, but I might, and if I thought there was a higher
chance of me dying sooner, I would get around to ﬁguring it out more urgently. So I
thought I'd point it out to others older than me, who might want to think about it more
promptly.
I found Waitbutwhy's essay on these topics pretty good.

The Economics of Media
When I was a kid I thought the news came from "investigative reporters" like Clark
Kent were who were paid to research stories. Since then, I have gotten my startup on
national television, placed a press release into the world news, discussed biological
warfare as a podcast guest, written a blog which has been reposted to Hacker News,
written fanﬁction which has been linked to on Reddit and read a lot of books. My
understanding of the media ecosystem has become more nuanced.
Media Economics
Small fry like Lyle McDonald, the McKays and Bruce Schneier can scrape by by selling
books, branded paraphernalia and other niche merchandise. Niche merchandise
doesn't scale. Large megacorp news outlets generally rely on subscriptions and
advertising for their core revenue.
Subscriptions and advertising scale linearly with the number of viewers. But the cost
of distributing Internet[1] media is negligible. An article costs the same to write
whether one person reads it or one million. The market equilibrium is one where the
great masses of people get our information from a tiny number of sources.
What people do with the information doesn't much aﬀect a media outlet's bottom line.
Whether the information makes people angry or happy doesn't matter except to the
extent anger and happiness aﬀect readership. Whether the information promotes
good policy doesn't matter at all—unless that policy directly aﬀects the news industry.
Content is fungible. Financially, what matters is how many people consume it.
Minimizing Costs
I learned a lot about Twitter when I hosted the 2020 Less Wrong Darwin Game. I wrote
a sequence 11,475 words. It dwarfed anything else I had ever written until then
because...I barely had to write anything. The story was created Vanilla_cabs and other
competitors. Reporters report on Twitter tweets for the same reason: because content
is fungible and because rehashing tweets is a cheap way to mass produce news.
But there's an even easier way to generate content: Let someone else do it for you.
Media businesses convert content into money. Media businesses don't care about the
content's secondary eﬀects. The cheaper media businesses can acquire content the
more money they can earn. Non-media business with products to sell want media
attention. Non-media businesses proﬁt only oﬀ of contents' secondary eﬀects. These
are the perfect conditions for symbiosis. If a non-media business can write a news
story for a news outlet then the news outlet gets free content and the business gets
free advertising. This kind of news story is called a "press release". The ﬁrst time I got
a press release posted in a major news outlet I was stunned by how little the press
release had been edited. The press release was basically copied word-for-word as
original content.

Political organizations, including governments, create press releases the same way
companies do, except their objective is political rather than commercial.
Press releases have the same economics as news stories because press releases are
news stories. Only large organizations (or startups with large aspirations) have the
economics to support press releases. Small organizations don't have comparable
economies of scale. The press release system therefore constitutes a emergent
pressure toward centralization. I suspect this pressure is related to how national
politics increasingly dominate the political dialogue in the USA.
Cleaning out your head
Most of the mainstream news is implicitly subsidized by large organizations who are
trying to get you to buy their products and ideologies. How do you ﬁght back against
mind control?
The ﬁrst step is to disconnect from the news. News makes you stupid.
The second step is to explore in orthogonal directions. Learn calculus and
physics. Learn foreign languages. Learn the histories of China and Islam (unless
you are Chinese and/or Muslim in which case you should check out The History
of Rome). Learn to read palms and Tarot cards[2]. Learn to draw. Use this
knowledge to start hard ambitious original projects like companies. The more
your actions deviate from the default script the more holes you'll discover in the
Matrix.
The third step is to create your own media. If you are consuming media created
by another person—even if that person is George Orwell—then you are not yet
thinking for yourself.
1. Paper media had a worse calculus based around monopolizing distribution. Risk-
adverse paper monopolies distributed only the most inoﬀensive content. ↩ 
2. But don't take them too seriously. ↩ 

Overconﬁdence is Deceit
Author's note: This essay was written as part of an eﬀort to say more of the simple
and straightforward things loudly and clearly, and to actually lay out arguments even
for concepts which feel quite intuitive to a lot of people, for the sake of those who
don't "get it" at ﬁrst glance.  If your response to the title of this piece is "Sure, yeah,
makes sense," then be warned that the below may contain no further insight for you.
Premise 1: Deltas between one's beliefs and the actual
truth are costly in expectation
(because the universe is complicated and all truths interconnect; because people
make plans based on their understanding of how the world works and if your
predictions are oﬀ you will distribute your time/money/eﬀort/attention less eﬀectively
than you otherwise would have, according to your values; because even if we posit
that there are some wrong beliefs that somehow turn out to be totally innocuous and
have literally zero side eﬀects, we are unlikely to correctly guess in advance which
ones are which)
Premise 2: Humans are meaningfully inﬂuenced by
conﬁdence/emphasis alone, separate from truth
(probably not literally all humans all of the time, but at least in expectation, in the
aggregate, for a given individual across repeated exposures or for groups of
individuals; humans are social creatures who are susceptible to e.g. halo eﬀects when
not actively taking steps to defend against them, and who delegate and defer and
adopt others' beliefs as their tentative answer, pending investigation (especially if
those others seem competent and conﬁdent and intelligent, and there is in practice
frequently a disconnect between the perception of competence and its reality); if you
expose 1000 randomly-selected humans to a debate between a quiet, reserved
person outlining an objectively correct position and a conﬁdent, emphatic person
insisting on an unfounded position, many in that audience will be net persuaded by
the latter and others will feel substantially more uncertainty and internal conﬂict than
the plain facts of the matter would have left them feeling)
Therefore: Overconﬁdence will, in general and in
expectation, tend to impose costs on other people, above
and beyond the costs to one's own eﬃcacy, via its
predictable negative impact on the accuracy of those other
people's beliefs, including further downstream eﬀects of
those people's beliefs infecting still others' beliefs.
I often like to think about the future, and how human behavior in the future will be
diﬀerent from human behavior in the past.

In Might Disagreement Fade Like Violence? Robin Hanson posits an analogy between
the "beneﬁts" of duels and ﬁghts, as described by past cultures, and the beneﬁts of
disagreement as presently described by members of modern Western culture.  He
points out that foreseeable disagreement, in its present form, doesn't seem
particularly aligned with the goal of arriving at truth, and envisions a future where the
other good things it gets us (status, social interaction, a medium in which to transmit
signals of loyalty and aﬃliation and intelligence and passion) are acquired in less
costly ways, and disagreement itself has been replaced by something better.
Imagine that we saw disagreement as socially destructive, to be discouraged. And
imagine that the few people who still disagreed thereby revealed undesirable
features such as impulsiveness and ignorance. If it is possible to imagine all these
things, then it is possible to imagine a world which has far less foreseeable
disagreement than our world, comparable to how we now have much less violence
than did the ancient farming world.
When confronted with such an imaged future scenario, many people today claim
to see it as stiﬂing and repressive. They very much enjoy their freedom today to
freely disagree with anyone at any time. But many ancients probably also greatly
enjoyed the freedom to hit anyone they liked at anytime. Back then, it was
probably the stronger better ﬁghters, with the most ﬁghting allies, who enjoyed
this freedom most. Just like today it is probably the people who are best at arguing
to make their opponents look stupid who enjoy our freedom to disagree today.
Doesn't mean this alternate world wouldn't be better.
Reading Hanson's argument, I was reminded of a similar point made by a colleague,
that the internet in general and Wikipedia in particular had fundamentally changed
the nature of disagreement in (at least) Western culture.  
There is a swath of territory in which the least-bad social technology we have
available is "agree to disagree," i.e. each person thinks that the other is wrong, but
the issue is charged enough and/or intractable enough that they are socially rewarded
for choosing to disengage, rather than risking the integrity of the social fabric trying to
ﬁght it out.
And while the events of the past few years have shown that widespread disagreement
over checkable truth is still very much a thing, there's nevertheless a certain sense in
which people are much less free than they used to be to agree-to-disagree about very
basic questions like "is Brazil's population closer to 80 million or 230 million?"  There
are some individuals that choose to plug their ears and deny established fact, but
even when these individuals cluster together and form echo chambers, they largely
aren't given social license by the population at large—they are docked points for it, in
a way that most people generally agree not to dock points for disagreement over
murkier questions like "how should people go about ﬁnding meaning in life?"
Currently, there is social license for overconﬁdence.  It's not something people often
explicitly praise or endorse, but it's rarely substantively punished (in part because the
moment when a person reaps the social beneﬁts of emphatic language is often quite
distant from the moment of potential reckoning).  More often than not, overconﬁdence
is a successful strategy for extracting agreement and social support in excess of the
amount that an omniscient neutral observer would assign.

([citation needed], but also [gestures vaguely at everything].  I conﬁdently assert that
clear and substantial support for this claim exists and is not hard to ﬁnd (one
extremely easy example is presidential campaign promises; we currently have an
open Guantánamo Bay facility and no southern border wall), but I'm leaving it out to
keep the essay relatively concise.  I recommend consciously noting that the assertion
has been made without being rigorously supported, and ﬂagging it accordingly.)
Note that the claim is not "overconﬁdence always pays oﬀ" or "overconﬁdence never
gets punished" or "more overconﬁdence is always a good thing"!  Rather, it is that the
pragmatically correct amount of conﬁdence to project, given the current state of
social norms and information ﬂow, is greater than your true justiﬁed
conﬁdence.  There are limits to the beneﬁts of excessively strong speech, but the
limits are (apparently) shy of e.g. literally saying, on the record, "I want you to use my
words against me, [in situation X I will take action Y]," and then doing the exact
opposite a few years later.
Caveat 1: readers may rightly point out that the above quote and subsequent
behavior of Lindsey Graham took place within a combative partisan context, and is a
somewhat extreme example when we're considering society-as-a-whole.  Average
people working average jobs are less likely to get away with behavior that blatant.
 But I'm attempting to highlight the upper bound on socially-sanctioned
overconﬁdence, and combative partisan contexts are a large part of our current
society that it would feel silly to exclude as if they were somehow rare outliers.
Caveat 2: I've been equivocating between epistemic overconﬁdence and
bold/unequivocal/hyperbolic speech.  These are in fact two diﬀerent things, but they
are isomorphic in that you can convert any strong claim such as Graham's 2016
statement into a prediction about the relative likelihood of Outcome A vs. Outcome B. 
One of the aggregated eﬀects of unjustiﬁably emphatic and unequivocal speech
across large numbers of listeners is a distortion of those listeners' probability spread—
more of them believing in one branch of possibility than they ought, and than they
would have if the speech had been more reserved.  There are indeed other factors in
the mix (such as tribal cohesion and belief-as-attire, where people aﬃrm things they
know to be false for pragmatic reasons, often without actually losing sight of the
truth), but the distortion eﬀect is real.  Many #stopthesteal supporters are genuine
believers; many egalitarians are startled to discover that the claims of the IQ
literature are not fully explained away by racism, etc.
In short, displays of conﬁdence sway people, independent of their truth (and often,
distressingly, even independent of a body of evidence against the person projecting
conﬁdence).  If one were somehow able to run parallel experiments in which 100
separate pitches/speeches/arguments/presentations/conversations were each run
twice, the ﬁrst time with justiﬁed conﬁdence and emphasis and the second with 15%
"too much" conﬁdence and emphasis, I would expect the latter set of conversations to
be substantially more rewarding for the speaker overall.  Someone seeking to be
maximally eﬀective in today's world would be well advised to put nonzero skill points
into projecting unearned conﬁdence—at least a little, at least some of the time.  
This is sad.  One could imagine a society that is not like this, even if it's hard
to picture from our current vantage point (just as it would have been hard
for a politician in Virginia in the early 1700s to imagine a society in which
dueling is approximately Not At All A Thing).

I do not know how to get there from here.  I am not recommending unilateral
disarmament on the question of strategic overconﬁdence.  But I am recommending
the following, as preliminary steps to make future improvement in this domain slightly
more likely:
0. Install a mental subroutine that passively tracks
overconﬁdence...
...particularly the eﬀects it has on the people and social dynamics around you (since
most of my audience is already informally tracking the eﬀects of their own
overconﬁdence on their own personal eﬃcacy).  Gather your own anecdata.  Start
building a sense of this as a dynamic that might someday be diﬀerent, à la dueling, so
that you can begin forming opinions about possible directions and methods of change
(rather than treating it as something that shall-always-be-as-it-always-has-been).
1. Recognize in your own mind that overconﬁdence is a
subset of deceit...
...as opposed to being in some special category (just as dueling is a subset of
violence).  In particular, recognize that overconﬁdence is a behavioral pattern that
people are vulnerable to, and can choose to indulge in more or less frequently, as
opposed to an inescapable reﬂex or inexorable force of nature (just as violence is a
behavioral pattern over which we have substantial individual capacity for control).
 Judge overconﬁdence (both in yourself and others, both knowing and careless) using
similar criteria to those you use to judge deceit.  Perhaps continue to engage in it, in
ways that are beneﬁcial in excess of their costs, but do not confuse "net positive" with
"contains no drawbacks," and do not confuse "what our culture thinks of it" with "what
it actually is."  Recognize the ways in which your social context rewards you for
performative overconﬁdence, and do what you can to at least cut back on the
indulgence, if you can't eschew it entirely ("if you would go vegan but you don't want
to give up cheese, why not just go vegan except for cheese?").  Don't indulge in the
analogue of lies-by-omission; if you can tell that someone seems more convinced by
you than they should be, at least consider correcting their impression, even if their
convinced-ness is convenient for you.
2. Where possible, build the habit of being explicit about
your own conﬁdence level...
...the standard pitch here is "because this will make you yourself better at prediction,
and give you more power over the universe!" (which, sure, but also [citation needed]
and also the degree matters; does ten hours of practice make you .01% more
eﬀective or 10% more eﬀective?).  I want to add to that motivation "and also because
you will contribute less to the general epistemic shrapnel being blasted in every
direction more or less constantly!"  Reducing this shrapnel is a process with increasing
marginal returns—if 1000 people in a tight-knit community are all being careless with
their conﬁdence, the ﬁrst to hold themselves to a higher standard scarcely improves
the society at all, but the hundredth is contributing to a growing snowball, and by the
time only a handful are left, each new convert is a massive reduction in the overall
problem.  

Practice using numbers and percentages, and put at least a one-time cursory eﬀort
into calibrating that usage, so that when your actual conﬁdence is "a one-in-four
chance of X" you can convey that conﬁdence precisely, rather than saying largely
contentless phrases like "a very real chance."  Practice publicly changing your mind
and updating your current best guesses. Practice explicitly distinguishing between
what seems to you to be likely, what seems to you to be true, and what you are
justiﬁed in saying you know to be true.  Practice explicitly distinguishing between
doxa, episteme, and gnosis, or in more common terms, what you believe because you
heard it, what you believe because you can prove it, and what you believe because
you experienced it.  
3. Adopt in your own heart a principle of adhering to true
conﬁdence...
...or at least engaging in overconﬁdence only with your eyes open, such that pushback
of the form "you're overconﬁdent here" lands with you as a cooperative act, someone
trying to help you enact your own values instead of someone trying to impose an
external standard.  This doesn't mean making yourself inﬁnitely vulnerable to attacks-
in-the-guise-of-feedback (people can be wrong when they hypothesize that you're
overconﬁdent, and there are forms of pushback that are costly or destructive that you
are not obligated to tolerate, and you can learn over time that speciﬁc sources of
pushback are more or less likely to be useful), but it does mean rehearsing the
thought "if they're right, I really want to know it" as an inoculation against knee-jerk
dismissiveness or defensiveness.
4. Don't go around popping bubbles...
...in which the local standards are better than the standards of the culture at large.  I
have frequently seen people enter a promising subculture and drag it back into the
gutter under the guise of curing its members of their naïveté, and forearming them
against a cruel outside world that they were in fact successfully hiding from.  I've also
witnessed people who, their self-esteem apparently threatened by a local high
standard, insisted that it was all lies and pretense, and that "everybody does X," and
who then proceeded to deliberately double down on X themselves, successfully
derailing the nascent better culture and thereby "proving their point."  I myself once
made a statement that was misinterpreted as being motivated primarily by status
considerations, apologized and hastened to clarify and provide an alternate coherent
explanation, and was shot down by a third party who explicitly asserted that I could
not opt out of the misinterpretation while simultaneously agreeing that the whole
status framework was toxic and ought to go. 
When society improves, it's usually because a better way of doing things incubated in
some bubble somewhere until it was mature enough to germinate; if you are fortunate
enough to stumble across a ﬂedgling community that's actually managed to relegate
overconﬁdence (or any other bad-thing-we-hope-to-someday-outgrow) to the same
tier as anti-vax fearmongering, maybe don't go out of your way to wreck it.
To reiterate: the claim is not that any amount of overconﬁdence always leads to
meaningful damage.  It's that a policy of indulging in and tolerating overconﬁdence at
the societal level inevitably leads to damage over time.  

Think about doping, or climate change—people often correctly note that it's diﬃcult or
impossible to justify an assertion that a given speciﬁc athletic event was won because
of doping, or that a given speciﬁc extreme weather event would not have happened
without the recent history of global warming.  Yet that does not weaken our overall
conﬁdence that drugs give athletes an unfair edge, or that climate change is driving
extreme weather in general.  Overconﬁdence deals its damage via a thousand tiny
cuts to the social fabric, each one seeming too small in the moment to make a strong
objection to (but we probably ought to anyway).
It's solidly analogous to lying, and causes similar harms: like lying, it allows the
speaker to reap the beneﬁts of living in a convenient World A (that doesn't actually
exist), while only paying the costs of living in World B.  It creates costs, in the form of
misapprehensions and false beliefs (and subsequent miscalibrated and ineﬀective
actions) and shunts those costs onto the shoulders of the listeners (and other people
downstream of those listeners).  It tends to most severely damage those who are
already at the greatest disadvantage—individuals who lack the intelligence or training
or even just the spare time and attention to actively vet new claims as they're coming
in.  It's a weapon that grows more eﬀective the more desperate, credulous, hopeful,
and charitable the victims are.
This is bad.
Not every instance of overconﬁdence is equally bad, and not every frequently-
overconﬁdent person is equally culpable.  Some are engaging in willful deception,
others are merely reckless, and still others are trying their best but missing the mark.
 The point is not to lump "we won the election and everyone knows it" into the same
bucket as "you haven't seen Fireﬂy?  Oh, you would love Fireﬂy," but merely to
acknowledge that they're both on the same spectrum.  That while one might have a
negative impact of magnitude 100,000 and the other of magnitude 0.01, those are
both negative numbers.
That is an important truth to recognize, in the process of calibrating our response.  We
cannot eﬀectively respond to what we don't let ourselves see, and it's tempting to act
as if our small and convenient overconﬁdences are qualitatively diﬀerent from those
of Ponzi schemers and populist presidents.
But they aren't.  Overconﬁdence can certainly be permissible and forgivable.  In some
strategic contexts, it may be justiﬁed and defensible.  But every instance of it is like
the cough of greenhouse gases from starting a combustion engine.  Focus on the
massive corporate polluters rather than trying to shame poor people who just need to
get to work, yes, but don't pretend that the car isn't contributing, too.
It's unlikely that this aspect of our culture will change any time soon.  We may never
manage to outgrow it at all.  But if you're looking for ways to be more moral than the
culture that raised you, developing a prosocial distaste for overconﬁdence (above and
beyond the self-serving one that's already in fashion) is one small thing you might do.
Author's note: Due to some personal considerations, I may not actively engage in
discussion below. This feels a little rude/defecty, but on balance I ﬁgured LessWrong
would prefer to see this and be able to wrestle with it without me, than to not get it
until I was ready to participate in discussion (which might mean never).

Distinguishing claims about training
vs deployment
Crossposted from the AI Alignment Forum. May contain more technical jargon than
usual.
Given the rapid progress in machine learning over the last decade in particular, I think
that the core arguments about why AGI might be dangerous should be formulated
primarily in terms of concepts from machine learning. One important way to do this is
to distinguish between claims about training processes which produce AGIs, versus
claims about AGIs themselves, which I'll call deployment claims. I think many
foundational concepts in AI safety are clariﬁed by this distinction. In this post I outline
some of them, and state new versions of the orthogonality and instrumental
convergence theses which take this distinction into account.
Goal speciﬁcation
The most important eﬀect of thinking in terms of machine learning concepts is clarity
about what it might mean to specify a goal. Early characterisations of how we might
specify the goals of AGIs focused on agents which choose between actions on the
basis of an objective function hand-coded by humans. Deep Blue is probably the most
well-known example of this; AIXI can also be interpreted as doing so. But this isn't how
modern machine learning systems work. So my current default picture of how we will
specify goals for AGIs is:
At training time, we identify a method for calculating the feedback to give to the
agent, which will consist of a mix of human evaluations and automated
evaluations. I'll call this the objective function. I expect that we will use an
objective function which rewards the agent for following commands given to it
by humans in natural language.
At deployment time, we give the trained agent commands in natural language.
The objective function is no longer used; hopefully the agent instead has
internalised a motivation/goal to act in ways which humans would approve of,
which leads it to follow our commands sensibly and safely.
This breakdown makes the inner alignment problem a very natural concept - it's
simply the case where the agent's learned motivations don't correspond to the
objective function used during training.[1] It also makes ambitious approaches to
alignment (in which we try to train an AI to be motivated directly by human values)
less appealing: it seems strictly easier to train an agent to obey natural language
commands in a common-sense way, in which case we get the beneﬁt of continued
ﬂexible control during deployment.[2]
Orthogonality
Consider Bostrom's orthogonality thesis, which states:
Intelligence and ﬁnal goals are orthogonal: more or less any level of intelligence
could in principle be combined with more or less any ﬁnal goal.

As stated, this is a fairly weak claim: it only talks about which minds are logically
possible, rather than minds which we are likely to build. So how has this thesis been
used to support claims about the likelihood of AI risk? Ben Garﬁnkel argues that its
proponents have relied on an additional separation between the process of making a
system intelligent, and the process of giving it goals - for example by talking about
"loading a utility function" into a system that's already intelligent. He calls the
assumption that "the process of imbuing a system with capabilities and the process of
imbuing a system with goals are orthogonal" the process orthogonality thesis.
It's a little unclear what "orthogonal" means for processes; here I give a more precise
statement. Given a process for developing an intelligent, goal-directed system, my
version of the process orthogonality thesis states that:
The overall process involves two (possibly simultaneous) subprocesses: one
which builds intelligence into the system, and one which builds goals into the
system.
The former subprocess could vary greatly how intelligent it makes the system,
and the latter subprocess could vary greatly which goals it speciﬁes, without
signiﬁcantly aﬀecting each other's performance.
Unlike the original orthogonality thesis, we should evaluate the process orthogonality
thesis separately for each proposed process, rather than as a single uniﬁed claim.
Which processes might be orthogonalisable in the sense speciﬁed above? Consider
ﬁrst a search algorithm such as Monte Carlo tree search. Roughly speaking, we can
consider the "intelligence" of this algorithm to be based on the search
implementation, and the "goals" of the algorithm to be based on the scores given to
possible outcomes. In this case, the process orthogonality thesis seems to be true: we
could, for example, ﬂip the sign of all the outcomes, resulting in a search algorithm
which is very good at ﬁnding ways to lose games.[3]
However, this no longer holds for more complex search algorithms. For example, the
chess engine Deep Blue searches in a way that is guided by many task-speciﬁc
heuristics built in by its designers, which would need to be changed in order for it to
behave "intelligently" on a diﬀerent objective.
The process orthogonality thesis seems even less plausible when applied to a typical
machine learning training process, in which a system becomes more intelligent via a
process of optimisation on a given dataset, towards a given objective function. In this
setup, even if the agent learns to pursue the exact objective function (without any
inner misalignment), we're still limited to the space of objective functions which are
capable of inducing intelligent behaviour. If the objective function speciﬁes a very
simple task, then agents trained on it will never acquire complex cognitive skills.
Furthermore, both the system's intelligence and its goals will be aﬀected by the data
source used. In particular, if the data is too limited, it will not be possible to instil
some goals.
We can imagine training processes for which the process orthogonality thesis is more
true, though. Here are two examples. Firstly, consider a training process which ﬁrst
does large-scale unsupervised training (such as autoregressive training on a big
language corpus) to produce a very capable agent, and then uses supervised or
reinforcement learning to specify what goals that agent should pursue. There's an
open empirical question about how much the ﬁrst stage of training will shape the
goals of the ﬁnal agent, and how much the second stage of training will improve its
capabilities, but it seems conceivable that its capabilities are primarily shaped by the

former, and its goals are primarily shaped by the latter, which would make the process
orthogonality thesis mostly true in this case.
Secondly, consider a model-based reinforcement learning agent which is able to plan
ahead in a detailed way, and then chooses plans based on evaluations of their
outcomes provided by a reward model. If this reward model is trained separately from
the main agent, then we might just be able to "plug it in" to an already-intelligent
system, making the overall process orthogonalisable. However, for the reward model
to evaluate plans, it will need to be able to interpret the planner's representations of
possible outcomes, which suggests that there will be signiﬁcant advantages from
training them together, in which case the process would likely not be
orthogonalisable.
Suppose that the process orthogonality thesis is false for the techniques we're likely
to use to build AGI. What implications does this have for the safety of those AGIs? Not
necessarily reassuring ones - it depends on how dangerous the goals that tend to
arise in the most eﬀective processes of intelligence-development will be. We could
evaluate this by discussing all the potential training regimes which might produce AGI,
but this would be lengthy and error-prone. Instead, I'd like to make a more general
argument by re-examining another classic thesis:
Instrumental convergence
The original version of this thesis is roughly as follows:
Instrumental convergence thesis: a wide range of the ﬁnal goals which an
AGI could have will incentivise them to pursue certain convergent instrumental
subgoals (such as self-preservation and acquiring resources).
However, this again only talks about the ﬁnal goals which are possible, rather than the
ones which are likely to arise in systems we build. How can we reason about the
latter? Some have proposed thinking using a simplicity prior over the set of all
possible utility functions. But in modern machine learning, the utility function of an
agent is not speciﬁed directly. Rather, an objective function is used to learn
parameters which make the agent score highly on that objective function. If the
resulting agent is suﬃciently sophisticated, it seems reasonable to describe it as
"having goals". So in order to reason about the goals such an agent might acquire, we
need to think about how easily those goals can be represented in machine learning
models such as neural networks. Yet we know very little about how goals can be
represented in neural networks, and which types of goals are more or less likely to
arise.
How can we reason about possible goals in a more reliable way? One approach is to
start, not by characterising all the goals an agent might have, but by characterising all
the objective functions on which it might be trained. Such objective functions need to
be either speciﬁable in code, or based on feedback from humans. However, training
also depends heavily on the data source used, so we need to think more broadly:
following reinforcement learning terminology, I'll talk about environments which, in
response to actions from the agent, produce observations and rewards. And so we
might ask: when we train an AGI in a typical environment, can we predict that it will
end up pursuing certain goals? This leads us to consider the following thesis:

Training goal convergence thesis: a wide range of environments in which we
could train an AGI will lead to the development of goal-directed behaviour aimed
towards certain convergent goals.
We can distinguish two ways in which these convergent goals might arise:
Training instrumental convergence: the AGI develops ﬁnal goals which
incentivise the pursuit of convergent instrumental subgoals.
Training ﬁnal convergence: the AGI develops "convergent ﬁnal goals" - i.e. a
set of ﬁnal goals which arise when trained in many diﬀerent environments.
The ﬁrst possibility is roughly analogous to the original instrumental convergence
thesis. The second draws on similar ideas, but makes a distinct point. I predict that
agents trained in suﬃciently rich environments, on a suﬃciently diﬃcult objective
function, will develop ﬁnal goals of self-preservation, acquiring resources and
knowledge, and gaining power. Note that this wouldn't depend on agents themselves
inferring the usefulness of these convergent ﬁnal goals. Rather, it's suﬃcient that the
optimiser ﬁnds ways to instil these goals within the agents it trains, because they
perform better with these ﬁnal goals than without - plausibly for many of the same
reasons that humans developed similar ﬁnal goals.
This argument is subject to at least three constraints. Firstly, agents will be trained in
environments which are quite diﬀerent from the real world, and which therefore might
incentivise very diﬀerent goals. This is why I've left some convergent instrumental
goals oﬀ the list of convergent ﬁnal goals. For example, agents trained in an
environment where self-improvement isn't possible wouldn't acquire that as a ﬁnal
goal. (To be clear, though, such agents can still acquire the convergent instrumental
goal of self-improvement when deployed in the real world, by inferring that it would be
valuable for their ﬁnal goals.) However, it seems likely that environments
sophisticated enough to lead to AGI will require agents to act over a suﬃciently long
time horizon for some inﬂuence-seeking actions to have high payoﬀs, in particular the
ones I listed in the previous paragraph.
Secondly, convergent ﬁnal goals are instilled by the optimiser rather than being a
result of AGI reasoning. But search done by optimisers is local and therefore has
predictable limitations. For example, reward tampering is suﬃciently diﬃcult to
stumble across during training that we shouldn't expect an optimiser to instil that trait
directly into agents. Instead, an AGI which had acquired the ﬁnal goal of increasing its
score on the objective function might reason that reward tampering would be a useful
way to do so. However, just as it was diﬃcult for evolution to instil the ﬁnal goal of
"increase inclusive genetic ﬁtness" in humans, it may also be diﬃcult for optimisation
to instil into AIs the ﬁnal goal of increasing their score on the objective function; hence
it's an open question whether "doing well on the objective function" is a convergent
ﬁnal goal.
Thirdly, the objective function may not just be composed of easily-speciﬁed code, or
human feedback, but also of feedback from previously-trained AIs. Insofar as those AIs
just model human feedback, then we can just think of this as a way to make human
feedback more scalable. But the possibility of them giving types of feedback that
groups of humans aren't realistically capable of reproducing makes it hard to
characterise the types of environments we might train AGIs in. For now, I think it's
best to explicitly set aside this possibility when discussing training convergence.

Fragility of value
Original formulation: losing only a small part of our goals leads to catastrophe.
Fragility of value thesis (deployment): a small error in the goals of an AGI
will lead it to pursue catastrophic misbehaviour.
Fragility of value thesis (training): a small error in the objective function
used to train an AGI will lead it to pursue catastrophic misbehaviour.
In the training case, we can quantify (in theory) what a small error is - for instance,
the diﬀerence between the reward actually given to the agent, versus the reward we'd
give if we were fully informed about which rewards will lead to which outcomes.
In the deployment case, it's much more diﬃcult to describe what a "small error" is;
we don't really have a good way of reasoning about the distances between diﬀerent
goals as represented in neural networks. But if we think of a "small perturbation" as a
small shift in neural weights, it seems unlikely that this would cause a fully aligned
agent to produce catastrophic outcomes. I interpret this claim to be roughly
equivalent to the claim that there's a "broad basin of corrigibility".
Goodhart's law
Original formulation: when a measure becomes a target, it ceases to be a good
measure.
Goodhart's law (deployment): when a measure becomes an agent's goal, it
ceases to be a good measure.
Goodhart's law (training): when a measure becomes a training objective
function, it ceases to be a good measure.
The distinction between these two is similar to the distinction between the two
training convergence theses from above. In one case, an agent reasons about ways to
optimise for the measure. In another case, though, an agent may just be optimised
towards doing well on that measure, without deliberately making plans to drive it to
extreme values. These have diﬀerent implications for when the measure might fail,
and in which ways.
 
Footnotes
1. These days I'm confused about why it took me so long to understand this
outer/inner alignment distinction, but I guess that's a good lesson about hindsight
bias.
2. Of course this will require the agent to internalise human values to some extent,
but plausibly in a much less demanding way. Some also argue that continued ﬂexible
control is not in fact a beneﬁt, since they're worried about how AI will aﬀect
geopolitics. But I think that, as much as possible, we should separate the problem of
AGI safety from the problem of AGI governance - that is, we should produce safety
techniques which can be used by anyone, not just "the right people".

3. It's also true for AIXI, because its intelligence comes from simulating all possible
futures, which can be used to pursue any reward function.

[Link] Sarah Constantin on RaDVaC
This is a linkpost for https://twitter.com/s_r_constantin/status/1357652836079837189

Intro to the Wedding Sequence
Our wedding was intended to be a ceremony of commitment, to each other, and also
to our values. We (Ruben Bloom and Miranda Dixon-Luinenburg) got married in the
Lawrence Hall of Science planetarium in Berkeley on February 21st, 2015. Mostly
because it took me six years to get the audio recording processed, I'm now, at last,
posting on the occasion of our 6th anniversary the recordings and transcripts of our
ceremony.
Our friends gave speeches, each expressing a diﬀerent facet of the values that we
were committing to pursue together. They delivered their words against the backdrop
of wonderous starscapes, and in between the prose, we played music that captured
our love and ambitions.
The speeches stand as excellent essays in their own right, and although some of the
authors/speakers have published them independently on their blogs, it seems
worthwhile bringing all of them together in one place, especially together alongside
the accompanying images and music. (Since it was in a dark planetarium, there is no
video).
Recording of the entire ceremony. Individual posts have the recordings for each
speech alongside the transcript
 
The ceremony had the following structure and was graciously oﬃciated by Logan
Brienne Strohl:
1. Values
1. Darkness (Nate Soares)
2. Hope & Triump:  How Far Humany Has Come (Tara Mac Aulay, written by
Jess Whittlestone)
3. Light: The Grandest Vision for Humanity (Riva Melissa-Tez)
4. Tsuyoku Naritai (Ruby)
2. Community (Oliver Habryka)
3. Partnership (Miranda)
4. Declaration
1. Feelings and Admiration
1. Ruby towards Miranda
2. Miranda towards Ruby
2. Vows
3. Declaration, exchange of rings
 
Miranda and I met via LessWrong (me ﬁnding her many excellent writings), so it feels
quite ﬁtting to celebrate one of our anniversaries here.

This Sunday, I have published the ﬁrst two speeches. I will post the remaining ones
daily until the Sequence is complete.

[Fiction] Lena (MMAcevedo)
This is a linkpost for https://qntm.org/mmacevedo
Wiki article about the ﬁrst brain image of a human upload (2031). Subpar in some
respects, but initially a compliant worker and free to copy thanks to court cases ruling
that the biological original did not have a legal right to restrict its use. 

Tournesol, YouTube and AI Risk
Crossposted from the AI Alignment Forum. May contain more technical jargon than
usual.
Introduction
Tournesol is a research project and an app aiming at building a large and varied
database of preference judgements by experts on YouTube videos, in order to align
YouTube's recommendation algorithm towards videos according to diﬀerent criteria,
like scientiﬁc accuracy and entertainment value.
The researchers involved launched the website for participating last month, and hope
to ratchet a lot of contributions by the end of the year, so that they have a usable and
useful database of comparison between YouTube videos. For more details on the
functioning of Tournesol, I recommend the video on the front page of the project, the
white paper and this talk by one of the main researchers.
What I want to explore in this post is the relevance of Tournesol and the research
around it to AI Alignment. Lê Nguyên Hoang, the main research on Tournesol, believes
that it is very relevant. And whether or not he is right, I think the questions he raises
should be discussed here in more detail.
This post focuses on AI Alignment, but there are also a lot of beneﬁts to get from
Tournesol on the more general problem of recommender systems and social media. To
see how Tournesol should help solve these problems, see the white paper.
Thanks to Lê Nguyên Hoang and Jérémy Perret for feedback on this post.
AI Risk or Not AI Risk
There are two main ways to argue about Tournesol's usefulness and importance for AI
Alignment, depending on a central question: is YouTube's algorithm a likely candidate
for a short timeline AGI or not? So let's start with it.
YouTube and Predict-O-Matic
Lê believes that YouTube's algorithm has a high probability of reaching AGI level in the
near future -- something like the next ten years. While I've been updating to shorter
timelines after seeing the GPT models and talking with Daniel Kokotajlo, I was initially
rather dismissive of the idea that YouTube's algorithm could become an AGI, and a
dangerous one at that.
Now I'm less sure of how ridiculous it is. I'm still not putting as much probability as Lê
does, but our discussion was one of the reasons I wanted to write such a post and
have a public exchange about it.
So, in what way could YouTube's algorithm reach an AGI level?

(Economic pressure) Recommending videos that are seen more and more is
very proﬁtable for YouTube (and its parent company Google). So there is an
economic incentive to push the underlying model to be as good as possible at
this task.
(Training Dataset) YouTube's algorithm has access to all the content on
YouTube. Which is an enormous quantity of data. Every minute, 500 hours of
videos are uploaded to YouTube. And we all know that pretty much every human
behavior can be found on YouTube.
(Available funding and researchers) YouTube, through its parent company
Google, has access to huge ressources. So if reaching AGI depends only on
building and running bigger models, the team working on YouTube's
recommender algorithm can deﬁnitely do it. See for example the recent trillion
parameter language model of Google.
Hence if it's feasible for YouTube's algorithm to reach AGI level, there's a risk it will do.
Then what? After all, YouTube is hardly a question-answerer for the most powerful and
important people in the world. That was also my ﬁrst reaction. But after thinking a bit
more, I think YouTube's recommendation algorithm might have similar issues as a
Predict-O-Matic. Such a model is an oracle/question-answerer, which will probably
develop incentives for self-fulﬁlling prophecies and simplifying the system it's trying to
predict. Similarly, the objective of YouTube's algorithm is on maximizing the time
spent on videos, which could create the same kind of incentives.
One example of such behavior happening right now is the push towards more and
more polarized political content, which in turns push people to look for such content,
and thus is a self-fulﬁlling prophecy. It's also relatively easy to adapt examples from
Abram's post with the current YouTube infrastructure: pushing towards more accurate
ﬁnancial recommendations by giving to a lot of people a video about how one stock is
going to tank, making people sell it and thus tanking the stock.
I think the most important diﬀerence with the kind of Predict-O-Matic I usually have in
mind is that a YouTube recommendation is a relatively weak output, that will probably
not be taken at face value by many people with strong decision power. But this is
compensated by the sheer reach of YouTube: There are 1-billion hours of watch-time
per day for 2 billion humans, 70% of which result from recommendations (those are
YouTube's numbers, so to take with a grain of salt). Nudging many people towards
something can be as eﬀective or even more eﬀective than strongly inﬂuencing a small
number of decision-makers.
Therefore, the possibility of YouTube's algorithm reaching AGI level and causing
Predict-O-Matic type issues appear strong enough to at least entertain and discuss.
(Lê himself has a wiki page devoted to that idea, which diﬀers from my presentation
here)
1%

2%

3%

4%

5%

6%

7%

8%

9%

Eliezer Yudkowsky (1%),TurnTrout (1%),Adele Lopez (1%),Daniel Kokotajlo
(3%),habryka (4%),ejacob (5%),Alexei (5%)
10%

11%
12%
13%
14%

15%
16%
17%
18%

19%
adamShimi (10%)
20%
21%

22%
23%
24%

25%
26%

27%
28%
29%

Orfeas (20%),gt22 (25%)
30%
31%
32%
33%
34%
35%
36%

37%
38%
39%
40%
41%
42%
43%
44%

45%
46%
47%
48%
49%
50%
51%
52%

53%
54%
55%
56%
57%
58%
59%
60%

61%
62%
63%
64%
65%
66%
67%
68%

69%
70%
71%
72%
73%
74%
75%
76%

77%
78%
79%
80%
81%
82%
83%
84%

85%
86%
87%
88%
89%
90%
91%
92%

93%
94%
95%
96%
97%
98%
99%
1%
What probability do you put on YouTube's algorithm reaching AGI level?
99%
1%

2%
3%
4%
5%

6%
7%
8%
9%

10%
11%
12%
13%

14%
15%
16%
17%

18%
19%
20%
21%

22%
23%
24%
25%

26%
27%
28%
29%

30%
31%
32%
33%

34%
35%
36%
37%

38%
39%
40%
41%

42%
43%
44%
45%

46%
47%
48%
49%

50%
51%

52%
53%

54%
55%

56%
57%

58%
59%

Orfeas (50%)
60%
61%

62%
63%

64%
65%

66%
67%

68%
69%

adamShimi (60%)
70%
71%

72%
73%

74%
75%

76%
77%

78%
79%

Daniel Kokotajlo (75%)
80%

81%
82%

83%

84%

85%
86%

87%

88%

89%
Adele Lopez (84%),gt22 (85%)
90%

91%

92%

93%

94%

95%

96%

97%

98%

99%

habryka (90%),TurnTrout (90%),ejacob (95%)
1%
Conditioning on YouTube's algorithm reaching AGI level, what probability
do you put on it showing Predict-O-Matic type problems?
99%
Assuming the above risk about YouTube's algorithm, Tournesol is the most direct
project to attempt the alignment of this AI. It has thus value both for avoiding a
catastrophe with this speciﬁc AI, but also for dealing with practical cases of alignment.

Useful Even Without a YouTube AGI
Maybe you're not convinced by the previous section. One reason I ﬁnd Tournesol
exciting is that even then, it has value for AI Alignment research.
The most obvious one is the construction of a curated dataset to do value learning, of
a scale that is unheard of. There are a lot of things one could do with access to this
dataset: deﬁne a benchmark for value learning techniques, apply microscope AI to
ﬁnd a model of expert recommendation of valuable content.
Such experimental data also seems crucial if we want to understand better what is the
inﬂuence of data on diﬀerent alignment schemes. Examining an actual massive
dataset, with directly helpful data but necessarily errors and attacks, might help
design realistic assumptions to use when studying speciﬁc ML algorithms and
alignment schemes.
What Can You Do To Help?
All of that is conditioned on the success of Tournesol. So what can you do to help?
If you're a programmer: they are looking for React and Django programmers to
work on the website and an Android app. For Lê, this is the most important point
to reach a lot of people.
If you're a student/professor/researcher: you can sign in for Tournesol with your
institutional email address, which means your judgement will be added to the
database when using Tournesol.
If you're a researcher in AI Alignment: you can discuss this proposal and
everything around it in the comments, so that the community doesn't ignore this
potential opportunity. There are also many open theoretical problems in the
white paper. If you're really excited about this project and want to collaborate,
you can contact Lê by mail at len.hoang.lnh@gmail.com
Conclusion
Tournesol aims at building a database of preference comparison between YouTube
content, primarily in order to align YouTube's algorithm. Even if there is no risk from
the latter, such a database would have massive positive consequences for AI
Alignment research.
I'm not saying that every researcher here should drop what they're doing and go work
on or around Tournesol. But the project seems suﬃciently relevant to at least know
and acknowledge, if nothing else. And if you can give a hand, or even criticize the
proposal and discuss potential use of the database, I think you'll be doing AI
Alignment a service.

A No-Nonsense Guide to Early
Retirement
(Edited 2021-02-28: Added a section on how retirement is risky, and
changed a few other sections to provide more context or clarify various
trade-oﬀs pointed out in the comments.)
I wanted to be able to link people to a guide on early retirement that succinctly
covered everything I thought was important, but I couldn't ﬁnd one that I was satisﬁed
with.  So I made this.
There are tons of communities and resources out there for anyone who wants to read
more about retirement, investing, ﬁnancial independence, etc -- many of which I'm
cribbing from.  You might start
here: https://www.reddit.com/r/ﬁnancialindependence/wiki/faq.
This is an opinionated guide, which means a lot of it is kind of made up -- but I think
it's ~95% in line with what you'll ﬁnd in ﬁnancial independence communities across
the internet.  Even if some numbers are wrong, I have decent conﬁdence nothing here
should lead you too far astray.
Also, disclaimer: I'm a random guy on the internet, please be careful with your
money!
Overview
To retire successfully, you need to have enough money to live on until you die.  This
requires saving money, and preferably investing it in assets that gain value over time.
Though there's a lot of ﬁddly details and no one can predict the future, given some
reasonable seeming assumptions the process for ﬁguring out how long this will take
you is pretty simple.  Just calculate:
How much you're saving per year
How much you're spending per year
How much money you currently have invested
and then plug those numbers into an early retirement calculator
like https://networthify.com/calculator/earlyretirement or https://engaging-
data.com/ﬁre-calculator/.  As a rule of thumb, you need to have ~25x your yearly
spending invested well to be able to live oﬀ of the returns.  So to support a $30k/year
lifestyle, you need ~$750k invested well.  The actual number may be 15x or 35x
based on the length of your retirement, the future performance of markets, whether
you ever generate any income during retirement, how ﬂexible your expenses are, etc.
-- but we can use 25x as a ballpark.
So you need to save money and invest it in assets that gain value over time.  The
more you do this, the quicker you'll retire.  Here's my ultra-sophisticated three part
strategy to doing so faster, and consequently the three sections in this guide:

Spend less
Earn more
Invest well
Risks of retirement
Before diving in, it's worth pointing out ways that retiring is risky.  The main way that
retiring is risky is that you might not have enough money at some point, and also
might not have any good options for getting more.
Some reasons you might not have good options for getting more money at a later
date:
Credential and professional network decay.  If you haven't worked in your
profession for 10 years (or 1 year in some cases), people may not want to hire
you for various reasons.
Age-related declines in health or cognitive function.
Ageism.
Automation and societal changes.  Your profession may no longer exist in the
same form in the future.
Hedonic adaptation.  You may have a harder time dealing with the pressures of
holding a job after you've gone a long time without holding one.
Retiring earlier is riskier than retiring later because you have to deal with risks over a
longer time frame.  You're reliant on market performance you can't control.  The
calculators and 25x rule mentioned above use historical market performance to
estimate how much you need to retire, but the market may not behave like it did
historically.  The longer your retirement will be, the more room there is for the market
to behave unexpectedly and wipe out your investment.
You also might need more money than you expect in the future.  Perhaps you have
children you did not plan for, suﬀer an unexpected medical expense, or encounter a
signiﬁcant opportunity that requires money.  New technology might create such
opportunities, e.g. costly anti-aging treatments.  Unless you think money will lose
most of its value, these risks can all be oﬀset by just saving more than you expect to
need.
Another way to manage these risks is to not fully retire.  Maintain some level of
professional activity, such that you can more easily jump back in to full-time
employment if you need/want to.  You could drop to part-time at your employer, try to
start your own business, or try to ﬁnd a consulting role which supports sabbaticals,
working only X months out of the year.  You could also use your newly found freedom
to retrain for a new profession that better supports these goals.
You can control some of these risks by modulating your spending based on your
investment performance; if the market goes down, downgrade your spending as
appropriate.  This can help substantially in back-tested simulations of retirement risk,
although there are obviously limits to how far you can downgrade.  This also doesn't
protect you from unexpected expenses.
Another, unrelated, risk to retirement is that not having a job could make you
unhappy.  In that case, you should get (or keep) a job!  This guide may still be useful
to you -- even if you never want to retire, having signiﬁcant savings and investment

income can open up new opportunities.  You could rely on savings to allow you to pick
a job you'll enjoy independent of its ﬁnancial payoﬀ, or to take risks in order to create
your own company/non-proﬁt/side-hustle.  If you haven't done so, you could also
explore ﬁlling the "job" slot in your life with things such as research, volunteering,
mentorship, media creation, lobbying, or anything else that you ﬁnd meaningfully
productive.
Spending less
Spending less helps in two ways: it lets you save more, and it also reduces the amount
you need to save.  Remember the rule of thumb that you need ~25x your yearly
spending in investments to retire.  If you consistently reduce spending by $100/month
aka $1,200/year, your necessary investment for retirement is lowered by $30,000.  A
$500/month increase in rent becomes a $150,000 increase in necessary investment. 
Minor looking ﬁnancial commitments can cost you years of your life!
It turns out that the calculation of years-to-retirement doesn't really depend on your
absolute level of spending or savings, just your relative level.  If you save 80% of your
net income, it will take you ~5 years to retire no matter what your income is.  If you
save 75% of your net income, it'll take you over 6 years.  This illustrates again how
minor diﬀerences in the amount you consistently save can have a big impact on when
you can retire.
It's hard to give speciﬁc advice about how to spend money, since it's so personal and
situational.  This area can also be surprisingly emotional; I recommend approaching it
with gentleness and honest reﬂection instead of moralism.  If you ﬁnd that you can't
consistently spend less, it's ok; you can rest satisﬁed with your current trajectory
(which you should calculate), or you can also try to make more money.
First, look at how much you're spending every month in categories like rent, groceries,
eating out, shopping, etc.  This might be scary, but knowing your spending in detail
will help you control it and make trade-oﬀs that you feel positive about.  There are
tools online to do this like Mint, but you can also just make a spreadsheet using
LibreOﬃce or Google Docs, copy the information from your bank statement, and then
use a pivot table to summarize spending by category.
If you know you have speciﬁc areas you tend to spend a lot in and would like to
reduce, make a monthly summary for them that you monitor.  Reﬂect on your most
expensive areas ﬁrst: saving $500 by selling your expensive car is worth more than
saving $200 from not eating out which is worth more than saving $10 from cancelling
a subscription.
Be careful of unintended eﬀects.  Reducing rent by moving further away from work
and increasing your commute can have a big negative impact on your happiness, for
instance.
There are massive reservoirs of information online about how to save money, but
there's no magic wand.  If rent and groceries take up 60% of your income, then you're
never going to save more than 40% of your income unless you reduce spending on
rent or groceries.  If your spending is already pretty well tightened, you might do
better by focusing on earning more.

Earning more
The way most people earn money is with a job, so all of my advice in this section
relates to jobs.  You also might be able to earn more by doing things like joining the
gig economy, starting a side business, or renting out space in your house -- deﬁnitely
consider such options if they seem like a good ﬁt for you.
Getting a better job
One of my biggest career mistakes (among many) was taking the wrong job after I
ﬁnished school.  I doubled my salary when I switched to a diﬀerent job 9 months later
-- a job that I'd been qualiﬁed for the whole time, and which made no use of my 9
months at the ﬁrst job.
My big takeaway: try applying for better jobs.  Better might mean more pay now, more
pay later on (for instance, by getting into a new profession with higher pay potential),
or some other improvement (such as a job that ﬁts your values better or oﬀers you
better working hours).  The time commitment to apply is at most a few hours to work
on your resume and cover-letter -- the potential payoﬀ is years oﬀ of your eventual
retirement timeline.  Imposter syndrome and self-esteem issues are big obstructions
for a lot of people; if you self-identify as having either of those, you're probably under-
applying and should apply to more jobs.  Apply even though you don't think you meet
the qualiﬁcations.  Even if you're completely happy with your current job, I'd propose
you should send something like a dozen applications out per year just to test for even
better opportunities.  The only reason I can see not to is if it'd be hard for you to ﬁnd a
dozen better opportunities anywhere in the world.
When applying for jobs, getting a recommendation from an existing employee is much
better than just sending your resume and cover letter blind.  People have written
mountains about networking, but I'm bad at networking so I'll summarize with
"meeting and befriending people in settings related to your profession can have high
payoﬀ."  Promising locales include real-life meetups, conferences, and social
networking sites.  Don't use your lack of a network as an excuse not to apply for
things though -- you can apply now AND try again later if you end up ﬁnding someone
to recommend you.
If you've worked at the same company for a while, try applying for other jobs even if
they seem like lateral moves; you might be able to get a pay boost or promotion by
switching companies.  Raises and promotions at a single company don't necessarily
keep pace with your market value as your experience increases.  Even if you don't
want to switch jobs, you may be able to negotiate compensation increases at your
current company if you have another competitive oﬀer. 
For certain jobs, building or improving a public portfolio might increase your
application success rate.
Depending on your situation, it might make sense to try earning credentials in order to
land better jobs.  This is extremely situational and you should do your own research
before committing to anything.  Here's a scattered list of thoughts:
Look for data on salaries by school, degree type, and ﬁeld before committing to
any degree program.  E.g., a Bachelor's degree in Computer Science from

Stanford is extremely valuable; a Master's degree in Fine Arts from For-proﬁt
College X is probably worthless.  Compare median graduate salaries with the
cost of attendance and opportunity cost from lost time.
PhDs are almost never worth the opportunity cost, with few exceptions.
Programming is still quite lucrative if you can break into it.  The ﬁeld is saturated
with entry-level applicants, but still has very high demand for experienced
talent.
I've heard that law school has become a bad deal for most people, unless you
get into one of the very top schools.
I've heard that med school has become a worse deal over time, but may still be
a good deal on average if you can hack it + residency.
I've heard nursing can be lucrative.
Negotiating
If you're in the application, interview, or job-oﬀer phase with any company, there's a
number of things you can do to potentially increase your pay.  There's a ton out there
about negotiation, so I'm just going to share the most important points as I see them.
In my overly simpliﬁed model of negotiation, your success has three primary inputs:
1. Your perceived value to the employer, which aﬀects how much they'll be willing
to oﬀer you.
2. Your best alternative to accepting the oﬀer on the table, which aﬀects how hard
you should be willing to push.
3. Your ability to execute a basic negotiation strategy without making mistakes.
There are a lot of ways to increase your perceived value, some of which are very
situational.  Another scattered list of ideas:
Acquire prestige.  This could be through schools, other jobs you've held,
professional accomplishments, building a public persona, etc.
Be good at the job in a visible way.  If applicable, build public portfolios which
demonstrate your skill.
Practice generic good social skills.  Try to get honest feedback from others about
your social skills.  This is obviously a big area to ﬁgure out.
If the interview process will involve any technical skill, practice that skill so that
you perform well (e.g. LeetCode for programmers).
Practice answering interview questions out loud on your own or with a friend. 
Record yourself and examine the results.
During interviews, talk (honestly) about your positive qualities, achievements,
and capabilities.  Don't focus on your negative qualities or failures -- if they do
come up, talk about what you've learned from them.
Don't show desperation.  Even if you are desperate, do what you need to do in
order to hide it for the duration of the interview -- the employer will not care and
will ﬁnd your desperation oﬀ-putting.
The impact of your best alternative is pretty straight-forward: if you're about to be
homeless, you'll probably accept whatever someone oﬀers you.  If you've already got
a comfy job that you're happy with, you've got no reason to leave unless the oﬀered
pay is substantially better, so you can hold out or make multiple counter-oﬀers.  This
is a good reason not to quit your current job before applying to other jobs.

As to basic strategy:  try not to tell potential employers your current salary or salary
expectations, as they'll mostly use this information to low-ball you when applicable. 
You've got nothing to gain by giving up this information, and the person on the other
end of the conversation is aware of this -- it's simply their job to try asking anyway.
There's a million strategies posted online about how to avoid giving up this
information, but here's a simple one that's worked for me: if they ask for your previous
salary or salary expectation, tell them you'd rather not share that information, but
that you're happy to conﬁrm your expectations are within a given salary range if they
have one -- this puts the obligation on them to list a range.  If they continue insisting
without giving a range, just politely repeat that you'd rather not share.  If they ask
why, you can truthfully explain that you'd rather hear their range ﬁrst to anchor the
negotiation.  If your current salary or salary expectations are required in a form, try
entering the smallest number it will accept (like $0 or $1 or $1000).  If a human tells
you these numbers are needed on a form, explain the above and then ask them to
enter a small number.  If a human later asks you about the number on the form,
repeat the above.  I ﬁnd it easier not to make mistakes if I just commit to never giving
this information, no matter how weird things get -- it's extremely unlikely an employer
will be petty enough to refuse to proceed based on this, and if they do you've got a
great story you can share on reddit.
After you receive a job oﬀer for a high-skill / professional class job, you should usually
ask for more money.  There is a chance that asking for more money will cause the
employer to retract the oﬀer, but as far as I know this chance is extremely low in most
high-skilled industries if you ask for +10-15% -- most employers expect and plan
around receiving counter-oﬀers in this range.  You might want to do some research on
your industry in particular in case it's weird about this.  People in high-skill jobs tend
to be overly paranoid about the chance of an oﬀer being withdrawn.  
If you receive an oﬀer for a low-skill / high-labor-supply job such as retail or restaurant
service, my impression is that attempting to negotiate at all might get an oﬀer
rescinded, so be careful.
A simple phrasing template for counter-oﬀers: "Excellent!  I'm excited about x,y,z.
 Unfortunately, the compensation is somewhat lower than I was aiming for.  Would you
be able to come up to <counter-oﬀer>?".  Add your own voice as desired, there's
nothing magical about this template.  If you're unsure about your writing but have
socially savvy friends, run things by them if you can.
If they don't counter-counter-oﬀer, but they also hint that higher compensation is still
on the table, ask about a slightly lower number (+5-10%).  If at any point they say
they can't go higher, then making further counter-oﬀers might cause them to
withdraw the oﬀer.  If you wouldn't want to accept their current oﬀer regardless,
there's no harm in continuing to hold out for the minimum you would accept.    As an
anecdote, my last three salary negotiations (as a programmer) have yielded 12%, 6%,
and 7% salary increases respectively over the counterfactual of accepting the ﬁrst
oﬀer given.
You have more at stake proportionally than a company does during negotiation, so to
reduce mistakes I think you should negotiate carefully by email whenever possible.  If
pushed for answers or acceptance in person or over the phone, tell them you're
excited but you'd prefer to think about things and get back to them shortly via email. 
If they say or insinuate they need an answer immediately, refuse to give one and re-
iterate that you'd like to think about it and get back to them shortly.  If they withdraw
an oﬀer due to you not giving an instant answer, then I guess they're either dumb or

abusive -- you probably don't want to work for them anyways.  If you do decide to
negotiate over the phone or in person, make sure you have your decision tree clearly
written out or rehearsed, and try to bail back to email at the ﬁrst sign of trouble.
Investing well
Despite all of the intense social signaling around personal ﬁnance, investing well is
surprisingly easy and boring.  You can get 80% of the value of everything in this
section by doing exactly the following without any additional context:
Build an emergency fund to cover a few months expenses
Invest in your employer's 401(k) up to the matching amount.  Buy whatever
stock index fund they oﬀer.
Pay oﬀ all of your debt unless the interest rate is very low, e.g. 3-4%.
Go to vanguard.com and open a taxable brokerage account.
Deposit $X each month.
Use that money to buy VFIFX.
Never look at stock market indicators and ignore all stock news.
Retire once the calculators say your account balance is high enough.
Sell as needed for money during retirement, keeping your expenses the same
modulo inﬂation.
By doing so, you'd primarily be missing out on the advantages of using more
retirement accounts (which help your money grow faster) and optimizing your index
fund portfolio.
Note that this whole section takes what is called a "passive view" on investing.  The
alternative "active view" is where you dive deep on trying evaluate various assets and
predict their market behavior on shorter terms than "when I retire".
Even among professional investors, most people who take an active view end up
making much less than they would with an index fund.  Most of us are not at the level
of professional investors, so should expect to do even worse.  All of your friends who
report making good money actively buying and selling are either 1. selectively
reporting, 2. lying, or 3. got temporarily lucky, but are just as likely to get unlucky in
the future.  If you feel the need to be included in such games, set aside at max 5% of
your monthly investment deposits for this purpose and put the other 95% into index
funds.  Never sell your index funds to buy into the latest investment fad.
You can "leverage" a passive indexing approach using various ﬁnancial products, and
the math on this might be better than just buying index funds directly, but this is
deﬁnitely straying from No Nonsense to Reasonably Large Amounts of Nonsense, so I
wouldn't recommend it for most people.  See this comment thread for some links and
context.
1. Emergency funds
Your ﬁrst investment priority should be taking care of your basic needs.  Have you
eaten today?  Did you stay up all night writing an early retirement guide?
Your second investment priority should be building an emergency fund that you keep
set aside for urgent and unexpected situations.  Having an emergency fund improves

your well-being by giving you leverage and letting you get through life events with
minimal disruption.  For example:
If your car dies, you can take Uber or rent a car.
If your roommate is late on rent, you can cover for them instead of being
evicted.
If your fridge dies, you can replace your fridge and then buy new food.
Etc.
You should keep your emergency fund somewhere safe like a savings account, not in
the stock market.
There's debate over how big your emergency fund should be given your situation.
Here's a concrete recommendation that you can adjust to your comfort level:
First, save enough to cover 1-2 months worth of expenses.
Then, pay oﬀ any crazy interest rate debt (payday loans, credit cards).
Then, save enough to cover 6-12 months of expenses.  This gives you time to
ﬁnd a new job if you lose your current one.
Finally, put your excess into paying oﬀ other debt or buying investments.
Make sure you save for your actual expenses, not your budgeted ones.  Look at
bank statements as discussed in the "Spending less" section to know how much
you're actually spending.
Although investments will provide you with additional cushion (you can sell them in an
emergency), you should plan to not sell investments until you really need them since
any gains you've made on the investment will incur tax when you sell.
2. Debt
Debt is an anti-investment with a guaranteed negative return (its interest rate).  For
this reason, it's basically always a bad idea to go into debt just to buy consumption
goods.  Treat any purchase that comes with a monthly payment as extremely suspect.
 Buy consumption goods (including cars) up front whenever possible, so you can't hide
their true cost from yourself.  You may sometimes need to go into debt temporarily to
survive; if so, work on escaping that situation as quickly as possible.  The other
techniques in this guide might help.
Debt can be a good idea when it's used to ﬁnance creation of future value; for
instance, taking out student loans which allow you to get a valuable degree that
doubles your expected lifetime earnings.  Just be careful; if you misjudge the value of
what you're buying, you might end up worse oﬀ. 
Mortgages and houses are a complicated topic that I've not researched much.  My
current opinion is that having a mortgage is probably slightly better than renting in
expected value, but riskier (your property might decline in value) and with much
higher transaction costs for moving.  Those transaction costs lock you into a
geographic location, which reduces some opportunities for making more money or
reducing spending.  Think carefully before locking in.
If the interest rate is small enough, investing money in index funds can be better in
the long run than paying oﬀ debt.  For instance, say you have a 3% mortgage and you
think the expected yearly gain from an index fund is 10%; then you could make 7% a

year by investing instead of paying oﬀ your mortgage.  You could even try to borrow
more money at a low interest rate in order to invest it.
The catch is that interest rates are certain and index fund gains are not.  You take the
risk that your investment does not pay oﬀ in any given year, which can be
psychologically diﬃcult when combined with debt.  Debt also increases your baseline
expenses through minimum payments -- this could put you in a worse short-term
situation if you lose your job at the same time as your investments decrease in value.
 Still, if you think the markets will go up on average over time and you can cover the
minimum payments, you should win out in the long run if the interest rate is low
enough.   I would personally not do this with an interest rate over 4% unless I had a
ton of other assets to cover me in case of a downturn or unemployment.
Make sure you have enough money to cover expenses before paying oﬀ debt.  Having
debt paid oﬀ is no good if you can't pay rent.
3. Retirement accounts
This is the most complicated part, because tax law is dumb.  This part is also entirely
U.S. focused -- I'm sure other countries have their own dumbnesses, but I don't have
knowledge of them.
Retirement accounts are accounts with money in them that you can use to buy
investments like index funds.  You either open them yourself or have them opened by
an employer.  You put money into them manually or through automatic paycheck
deposits.  A non-retirement account for buying investments is usually called a
"brokerage" or "taxable" account.  Retirement accounts have various tax beneﬁts over
non-retirement accounts, so are often called "tax-advantaged" accounts.  You
generally make more money long-term by investing in retirement accounts, but they
also come with various limitations.
I'm going to talk about 3 specialized retirement account types which are all that 90%
of people should need to touch: traditional and Roth 401(k)s,  traditional and Roth
IRAs, and HSAs. There's a few others ﬂoating around (like Solo 401(k)s and 403(b)s),
but they work on a lot of the same principles anyways.
IRAs are accounts opened personally by you at some provider.  I recommend
vanguard.com.  They're pretty straight-forward to use: you put money in and then
select investments to buy.  The only catch to IRAs is you can't contribute to them if
your income is too high.
401(k)s are opened by an employer, but you own the money in them.  Employers will
often oﬀer a "matching percentage", where they'll give you free money in exchange
for investing in your 401(k) -- this is usually an awesome deal that you should
deﬁnitely take.  Unfortunately, sometimes employers use bad providers with bad asset
options and bad websites, so you have to ﬁnd the best option you can among what's
on oﬀer.  I'll talk more about this in the section on index funds below.  You can
eventually "rollover" a 401(k) into an IRA at the provider of your choice, usually after
you've left the employer.
HSAs are only kind of retirement accounts, with their nominal purpose being to give
you tax beneﬁts on medical spending.  They can be opened by either you or your
employer, although you pay less taxes if your employer deposits money directly into

the HSA from your paycheck, so you should have them do that. You can only deposit
into an HSA if you have a High-Deductible Health Plan (HDHP).  You can withdraw from
an HSA at any time to pay for "qualiﬁed medical expenses", or you can hold the HSA
until age 65, at which point it works mostly like a traditional IRA (see below).  Some
HSAs are basically savings accounts with no investment opportunities; some others
will let you buy things like index funds.  HSA's are not to be confused with FSA's,
which as far as I can tell are really dumb and will eat your money.
All retirement accounts have limits on how much you can put into them per year. 
Having multiple accounts at diﬀerent institutions does not increase the limit; it's a
total limit across all accounts. For instance, for 2021 you can contribute a maximum of
$6000 to IRAs, or $7000 if you're age 50+.
If you withdraw money from an account before a certain age, you'll have to pay a
penalty on your taxes.  The age rules diﬀer for every account type, but the cutoﬀ is
always in the 55 to 65 range.  I'll just say "retirement age" to refer to these
cutoﬀs.  The penalty has either one or two parts:
You'll always be taxed a ﬂat percentage of what you withdraw; 20% for HSAs and
10% for most other accounts.
You might additionally owe regular taxes on some of the money withdrawn, even
though you wouldn't owe taxes for an "authorized" withdrawal.
There are some important exceptions to the penalty rules, which we'll discuss shortly. 
Those exceptions play a major role for early retirees who want to withdraw money
before retirement age.
You'll notice the words "traditional" and "Roth" used above; these refer to two types of
tax advantages.  The short summary:
Contributions to traditional accounts are tax free in the present (you get a
deduction for what you contribute); you pay taxes when you withdraw money
after retirement age.
Contributions to Roth accounts are taxed in the present (no deduction, you
contribute with post-tax income), but then you can withdraw tax-free after
retirement age.
With both versions, activity within the account isn't taxed; you can buy and sell
diﬀerent assets or receive dividends with no tax consequences.
Compare to a taxable brokerage account: you're taxed in the present (no deduction,
you invest with post-tax income), and you also pay taxes on sales and dividends. 
Taxes on dividends will drag down your returns somewhat, and even if you only buy
once and sell once you'll still have to pay 0% to 20% in long-term capital gains tax
that you wouldn't pay in a Roth IRA.  If you buy and sell more often then you'll drag
down returns even more, since any gains you realize will be taxed and that tax money
can no longer be kept invested.
You get to choose whether to invest in traditional or Roth accounts; you can mix and
match however you want.  Which of the two options is better is kind of complicated --
here's an article with more
details: https://www.reddit.com/r/personalﬁnance/wiki/rothortraditional.  The short
answer:
If your tax bracket / income is low right now, you should probably do Roth.
If your tax bracket / income is high right now, you should probably do traditional.

If it's in between, there's pros and cons but probably either is ﬁne.  I lean toward
Roth.
Back to those penalty exceptions -- there's two big ones:
The principal amount you invest in a Roth IRA can be withdrawn at any time,
penalty and tax free.  This is the main reason I would lean Roth for middle tax
brackets -- extra liquidity is very good for the nerves.  You can also access the
principal of a Roth 401(k), but ﬁrst you need to roll it over into a Roth IRA.  Most
service providers allow such rollovers while you're still employed, but
supposedly a few do not -- thus you might not be allowed to do this unless you
quit your job.
You can convert funds from a traditional IRA to a Roth IRA at any time, pay taxes
on the conversion amount, and then withdraw that money penalty and tax free
after waiting at least 5 (tax) years.  You can also do this with a 401(k), but you
have to roll it over -- again, there's a small chance you might need to quit your
job to do this.
Combined, these two exceptions let you access a good chunk of retirement account
assets early without penalties: Roth principal whenever you want, and traditional
principal+earnings if you can plan it 5 years in advance.  Roth earnings, unfortunately,
are stuck until retirement age, as are HSA principal and earnings for every purpose
besides qualiﬁed medical expenses.
(EDIT: An important point I left out here -- the oﬃcial record of your Roth
IRA principal lives on tax form 5498 that your brokerage will send you or
allow you to download each year.  As far as I understand, oﬃcially you need
to keep these forms until age 59.5 to justify any early withdrawals to the
IRS.  Brokerages tend to delete these forms after a few years, and they
don't separately track a "contribution" or "conversion" number attached to
the account.  I found this out the hard way when I transferred my Roth IRA
between brokerages, my transaction history was deleted, and no one from
either brokerage could tell me my contribution or conversion basis.)
Since you can convert from traditional to Roth whenever you want, you can control
what year you pay conversion taxes in.  This means you can pick a year when you
have low income (say, during an early retirement), and ﬁll up your deductible and
lower tax brackets with conversion money.  Think of your deductible and lower tax
brackets as a resource which expires every year; traditional to Roth conversions let
you make use of that resource whenever it makes sense.  This leads to a tactic called
a "Roth Conversion Ladder", where each year you convert just enough to cover
predicted expenses 5 years hence.
If you have money in taxable accounts, you should usually withdraw that ﬁrst before
hitting your tax-advantaged accounts, since money in tax-advantaged accounts grows
faster.
That's a lot of info; I'll summarize my recommendations on how to use retirement
accounts in the section below on "Putting it all together".
4. Index funds

An index fund is a pool of money that someone invests in a bunch of diﬀerent assets,
with the goal of having returns match an "index" of some kind.  Usually that index
measures the total value of some big market.  Index funds are generally really good at
tracking their indices -- they just buy up a proportional share of everything in the
indexed market.  Because this is a really easy strategy to execute, they're cheap to
run.  Plenty of providers will let you buy into their index funds, and thus you as a tiny
investor can easily get an investment return that tracks the total value of a huge
market.  Providers will usually charge a fee, and the smaller this fee is, the better.  I
recommend vanguard.com; their ownership structure is designed to incentivize small
fees.
I am not going to do justice to the theory behind index funds, so here's the short and
probably misleading version of why they're such a good idea:
The performance of an individual stock is really hard to predict, even in the long-
term.
The total value of the entire stock market is much easier to predict in the long-
term -- or at least it looks that way based on historical data.  Inﬂation-adjusted,
it seems to go up about 4-10% annualized over long enough time periods.
This fact is related to a math thing, where diversiﬁcation (having lots of
somewhat diﬀerent assets) reduces risk without hurting returns.
Basically, picking individual stocks is a suckers game and no one is any good at it --
though lots of people pretend to be.  On average stocks are good, but any individual
stock is an unpredictable rollercoaster that might eventually go bankrupt.  But if you
pick ALL the stocks, things smooth out into a blissful upward rise -- at least,
historically they do over investment time frames of 20+ years
The observation about diversiﬁcation being good applies to basically any type of
asset, not just stocks.  The most popular assets besides stocks are "bonds", and of
course there's index funds for them too.  Bonds are (on average) a lower-risk, lower-
return asset than stocks.  The main way people manage risk-reward tradeoﬀ in a
portfolio is to mess with the proportion of stocks vs bonds.  More stocks give higher
risk, but also higher average return over the long-term.
So that's all good, but which index funds should you buy?  If you're on Vanguard:
"Target Retirement Funds" such as VFIFX are one-stop shops that are hard to
screw up.  These funds hold a couple of other big stock and bond index funds,
and automatically shift to fewer stocks/more bonds over time as you approach
their target retirement date.  VFIFX targets a 2050 retirement so currently has a
more aggressive 90/10 stock/bond portfolio, but there are funds available for
every 5 year increment. VTTVX targets 2025 and has a more conservative 60/40
ratio.
You could buy VTWAX (total world stock market) for a one fund stock-only
portfolio.  Lots of people would advise against having no bonds, however.
If you want to roll your own allocation, you could buy some mixture of VTSAX
(US stock), VTIAX (International stock), VBTLX (US bonds), and VTABX
(International bonds).  You could start with the mix from a Target Retirement
Fund and go from there -- details are available on the fund pages.  If you do this,
you might need to occasionally "rebalance" to maintain your target percentages
as some investments grow more quickly than others.
You could read countless arguments online about exactly what you should do,
and then do whatever.  As long as your strategy is "buy X% of some stock index

funds and (100 - X)% of some bond index funds" it's probably sane, although
IMO X should be at least 50.
If you're not on Vanguard, I recommend ﬁrst ﬁguring out what you'd do if you were on
Vanguard, then ﬁnding the nearest equivalent on your provider.  Vanguard is so
popular that many online conversations are phrased in terms of its funds.  Your 401(k)
is probably not on Vanguard, but many 401(k)s now oﬀer at least some Vanguard
options anyways.  If not, look for terms like "S&P 500", "total US stock market", and
"US large cap" -- these will all track relatively large stock market indices.  You can
Google to learn more about the distinctions if you want to optimize, and you can use
your IRA or taxable accounts to help balance out the poor selection in your 401(k).
5. Don't screw up
Don't sell assets when the market crashes.  Stock markets have always
recovered after crashes, and then some.  If you sell after a crash, the main thing
you're likely to accomplish is missing out on the eventual recovery -- even if more
crashing happens in the meantime!  There will never be a clear signal of when you
should buy back in, so when you do buy back in, it will only be after you've seen that
the market has already substantially recovered. You'll have missed out on that
recovery.  Just buy investments and then don't touch them.  Market crashes mean
things are selling at a discount, which is great for you in the long-term!  Keep steadily
buying with your paychecks!  Ignore market performance!  The road to inner peace is
to just admit that in the short-term you have absolutely no idea what the market will
do and when it will do it.  Just steadily invest and ignore short-term results.  This is
the most important point in all of investing.  You are actually better oﬀ not
investing at all ever if you end up selling during crashes.
The paragraph above exists because humans instinctually want to sell their assets
during crashes.  Note this about yourself and take precautions.  You might try buying a
few shares in some volatile stock for a ﬁxed period of time -- not enough to mess up
your plans, but enough that a loss will hurt a bit.  Just see how it feels when the value
goes down substantially.  Practice monitoring it daily, but only selling after the
designated time period has passed.
If given all of the above you still predict that you're likely to sell if the market crashes,
try moving to a less risky investment allocation NOW before the market crashes.  For
instance, put a larger percent of your investments in VBTLX (total US bond market) or
VFITX (intermediate duration treasuries).  The maximally safe place to keep your
money would be VMFXX, or even better a savings account at your bank.  If you don't
take any risk with your money, however, you won't get much reward.  VFIFX has
returned ~10% per year over the last 10 years, wheras VBTLX has returned ~4% and
VMFXX has returned ~0.5%.  Not having enough money to achieve what you want in
the future is its own risk.
A less obvious way to mess up is to buy too much of the wrong assets.  If you really
want to buy an asset that's not a stock or bond index fund, then just be careful not to
buy too much of it.  I'll talk about four that seem to be popular: gold, other investment
products, houses, and cryptocurrency.
Looking at historical returns, gold is just not a very good investment for its risk level --
the same applies to its cousin silver.  I think there's some trend around buying gold
related to fear of hyper-inﬂation/market collapse.  I've not read anything that

convinces me it's a good idea; if you're convinced, just keep the amount you buy
relatively small.
"Other investment products" is a big category, but some common ones: speciﬁc
stocks, ETFs that don't track a large market index, actively managed mutual funds,
various commodities, annuities, futures, option contracts, and whole life insurance. 
I'm pretty sure that 99% of everyone would be better oﬀ never buying any of these. 
But if you do, just don't buy very much of them.
I mentioned houses when I talked about debt.  But debt is not the primary reason I
think houses are dangerous.  Houses are dangerous because people tend to buy too
much house.  Even with a paid oﬀ mortgage, money you have invested in a house is
money that's not invested in the stock market.  You could own a $500k house and pay
5k/year on repairs and $5k/year on property taxes -- or, you could own $500k in index
funds and safely withdraw $20k/year.  That -$10k to +$20k spread is money you could
use to pay up to $2.5k/month of rent.  That seems pretty reasonable -- until you step
back and wonder whether you should be paying eﬀectively $2.5k/month rent in the
ﬁrst place.  Downgrading to a smaller apartment that costs $1k/month in rent would
lower your necessary retirement investment by $450k, saving you potentially many
years of your life.  But moving from a $500k house to a $1k/month apartment can
become too big of a psychological leap for people to even consider.  So if you're going
to buy a house, I think you should try hard to buy a small/cheap one until you've
achieved all of your other ﬁnancial goals.
I have no idea what the hell is going on with cryptocurrency and it has consistently
surprised me, so I think it's completely sane to buy some cryptocurrency.  As of this
writing, cryptocurrency has a market cap of ~$1.6 trillion, with ~$1 trillion of that
being Bitcoin.  The total market cap of all stocks is ~$100 trillion, so overall investors
are putting ~1% as much into Bitcoin as into stocks.  So far, cryptocurrency has been
extremely high risk and high return as an asset class.   If you have a higher risk vs
reward preference proﬁle than the average investor, I can imagine going up to 5-10%
crypto investment.  However, I don't think anyone really knows what's going to
happen with crypto -- it may be a speculative bubble.
In all of these cases, I think it's ok to make a mistake and buy the wrong thing, or to
take a risky gamble that doesn't pay oﬀ -- as long as that thing is only a small portion
of your investment portfolio!  You'll be totally ﬁne whichever way the gamble lands if
you use 10% of your disposable paycheck for a few months to buy Dogecoin.  But if
you sell everything to buy into a fad, and then the fad crashes, it will suck.  Be ok with
getting rich slowly.
Putting it all together
Given all of the above, here's my detailed recommendations on how to invest:
Save an emergency fund of 1-2 months of expenses in a savings account.
Contribute to your employer's 401(k), but only up to the matching amount.  E.g.
if they match half up to 6% of your salary, then contribute 6% of your salary. 
Use contributions to buy your choice of index funds.  Default to just buying VFIFX
if available.
Pay oﬀ high payday loans/credit cards/other crazy debt.
Increase your emergency fund to 6-12 months of expenses.
Pay oﬀ other debt (unless its interest rate is ~3% or less).

Put aside any money for large expected purchases (school, car, etc) in a savings
account.
Max out your HSA if you have one.  Buy your choice of index funds if it has that
option.  Default to just buying VFIFX if available.
If your income is low enough to be allowed to contribute, max out your
traditional or Roth IRA.  Pick traditional if you're high tax-bracket, Roth if you're
low tax-bracket.  Open one on Vanguard.com if you don't have one.  Use it to
buy your choice of index funds.  Default to just buying VFIFX.
Finish maxing out your 401(k).
Open a taxable brokerage account on Vanguard.  Dump the rest of your
investment money in here.  Buy your choice of index funds.  Default to just
buying VFIFX.
Never look at stock market indicators and ignore all stock news.  In principle,
look at your total portfolio value every 6 months or so to check whether you
have enough to retire.  Never click the sell button.
Retire once you have enough.
Start converting some traditional funds to Roth if you'll need the money 5
years from now or have space in lower tax brackets due to low income.
Sell and withdraw as needed, starting with your taxable accounts.
Keep your expenses the same modulo inﬂation.
Do whatever you want!  Keep some level of professional activity / money-
making to further reduce your risk.
Here's another great ﬂowchart that I mostly agree with, with more detail in certain
areas: https://u.cubeupload.com/demonlesondledon/FIREFlowChart.png.
Conclusion
In its ideal form, this guide should become an extremely boring set of procedures and
habits that you execute in the background of your life, taking up roughly 0.1% of your
attention.  Then as a consequence, at some magical future date far in advance of
what it should be, you are freed forever from basic ﬁnancial concerns.  A boring set of
procedures and habits that can grant you additional decades of freedom and
autonomy strikes me as a surprisingly beautiful artifact.  I'm not sure if this guide will
live up to that ideal for anyone reading, but I hope it helps and makes your future just
a little brighter.

The Kelly Criterion in 3D
The Kelly Criterion is a gambling strategy which maximizes the logarithm of your
expected wealth. The Kelly Criterion tells you what fraction f ∗ of your bankroll to
wager. It is a function of the net fractional odds[1] received b > 0 and the probability of
a win p ∈(0, 1).
f ∗=
Some properties are intuitively easy to understand.
The Kelly wager is positive iﬀ the expected value bp −(1 −p) is positive. The
Kelly wager is zero otherwise.
The Kelly wager is 1 for all p = 1. (Ignore b = 0.)
The Kelly wager is 0 for all b = 0. (Ignore p = 1.)
What surprised me is that if you ﬁx b and restrain p to the region of positive f ∗ then f ∗
is a linear function of p. This was not intuitive to me.
p(b + 1) −1
b

I expected asymptotic behavior with the greatest 
 in a neighborhood of p = 1. In
other words, I expected the fractional wager to increase slowly at ﬁrst and then
increase faster as p approached 1. Actually, p is linear.
Kelly wagers tend to be more aggressive then human intuitions. I knew this and I still
underestimated the Kelly wager. I didn't mess this up in a high stakes situation where
fear throws oﬀ my calculations. I didn't even mess this up in a real-world situation
where uncertainty complicates things. I underestimated the Kelly wager on a purely
conceptual level.
I have written before about the utility of my fear heuristic. My fear heuristic might be
helping to compensate for my Kelly miscalibration.
Recalibrating
I'm good at tolerating risk when it comes the small number of gigantic risky bets
guiding my professional career. I'm also good at tolerating risk in the domain of
painlessly small bets. (Not that there is much risk to tolerate in this latter case.)
Judging by this post's analysis, I am awful at calibrating my risk tolerance for wagers
between 0.05% and 1% of my net worth. Speciﬁcally, I am insuﬃciently risk tolerant.
What makes this worse is that the region of 0.05% to 1% of my net worth is full of long
tails. The wagers I'm skipping could easily repay themselves a thousandfold. If I take a
wager like this every day for 2 years and just a single one of them repays itself a
thousandfold then I win bigtime.
I need to gamble more.
Optional Practice
df ∗
dp

I used these problems is to help develop my intuitive grasp of the Kelly criterion.
Q1: If p = 0.01 and b = 1000 then what is the corresponding f ∗?
0.9%
The above number is way higher than what my intuition tells me is appropriate.
Q2: If p = 0.1 and b = 20 then what is the corresponding f ∗?
5.5%
The above number is higher than the answer to Q1. This result was, again, unintuitive
to me. I expected it to be smaller because b is smaller in absolute terms. But I didn't
pay suﬃcient attention to bp = 2. The average return is 2× your initial investment.
Q3: If p = 0.51 and b = 1 then what is the corresponding f ∗?
2%
Q4: If p = 0.51 and b = 2 then what is the corresponding f ∗? (Not that b = 1 means
you get back your original wager plus double you wager for a total of 3× your wager.)
26.5%
Q5: If p = 0.65 and b = 100 then what is the corresponding f ∗? (In practice,
opportunities like this are so rare you will usually not get to wager a full Kelly.)
65%
I was a little surprised; I had expected a higher result. The logarithmic value function is
doing the work of keeping Kelly down.
Q6: If p = 0.05 and b = 100 then what is the corresponding f ∗?
4%
1. The "net fractional odds" b indicate how much you win in the case of a win. If you
wager x and lose then you lose x. If you wager x and win then you get your x
back plus an additional xb. ↩ 

Timeline of AI safety
Crossposted from the AI Alignment Forum. May contain more technical jargon than
usual.
This is a linkpost for https://timelines.issarice.com/wiki/Timeline_of_AI_safety
Here is a timeline of AI safety that I originally wrote in 2017. The timeline has been
updated several times since then, mostly by Vipul Naik.
Here are some highlights by year from the timeline since 2013:
Year
Highlights
2013
Research and outreach focused on forecasting and
timelines continue. Connections with the nascent
eﬀective altruism movement strengthen. The Center for
the Study of Existential Risk and the Foundational
Research Institute launch.
2014
Superintelligence: Paths, Dangers, Strategies by Nick
Bostrom is published. The Future of Life Institute is founded
and AI Impacts launches. AI safety gets more mainstream
attention, including from Elon Musk, Stephen Hawking, and
the ﬁctional portrayal Ex Machina. While forecasting and
timelines remain a focus of AI safety eﬀorts, the eﬀort
shifts toward the technical AI safety agenda, with the
launch of the Intelligent Agent Foundations Forum.
2015
AI safety continues to get more mainstream, with the
founding of OpenAI (supported by Elon Musk and Sam
Altman) and the Leverhulme Centre for the Future of
Intelligence, the Open Letter on Artiﬁcial Intelligence, the
Puerto Rico conference, and coverage on Wait But Why.
This also appears to be the last year that Peter Thiel
donates in the area.
2016
Open Philanthropy makes AI safety a focus area; it would
ramp up giving in the area considerably starting around
this time. The landmark paper "Concrete Problems in AI
Safety" is published, and OpenAI's safety work picks up
pace. The Center for Human-Compatible AI launches. The
annual tradition of LessWrong posts providing an AI
alignment literature review and charity comparison for the
year begins. AI safety continues to get more mainstream,
with the Partnership on AI and the Obama administration's
eﬀorts to understand the subject.
2017
This is a great year for cryptocurrency prices, causing a
number of donations to MIRI from people who got rich
through cryptocurrency. The AI safety funding and support
landscape changes somewhat with the launch of the
Berkeley Existential Risk Initiative (BERI) (and funding of its
grants program by Jaan Tallinn) and the Eﬀective Altruism
Funds, speciﬁcally the Long-Term Future Fund. Open
Philanthropy makes several grants in AI safety, including a

$30 million grant to OpenAI and a $3.75 million grant to
MIRI. AI safety attracts dismissive commentary from Mark
Zuckerberg, while Elon Musk continues to highlight its
importance. The year begins with the Asilomar Conference
and the Asilomar AI Principles, and initiatives such as AI
Watch and the AI Alignment Prize begin toward the end of
the year.
2018
Activity in the ﬁeld of AI safety becomes more steady, in
terms of both ongoing discussion (with the launch of the AI
Alignment Newsletter, AI Alignment Podcast, and
Alignment Forum) and funding (with structural changes to
the Long-Term Future Fund to make it grant more regularly,
the introduction of the annual Open Philanthropy AI
Fellowship grants, and more grantmaking by BERI). Near
the end of the year, MIRI announces its nondisclosure-by-
default policy. Ought, Median Group, and the Stanford
Center for AI Safety launch during the year.
2019
The Center for Security and Emerging Technology (CSET),
that is focused on AI safety and other security risks,
launches with a 5-year $55 million grant from Open
Philanthropy. The Stanford Institute for Human-Centered
Artiﬁcial Intelligence (HAI) launches. Grantmaking from the
Long-Term Future Fund picks up pace; BERI hands oﬀ its
grantmaking of Jaan Tallinn's money to the Survival and
Flourishing Fund (SFF). Open Philanthropy begins using the
Committee for Eﬀective Altruism Support to decide grant
amounts for some of its AI safety grants, including grants
to MIRI. OpenAI unveils its GPT-2 model but does not
release the full model initially; this sparks discussion on
disclosure norms.
2020
Andrew Critch and David Krueger release their ARCHES
paper. OpenAI unveils GPT-3, leading to further discussion
of AI safety implications. AI Safety Support launches. The
funding ecosystem continues to mature: Open Philanthropy
and the Survival and Flourishing Fund continue to make
large grants to established organizations, while the Long-
Term Future Fund increasingly shifts focus to donating to
individuals.
I previously shared timelines for MIRI and FHI here on LessWrong.
Any thoughts on the timeline (such as events to add, events to remove, corrections,
etc.) would be greatly appreciated! I'm also curious to hear thoughts about how useful
a timeline like this is (or how useful it could become after more work is put into it).

Forecasting Prize Results
The "Forecasting Innovations Prize" was announced on the 15th of November of 2020
on the Eﬀective Altruism Forum and on LessWrong, with the goal of incentivizing
valuable research around forecasting. We received 10 submissions.
Judges—AlexRJL, Eric Neyman, Tamay Besiroglu, Linch Zhang, Ozzie Gooen and myself
— recommended a quantity of money to be awarded to each submission. The next
section is a short summary of each entry, the prize they were assigned, and the
reasons the judges gave. This is followed by a brief discussion of the judging process
and takeaways.
We will be contacting authors soon.
Crowd-forecasting COVID-19
The post describes the results of a COVID-19 crowd-forecasting project created during
the author's PhD. The judges didn't know of any other app in which human forecasters
could conveniently forecast diﬀerent points in a time series, with conﬁdence intervals.
The project's forecasts were submitted to the German and Polish Forecast Hub, and
they did surprisingly well in comparison with other groups. 
Judges brought up the issue that R/shiny is probably the suboptimal technology for a
web-app. Further, as of the time the post was published neither the post under
consideration nor other submissions to the German and Polish Forecast Hub were able
to outperform a model that simply predicts constant cases on a four-week horizon. 
This post receives a prize of $250.
Incentivizing forecasting via social media
The post explores the implications of integrating forecasting functionality with social
media platforms. They consider several important potential issues in some length, and
possible solutions to these, as well as indications for next steps. The scenario they
consider— if it were to occur—could possibly have a large impact on the 'information
economy'. 
However, as the author's note, the feasibility of the proposal is very unclear (<1%,
though note that Twitch recently added some prediction functionality). Further, the
authors were not aware of Facebook's Forecast at the time they wrote the post.
This post receives a prize of $250.
Central Limit Theorem investigation
The post visualizes how quickly the central limit theorem works in practice, i.e., how
many distributions of diﬀerent types one has to sum (or convolve) to approximate a
Gaussian distribution in practice. The visualizations are excellent, and give the readers
intuitions about how long the central limit theorem takes to apply. Judges thought that

explanations of important ideas to a speciﬁc community are valuable even if they are
only new to that community. 
As a caveat, the post requires understanding that the density of the sum of two
independent variables is the convolution of their densities. That is, that when the post
mentions "the number of convolutions you need to look Gaussian", this is equivalent
to "the number of times you need to sum independent instances of a distribution in
order for the result to look Gaussian". This point is mentioned in an earlier post of the
overall sequence. Judges also weren't sure to what extent this post was "forecasting-
related." Future competitions, if they happen, will have a clearer cut-oﬀ. 
This post receives a prize of $120.
Forecasting of Priorities (Czech Priorities)
This post explains a set of ideas by Czech Priorities to use forecasting as a method of
public deliberation, in particular to identify "priorities'' or "mega-trends". Judges
thought that, with a less messy design, this post could have won the ﬁrst prize. In
particular, it seems that this group has managed to convince the Czech government
to give it two large grants and to pay attention to the result.
However, the suggested implementation really was quite messy. On the one hand,
they suggest predicting the result of expert deliberation on the importance of
"priorities", but the selection of those experts could be politicized. On the other hand,
one of the proposed mechanisms incorporates both forecasting and preference
elicitation, and might not end up producing either good elicitation or good forecasting.
This post receives a prize of $90
One's Future Behavior as a Domain of
Calibration
This post advocates for forecasting one's future actions, and presents the author's
method to do so. Some judges liked that it is pretty easy for this post to have an
actual impact, as long as at least one person acts on it. One small detail the judges
disagreed with was the post's assertion that calibration doesn't transfer between
domains (this somewhat conﬂicts with some of the judges' own experiences)
This post receives a prize of $80
What to do about short AI timelines?
This short sequence gathers three posts on short timelines, and asks two questions:
How to bet on short AI timelines, and how one's inﬂuence depends on the length of AI
timelines. This posts part of a longer running investigation by Daniel Kokotajlo into
short timelines.
The posts used the EA forum's question functionality, and the author didn't seem very
satisﬁed with the responses, though the least forecasting-related post in the series did
see more discussion on LessWrong. Judges found that other posts by the author on the

topic of timelines (e.g., this one) were much stronger, whereas the particular research
questions in the prize submission didn't really pan out. Some judges thought that
question creation might be underrated. 
This post receives a prize of $70
How might better collective decision-making
backﬁre?
The post is faithful to the title, and comes up with or elicits several pathways through
which collective decision-making might backﬁre.
Judges found the question asked to be important, but found it hard to evaluate the
answers, because there was no overall framework to do so. In particular, there was no
discussion about which concerns were or would have been historically important. It is
also unclear whether any practical actions will be taken as a result of the post, or
whether it will be built upon.
This post receives a prize of $60
The Fermi Paradox has not been dissolved
The post points out some ﬂaws in Dissolving the Fermi Paradox, a paper by Sandberg
et al. Among other reasons, having good probabilities around the Fermi paradox is
valuable because it provides (indirect) evidence about the existence of a "Great Filter"
and thus for our likelihood of extinction.
Judges disagreed substantially about to what extent the points raised in the post were
substantive, and to what extent the author was too overconﬁdent or forceful. There
was also some disagreement about whether the post was very related to "human
judgmental forecasting."
This post receives a prize of $50
The First Sample Gives the Most Information
The post concisely introduces a powerful and simple concept. Judges agreed that the
post wasn't hugely impactful, but that it probably did have a pretty great ratio of
value to time spent on it. 
This post receives a prize of $50
A tenth post was also submitted, but some ﬂaws were identiﬁed, and the author asked
us not to mention it until it is ﬁxed.
Judging process
Judges read each submission and produced:

An assessment of the quality of the project (execution)
An estimate of how valuable the project was
A funding recommendation
Comments as to their reasoning
The reasons why the funding recommendations were not directly proportional to
impact and quality were:
Adjusting for closeness to forecasting: more impactful projects which weren't
that related to forecasting received smaller prices.
Some (but not all) judges tried to think about what signals giving higher or lower
prizes sends. For example, some judges gave higher prizes to projects which had
higher expected values even if they didn't pan out in the end. Similarly, some
judges penalized a post which sounded very overconﬁdent even if it was
otherwise impactful or valuable.
A high quality project can have low value if it belongs to a less impactful domain.
Some judges felt higher eﬀort posts were worth more money per unit of impact,
perhaps because lower eﬀort posts could have been written by someone else if
the original author hadn't done it.
After giving their initial estimates, judges met in a Zoom call to discuss their
estimates. This was done by going project by project and bringing up disagreements.
Afterwards, judges updated their estimates and recommendations. The ﬁnal prize is
simply the mean of all judges' recommendations. 
Comments and Reﬂections
The counterfactual impact of this prize seems uncertain. Of the 10 submissions, only
three were counterfactually caused by the prize, with the other seven being submitted
because I (Nuño) asked the authors to do so after ﬁnding them by browsing
forecasting related content in the EA forum and LessWrong. 
Overall, it is possible that there were too many judges which spent too much time
cumulatively judging, and that the marginal value of a judge wasn't too high.
However, when hashing out disagreements, each judge did bring unique points.
If there is a second round for this prize before 2022, entries published after the end of
the ﬁrst round will be accepted so as not to generate an incentive to not post
forecasting-related content until there is a prize.
Appendix: Quality Adjusted Research Papers.
Judged also estimated the impact of these projects in terms of Quality Adjusted
Research Papers (Qs). QARPs are intended to both have relative value (a 20 QARPs
project should be estimated to be twice as valuable as a project which has 10 QARPs),
and absolute meaning (0.1 QARPS, or 100mQARPs should correspond to "A fairly
valuable paper", such as this one)
The value judges assigned to each submission was:
Crowd-forecasting Covid-19: 32 mQARPs
Central Limit Theorem investigation : 17 mQARPs

The Fermi Paradox has not been dissolved: 16 mQARPs
Incentivizing forecasting via social media: 12 mQARPs
Forecasting of Priorities (Czech Priorities): 8 mQARPs
What to do about short timelines?: 8 mQARPs
One's Future Behavior as a Domain of Calibration: 7 mQARPs
How might better collective decision-making backﬁre?: 5 mQARPs
The First Sample Gives the Most Information: 3 mQARPs
Note that this method of rating is highly speculative, and having judges using it was in
part intended as a test. Judges brought up that they weren't sure that the scale was
well deﬁned, and that they were much more sure about their own relative values than
about the absolute magnitude. Also, note that this didn't consider the relevance of
forecasting, which is the main reason why these values don't perfectly correlate with
the prizes.

Support vs Advice & Holding Oﬀ
Solutions
What I'm calling support vs advice is a fairly standard division. Both kinds of
discussion start with one person talking about something that bothers them. In a
support conversation, they're looking for empathy, and the other person shows that
they care by listening, showing that they understand, and emotionally comforting. In a
problem-solving conversation, they're looking for solutions, and the other person
engages by making suggestions. This distinction is important to recognize mainly
because it's easy for the second person to get confused about which type of
conversation they're in, and engage in the wrong way; in particular, oﬀering solutions
when the other person wants support can be pretty bad, because a person who wants
support can perceive advice as criticism. Here's the standard amusing youtube link.
I'm not sure what to call it; I think it's been discussed on LessWrong before, but I'm
not ﬁnding it by searching. Other possible terms for it:
care vs help;
emotional support vs problem-solving;
feeling-oriented conversation vs solution-oriented conversation.
LMK what the more standard terms for this are, if indeed there are any.
Anyway, I'm not writing this post to communicate the support-vs-advice model;
rather, to name a third conversational mode which has some advantages of the other
two.
I'll tentatively call this a problem-oriented conversation.
First, note that one of the main ways to show empathy is to show that you care about
what's going on with the other person, and to demonstrate that you understand. To
listen well, get curious.
Second, note that it's not advisable to propose solutions right oﬀ the bat. People come
up with better solutions if they ﬁrst discuss the problem in more detail. Hold oﬀ on
proposing solutions. 
You can probably see where I'm going: in a "problem-oriented conversation", the
second person responds with curiosity to the problem, asking questions instead of
proposing solutions. They hold oﬀ proposing solutions, instead just trying to
understand what's going on for the other person.
Consider:
The initial framing of a problem is rarely the right one. Often the problem turns
out to be totally diﬀerent if you talk about it a little while.
Your "obvious solutions" are probably just as obvious to the other person, if
they're thinking about the problem the same way you are. Once both of you see
the problem in the same frame, it's probably not necessary to propose actual
solutions.
(Though, sometimes, proposing "obvious" solutions can be incredibly
helpful; I'm not saying you should never do that! Just that you should

consider holding oﬀ.)
Even when I want solutions, it's often unhelpful for the other person to get too
far into "debugging mode" before they understand the problem in as much
detail as I do. Their suggestions won't deal with my real problem.
The problem-oriented mode is not without its own problems, however.
I've recently found myself in a few conversations where I try to take a problem-
oriented stance (sometimes as 'transmitter' and sometimes as 'receiver'). Some
issues:
When the other person really wants advice, the problem-oriented stance can be
baﬄing. I found myself in a position where my questions were being
misinterpreted as advice. "I just don't see what you're proposing that I do."
Sometimes people take it as an axiom that a line of questioning isn't helpful if
it's not connected with a proposed solution. A problem-oriented conversation is
then axiomatically 'unhelpful'.
Similar, as a 'transmitter' seeking a problem-oriented discussion of some issue, I
might get frustration from others because I'm not pursuing solution-oriented
lines of thought. The conversation might get shut down as unfruitful before I've
gotten the understanding I was looking for.
Another problem is that problem-oriented conversations can get too meta and
make a bigger problem out of things. For example, lots of speciﬁc household
issues turn into "communication problems" if you keep looking for the larger root
of the problem. You can end up in a conversational frame where it sounds like
you need to have a big intervention. 
More generally, things will go poorly if there's an implicit assumption that any
aspect of the problem you talk about, you're saying needs to be changed. There
needs to be room to explore the problem without necessarily suggesting action.
Otherwise it isn't possible to explore things from all angles.
Still, this strikes me as an important mode of conversation.

Killing the ants
(Cross-posted from Hands and Cities)
I. The ants
Recently, my housemates and I started seeing a lot of ants in the house. They
marched in long lines along the edges of the basement and the bathrooms. A few
showed up in the drawers. My girlfriend put out some red pepper, which was
supposed to deter them from one of their routes, but they cut a line straight through.
We thought maybe they were sheltering from the rain, which had become more
frequent. We had had ants before; we'd talked, then, about whether to do something
about it; but we hadn't, and eventually they disappeared. We thought maybe this
would happen again.
It didn't. Over weeks, the problem got worse. There were hundreds of ants in the
upstairs bathroom. They started to show up much more in the kitchen. We threw out
various things, sealed various things. They showed up in beds. Kitchen drawers were
now ant territory.
We talked about what to do. We were reluctant to kill them, which was part of why we
had waited. But a number of people in the house felt that the situation was getting out
of hand, and that we were on track for something much harder to control. I thought of
a house I had stayed at, where the ants swarmed over the coﬀee maker every
morning, and eﬀorts (I'm not sure how extreme) to get rid of them had failed.
The most eﬀective killing method is to poison the colony as a whole. The ants are
lured into a sugary liquid that also contains borax, which is poisonous for ants, but
relatively safe for humans. They then track the poison back to the colony. We talked
about how bad this would be for the ants — and in particular, the fact that the poison
is slow-acting. Crushing them directly, we thought, might be more humane; though it
would also be more time-consuming, and less likely to solve the problem.
Eventually, though without resolving all disagreements amongst housemates, we put
out the poison baits (my girlfriend also tried cloves, coﬀee grounds, and lemon juice
around that time, as well as luring the ants to some peanut butter and honey outside,
away from the house). The ants in the kitchen disappeared. There are still a few in the
upstairs bathroom; and inside the clear plastic baits, you can see ant bodies, in the
syrup.
II. Owning it
At one point, on the topic of the ants, I said, in passing, something like: "may we be
forgiven." My girlfriend responded seriously, saying something like: "We won't be.
There's no forgiveness."
Something about her response made me realize that the choice to kill the ants had
had, for me, a quality of unreality. I had exerted some limited advocacy, in the
direction of some hazy set of norms, but with no real sense of responsibility for what I
was doing. There was something performative and disengaged about it — a type of

disengagement in which one, for example, "feels bad" about killing the ants — and
the question of whether we were doing the "right thing" was part of that. I was looking
at the concepts. I was hoping for some kind of conformity, some kind of "pass" from
the moral "authorities." But I wasn't looking down my arm, at the world I was creating,
and the ants that were dying as a result. I wasn't owning it.
Regardless of whether our choice was right or wrong (I'm still not sure), we chose for
these ants to die. We killed them. What we got, when we chose, was not a "good job"
or "bad job" from the universe: what we got was this world, and not another. And this
world was right there, in front of me, whether we should be "forgiven" or no.
Not owning the choice was made easier, I think, by the fact that the death of the ants
would mostly occur oﬀscreen; outside of my "zone", and not, directly, by my own
hand. Indeed, I had declined to crush the ants myself, and I hadn't been the one to
put out the baits, or to push for getting them. I'd said OK to a plan; the baits went out;
the problem disappeared. It would have been very possible to let the incident leave
barely a trace on my mind. It happened at the edges of my awareness. In a sense, I
barely noticed.
There is some sort of virtue in the vein of: "if you kill something, look it in the eyes as
you do." (This is related to a virtue prized by someone I know, but which he
characterizes as "looking your enemies in the eyes as you kill them." I much prefer
my version, though, which doesn't assume that you're killing things, or that they're
understood as "enemies.") If we harm some creature for the sake of something else
we value, or if we risk doing such harm (and we are basically always risking harm —
see MacAskill and Mogensen (unpublished) for some discussion), or if we choose our
own goals and values and beliefs over those of another, we should own that we are
doing it.
It's easy to push the harm we do, or that we risk, outside of our zone of awareness; to
live with, or to strive for, a false sense of purity, propped up by attention only to what
can be readily seen, or to what registers, by the standards of everyday
conscientiousness and social reproach, as "intentional." On killing insects in particular:
when you wash your sheets, you kill large numbers (thousands?) of dust-mites; when
you walk on the grass, you crush insects under your feet; when you drive, bugs
splatter against your windshield. But more broadly: the things we use and consume,
the institutions and systems that structure our lives, the resources we trade and
inherit, the causal sequences we casually initiate — all are tangled in intricate webs of
harm; and everyday, always, there are things we leave undone; things that we let die,
or let suﬀer, because we are prioritizing something else.
I'm not saying we need to dwell on these things all the time; or that emotions that are
in some sense "ﬁtting" should always be felt. But we should live in the actual world,
that includes the full consequences of our actions. We should look ourselves in the
eye, too. We should know who we are.
III. Paying attention
Later, thinking about the ants, I thought of some videos in which Brian Tomasik ﬁlms
the insects he ﬁnds in his house, to document and understand the harms they
undergo. In one, he examines, using a microscope camera, the bugs that are crushed
when he scoops compost with his hands; in another, he ﬁlms the ﬂies that buzz
against a window in his attic; in another, the bugs he ﬁnds in the dirt of a potted plant.
The videos I've seen (I've watched maybe four or ﬁve) have a tone of matter of fact-

ness and muted sadness. They end, often, with extended footage of the insects in
question, without narrative.
I was ﬁrst introduced to these videos — in particular, the compost one — by someone
who was suggesting that I laugh at them. "Isn't this ridiculous?", he was saying. It
didn't seem that way at all to me. Rather, it seemed like an example of someone who
was really paying attention. Tomasik was looking, directly, at something we normally
leave outside our zones; something we barely notice, and that our minds bounce oﬀ of
when we do.
Many of Tomasik's views and practices — including the policy responses he endorses
in those videos — are extreme and unusual. I disagree with him on a lot of important
things, and I'm not trying to debate them here. Nor am I assuming answers to the
question of whether insects of various types really have any moral weight (see
Muelhauser here, and here); if so, how much; or what, if anything, it makes sense to
do in response. Indeed, answering such questions with any conﬁdence seems a
daunting challenge.
What I want to point at is the type of attention that it seems to me like Tomasik is
paying to the world, in those videos. It seems related to the type that I wasn't paying
to the ants in my house.
IV. "What one does"
Bugs generally lack the charisma that beneﬁts other animals in human moral
discourse. They're gross, small, slimy, invasive, disease-y. Indeed, I expect that part of
the unreality of the decision about killing the ants, for me, stemmed from the fact that
our social world doesn't treat such decisions as morally stakes-y. We disapprove of
people frying insects with magnifying glasses just for fun; but in other contexts, and
especially in the course of doing other things, we kill insects with little thought; and
sometimes, with zeal.
Indeed, it seems easier to see an ant as an intricate biological machine, devoid of
consciousness and moral value, than to see a pig that way, or a cow — despite the
fact that pigs, cows, and, indeed, humans are all, equally, biological machines, albeit
of diﬀering size and complexity. And perhaps there really are qualitative diﬀerences —
or suﬃciently large quantitative ones — in how much what we would care about on
reﬂection is at stake in the lives of insects vs. other animals (though here our
uncertainty about consciousness and its relation to value looms large). At the least,
we tend to act that way.
But would we act diﬀerently, if the truth about the moral status of insects were
otherwise? Consider the dust-mites we kill when we wash our sheets. If you're like me,
you were choosing to wash your sheets long before you knew that dust-mites existed.
Indeed, perhaps you're only learning about it now (I think I only really learned about
dust-mites a few years ago).
It's easy, upon learning about dust-mites, for the question of whether to adjust one's
sheet related practices, in view of these mites, to never get genuinely asked. Washing
one's sheets is "what one does." If we learn that it kills thousands of tiny creatures we
didn't know existed, it's easy to conclude that apparently, killing these creatures is
OK; it's also, apparently, "what one does." The idea that we might better protect and
promote what we care about by changing our sheet related practices (Tomasik
reports: "To be safe, I daily ﬂap out my bed sheet into an unused area of my house in

an eﬀort to remove some of the dead skin on it") is treated as a reductio ad absurdum
of the idea that the welfare of the mites justiﬁes such a change. We are traditionalist
sheet-users ﬁrst; philosophers, second — or not at all.
Indeed, threatened by the burdens of new obligations, it's possible greet reductios of
this kind with a type of relief. On the topic of the ants, for example, I noticed some
sort of relief in relation to the idea that I was already killing bugs when I drove or
walked on grass: "No one's going to say we should stop driving or walking on grass,
right? So killing these ants must be OK, too." If a candidate norm is seen as externally
imposed, rather than grounded in something one cares about wholeheartedly, one
greets evidence that abiding by the norm is impossible or extremely burdensome with
enthusiasm, rather than sadness. 
V. If dust-mites were diﬀerent
Imagine a world in which humans were the only macroscopically visible species. For
centuries, these humans lived wonderful lives; dancing in the grass, cooking delicious
meals over open ﬁres, playing music together — all under the assumption that they
were the only sentient creatures in existence.
Then one day, a scientist invents a microscope, and begins examining the world with
it. She ﬁnds, to her surprise, that the surface of everything is covered with a thin ﬁlm
— invisible to the naked eye — of something that looks like a civilization all unto itself.
The creatures in this civilization are made of a type of intricate slime, but their
nervous systems are incredibly complex — much more complex, indeed, than human
nervous systems, and made of superior materials. These slime, it seems, have a kind
of art, language, and religion; they, too, engage in a type of dancing. And they do
much else besides, which human scientists cannot, at present, understand (let's
imagine that communication remains, for now, impossible).
What's more, the humans realize, whenever humans walk or dance on the grass, they
crush this slime civilization under their feet; whenever they make an open ﬁre, the
slime civilization burns; whenever they pluck the strings of a guitar, slime creatures
are thrown into the air and killed. For centuries, they realize, they have been
devastating a sophisticated and invisible civilization; with no knowledge that they
were doing so.
What, then, do they do? Do they argue that the slime civilization can't be worthy of
care, because changing practices of dancing, cooking, music-making, etc would be too
demanding? Do they start looking for ways to protect and understand the slime? Do
they start wondering about future conﬂicts with the slime? If there was a pill they
could take, that would allow them to forget about the slime, and go back to how
things were before they had microscopes, would they take it?
The point of the set-up here is not to force or pressure the humans to give up their
beautiful lives, on pain of being bad. They've learned something new about the world
they're living in, and the consequences of their actions, but it's up to them how to
respond. The point is that the real world — the world they've always been living in —
stays real regardless. Whatever the truth was about slime art, and religion, and music
— and about the damage that dancing and ﬁres and guitars do — that truth stays
true.

Science Fiction
This morning (Amman time) I taught a class to a middle school in Jordan. It was the
opening to a big daylong event where the parents were invited and the
superintendant said some formal words.
Ostensibly, my lecture was about design in the COVID-19 world. That was the pretext
from which I obtained the opportunity. Actually, I turned it into a Q&A where I
answered questions about what it's like to invent things.
Some of the questions were technical like "How do you advertise your products?" and
"What programming language(s) do you use?" When a nerd asked about Arduinos I
was happy to answer that we used a few in the prototyping stage.
Technical stuﬀ consists of things you can learn in school...eventually...in theory. The
more interesting questions (from my perspective) concerned open-ended topics like
"What did you learn?" How am I supposed to explain to middle schoolers what it's like
to carry on when all hope seems lost?
Another interesting question was "Where do you get inspiration?" It was asked more
than once. I was surprised by how quickly, precisely and consistently I answered the
same three words each time. "Read science ﬁction." These are middle schoolers and
they're living in science ﬁction's golden age.
I am getting better at interfacing with schools. The ﬁrst time I guest lectured to middle
schoolers I gave the teacher nightmares. The students loved my blunt honesty. The
teacher did too; he was worried the parents would complain. None did, but I learned
my lesson. It is more eﬃcient—and produces less collateral damage—if I can point
children to George Orwell and Paul Graham rather than attempting to foment mischief
directly.
For me, the golden age of science ﬁction was 9 to 17, with a peak from 12 to 14.
Following that, I have studied science and faced the real world instead. When I
returned to science ﬁction the magic was gone. I would read a story and think to
myself "I know, from personal experience, that's not how things work."
I am a technical entrepreneur. My job is to build the future. To build the future you
must balance conviction against skepticism. Rationalism is full of advice on cultivating
skepticism. Science is an unrivaled tool for cultivating conviction within its domain.
However, the vanguard of progress is beyond the reach of science. Peer review is not
a fountain of inspiration. I cannot aﬀord to lack imagination.
If you want, as an adult, to maintain the imagination you had as a kid then you have
to do for real the things you merely imagined doing as a kid. Turn science ﬁction into
science fact.

Suggestions of posts on the AF to
review
Crossposted from the AI Alignment Forum. May contain more technical jargon than
usual.
How does one write a good and useful review of a technical post on the Alignment
Forum?
I don't know. Like many people, I tend to comment and give feedback on posts closely
related to my own research, or to write down my own ideas when reading the paper.
Yet this is quite diﬀerent from the quality peer-review that you can get (if you're lucky)
in more established ﬁelds. And from experience, such quality reviews can improve the
research dramatically, give some prestige to it, and help people navigate the ﬁeld.
In an attempt to understand what makes a good review for the Alignment Forum, Joe
Collman, Jérémy Perret (Gyrodiot on LW) and me are launching a project to review
many posts in depth. The goal is to actually write reviews of various posts, get
feedback on their usefulness from authors and readers alike, and try to extract from
them some knowledge about how to go about doing such reviews for the ﬁeld. We
hope to have enough insights to eventually write some guidelines that could be used
in an oﬃcial AF review process.
On that note, despite the support of members of the LW team, this project isn't
oﬃcial. It's just the three of us trying out something.
Now, the reason for the existence of this post (and why it is a question) is that we're
looking for posts to review. We already have some in mind, but they are necessarily
biased towards what we're more comfortable about. This is where you come in, to
suggest a more varied range of posts.
Anything posted on the AF goes, although we will not take into account things that are
clearly not "research outputs" (like transcripts of podcasts or pointers to surveys). This
means that posts about speciﬁc risks, about timelines, about deconfusion, about
alignment schemes, and more, are all welcome.
We would deﬁnitely appreciate it if you add a reason to your suggestion, to help us
decide whether to include the post on our selection. Here is a (non-exhaustive) list of
possible reasons:
This post is one of the few studying this very important question
This is my post and I want some feedback
This post was interesting but I cannot decide what to make of it
This post is very representative of a way to do AI Alignment research
This post is very diﬀerent from most of AI Alignment research
...
Thanks in advance, and we're excited about reading your suggestions!

Networking and Expert Consulting As
Rationality Bottlenecks
Introduction
John Wentworth is on ﬁre writing about the importance of gears-level models and the
challenge that novices face in evaluating the claims of experts. Let's call the latter
"consulting."
It's an absolutely basic problem of everyday life. How do I know the salesman, or the
plumber, or the mechanic, is giving me a fair deal? When a friend invites you on a
technical climbing trip, and tells you not to worry and that they'll plan everything out
safely, how do you know whether to trust them or decline? Should you get a second
opinion from another doctor, and if so, why not get a third, and even a fourth?
It's also an issue in politics. Julia Galef and Matthew Yglesias just put out a scintillating
Rationally Speaking episode about their mutual mistake in initially supporting the Iraq
War. Matt thought at the time that he should trust the experts in Washington, who had
access to classiﬁed information and top experts in the ﬁeld, over the opinions of the
anti-war pundits.
This issue feeds back into itself in the form of credentialism. After all, there's little to
stop people from speaking beyond their speciﬁc domain of expertise. As Julia and Matt
discuss in this same episode, a textile manufacturer probably knew more about
whether or not we could rapidly get cloth masks out to the population than Dr. Fauci. If
the initial decision to tell people that masks were ineﬀective was motivated by a
desire to preserve PPE for healthcare providers, did they think to ask textile
manufacturers whether this was a serious concern? If not, why not?
In general, how do issues come to be "owned" by a certain profession or specialty?
How did "bioethicist" become something you could be an "expert" in? Do I have to
defer to Peter Singer on moral issues, or can I think for myself?
And this is a meta-issue as well. After all, who's qualiﬁed to have opinions on how
specialty topics should be divided up? Who can claim to be an expert in distinguishing
issues where we should defer to experts, and where we can trust our own judgment?
On what basis do they claim that expertise?
Now, it might be true that most or all of these questions can be answered by learning
how to think for ourselves on every issue. Building our own complete set of gears level
models.
But let's assume for a moment that there's a reason we've had roles and hierarchies
of experts all around the world, since time immemorial. If we need to consult with
experts, can we create gears-level models of when to do it, who to consult with, how
to have a useful interaction with a consultant, how to verify their advice, and how to
implement or broadcast it when it seems widely useful?
Why Expert Consultation Is Necessary
Rationality often revolves around how to learn from and evaluate public information or
the claims of the people in our personal lives. We talk a lot about scientiﬁc papers,

news articles, claims on social media, personal debates, and our own thoughts and
feelings.
However, we know that a lot of the most important information in the world is
inaccessible, to the public or just to us. It might be classiﬁed, a carefully kept secret,
somebody else's private thoughts, or written in a language we don't speak. They
might be meaningful only in the context of a particular person's skillset. It might be
point of pride to keep it hidden, like the fact that one woman in my choir wears a wig.
Once, I hiked all the way through Zion National Park and kept it a secret the whole
way through that I'd forgotten my sleeping bag and was freezing cold at night,
because I didn't want other people to worry about me.
The people who possess that knowledge might have so much demand for their
attention that they won't freely disseminate it, or won't take the time to ensure that
others adequately understand it. Transmitting and triangulating information - making
sure the right information gets to the right person, and that they absorb the right
message - can be a very expensive and sometimes controversial task. When done
badly, it can reﬂect negatively not only on the people directly involved, but their
associated communities as well.
Knowledge can be a bargaining chip in a negotiation. And of course, many sectors,
including science, business, and even philosophy, are focused on trying either to
produce new information, or to discover information that at present is unobserved
physical phenomena.
Hiding information can also be a way to improve signaling. If you have a job you'd like
my help on, but are worried I'll feel pressured if you ask, you might not tell me about it
unless I independently realize it and oﬀer to help you out. If Alice is romantically
interested in Ryan, she might keep that hidden until she's had a chance to observe
him for a while so that he won't modify his behavior to impress her or push her away.
Some topics are so complex or ﬂuid that we're almost certain to go astray working on
our own. The relevant information might be constantly shifting, and to build a gears-
level model of it is like trying to map the ocean waves. Other topics actively resist our
attempts at inquiry, and naïve attempts to measure them will only generate illusions.
In these areas, it may be possible to pursue the truth, but only by relying on others to
help us get our footing and learn how to deal with it productively. Their ability to do so
might be based on rare insights and strokes of genius that have been carefully
preserved and transmitted for generations, and provide the ground for further
productive work.
Expert Consultation As A Rationality Bottleneck
John Wentworth writes about how above a certain income, knowledge, not wealth,
tends to become the bottleneck. You can't purchase the expertise you need, so you
have to acquire it yourself.
It may also be that above a certain level of rationality, a social network, not one's own
skills and knowledge, become the bottleneck. I'm in the preliminary stages of building
a career in tissue engineering research, and I fully expect that I won't be able to focus
my scholarship or research very well without mentors and colleagues, technicians,
advisors, and contacts. 
Indeed, the most high-yield activities of the last two years have almost all been about
social networking. By contacting PIs at grad schools I was considering, I was able to

ﬁnd speciﬁc labs I wanted to work in, and narrow down the types of papers and
technical knowledge I need to acquire. I changed my intended MS degree from
bioinformatics to bioengineering based on their advice, and was oﬀered a job and
funding should I be accepted.
Prior to that, social networking events hosted for post-bacc career changing
biomedical students (most of whom were pre-med) was a source of long-term
friendships who've provided me with smart, scientiﬁcally literate, trustworthy friends.
A huge asset to my life. I also have made friends by posting about myself online,
which resulted in fruitful research collaboration and friendship.
When I read forums on the academic life on Reddit, the posts are never about how
hard it is to understand the intellectual material. It's virtually always about
relationships with labmates or their PI, how to navigate bureaucracies, and similar
people issues.
It seems possible and potentially high-value to build gears-level models for how to
consult eﬀectively. There are a range of speciﬁc problems, tradeoﬀs, structural issues,
and domains to consider. I expect that evaluating a colleague's advice on where to
work entails a very diﬀerent set of considerations from choosing a textbook.
The challenge is that, while a written document gives everybody the ability to look at
and evaluate the same thing, we have to describe our problems with evaluating
expertise anecdotally. It's very black-box. The speciﬁc details may be more important
than the general principles.
I imagine that a rationalist who'd devoted themselves more to the study of networking
and consultation than to the study of Bayesian statistics would be having a lot of
zoom calls and email exchanges with strangers. They'd be going to a lot of social
events (post-COVID). They'd approach novel problems not by reading books and
articles, but by ﬁguring out who'd be the best people to talk about to ﬁnd out more.
They'd assume that even the most technical issues have a huge human factor in their
execution, and would be at least as interested in ﬁnding out those details as in
learning about the engineering problem.
Discussion
My guess is that you can and should (and already do, to some extent) build gears-
level models about how to consult on a variety of topics. Learning how to do this
eﬀectively might also improve your ability to form gears-level models in a virtuous
cycle. The ﬂuid, unwritten nature of consultation means that it might get somewhat
neglected by rationalists due to the streetlight eﬀect. Its superﬁcial diﬀerence from
gears-level modeling might also set us up to see it standing in opposition to modeling,
rather than as a necessary complement to it.
Our culture is full of common-sense knowledge about expert consultation, and
evaluating expertise or ability. Get three bids. Ask for a second opinion. It's also known
to be a particularly challenging and high-stakes problem, a key issue in how we
structure our society. It's one of the drivers of credentialism, the other being rent-
seeking behavior.
It's also one of the areas where people seem to systematically neglect it, for weird
psychological/social/cultural reasons. It seems intimidating, like a violation of a
hierarchy or status code. People are afraid they'll embarrass themselves, or that the
person they're asking will somehow be able to exploit them. They get socially anxious.

Yet isn't this an obvious form of low-hanging fruit? If you can't get the ear of the
President, can you get the ear of their staﬀers? If not, of the friend of a staﬀer? Do you
at least know a guy who knows people in Washington, D.C.?
People sometimes play a game on Wikipedia where they choose two random pages,
and see if they can ﬁgure out how to navigate from one page to the other through the
in-page links. Why not play an analogous game with people? Set your sights on an
inaccessible person who you'd like to talk to, and see if you can ﬁgure out a strategy
to network your way to a conversation with them.
Where to start
It seems likely that when you're consulting, it's good to have clear objectives, and
some relevant questions in mind. You wouldn't consult with a plumber "just to hear
what he had to say." You have a speciﬁc plumbing problem in mind, and then you call
the guy. Likewise, don't email an infectious disease expert just because you're
"interested in COVID-19." Have an objective in mind, and some questions to ask.
The most valuable and logical use of expert consulting is to ﬁnd out things you can't
get from a written source. It doesn't make sense to email a professor to ask them for
data that's publicly available in their latest publication (though you could request the
paper if it's not open access). Instead, the expert can be a source for hidden
information.
So gaining a sense of what sort of hidden information might be interesting to ﬁnd out
about would be a great investment. "Is there a less expensive alternative?" "There are
lots of accounts of the fall of Rome, so why don't historians seem to attempt to falsify
each others' hypotheses on this subject all that often?" "Did infectious disease experts
consult with psychologists when they were trying to set policy in a way that inﬂuenced
public response, and who exactly would be the relevant domain expert for doing that,
anyway?" "What sort of books does your book club read, and how in-depth is the
discussion?"
I imagine that people might have all kinds of deﬁciencies in this skill set. Areas to
grow might include:
Articulating their own goals, skills, and background
Knowing what questions to ask, what information to seek
Understanding the risks and rewards involved
Thinking through who to contact, and how
Holding a good one-oﬀ conversation with a stranger
Converting relationships with strangers into repeated contacts
Figuring out how to provide value to the other person
Updating strategies for who to talk to next based on the previous conversation

Potential factors in Bell Labs'
intellectual progress, Pt. 1
Epistemic status: these are notes from a popular account ﬁltered through my own
existing beliefs. Here, I am largely trusting the book to report true things and not
misrepresent them, though, in fact, I suspect the book is trying to create a certain
narrative that might be misleading. If I were to get very serious about Bell Labs, I'd
have to look at more source material.
Over the years, I've heard various people reference Bell Labs as a place where a
uniquely large amount of intellectual progress was made, making it a worthy target of
investigation if you're interested in intellectual progress.
A few days ago, I started reading The Idea Factory: Bell Labs and the Great Age of
American Innovation. I'm only 20% of the way through, but I've started to note various
factors that might explain their output.
Many of the factors that are salient to me were already in my bag of hypotheses and
could just represent conﬁrmation bias on my part. A few were surprising. I suppose I
should also look for factors I expected to see but haven't yet (look into the dark).
Note: the most signiﬁcant invention to come out of Bell Labs was the transistor and a
lot of the book has focused on that, but they did other notable things too.
Factors Salient to Me
While the work often tended in the direction of basic science that was distant
from practical application, by dint of it occurring within AT&T, it was expected
that all the research done might somehow beneﬁt AT&T and I sense a degree of
backchaining from that in all they did.
Ten years before the achievement of the transistor, Mervin Kelly said to William
Shockley that they really needed something solid state that could amplify and
switch to replace fragile and undurable vacuum tubes and relays. It took a tonne
of basic research in solid state physics to get there, but ultimately that was the
driving motivation. (Only after its announcement did some folks from MIT write
to say it might be applicable to electronic computer circuits.)
A lot of the innovation was motivated by concrete problem solving, e.g., needing
to ﬁgure out better cable insulation and sheathing so they could run underwater
cables - that and related projects required a lot of materials innovation.
Their work was highly empirical, highly directed, and highly applied. There was a
lot of feedback. Often they were trying to build devices that did certain things
and I expect it was clear when they were succeeding or not. Often they were just
trying to ﬁgure how the physical world worked (conductors, insulations,
whatever) but this was grounded in the hope the expectation that this
understanding would help their engineer more stuﬀ.
There was an overarching grand lofty mission: "Our job, essentially, is to devise
and develop facilities which will enable two human beings anywhere in the world
to talk to each other as clearly as if they were face to face and to do this
economically as well as eﬃciently." It was reminiscent of Theodore Vail's dictum

of "one policy, one system, universal service." But it likewise suggested that the
task at hand was immense.
Although they had to ﬁgure out many pieces of their more speciﬁc paradigms
(tools, methods, principles), their overall work was embedded with an
established broader paradigm of physics.
The researchers noted in the book were typically physics PhDs from top
universities who'd been working on related problems in their academic (and
were oﬀering recruiting each other because of it). To me, this implies that a)
they shared a common paradigm, meaning methods, background assumptions,
etc., and b) they entered Bell Labs with a lot of relevant knowledge and
experience.
At the same time as their academic education, the book paints the researchers
as having grounded backgrounds: working on farms and mills. Though I suspect
this easily could be spun for a narrative.
If the book can be trusted, they had a lot of top talent. Bell Labs was prestigious,
it had many people who were known to be good, and it paid well (better than
universities).
Many, many people's work fed into the invention of the transistor. Shockley,
Bardeen, and Brittain might be the names attached to it, but in fact they built
upon the work of many others at Bell Labs and were supported by a large staﬀ
of specialists who were responsible for all kinds of little discoveries they were
necessary along the way.
The big discoveries didn't happen that fast. Ten years between the desire for a
solid state ampliﬁer and getting there. Not one or two.
It was a "destination". Many people would come and visit: chat and lecture with
the people there (their building had an auditorium). Very connected to a broader
idea ecosystem.
Increasingly, during the late 1920s and early 1930s, ideas arrived in the ﬂesh, too.
Some years Karl Darrow would visit California to lecture; some years students in
various locations would learn from a physics professor named John Van Vleck, who
was permitted to ride the nation's passenger trains free of charge because he had
helped work out the national rail schedules with exacting precision. It also was the
case that a scholar from abroad (a 1931 world tour by the German physicist
Arnold Sommerfeld, for instance) would bring the new ideas to the students at
Caltech or the University of Michigan. Indeed, the Bell Labs experimentalist Walter
Brattain, the physicist son of a ﬂour miller, was taking a summer course at
Michigan when he heard Sommerfeld talk about atomic structure. Brattain
dutifully took notes and brought the ideas back to New York. At West Street, he
gave an informal lecture series to his Bell Labs colleagues. 
Every month, as it happened, seemed to bring a new study on physics, chemistry,
or metallurgy that was worth spreading around—on the atomic structure of
crystals, on ultra-high-frequency radio waves, on ﬁlms that cover the surface of
metals, and so forth. One place to learn about these ideas was the upper ﬂoor of
the Bell Labs West Street oﬃces, where a large auditorium served as a place for
Bell Labs functions and a forum for new ideas. In the 1920s, a one-hour
colloquium was set up at 5 p.m. on Mondays so that outside scholars like Robert
Millikan and Enrico Fermi or inside scholars like Davisson, Darrow, and Shockley—
though only twenty-seven years old at the time—could lecture members of the
Bell Labs technical staﬀ on recent scientiﬁc developments. (Albert Einstein came
to West Street in 1935, but was evidently more interested in touring the
microphone shop with Harvey Fletcher than giving a talk.) Another place to learn
about the new ideas was the local universities. The Great Depression, as it

happened, was a boon for scientiﬁc knowledge. Bell Labs had been forced to
reduce its employees' hours, but some of the young staﬀers, now with extra time
on their hands, had signed up for academic courses at Columbia University in
uptown Manhattan. Usually the recruits enrolled in a class taught on the Columbia
campus by a professor named Isidor Isaac (I. I.) Rabi, who was destined for a
Nobel Prize. - Gertner, Jon. The Idea Factory (pp. 42-43). Penguin Publishing Group.
Kindle Edition. 
They were strongly connected to other laboratories working on similar (or the
same) problems. Top researchers would spend months touring labs in Europe
and then come back and share what they had learned.
They had an internal scientiﬁc journal: Bell Labs Technical Journal 
They had study groups were researchers would together through new material
on physics.
And there was, ﬁnally, another place on West Street where new ideas could now
spread. Attendance was allowed by invitation only. Some of the Labs' newest
arrivals after the Depression had decided to further educate themselves through
study groups where they would make their way through scientiﬁc textbooks, one
chapter a week, and take turns lecturing one another on the newest advances in
theoretical and experimental physics. One study group in particular, informally led
by William Shockley at the West Street labs, and often joined by Brattain, Fisk,
Townes, and Wooldridge, among others, met on Thursday afternoons. The men
were interested in a particular branch of physics that would later take on the
name "solid-state physics." It explored the properties of solids (their magnetism
and conductivity, for instance) in terms of what happens on their surfaces as well
as deep in their atomic structure. And the men were especially interested in the
motions of electrons as they travel through the crystalline lattice of metals. "What
had happened, I think, is that these young Ph.D.'s were introducing what is
essentially an academic concept into this industrial laboratory," one member of
the group, Addison White, would tell the physics historian Lillian Hoddeson some
years later. "The seminar, for example, was privileged in that we started at let's
say a quarter of ﬁve, when quitting time was ﬁve." The men had tea and cookies
served to them from the cafeteria—"all part of the university tradition," White
remarked, "but unconventional in the industrial laboratory of that day." The
material was a challenge for everyone in the group except Shockley, who could
have done the work in his sleep, Wooldridge would recall. Out of habit, the men
addressed one another by their last names. According to Brattain, it was always
Shockley and Wooldridge—never Bill and Dean, and never Dr. Shockley and Dr.
Wooldridge. - Gertner, Jon. The Idea Factory (pp. 43-44). Penguin Publishing Group.
Kindle Edition. 
They specialized. Notably, there was a split between theorists and
experimentalists who worked together. A theorist would predict something, the
experimentalist would construct and run the experiment, then the theorist would
interpret the data. There was also the split between physicists, chemists,
metallurgists, etc.
And yet at the same time, this is also quoted as applying to at least one
period: There was no real distinction at West Street between an engineer
and a scientist. If anything, everyone was considered an engineer and was
charged with the task of making the thousands of necessary small
improvements to augment the phone service that was interconnecting the
country. - Gertner, Jon. The Idea Factory (p. 27). Penguin Publishing Group.
Kindle Edition.

The period where specialization seemed was apparent was later, when
they'd moved from West Street to Murray Hills.
Bell Labs was large. Thousands of people worked during at least some periods
(9,000 during WWII supposedly).
They eventually built out custom oﬃces/laboratories in a suburban area, making
me think of the Steve Jobs building at Pixar, but in the former case each lab was
hooked up with "everything an experimentalist could need: compressed air,
distilled water, steam, gas, vacuum, hydrogen, oxygen, and nitrogen."
No one was allowed to work with their doors closed.
No one was allowed to refuse help to colleagues, regardless of rank or
department, when it might be necessary.
Supervisors were allowed to guide but not interfere with research.
There was more chance and random experiment leading to the transistor than I
expected. I'd kind of assumed the theory and experiments had proceeded in a
very deﬁnite way. Instead, semiconductor doping was a random discovery they
ﬁgured out after they'd been mucking around a bunch with semiconductors and
just trying to understand their observations.
Three Bell Labs researchers in particular—Jack Scaﬀ, Henry Theurer, and Russell
Ohl—had been working with silicon in the late 1930s, mostly because of its
potential for the Labs' work in radio transmission. Scaﬀ and Theurer would order
raw silicon powder from Europe, or (later) from American companies like DuPont,
and melt it at extraordinary temperatures in quartz crucibles. When the material
cooled they would be left with small ingots that they could test and examine. They
soon realized that some of their ingots—they looked like coal-black chunks, with
cracks from where the material had cooled too quickly—rectiﬁed current in one
direction, and some samples rectiﬁed current in another direction. At one point,
Russell Ohl came across a sample that seemed to do both: The top part of the
sample went in one direction and the bottom in the other. That particular piece
was intriguing in another respect. Ohl discovered that when he shone a bright
light on it he could generate a surprisingly large electric voltage. Indeed the eﬀect
was so striking, and so unexpected, that Ohl was asked to demonstrate it in
Mervin Kelly's oﬃce one afternoon. Kelly immediately called in Walter Brattain to
take a look, but none of the men had a deﬁnitive explanation. - Gertner, Jon. The
Idea Factory (pp. 84-85). Penguin Publishing Group. Kindle Edition. 
There were other people working on the same things as they were, and they
were racing against them. It was Leibniz and Newton, Tesla and Edison, Graham
Bell and Elisha Gray. In particular, Julius Lilienfeld had independently discovered
and patented the ﬁeld-eﬀect also theorized by Shockley, and Herbert Mataré
independently invented the point-contact transistor in 1948 (vs 1947 for
Bardeen and Brittain).
This actually ﬂies against my sense that Bell Labs was able to build the
transistor because of their resources and build-up of particular knowledge
and expertise they had after 20-years. Possibly their ideas were just
getting spread around via their external contacts, or actually, solid-state
physics was taking oﬀ generally.

We got what's needed for COVID-19
vaccination completely wrong
I would summarize the leading thought in 2020 on vaccination on LessWrong and the
review that's now popular in the mainstream as:
New vaccination technology like mRNA-based vaccines and adenovirus-based
vaccines allow faster development of vaccines. We still have the challenge of
building enough vaccine factories. To build enough vaccine factories.
This seems to be wrong and the better view is:
Peptide-based vaccines are well understood and unsexy. We have existing
adjuvants with well understood safety proﬁle. They can be easily produced with
equipment we already have. Given that they are unsexy nobody wants to run a
clinical trial right and Western governments are interested in suing people for
developing such technology then they are interested in vaccine development.
According to it's Moderna's information, the ﬁrst patient who got the Moderna vaccine
got it on the March 16. Two weeks later Euroimmun founder and biotech billionaire
Winfried Stöcker gave himself the ﬁrst dose of a vaccine he developed himself. In
contrast to Moderna he however was not focused on bringing a vaccine to market. He
just wanted don't wanted to get COVID-19 and vaccinated himself. His company rather
focused on developing antibody tests that were in short supply at the time.
Given past studies of the Coronavirus it was common knowledge that targeting the
spike protein of COVID-19 was a good idea for developing a vaccine. Moderna
announced that they designed a vaccine in one day by simply targeting the spike
protein. Stöcker decided to also go for a domain of the spike protein and mixed it with
an already well-understood adjuvant. Given that a lot of the risks from a vaccine come
from bad adjuvants and he thought that being in his 70ths getting COVID-19 was
undesirable the risk calculation clearly came out in favor of vaccinating himself with
his mix. After everything went well with himself and he developed antibodies as
predicted he blogged about it and gave it to his family as he didn't want them to get
COVID-19 either.
It's hard to get the timeline right here but Preston Estep, Don Wang, Alex Hoekstra,
Ranjan Ahuja and George Church et al had a similar idea. They also didn't want to get
COVID-19 and knew plenty about biology. In contrast to Stöcker they cared a bit more
about not being boring and thought about what they wanted out of a vaccine and
coordinated with their friends instead of just making a vaccine alone for themselves.
They wanted something that's easy to brew together and that still works even if the
spike protein mutates. Instead of just targeting a protein domain of the spike protein
they focused on nanopeptides that are shorter sequences then individual protein
domains. Short peptides also have the advantage that they are easy to order online
instead of having to wait 1-2 weeks for a protein domain like the one targeted by
Stöcker it's a matter of days to get the sequences one orders for short peptides.
They brew together RadVac and decided to make their whitepaper public in late July
where the ﬁrst public version of the whitepaper seems to be version 2-3-2 from the
July 29, 2020. That's the kind of version number one usually sees in software projects.
While the FDA would never allow a product that's developed as agile to be sold,

publishing information is free and given that no scheduled substances are involved in
RadVac people are free to brew RadVac together for themselves.
Sometime in September Stöcker thinks (not his words):
"It seems like the commercial vaccine trials don't provide us a vaccine that allows us
to vaccinate everyone in Germany this year. I could easily brew up enough vaccine
doses so that we could vaccinate everybody in Germany this year and give them
antibodies."
Stöcker then writes the Paul-Ehrlich-Institut (PEI), which is the German institution
responsible for vaccination, a letter proposing to vaccinate everybody in Germany
who wants by the end of the year based on his experience of giving ﬁve probands
(including himself) his vaccine nobody having side-eﬀects and all developing
antibodies. First giving it to a sizeable number of volunteers and then giving it to even
more volunteers. A single 2000-liter-reactor is able to produce enough peptides for
vaccines for 1 million people per day.
From the perspective of the PEI this is heresy. They ﬁrst ignore his letter and then
contact another agency to sue Stöcker for making an unregistered clinical trial with
his ﬁve probands. By German law as a doctor who's allowed to practice medicine,
Stöcker is allowed to give his patients a mix that he brew together medical trials
require registration. In an actual trial with 64 patients Stöcker ﬁnds that the adverse
reactions to his vaccine brew are a lot lower then that of the currently approved
vaccines with their new technologies.
It's worth noting here that the side-eﬀects of the existing vaccines are worth enduring
to be protected against COVID-19. I just want a vaccine and if that means I'm ill for a
day because of an adverse reaction that's completely worth it to be protected against
COVID-19. For this post I will leave the question of why companies pushed for getting
the new technology to market here for the reader.
Zvi wrote that the problem with the Gates Foundation was that they didn't trust the
new vaccination technologies enough. The problem seems to me the polar opposite.
They fall for the mRNA researchers conning them when they funded them via CEPI.
The mRNA technology seems to provide no beneﬁt over simply giving the peptides
directly but the mRNA researchers really wanted to do fancy research on mRNA.
Gates had a model where he could simply give the mRNA people a few billions to build
the necessary factories to produce the vaccines in a time of crisis like our pandemic.
Zvi also seems to think this to be true. From basic EA principles we know that room for
funding is central when it comes to eﬀective charity interventions. As LessWrongers
we understand programming and the principle of the Mythical Man-Month where
adding more programmers to a project doesn't always make it faster. Chief Financial
Oﬃcer and Chief Operating Oﬃcer of BioNTech Sierk Poetting is on record (DER
SPIEGEL Nr. 6 / 6. 2. 2021 Site 64) for saying that there was open room for funding for
their vaccine eﬀort in 2020. Given that Moderna's vaccination eﬀort got a similar
amount of funding as that of BioNTech/Pﬁzer, I would expect them also to have no
open room for funding. Mixing the mRNA with their lipid coating seems to require
custom microﬂuid mixing technology that can't be simply ordered and where scaling
up the production needs more then just money.
After hearing from Michael Vassar last year that we need a truth and reconciliation
committee after this is over, I'm at the point where I want a truth and reconciliation
committee.

Coincidences are Improbable
This is a linkpost for https://markxu.com/coincidences
Ada Palmer:
events which are improbable and proximal are likely to have a causal link
I usually feel ﬁne after eating food. One day, I decided to try a new dish at a
restaurant. Afterward, my stomach is upset. I suspect that the new dish caused my
stomachache. How justiﬁed is this suspicion?
Suppose events A and B both have a probability 0.01 of occurring, and you observe
both. This event favors various hypotheses over each other to the extent that they
sharply predicted A ∧B. A hypothesis that has P(B ∣A) = c ∗0.01 assigns c times
more probability mass to A ∧B than hypotheses that suppose A and B are
independent.
More concretely, a hypothesis that postulates a strong causal link between A and B
might have P(B ∣A) = 0.9. This hypothesis is favored 90 : 1 over a hypothesis that has
P(B ∣A) = P(B) = 0.01. More generally, if you observe two improbable things, this is
evidence that the presence of one observation makes the other more likely, with the
evidence getting stronger as the connection between the two events strengthens.
Coincidences happen, but they are improbable. If you get a dog and your couch starts
getting damaged, your dog is probably doing it. If your skin gets irritated and you
recently switched lotion brands, you're probably allergic to the new brand. If my friend
and I both saw someone six feet tall with red hair, we probably saw the same person.
If your friend introduces you to someone that is both vegan and plays Magic the
Gathering, you probably forget that your friend is also vegan and plays Magic the
Gathering.
There are four ways events can be causally linked, only two of which are direct:
A causes B; your dog caused the couch damage.
B causes A; your skin irritation is caused by the new lotion brand.
Some event C causes both; the same 6-foot person causes both you and your
friend to see them.
Some event D caused by both has been conditioned upon; new introductions
have improbable attribute combinations because your friend seeks those
combinations out.
When enough coincidences happen, start looking for a causal link.

