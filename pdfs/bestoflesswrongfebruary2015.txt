
Best of LessWrong: February 2015
1. Attempted Telekinesis
2. How to learn soft skills
3. The Truth About Mathematical Ability
4. If you can see the box, you can open the box
5. Easy wins aren't news
6. Don't estimate your creative intelligence by your critical intelligence
7. Innate Mathematical Ability
8. The Galileo aﬀair: who was on the side of rationality?
9. An alarming fact about the anti-aging community
10. The Value of a Life

Attempted Telekinesis
Related to: Compartmentalization in epistemic and instrumental rationality; That other
kind of status.
Summary:  I'd like to share some techniques that made a large diﬀerence for me,
and for several other folks I shared them with.  They are techniques for reducing
stress, social shame, and certain other kinds of "wasted eﬀort".  These techniques are
less developed and rigorous than the techniques that CFAR teaches in our workshops -
- for example, they currently only work for perhaps 1/3rd of the dozen or so people
I've shared them with -- but they've made a large enough impact for that 1/3rd that I
wanted to share them with the larger group.  I'll share them through a sequence of
stories and metaphors, because, for now, that is what I have.
For me, these techniques came out of a stressful time period.
In October 2012, CFAR was very new, and I was very new to being its executive
director.  
I was faced with a task that I basically didn't know how to do -- ﬁlling the ﬁrst
workshop for which we charged "real" money (the $3900/person that actually let CFAR
run), and helping our team create our ﬁrst decently polished workshop at the same
time (which needed curriculum, operations, etc.).  But whenever I sat down to try to
work, my head would ﬁll up with all the other tasks I "needed" to get done, instead of
the particular task I was trying to work on.  Or my head would ﬁll with stress and
mental static.  So, almost because of how badly I needed to work, I found myself
unable to accomplish much of anything.
The set of stories and metaphors below is somehow what eventually gave me the
ability to work with full focus in those conditions (I found them partway through that
October), and cured most of my decades-long social shame at the same time.[1]
 (Though, again, this stuﬀ isn't rigorous yet.  It worked for a few folk, but failed a few
others; your mileage may vary.  Do share your thoughts.)
Attempted telekinesis
One morning, that month, I was lying in bed, half-asleep.  And I wanted my laptop.
 But my laptop was a few feet away, so reaching it sounded hard (because I was half-
asleep).  
After lying there a while wishing, I ﬁnally noticed what my brain was up to.  And I
noticed that what my brain was doing was visualizing my laptop whooshing toward
me.  Again and again.  (Fix attention on laptop... visualize the woosh.  Nope, laptop
isn't here yet: repeat!)[2]

I'm going to call this process "Attempted telekinesis".
It seems to me that something like "attempted telekinesis" underlies a large set of
stress / shame / worry / etc., and that learning to vanish it has been super-useful for
me and several others.  I'll start with several examples of what I'll be calling
"attempted telekinesis", and then go into some techniques for vanishing it.
The case of the munching noises
Later that day, I was sitting at the oﬃce trying to work, and someone next to me was
eating.  Noisily.
Now, I'm part of the sizable minority of the population that is driven absolutely
bonkers by munching noises.  Munching noises ﬁll me with rage and make me want to
punch someone.  But, like, I get that that's petty of me.  
So my internal thinking stream goes something like this:
Coworker:  [Munch.  Munch.]
My system 1/ intuitive brain (silently, in my head):  Argh!  Stop it! 
Me:  [Type, type.]  (While thinking:  "I don't want to be petty; best not say
anything, nor show annoyance on my face in any way.")
[1 minute later]
Coworker:  [Munch.  Munch.]
My system 1/ intuitive brain (silently, in my head):  Didn't you hear me??  Stop
it!!  
Me:  [Type, type.]  (... I don't want to be petty; best not say anything, or show it
on my face in any way.)
[and another minute later]
Coworker:  [Munch.  Munch.]
My system 1/ intuitive brain (silently, in my head):  Argh!!  Didn't you hear
me??  Stop it!!  Why won't it stop!!  Clearly I need to use even more emotional
force to make it stop!!
Me:  [no longer typing]  (... Oh, huh, this is that "attempted telekinesis" thing
again, isn't it.  I'm not doing anything with my face or voice that would cause the
eating noises to cease.  I'm intentionally not doing anything with my face or
voice, because I don't want to be petty.  And yet my intuitive brain seems to feel
like its "be upset" action should've changed something in the world...)

The ad copy writer who doesn't know if she's
"good enough"
So, later on that day, I sit down to write some ad copy -- something I can email out to
folks who might be interested in the workshop.
And I notice that a bunch of my thoughts aren't about the details of the ad wording at
all -- they're about whether I'm good enough at writing to write ad copy, and also
about whether the whole workshop is doomed and I'll be cast desolate to the hyenas
while my entire tribe mocks me for having ruined CFAR.
So I stop and think through my fears for a moment.  And I agree that, indeed, the
workshop might not work -- but since it also might well work, it'd be pretty damn
stupid to stop preparing right then.  And in fact, my useful "next actions" from this
moment basically involve doing whatever's most likely to make it work, and not
wasting motions on the opposite prospect.
Similarly, I might not be good enough at the writing -- maybe I should be getting
someone else to write it for me.  But since I might well be able to, and since there's no
one good sitting right there to give the task to instead, it seems best to set a 1-hour
timer, do the best writing I can for 1 hour without distracting myself trying to evaluate
it -- and then, when the timer rings, I can deliberately evaluate whether to write more
myself or to look for someone else who can write it.
But even after I think that through... my brain keeps on trying to waste these motions.
 It's like "write... pause... `what if I'm not good enough?'".  And I notice that it has the
same feel as the laptop and the munching noises.  As though something in me hopes
that if I just feel upset about things, or if I just visualize that I need the world to be a
certain way or worry about how it isn't, this will somehow magic the world into a
better state.
A musical artist once said:  "You know, how good or bad you are [at making music] is
really none of your goddamn business."  And I get what he meant, now.  My business
this hour is to write, not to worry about how I'm not good enough at writing.  
But how to do it?  How to get my brain to focus on writing, and to drop the attempted
telekinesis?[3] 
Useful "telekinesis":  Separating
babies from bathwater
The "attempted telekinesis" examples above are all examples of pointless behaviors --
the kinds of behaviors a person is better oﬀ removing.  I'd like to take a moment, now,
to distinguish pointless cases of "attempted telekinesis" (where a person tries to
change the world just by repeatedly stressing out about it) from their useful cousins.

Here's a useful cousin:
The other morning, I was lying in bed, again.  Thinking that maybe I should get up.
 But feeling like bed was warm and getting up would be a little hard.  
And then I thought about breakfast.  I pictured it: nice, fried eggs; a sliced fresh
tomato; a steaming cup of tea.  I pictured biting into the eggs, with the runny yolk on
my tongue.  And suddenly, without any need of prompting from conscious-me, my
body was in motion -- up and heading toward the eggs.  (Perhaps, from the
perspective of the submodule of my brain that did the "wishing for eggs" manuever,
wishing had in fact made it so!  It wished, and my body responded: telekinetic
success.)
As in the above "pointless" cases, my system 1 brain had a thing that it wanted, and
visualized a picture of the desired end-state.  But in the breakfast example, that
visualization was useful.  The imagined ﬂying laptop had just ﬁlled my head with
repeated wishing.  The imagined vanishing munching noises had just ﬁlled my head
with repeated aggravation.  The imagined "being a better writer" state had only
distracted me from writing.  But the imagined experience of eating breakfast... pulled
my system 1 into actually obtaining breakfast.
Similarly, when I imagine Archimedes in the classic bathtub story, I imagine him
obsessing a bit about how to measure the crown's density.  "How can I measure it?
 How can I measure it?" his brain might repeat... a little like repeating "Get my laptop
to whoosh toward me!".  Obsessing on problems at CFAR certainly seems to help me
notice potential solutions.
So, what's the take-away?  When is it useful to try to wish the world into a diﬀerent
state?  What distinguishes the kinds of "attempted telekinesis" that one might like to
remove, from the kinds that fetch you breakfast or give you insights into the king's
crown?  
This matter seems to me to be a bit complicated, but also seems quite important -- if
you get it wrong, you either stay unnecessarily distracted and ineﬀective (like me in
the lead-up to CFAR's ﬁrst workshop), or you end up a sort of parody of pop Buddhism,
sitting there being placid about your problems instead of harnessing your drives to
solve them.
How to distinguish?
In practice, I tend to distinguish between useful and useless attempted telekinesis
based on task type and emotional tone.  (Improvements/kibbitzes appreciated.)
Task type:
Type 1: Problems that System 1 can solve by itself:
Examples: Making breakfast; causing someone to know you care about them.

Suggested response:  This sort of wishing is healthy, and may prompt actions that
make a lot more sense than those system 2 would plan (e.g., your nonverbals as you
apologize are likely to be far better if you viscerally care about your interlocutor). 
Leave system 1 be.
Type 2: Problems that are worth solving, but that need help from System 2:
Examples:  "There's nothing good to eat" (situation: you notice that several times,
over the last hour, you've gone to the fridge, opened it, stared inside, closed it... and
then opened it again a few minutes later -- as though to see if something good has
magically materialized into the closed fridge); Feeling 'stuck' at one's job (or in a
relationship); Not having enough money. (The distinguishing feature here is that
system 1 has been looping on the problem for a while to no eﬀect, and that system 2
has not yet taken a good look at the problem.)
Suggested response:  Raise the problem to conscious attention; then, try to ﬁgure out
what is bothering system 1; ﬁnally, decide what to do about it.  As you do this, parts
of the wishing will naturally shift from the general problem ("Somehow make work less
stuck-feeling") to the speciﬁc strategy you've chosen ("Figure out how to renegotiate
with my manager").[4]
Type 3: "Problems" that should be given up on:
Examples:  "Make the munching noises go away" (in a case where you've decided not
to); "Make San Franciscans be better drivers";  "Let me vanish into the ﬂoor."  (The
distinguishing feature here is simply that these are "problems" that, on reﬂection, you
do not wish to take action on.)
Suggested response:  Find a way to let system 1 know that solving this problem isn't
worth the cost, or that keeping this problem on your internal "worry/fume about" list is
quite unlikely to have positive eﬀects.  For example, you might:
Make a plan for what it would actually take to cause San Franciscans to be better
drivers.  Estimate the total amount of work involved.  Ask your emotional brain if
it would, in fact, like you to carry out this plan.
Visualize a stressed-out/fuming/worrying you getting cut oﬀ in traﬃc.  Now
visualize a calm you getting cut oﬀ in traﬃc.  See if you expect to see anything
good happen in the stressed-out case that doesn't happen in the calm case. (Be
open to the fact that the answer might be "yes".)[5]
Notice, in detail, what system 1 is upset about.  Acknowledge that, yes, you may
be late to your work meeting because of the traﬃc.  And that, indeed, your
personal driving habits are diﬀerent from those of the driver who cut you oﬀ.
 And that someday a driver like that may in fact kill you via aggression or
carelessness -- it isn't likely, but it's possible, and the lifetime risk of death by
traﬃc accident is distinctly nonzero.  Once you've noticed all the painful things,
check again to see whether it's worth taking some sort of constructive action on
some of them.  System 1 may trust your policy decision more now that you've
looked at all the downsides (and may be more willing, therefore, to stop trying to
will the drivers into a diﬀerent state).[6]
Type 4: Problems that should be delegated to a particular future-you:
Examples: The problem of locating a workshop venue (during the hour at which I was
trying to write the workshops ad, that October); the situation with your roommates
and the dishes (while you're at work solving a coding problem).

Suggested response:  Designate a particular future-you to do the task.  Dialog with
your "inner simulator" (your system 1 anticipations) until both system 1 and system 2
are convinced that that speciﬁc you will actually do the task, and that there is no
additional positive eﬀect to be gained via staying preoccupied now.
Type 5: Problems that System 2 needs "shower-thoughts" help with:
Examples: Archimedes' problem measuring the king's crown; "My relationship with
Fred is broken, and I can't ﬁgure out what to do about it"; "How the heck can I solve
that math riddle?"  (The distinguishing feature here is that both: (1) the problem has
already been raised to conscious attention at some point (and system 2 failed to
instantly solve it); and (2) the problem is a worthy use of your shower-thoughts --
either for what it'll accomplish directly, or for the improvement it may give to your
pattern of thought.))
Suggested response:  This sort of wishing is healthy.  Leave system 1 be.
Emotional tone:
Wishes often seem to me to have emotional tones.  Some tones are simple desire
("Breakfast... mmm....").  Others have an overlayed hopelessness or bitter resignation
about them ("I just always have to put up with how everyone else is incompetent");
others, still, have a tone (at least in me) of hammed-up ﬂailing, self-pity, or desire for
outside help -- as though if I just feel helpless enough, somehow a grown-up will come
to the rescue ("Make the workshop crisis not be in this state... Make the workshop
crisis not be in this state...").
It seems to me that it's worth installing an "alert" that sounds, in your head, whenever
it hears either the hopeless/bitter/resigned tone, or the ﬂailing/save-me tone.  Both
are often signs of buggy "attempted telekinesis" situations that are worth conscious
debugging (a la the schema above).  And the emotional tones can be easier to
automatically ﬂag.
 
[1]  A book called "Bonds that make us free" played a substantial role in prompting
these thoughts and was extremely helpful to me.  It's written from a Christian
worldview, but if you're up for navigating a foreign expository style and sorting out for
yourself which parts to keep, and if in addition you are interested in vanishing social
shame or other forms of loopy thoughts, I'd recommend it.
[2] Thanks to Alicorn for making the cartoon.
[3]  Other than, you know, to repeatedly visualize my thought patterns whooshing into
the new state that I now wished them to be in?  ;) 
[4]  The book "Focusing" by Eugene Gendlin teaches one useful way to do this.  If you
decide to check it out, I'd strongly recommend the audiobook over the paper book, as
it is abridged and far clearer.

[5] For example, perhaps, if you remain stressed out, perhaps your boss will see how
much you suﬀered in your attempt to be on time to work and will deduce that you
care about timeliness.  (If you notice some good eﬀect coming from the stress that
doesn't come from the calm, you might want to look for an alternative way to cause
the eﬀect.  For example, you might update your heuristics to decrease the chances of
future lateness; plan to explain this to your boss and to oﬀer a 1-sided $100 bet
against this ever happening again; and then drive with your mind free to focus fully on
interesting problems.)
[6] More generally, when setting out to convince system 1 that X is true, it is best to
be honestly curious as to whether X might in fact be false, and whether system 1 may
have some good reason for suspecting this.  It is much the same as when attempting
to convince another human.  Saying "Hey, look, you're wrong and stupid and so your
proposed oﬃce policy is really bad" is usually not very persuasive; saying "huh; I'm
confused; the oﬃce policy looks to me as though it'll cost a lot of hours to little eﬀect,
but you usually have good reasons for things; maybe you could tell me why you think
it's plausible?" is often a better way to persuade; one wishes to do the same thing for
system 1.

How to learn soft skills
Acquiring some skills is mostly about deliberate, explicit information transfer.  For
example, one might explicitly learn the capital of Missouri, or the number of miles one
can drive before needing an oil change, or how to use the quadratic formula to solve
quadratic equations.
For other skills, practitioners' skill rests largely on semi-conscious, non-explicit
patterns of perception and action.  I have in mind here such skills as:
Managing your emotions and energy levels;
Building strong relationships;
Making robust plans;
Finding angles of attack on a mathematical problem;
Writing persuasively;
Thinking through charged subjects without bias;
and so on.  Experts in these skills will often be unable to accurately and explicitly
describe how to do what they do, but they will be skilled nonetheless.
I'd like to share some thoughts on how to learn such "soft skills".
 
Usefulness of non-true stimuli
If you read a chemistry textbook, it makes sense to ask after each sentence: "Is this
true?".  If the answer is "no", "no", "no", for a suﬃcient number of sentences, you
should probably abandon that book and look for a better one.  Chemistry textbooks
are supposed to be made out of statements you can trust -- statements you can add
to your ﬁle of "trusted explicit claims", in such a fashion as to make you better at
chemistry.  When a book fails at this property, its main value is lost.
Not so, IMO, for soft skills.
You can test ideas in your "inner simulator"
Your "inner simulator" is CFAR's version of the distinction between profession and
anticipation.  Basically, your "inner simulator" is the part of you that can play movies
forward to determine what to anticipate: "Do I have time to turn left before that car
reaches me?"; "What will she do, if I approach and say 'hi'?" (that is: what does my
inner movie-player show as the next scene, when I play it a movie in which I walk up
to her and say 'hi'?).
Your inner simulator is probably more accurate than your explicit models in domains
where you have a rich experience base, such as social phenomena, and day-to-day
physical phenomena.  It is probably worse in areas where you have good book-
learning behind you (e.g., you may have an accurate conscious model of the
bystander eﬀect, but still mismodel this when you anticipate without conscious
adjustment).  Your inner simulator is also the place where learning *must* land, if it is

to aﬀect your automatic system 1 responses (such as the perceptual patterns, and the
trigger-action habits, that play into many soft skills).
IMO, most "soft skills" books are not trying to add explicit statements to your store of
"trusted explicit/verbal statements".  Instead, they are trying to evoke experiments to
try out in your inner simulator -- bits that you can then keep, or not, according to
whether they feel promising when you imagine trying them out.  Later, you can try the
promising bits out in the actual world.
Example: Roommate
To see how this can work, imagine you're in a tricky social situation.  Perhaps your
roommate, Fred, is easily oﬀended, and also keeps leaving the kitchen in a state of
total mess.  You've brainstormed a number of options for talking to him, but they all
seem likely to end badly, and so you ﬁnd yourself in the self-help section of the
bookstore, looking for, well, help. 
As you browse, you notice a lot of advice that you've heard before -- advice like
"imagine what things feel like from Fred's perspective" and "explain what's in it for
Fred; ﬁnd a way to appeal to his pride and self-interest".  You could've generated a lot
of this advice yourself.  Nevertheless, much of it is advice you hadn't actually tried, in
Fred's case.  You ﬁnd yourself moved to actually try it as you read -- the stories in the
books pull you to actually want to see things from Fred's perspective, and you begin
spontaneously picturing how he might be feeling.  You also ﬁnd diﬀerent sentence-
stems in your head for how you might start the conversation -- sentence-stems
seeded, in part, from the stories you read in the books -- and some of them seem
promising.
Some of the books also contain statements that, as far as you can tell, are outright
nonsense.  One suggests that the only reason you or Fred have any problems is that
you weren't praised enough as children.  You try on that perspective as well, but it
feels yucky and nothing new clicks into place, and so you move along to the next part.
In this case, the books are acting, not as a source of trusted information, but as spur
to your own process of anticipating, perceiving, desiring, and planning -- and, in this
way, they are useful.
Example: Reading a good "woo" book
As I read "Bonds that Make Us Free", I read many explicit statements I disagreed with
(such as statements about a Christian God).  I took these in as poetry: I tried to
imagine the world the author saw himself in, and to see myself in the same world, so
as to have more access to the way he was parsing human phenomena.  
The book also contained many stories, all of which "rang true" in my inner simulator
(they matched the world as I anticipated it), but which formed new patterns when
placed next to each other.  I felt my intuitions update as I read -- I felt the stories take
patterns I had previously half-seen, and pull them into full conscious awareness.
I left the book with a changed perception of how rationalization patterns aﬀect close
relationships, and with an increased ability to separate from my rationalizations and
see the people close to me.  I left also with some new freedom from social shame.

 These changes did not come about via trusting or deferring to the author; they came
via trying on his perspective, and ﬁnding that pieces of the pattern he was pointing to
"clicked".
Try it!
One way to try this is to read a book.  But, since books' usefulness is not just about
their accuracy, it can *also* be surprisingly eﬀective to just write your own book -- or,
at least, to write 5 minutes of it.  You can think of this as a way of getting system 1
unstuck from its default pattern.[1]
Set a 5-minute timer (I):
Pick a soft skill, X, that you'd like to get better at.  Then, set a 5-minute timer (yes, an
actual one — thinking for "about 5 minutes" doesn't work nearly as well).  Spend
those 5 minutes explaining to yourself, in writing, how to do X.  (For example, if you
picked "networking at conferences", you might spend the 5 minutes brainstorming on
what the key tricky bits are, and on strategies for navigating them.  E.g., "I'm not sure
how to start conversations.  So, at the conference, I can watch and see what
sentence-stems other people use.  I can also just start with 'Hi, my name is Anna', or
with 'Oh, are you Dr. so-and-so?  I loved your paper on such-and-such'.  That starter
sounds promising, actually; I should try to skim abstracts and Google at least a few
papers before the conference....")
(You might consider giving this a try right now.)
Set a 5-minute timer (II):
This exercise was created by Zak Vance, and is one of my favorites.  It's seriously
worth 5 minutes of your life to try this one out.  Pick, again, a soft skill, X, that you'd
like to get better at (e.g., "networking at conferences").  Now pick a diﬀerent skill, Y,
that you're already highly skilled at (e.g., "programming" — Y can be a soft skill or any
other sort).  Now, set a 5-minute timer, and spend 5 minutes explaining (in writing, or
aloud to a friend) how skill X is really actually just the same as skill Y, in the sense that
anyone who is ﬂuent in skill Y already knows all they need to know to be good at X —
they just need to apply their Y-skill to X.  (Your goal, as you do this, is to create a very
short guide that enables anyone who already knows Y to hit the ground running with
X.) You can see my example (taken from the seed "networking at conferences is really
just the same skill as programming") in footnote [2].  
It's important, of course, not to believe everything you generate in such an exercise —
after all, it was secretly written by a *beginner* in Skill X.  But, again, you can use it to
brainstorm ideas to try out, and to thereby get your system 1 intuitive search pattern
out of any local optima you may be caught in.
Some good "soft skills" books to try reading:
Bonds that Make Us Free, by Terry Warner
An Open Heart, by the Dalai Lama
Feeling Good Together, by David Burns
Eat That Frog, by Brian Tracy
How to Win Friends and Inﬂuence People, by Dale Carnegie

Self-therapy, by Jay Earley 
Focusing, by Eugene Gendlin (the audiobook is much better than the paper, IMO)
The Core LW Sequences, by Eliezer.
You might also just try going to the bookstore and locating a new "soft skills" book, by
scanning through a few and seeing if any "speak to you".  Books of the relevant sort
can be found in the business, self-help, continental philosophy, and spirituality
sections, as well as in sections focused on particular soft skills such as writing or
problem-solving.
As you read:
As you read a soft skills book (or the results of your own 5-minute timers), you may
wish to ask about each paragraph:
Is it true?  Can I use it to update my explicit model of Skill X?  (Yes, explicit
models are still useful!)
Even if it's false -- is there something near it that is true?
If I free associate from here, do any of my past experiences click into a new
focus?  
What feels fruitful/interesting about this idea?  About ideas I can free associate
to from here?  Does this improve my implicit space of hypotheses?
As I read this, can I visualize myself carrying out soft skill X in a usefully diﬀerent
way?  Do I ﬁnd my intuitions changing?  
How can I climb as thoroughly as possible into the frame, feeling, groove, or
worldview that generated this book?  And once I do that, does anything new
click into focus? 
Do consider adding your favorite books, or book-reading strategies, in the comments!
 
[1] System 1 stuckness of this sort seems to be almost ubiquitous. For example, I type
and drive quite a bit, but my typing and driving skill are pretty similar to what they
were several years ago; my conversational skills improve more, but they seem to have
some of this same "trying the same things again and again" ﬂavor. In this context,
even random noise seems helpful to jumpstart learning.
("Learned blankness" seems related here as well; one somehow gets stuck in an
ontology; the goal of soft skills books is often to help a person jumpstart out of it.)
[2] The example I generated from this seed, in 90 seconds:
Networking at conferences is really just the same skill as programming.  The three
programmers' virtues of Laziness, Impatience, and Hubris will take you all the way
there, as will basic principles such as analytic thinking and code reuse. 
Re: Laziness: Many folks who set out to network at conferences work hard, and
push themselves to talk to lots of people.  But in fact, some conversations are
predictably much higher value than others.  Be Lazy: plan a bit during your plane-
ride to the conference (or during a boring talk!), so that you know *who* you're
hoping to have *what kind* of conversations with, and can position yourself
accordingly.   

Also, when you approach a new person, see it as an opportunity to *practice* and
*debug* your greeting, as a re-usable code module, instead of treating it as a one-
oﬀ task to separately sweat about and make throw-away code for.  And, afterward,
review it brieﬂy in your mind — and see if you can create a way to reﬁne it. 
You might also look for "test cases", much as you would when debugging — you
might approach people who you already know by reputation, or who a friend of
yours has secretly already approached, and see if your interaction pattern is
similar to what you've heard.  You can use "test cases" of this sort to ﬁnd out how
your results compare to others, and to gain valuable info for debugging your own
routines. 
Note that, to show a real example, the text above is the ﬁrst thing I generated when I
gave myself 90 seconds to type from that seed -- it is a typical case, not a selected
case -- and certainly not a vetted guide to networking. Nevertheless, you can perhaps
see how this sort of rationalization(!) process might be helpful to seed learning.

The Truth About Mathematical Ability
There's widespread confusion about the nature of mathematical ability, for a variety of
reasons:
Most people don't know what math is.
Most people don't know enough statistics to analyze the question properly.
Most mathematicians are not very metacognitive.
Very few people have more than a casual interest in the subject.
If the nature of mathematical ability were exclusively an object of intellectual interest,
this would be relatively inconsequential. For example, many people are confused
about Einstein's theory of relativity, but this doesn't have much of an impact on their
lives. But in practice, people's misconceptions about the nature of mathematical
ability seriously interfere with their own ability to learn and do math, something that
hurts them both professionally and emotionally.
I have a long standing interest in the subject, and I've found myself in the unusual
position of being an expert. My experiences include:
Completing a PhD in pure math at University of Illinois.
Four years of teaching math at the high school and college levels (precalculus,
calculus, multivariable calculus and linear algebra)
Personal encounters with some of the best mathematicians in the world, and a
study of great mathematicians' biographies.
A long history of working with mathematically gifted children: as a counselor at
MathPath for three summers, through one-on-one tutoring, and as an instructor
at Art of Problem Solving.
Studying the literature on IQ and papers from the Study of Exceptional Talent as
a part of my work for Cognito Mentoring.
Training as a full-stack web developer at App Academy.
Doing a large scale data science project where I applied statistics and machine
learning to make new discoveries in social psychology.
I've thought about writing about the nature of mathematical ability for a long time,
but there was a missing element: I myself had never done genuinely original and high
quality mathematical research. After completing much of my data science project, I
realized that this had changed. The experience sharpened my understanding of the
issues.
This is a the ﬁrst of a sequence of posts where I try to clarify the situation. My main
point in this post is:
There are several diﬀerent dimensions to mathematical ability. Common measures
rarely assess all of these dimensions, and can paint a very incomplete picture of
what somebody is capable of.
What is up with Grothendieck?
I was saddened to learn of the death of Alexander Grothendieck several months ago.
He's the mathematician who I identify with the most on a personal level, and I had

hoped to have the chance to meet him. I hesitated as I wrote the last sentence,
because some readers who are mathematicians will roll their eyes as they read
this,  owing to the connotation (even if very slight) that the quality of my research
might overlap with his. The material below makes it clear why:
"His technical superiority was crushing," Thom wrote. "His seminar attracted the
whole of Parisian mathematics, whereas I had nothing new to oﬀer. — Rene
Thom, 1958 Fields Medalist
"When I was in in Paris as a student, I would go to Grothendieck's seminar at
IHES... I enoyed the atmosphere around him very much ... we did not care much
about priority because Grothendieck had the ideas that we were working on and
priority would have meant nothing. — Pierre Deligne, 1978 Fields Medalist
"[The IHES] is a remarkable place.. I knew about it before I came there; it was a
legendary place because of Grothendieck. He was kind of a god in mathematics."
— Mikhail Gromov, 2010 Abel Prize Winner
"On arriving at the IHES, we ordinary mathematicians share the same feeling that
Muslims experience on a pilgrimage to Mecca. Here is the place were, for a dozen
or so years, Grothendieck relentlessly explained the holy word to his apostles. Of
that saga, only the apocrypha reached us in the form of big, yellow, boring-looking
books edited by Springer. These dozens of volumes...are still our most precious
working companion." — Ngo Bau Chau, 2010 Fields Medalist
Based on these remarks alone, it seems hard to imagine how I could be anything like
Grothendeick. But when I read Grothendieck's own description of himself, it's
hauntingly familiar. He writes:
"I've had the chance...to meet quite a number of people, both among my "elders"
and among young people in my general age group, who were much more brilliant,
much more "gifted" than I was. I admired the facility with which they picked up, as
if at play, new ideas, juggling them as if familiar with them from the cradle - while
for myself I felt clumsy. even oaﬁsh, wandering painfully up a arduous track, like a
dumb ox faced with an amorphous mountain of things that I had to learn ( so I was
assured), things I felt incapable of understanding the essentials or following
through to the end. Indeed, there was little about me that identiﬁed the kind of
bright student who wins at prestigious competitions or assimilates, almost by
sleight of hand, the most forbidding subjects."
When I mentioned this to professor at a top math department who had taken a class
with Grothendieck, he scoﬀed and said that he didn't believe it, apparently thinking
that Grothendieck was putting on airs in the above quotation - engaging in a sort of
bragging, along the lines of "I'm so awesome that even though I'm not smart I was still
one of the greatest mathematicians ever."  It is hard to reconcile Grothendieck's self-
description with how his colleagues describe him. But I was stunned by the professor's
willingness to dismiss the remarks of somebody so great out of hand.
In fairness to the professor, I myself am much better situated to understand how
Grothendieck's remarks could be sincere and faithful than most mathematicians
are, because of my own unusual situation.
What is up with me?

I went to Lowell High School in San Francisco, an academic magnet school with ~650
students per year, who averaged ~630 on the math SAT (81st percentile relative to all
college bound students). The math department was very stringent with respect to
allowing students to take AP calculus, apparently out of a self-interested wish to keep
their average AP scores as high as possible. So despite the strength of the school's
students, Lowell only allowed 10% of students to take AP Calculus BC. I was one of
them. The teachers made the exams unusually diﬃcult for an AP Calculus BC course,
so that students would be greatly over prepared for the AP exam . The result was that
a large majority of students got 5's on the AP exam. By the end of the year, I had the
2nd highest cumulative average out of all students enrolled in AP Calculus BC. It
would have been the highest if the average had determined exclusively by tests,
rather than homework that I didn't do because I already knew how to do everything.
From this, people understandably inferred that I'm unusually brilliant, and thought of
me as one of the select few who was a natural mathematician, having ability perhaps
present in only 1 in 1000 people. When I pointed out that things had not always been
this way, and that I had in fact failed geometry my freshman year and had to retake
the course, their reactions tended to be along the lines of Qiaochu's response to my
post How my math skills improved dramatically:
I ﬁnd this post slightly disingenuous. My experience has been that mathematics is
heavily g-loaded: it's just not feasible to progress beyond a certain point if you
don't have the working memory or information processing capacity or whatever g
factor actually is to do so. The main conclusion I draw from the fact that you
eventually completed a Ph.D. is that you always had the g for math; given that,
what's mysterious isn't how you eventually performed well but why you started
out performing poorly.
It's not at all mysterious to me why I started out performing poorly. In fact, if Qiaochu
had known only a little bit more, he would be less incredulous.
Aside from taking AP Calculus BC during my senior year, I also took the SAT, and
scored 720 on the math section (96th percentile relative to the pool of college bound
students). While there are many people who would be happy with this score, there
were perhaps ~60 students at my high school who scored higher than me (including
many of my classmates who were in awe of me). Just looking at my math SAT score,
people would think very unlikely that I would come close to being the strongest
calculus student in my year.
As far removed my mathematical ability is from Grothendieck's, we have at least one
thing in common: our respective performances on some commonly used measures of
mathematical ability are much lower than what most people would expect based on
our mathematical accomplishments.
Hopefully these examples suﬃce to make clear that whatever mathematical ability is,
it's not "what the math SAT measures." What the math SAT measures is highly
relevant, but still not the most relevant thing.
What does the math SAT measure?
Just for fun, let's ﬁrst look at what the College Board has to say on the subject.
According to The Oﬃcial SAT Study Guide

The SAT does not test logic abilities or IQ. It tests your skills in reading, writing and
mathematics - the same subjects you're learning in school. [...] If you take
rigorous challenging courses in high school, you'll be ready for the test.
Some of you may be shocked by the College Board's disingenuousness without any
further comment. How would they respond to my own situation? Most hypothetical
responses are absurd: They could say "Unfortunately, you were underprivileged in
having to go to the high school ranked 50th in the country, where you didn't have
access to suﬃciently rigorous challenging courses" or "While you did take AP Calculus
BC, you didn't take AP US History, and that would have further developed your
mathematical reasoning skills" or "Our tests are really badly calibrated - we haven't
been able to get them to the point where somebody with 99.9 percentile level subject
matter knowledge reliably scores at the 97th percentile or higher."
Their strongest response would be to say that the test has been revised since I took it
in 2002 to make it more closely aligned with the academic curriculum. This is true. But
a careful examination of the current version of the test makes it clear that it's still not
designed to test what's learned in school. For example, consider questions 16-18 in
Section 2 of the sample test:
SATItem
The grid above represents equally spaced streets in a town that has no one-way
streets. F marks the corner where a ﬁrehouse is located. Points W, X, Y, and Z
represent the locations of some other buildings. The ﬁre company deﬁnes a
building's m-distance as the minimum number of blocks that a ﬁre truck must
travel from the ﬁrehouse to reach the building. For example, the building at X is an
m-distance of 2, and the building at Y is an m-distance of 1/2 from the ﬁrehouse
1. What is the m-distance of the building at W from the ﬁrehouse?

2. What is the total number of diﬀerent routes that a ﬁre truck can travel the
m-distance from F to Z ?
3. All of the buildings in the town that are an m-distance of 3 from the
ﬁrehouse must lie on a...
I don't think that rigorous, academic challenging courses build skills that enable high
school students to solve these questions. They have some connection with what
people learn in school - in particular, they involve numbers and distances. But the
connection is very tenuous - they're extremely far removed from being the best test
of what students learn in school. They can be solved by a very smart 5th grader who
hasn't studied algebra or geometry.
The SAT Subject Tests are much more closely connected with what students (are
supposed to) learn in school. And they're not merely tests of what students have
memorized: some of the questions require deep conceptual understanding and ability
to apply the material in novel concepts. If the College Board wanted to make the SAT
math section a test of what students are supposed to learn in school, they would do
better to just swap it it with the Mathematics Level 1 SAT Subject Test.
If the SAT math section measures something other than the math skills that students
are supposed to learn in school, what does it measure? The situation is exactly what
the College Board explicitly disclaims it to be: the SAT is an IQ test. This accounts for
the inclusion of questions like the ones above, that a very smart 5th grader with no
knowledge of algebra or geometry could answer easily, and that the average high
school student who has taken algebra and geometry might struggle with.
The SAT was originally designed as a test of aptitude: not knowledge or learned skills.
Though I haven't seen an authoritative source, the consensus seems to be that the
original purpose of the test was to help smart students from underprivileged
backgrounds have a chance to attend a high quality college - students who might not
have had access to the educational resources to do well on tests of what students are
supposed to learn in school. Frey and Detterman found that as of 1979, the
correlations between SAT scores and IQ test scores were very high (0.7 to 0.85). The
correlations have probably dropped since then, as there have in fact been changes to
make the SAT less like an IQ test, but to the extent that the SAT diﬀers from the SAT
subject tests, the diﬀerence corresponds to the SAT being more of a test of IQ.
The SAT may have served its intended purpose at the time, but since then there's
been mounting evidence that the SAT has become a harmful force in society. By 2007,
things had reached a point that Charles Murray wrote an article advocating that the
SAT be abolished in favor of using SAT subject tests exclusively. This will have
signiﬁcance to those of you who know Charles Murray as the widely hated author The
Bell Curve, which emphasizes the importance of IQ.
Twice exceptional gifted children
Let's return to the question of reconciling my very strong calculus performance with
my relatively low math SAT score. The diﬀerence comes in substantial part from my
having a much greater love of learning than is typical of people of similar intelligence.
I think that the same was true of Grothendieck.
I could have responded to Qiaochu's suggestion that I had always had very high
intelligence and that that's why I was able to learn math well by saying "No, you're

wrong, my SAT score shows that I don't have very high intelligence, the reason that I
was able to learn math well is that I really love the subject." But that would
oversimplify things. In particular, it leaves two questions open:
A large part of why I failed geometry my freshman year of high school is that I
wasn't interested in the subject at the time. I only got interested in math after
getting interested in chemistry my sophomore year. But almost nobody at my
high school was interested in geometry, and almost everybody passed
geometry. What made me diﬀerent?
Can a love of learning really boost one's percentile from 1 in 30 to 1 in 1000?
The gap seems awfully large to be accounted for exclusively by love of learning.
And what of Grothendieck, for whom the gap may have been far larger?
Partial answers to these questions come from the literature on so-called "Twice
Exceptional" (2e) children. The label is used broadly, to refer to children who are
intellectually gifted and also have some sort of disability.
The central ﬁnding of the IQ literature is that people who are good at one cognitive
task tend to be good at any another cognitive task. For example, people who have
better reaction time tend to also be better at arithmetic, better at solving logic
puzzles, better able to give coherent explanations of real world concepts, and better
able to recall a string of numbers that are read to them. When I was a small child, my
teachers noticed that I was an exception to the rule: I had a very easy time learning
some things and also found it very diﬃcult to learn others. They referred me to a
school psychologist, who found that I had exceptionally high reasoning abilities, but
only average short term memory and processing speed: a 3 standard deviation
diﬀerence.
There's a sense in which my situation is actually not so unusual. The ﬁnding that
people who are good at one cognitive task tend to be good at another is based on the
study of people of average intelligence. It becomes less and less true as you look at
people of progressively higher intelligence. Twice exceptional children are not very
rare amongst intellectually gifted children.  Linda Silverman writes
Gifted children may have hidden learning disabilities. Approximately one-sixth of
the gifted children who come to the Center for testing have some type of learning
disability—often undetected before the assessment—such as central auditory
processing disorder (CAPD), diﬃculties with visual processing, sensory processing
disorder, spatial disorientation, dyslexia, and attention deﬁcits. Giftedness masks
disabilities and disabilities depress IQ scores. Higher abstract reasoning enables
children to compensate to some extent for these weaknesses, making them
harder to detect.
This starts to explain why I failed geometry during my freshman year of high school.
The material was boring and I wasn't very focused on grades. But I also genuinely
found it diﬃcult to an extent that my classmates didn't. Learning the material the way
in which the course was taught required a lot of memorization - something that I was
markedly worse at than my classmates at Lowell, who had been selected for having
high standardized test scores.
It also explains why I didn't score higher than 720 on the math section of the SAT. It
wasn't because I couldn't answer questions like the ones that I pasted above. It was
because some of the math SAT questions are engineered to trip up students who
forget exactly what a problem asked for, or who are prone to arithmetic errors. Often a

multiple choice question will have one wrong answer for every such mistake that a
student might make. I used to think that this was a design ﬂaw, and that the test
makers didn't know that they were penalizing minor mistakes very heavily. No - it
wasn't a design ﬂaw - they designed the test that way on purpose. The questions test
short-term memory as a proxy to IQ. I tried to avoid mistakes by being really
systematic about my work, and not take shortcuts. But it wasn't enough given the
time constraints - making 3 minor mistakes on any combination of 54 questions is
enough to reduce one's score from 800 to 720.
It's plausible that something similar was true of Grothendieck.
It's probably intuitively clear even to readers who are not mathematicians that math is
not about being able to avoid making 3 minor mistakes on 54 questions. It's very
helpful to be quick and accurate, and my mathematical ability is far lower than it
would have been if my speed and accuracy were substantially greater, but speed and
accuracy are not the essence of mathematical ability.
What is the essence of mathematical ability?
I've only just scratched the surface of the subject of mathematical ability in this post,
largely focusing on describing what mathematical ability isn't rather than what
mathematical ability is. In subsequent posts I'll describe mathematical ability in
more detail, which will entail a discussion of what math is. I'll also address the
question of how one can improve one's mathematical ability.
Intelligence is highly relevant and largely genetic, but there are other factors that are
collectively roughly as important, some of which are things that individuals are in fact
capable of developing. For now, I'll oﬀer a teaser, which will be obscure to readers
who lack substantial additional context, and which paints a very incomplete picture
even when understood deeply, but which should nevertheless serve as food for
thought. Grothendieck wrote:
In our acquisition of knowledge of the Universe ( whether mathematical or
otherwise) that which renovates the quest is nothing more nor less than complete
innocence. It is in this state of complete innocence that we receive everything
from the moment of our birth. Although so often the object of our contempt and of
our private fears, it is always in us. It alone can unite humility with boldness so as
to allow us to penetrate to the heart of things, or allow things to enter us and
taken possession of us.
This unique power is in no way a privilege given to "exceptional talents" - persons
of incredible brain power ( for example), who are better able to manipulate, with
dexterity and ease, an enormous mass of data, ideas and specialized skills. Such
gifts are undeniably valuable, and certainly worthy of envy from those who ( like
myself) were not so endowed at birth," far beyond the ordinary".
Yet it is not these gifts, nor the most determined ambition combined with
irresistible will-power, that enables one to surmount the "invisible yet formidable
boundaries " that encircle our universe. Only innocence can surmount them, which
mere knowledge doesn't even take into account, in those moments when we ﬁnd
ourselves able to listen to things, totally and intensely absorbed in child play.
Readers are welcome to speculate on what Grothendieck had in mind in writing this.

Cross-posted from my website.

If you can see the box, you can open
the box
First post here, and I'm disagreeing with something in the main sequences.  Hubris
acknowledged, here's what I've been thinking about.  It comes from the post "Are your
enemies innately evil?":
On September 11th, 2001, nineteen Muslim males hijacked four jet airliners in a deliberately
suicidal effort to hurt the United States of America.  Now why do you suppose they might have
done that?  Because they saw the USA as a beacon of freedom to the world, but were born
with a mutant disposition that made them hate freedom?
Realistically,  most people don't construct their life stories with themselves as the villains. 
Everyone is the hero of their own story.  The Enemy's story, as seen by the Enemy, is not
going to make the Enemy look bad.  If you try to construe motivations that would make the
Enemy look bad, you'll end up flat wrong about what actually goes on in the Enemy's mind.
If I'm misreading this, please correct me, but the way I am reading this is:
1) People do not construct their stories so that they are the villains,
therefore
2) the idea that Al Qaeda is motivated by a hatred of American freedom is false.
Reading the Al Qaeda document released after the attacks called Why We Are Fighting You you
find the following:
 
What are we calling you to, and what do we want from you?
1.  The first thing that we are calling you to is Islam.
A.  The religion of tahwid; of freedom from associating partners with Allah Most High ,
and rejection of such blasphemy; of complete love for Him, the Exalted; of complete
submission to his sharia; and of the discarding of all the opinions, orders, theories,
and religions that contradict with the religion He sent down to His Prophet Muhammad.
 Islam is the religion of all the prophets and makes no distinction between them. 
It is to this religion that we call you ...
2.   The second thing we call you to is to stop your oppression, lies, immorality and
debauchery that has spread among you.
A.  We call you to be a people of manners, principles, honor and purity; to reject the immoral
acts of fornication, homosexuality, intoxicants, gambling and usury.
We call you to all of this that you may be freed from the deceptive lies that you are a great
nation, which your leaders spread among you in order to conceal from you the despicable
state that you have obtained.

B.  It is saddening to tell you that you are the worst civilization witnessed in the history of
mankind:
i.  You are the nation who, rather than ruling through the sharia of Allah, chooses to
invent your own laws as you will and desire.   You separate religion from you policies,
contradicting the pure nature that affirms absolute authority to the Lord your Creator....
ii.  You are the nation that permits usury...
iii.   You are a nation that permits the production, spread, and use of intoxicants.  You also
permit drugs, and only forbid the trade of them, even though your nation is the largest
consumer of them.
iv.  You are a nation that permits acts of immorality, and you consider them to be pillars
of personal freedom.  
"Freedom" is of course one of those words.  It's easy enough to imagine an SS oﬃcer
saying indignantly: "Of course we are ﬁghting for freedom!  For our people to be free
of Jewish domination, free from the contamination of lesser races, free from the sham
of democracy..."
If we substitute the symbol with the substance though, what we mean by freedom -
"people to be left more or less alone, to follow whichever religion they want or none,
to speak their minds, to try to shape society's laws so they serve the people" - then Al
Qaeda is absolutely inspired by a hatred of freedom.  They wouldn't call it "freedom",
mind you, they'd call it "decadence" or "blasphemy" or "shirk" - but the substance is
what we call "freedom".
Returning to the syllogism at the top, it seems to be that there is an unstated premise.
  The conclusion "Al Qaeda cannot possibly hate America for its freedom because
everyone sees himself as the hero of his own story" only follows if you assume that
What is heroic, what is good, is substantially the same for all humans, for a liberal
Westerner and an Islamic fanatic.
(for Americans, by "liberal" here I mean the classical sense that includes just about
everyone you are likely to meet, read or vote for.   US conservatives say they are
defending the American revolution, which was broadly in line with liberal principles -
slavery excepted, but since US conservatives don't support that, my point stands).
When you state the premise baldly like that, you can see the problem.   There's no
contradiction in thinking that Muslim fanatics think of themselves as heroic precisely
for being opposed to freedom, because they see their heroism as trying to extend the
rule of Allah - Shariah - across the world.
Now to the point - we all know the phrase "thinking outside the box".  I submit that if
you can recognize the box, you've already opened it.  Real bias isn't when you have a
point of view you're defending, but when you cannot imagine that another point of
view seriously exists.
That phrasing has a bit of negative baggage associated with it, that this is just a
matter of pigheaded close-mindedness.  Try thinking about it another way.  Would you
say to someone with dyscalculia  "You can't get your head around the basics of
calculus?  You are just being so close minded!"  No, that's obviously nuts.  We know
that diﬀerent peoples minds work in diﬀerent ways, that some people can see things
others cannot. 

Orwell once wrote about the British intellectuals inability to "get" fascism, in particular
in his essay on H.G. Wells.  He wrote that the only people who really understood the
nature and menace of fascism were either those who had felt the lash on their backs,
or those who had a touch of the fascist mindset themselves.   I suggest that some
people just cannot imagine, cannot really believe, the enormous power of faith, of the
idea of serving and ﬁghting and dying for your god and His prophet.  It is a kind of
thinking that is just alien to many.
Perhaps this is resisted because people think that "Being able to think like a fascist
makes you a bit of a fascist".  That's not really true in any way that matters - Orwell
was one of the greatest anti-fascist writers of his time, and fought against it in Spain. 
So - if you can see the box you are in, you can open it, and already have half-opened
it.  And if you are really in the box, you can't see the box.  So, how can you tell if you
are in a box that you can't see versus not being in a box?  
The best answer I've been able to come up with is not to think of "box or no box" but
rather "open or closed box".  We all work from a worldview, simply because we need
some knowledge to get further knowledge.  If you know you come at an issue from a
certain angle, you can always check yourself.  You're in a box, but boxes can be useful,
and you have the option to go get some stuﬀ from outside the box.
The second is to read people in other boxes.   I like steelmanning, it's an important
intellectual exercise, but it shouldn't preclude ﬁnding actual Men of Steel - that is,
people passionately committed to another point of view, another box, and taking a
look at what they have to say.  
Now you might say: "But that's steelmanning!"  Not quite.  Steelmanning is "the art of
addressing the best form of the other person's argument, even if it's not the one they
presented."   That may, in some circumstances, lead you to make the mistake of
assuming that what you think is the best argument for a position is the same as what
the other guy thinks is the best argument for his position.  That's especially important
if you are addressing a belief held by a large group of people.
Again, this isn't to run down steelmanning - the practice is sadly limited, and anyone
who attempts it has gained a big advantage in ﬁguring out how the world is.  It's just a
reminder that the steelman you make may not be quite as strong as the steelman that
is out to get you.  
[EDIT: Link included to the document that I did not know was available online before
now]

Easy wins aren't news
Recently I talked with a guy from Grant Street Group. They make, among other things,
software with which local governments can auction their bonds on the Internet.
By making the auction process more transparent and easier to participate in, they
enable local governments which need to sell bonds (to build a high school, for
instance), to sell those bonds at, say, 7% interest instead of 8%. (At least, that's what
he said.)
They have similar software for auctioning liens on property taxes, which also helps
local governments raise more money by bringing more buyers to each auction, and
probably helps the buyers reduce their risks by giving them more information.
This is a big deal. I think it's potentially more important than any budget argument
that's been on the front pages since the 1960s. Yet I only heard of it by chance.
People would rather argue about reducing the budget by eliminating waste, or cutting
subsidies to people who don't deserve it, or changing our ideological priorities.
Nobody wants to talk about auction mechanics. But ﬁxing the auction mechanics is
the easy win. It's so easy that nobody's interested in it. It doesn't buy us fuzzies or let
us signal our aﬃliations. To an individual activist, it's hardly worth doing.

Don't estimate your creative
intelligence by your critical
intelligence
When I criticize, I'm a genius. I can go through a book of highly-referenced scientiﬁc
articles and ﬁnd errors in each of them. Boy, I feel smart. How are these famous
people so dumb?
But when I write, I suddenly become stupid. I sometimes spend half a day writing
something and then realize at the end, or worse, after posting, that what it says
simpliﬁes to something trivial, or that I've made several unsupported assumptions, or
claimed things I didn't really know were true. Or I post something, then have to go
back every ten minutes to ﬁx some point that I realize is not quite right, sometimes to
the point where the whole thing falls apart.
If someone writes an article or expresses an idea that you ﬁnd mistakes in, that
doesn't make you smarter than that person. If you create an equally-ambitious article
or idea that no one else ﬁnds mistakes in, then you can start congratulating yourself.

Innate Mathematical Ability
In my present sequence of posts, I'm writing about the nature of mathematical ability.
My main reason for doing so is to provide information that can help improve
mathematical ability.
Along the way, I'm going to discuss how people can't improve their mathematical
ability. This may seem antithetical to my goal. Focus on innate ability can lead to a
sort of self-fulﬁlling prophesy, where people think that their abilities are ﬁxed and
can't be improved, which results in them not improving their abilities because they
think that doing so is pointless.
Carol Dweck has become well known for her growth mindset / ﬁxed mindset
framework. She writes:
"In a ﬁxed mindset students believe their basic abilities, their intelligence, their
talents, are just ﬁxed traits. They have a certain amount and that's that, and then
their goal becomes to look smart all the time and never look dumb. In a growth
mindset, students understand that their talents and abilities can be developed
through eﬀort, good teaching and persistence. They don't necessarily think
everyone's the same or anyone can be Einstein, but they believe everyone can
get smarter if they work at it." [...] This is important because individuals with a
"growth" theory are more likely to continue working hard despite setbacks...
As I'll describe in my next post, I'm broadly sympathetic with Dweck's perspective. But
it's not an either-or situation. Some abilities are innate and can't be developed, and
other abilities can be.
One could argue that this idea is too nuanced for most people to appreciate, so that
it's better to just not talk about innate ability. This seems to me paternalistic and
patronizing. People need to know which abilities are ﬁxed and which can be
developed, so that they can focus on developing abilities that can in fact be
developed rather than wasting time and eﬀort on developing those that can't be.
Working to improve abilities that are ﬁxed is
unproductive
When I was in elementary school, I would often fall short of answering all questions
correctly on timed arithmetic tests. Multiple teachers told me that I needed to work on
making fewer "careless mistakes."  I was puzzled by the situation - I certainly didn't
feel as though I was being careless. In hindsight, I see that my teachers were mostly
misguided on this point. I imagine that their thinking was:
"He knows how to do the problems, but he still misses some. This is unusual:
students who know how to do the problems usually don't miss any. When there's a
task that I know how to do and don't do it correctly, it's usually because I'm being
careless. So he's probably being careless."
If so, their error was in assuming that I was like them. I wasn't missing questions that I
knew how to do because I was being careless. I was missing the questions because
my processing speed and short-term memory are unusually low relative to my other

abilities. With twice as much time, I would have been able to get all of the problems
correctly, but it wasn't physically possible for me to do all of the problems correctly
within the time limit based on what I knew at the time. (The situation may have been
diﬀerent if I had had exposure to mental math techniques, which can substitute for
innate speed and accuracy.)
Even at that age, based on my introspection, I suspected that my teachers were
wrong in their assessment of the situation, and so largely ignored their suggestion,
while at the same time feeling faintly guilty, wondering whether they were right and I
was just rationalizing. I made the right judgment call in that instance - making
a systematic eﬀort to stop making "careless errors" under time constraints wouldn't
have been productive. To avoid such waste we need to delve into a discussion of
innate ability.
Intelligence and innate mathematical ability
I think that mathematical ability is best conceptualized as the ability to recognize
and exploit hidden structure in data. This deﬁnition is nonstandard, and it will
take several posts to explain my choice.  
Abstract pattern recognition ability
A large part of "innate mathematical ability" is "abstract pattern recognition ability,"
which can be operationalized as "the ability to correct answer Raven's Matrices type
items." Tests of Raven's Matrices type are perhaps the purest tests of IQ: the
correlation between performance on them and the g-factor is ~0.8, as high as any IQ
subtest, and answering the items doesn't require any subject matter knowledge. One
example of an item is:
 

The test taker is asked to pick the choice that completes the pattern. People who are
able to pick the correct choice at all can usually do so within 2 minutes - the questions
have the character "either you see it or you don't." Most people can't see the pattern
in the above matrix. A small number of people can see much more subtle patterns.
There's fairly strong evidence that something like 30% of what diﬀerentiates the best
mathematicians in the world from other mathematicians is the innate ability to see
the sorts of patterns that are  present in very diﬃcult Raven's matrices type items. (I'll
make what I mean by "something like 30%" more precise in a future post.)
Fields Medalist Terry Tao was part of the Study of Mathematically Precocious Youth
(SMPY). Professor Julian Stanley wrote: 
On May 1985 I administered to [10 year old] Terry the Raven Progressive Matrices
Advanced, an untimed test. He completed its 36 8-option items in about 45
minutes. Whereas the average British university student scores 21, Terry scored
32. He did not miss any of the last, most diﬃcult, 4 items. Also, when told which 4
items he had not answered correctly, he was quickly able to ﬁnd the correct
response to each. Few of SMPY's ablest protégés, members of its "700-800 on SAT-
M Before Age 13" group, could do as well.
People like Terry are perhaps 1 in a million, but I've had the chance to tutor several
children who are in his general direction.
Descriptions of milestones like "scored 760 on the math SAT at age 8" (as Terry did)
usually greatly understate the ability of these children when the milestone is
interpreted as "comparable to a high school student in the top 1%," in that there's a
connotation that the child's performance comes from the child having learned the
usual things very quickly. The situation is usually closer to "the child hasn't learned
the usual things, but is able to get high scores by solving questions ththat high school
students wouldn't able to able to solve without having studied algebra and geometry."
A impact of interacting with such a child can be overwhelming. I've repeatedly had the
experience of teaching such a child a mathematical topic typically covered only in
graduate math courses, and one that I know well beyond the level of textbook
expositions, and the child responding by making observations that I myself had
missed. The experience is surreal, to the point that I wouldn't have been surprised to
learn that it had all been a dream 30 minutes later. 
I'll give an example to give a taste of a visceral sense for it. In one of my high school
classes, my teacher assigned the problem of evaluating 'x' in the equation below:
 
 

Tangentially, I don't know why we were assigned this problem, which is of
considerable mathematical interest, but also outside of the usual high school
curriculum. In any case, I remember puzzling over it. Based on my experiences with
children similar to Terry, it seems likely that his 8-year old self would see how to
answer it immediately, without having ever seen anything like the problem before.
Roughly speaking, an 8-year old child like Terry can recognize abstract patterns that
very few (if any) of a group of 30 high school students with the math SAT score would
be able to recognize.
In A Parable of Talents, Scott Alexander wrote:
IQ is so important for intellectual pursuits that eminent scientists in some ﬁelds
have average IQs around 150 to 160. Since IQ this high only appears in 1/10,000
people or so, it beggars coincidence to believe this represents anything but a very
strong ﬁlter for IQ (or something correlated with it) in reaching that level. If you
saw a group of dozens of people who were 7'0 tall on average, you'd assume it
was a basketball team or some other group selected for height, not a bunch of
botanists who were all very tall by coincidence.
Of the sciences, pure math is the one where innate abstract pattern ability is most
strongly correlated with success, and data suggest that many of the best
mathematicians in the world have innate abstract pattern recognition possessed by
fewer than 1 in 10,000 people. Terry Tao's innate abstract pattern recognition ability is
much rarer than 1 in 10,000, perhaps 1 in 1 million: it's extremely improbable that
someone with such exceptional innate ability would by chance also be someone who
would go on to do Fields Medal winning research.
Interestingly, many mathematicians are unaware of this. Terry Tao himself wrote:
A reasonable amount of intelligence is certainly a necessary (though not
suﬃcient) condition to be a reasonable mathematician. But an exceptional
amount of intelligence has almost no bearing on whether one is an exceptional
mathematician.
It's not entirely clear to me how somebody as mathematically talented as Tao could
miss the basic Bayesian probabilistic argument that Scott Alexander gave, which
shows that Tao's own existence is very strong evidence against his claim. But two
hypotheses come to mind.
Verbal reasoning ability
Like Grothendieck, like Scott Alexander, and like myself, Tao has very uneven abilities,
only in an entirely diﬀerent direction:
Yet at age 8 years 10 months, when he took both the SAT-M and the SAT-Verbal,
Terry scored only 290 on the latter. Just 9% of college-bound male 12th-graders
score 290 or less on SAT-V; a chance score is about 230. The discrepancy between
being 10 points above the minimum 99th percentile on M and at the 9th
percentile on V represents a gap of about 3.7 standard deviations. Clearly, Terry
did far better with the mathematical reasoning items (please see the Appendix for
examples) than he did reading paragraphs and answering comprehension
questions about them or ﬁguring out antonyms, verbal analogies, or sentences
with missing words.

Was the "lowness" of the verbal score (excellent for one his age, of course) due to
his lack of motivation on that part of the test and/or surprise at its content? A year
later, while this altogether charming boy was spending four days at my home
during early May of 1985, I administered another form of the SAT-V to him under
the best possible conditions. His score rose to 380, which is the 31st percentile.
That's a ﬁne gain, but the M vs. V discrepancy was probably as great as before.
Quite likely, on the SAT score scale his ability had risen appreciably above the 800
ceiling of SAT-M. 
It's likely that principal component analysis would reveal that Tao's relatively low
verbal scores reﬂect still lower ability on some aspect of verbal ability, which he was
able to compensate for with his abstract pattern recognition ability, just as my
relatively low math SAT score reﬂected still lower short-term memory and processing
speed, which I was able to compensate for in other ways.
Aside from abstract pattern recognition ability, verbal reasoning ability is another
major component of innate mathematical ability. It's reﬂected in performance on the
analogies subtests of IQ, which like Raven's Matrices, are among the IQ subtests that
correlate most strongly with the g-factor.  
Broadly, the more theoretical an area of math is, the greater the role of verbal
reasoning is in understanding it and doing research in it. As one would predict based
on his math / verbal skewing, Tao's mathematical research is in areas of math that are
relatively concrete, as opposed to theoretical. Verbal reasoning ability is also closely
connected with metacognition: awareness and understanding of one's own thoughts.
Tao's apparent lack of awareness of the role of his exceptional abstract reasoning
ability in his mathematical success may be attributable to relatively low
metacognition.
[Edit: Some commenters found the above paragraph confusing. I should clarify that
the standard that I have in mind here is extremely high — I'm comparing Tao with
people such as Henri Poincare, whose essays are amongst the most penetrating
analyses of mathematical psychology.]
My own inclination is very much in the verbal direction, as may be evident from my
posts. I used to think that it was a solely a matter of preference, but after reading the
IQ literature, I realized that probably the reason that I have the preference is because
verbal reasoning is what I'm best at, and we tend to enjoy what we're best at the
most.
Charles Spearman, the researcher who discovered the g-factor found that the more
intellectually gifted somebody is, the less correlated his or her cognitive abilities, and
that when one takes this vantage point, Tao's math / verbal ability diﬀerential is not so
unusual. For further detail, see Cognitive proﬁles of verbally and mathematically
precocious students by Benbow and Minor. 
I'll have more to say about the role of verbal reasoning ability in math later on. 
Is this all depressing?
Another reason that Tao may have missed the evidence that his mathematical success
can be in large part attributed to his exceptional abstract reasoning ability is that he
might have an ugh ﬁeld around the subject. Terry might ﬁnd it disconcerting that the
main reason that many of his colleagues at UCLA are unable to produce work that's

nontrivial relative to his own is that he was born with a better brain (in some sense)
than the brains of his colleagues were. Such a perspective can feel dehumanizing.
An analogy that may be oﬀer further insight. Like Tao, Natalie Portman is talented on
many diﬀerent dimensions. But had she been less physically attractive than the
average woman (according to the group consensus), she would not have been able to
become Academy Award winning actress. Women of similar talent probably failed
where she succeeded simply because they were less attractive than she is. If asked
about the role of her physical appearance in her success, she would probably feel
uncomfortable. One can imagine her giving an accurate answer, but one can also
imagine her trying to minimize the signiﬁcance of her appearance as much as
possible. It might remind her of how painfully unfair life can be.
But whether or not we believe in the existence and importance of individual
diﬀerences in intelligence, they're there: we can't make them go away by ignoring
them. Furthermore, if not for people with unusually high intelligence, there would have
been no Renaissance and no industrial revolution: Europe would still be in the dark
ages, as would the rest of the world. We're very lucky to have people with cognitive
abilities like Tao's, and he would have no reason to feel guilty about having being
privileged. He's given back to the community through eﬀorts such as his blog. Even if
one doubts the value of theoretical research, one can still appreciate the fact that his
blog serves as a proof of concept showing how elite scientists in all ﬁelds could better
communicate their thinking to their research communities.
To be continued
I'll have more to say about innate later ability, but I've said enough to move on to a
discussion of the connection between innate ability and mathematical ability more
generally, with a view toward how it's possible to improve one's mathematical ability. 
Since people's primary exposure to math is generally through school, in my next post
I'll discuss math education as it's currently practiced.
My basic premise is that math education as it's currently practiced is extremely
ineﬃcient for reasons that I touched on earlier on: what goes on in math classes in
practice is often very similar to studying for intelligence tests. Students and teachers
are eﬀectively trying to build abilities that are in fact ﬁxed, rather than focusing on
developing abilities that can be improved, just as I would have been if I were to have
worked on making fewer "careless mistakes" in elementary school. Things don't have
to be this way - math education could in principle be much more enriching.
More soon.

The Galileo aﬀair: who was on the
side of rationality?
Introduction
A recent survey showed that the LessWrong discussion forums mostly attract readers
who are predominantly either atheists or agnostics, and who lean towards the left or
far left in politics. As one of the main goals of LessWrong is overcoming bias, I would
like to come up with a topic which I think has a high probability of challenging some
biases held by at least some members of the community. It's easy to ﬁght against
biases when the biases belong to your opponents, but much harder when you yourself
might be the one with biases. It's also easy to cherry-pick arguments which prove your
beliefs and ignore those which would disprove them. It's also common in such
discussions, that the side calling itself rationalist makes exactly the same mistakes
they accuse their opponents of doing. Far too often have I seen people (sometimes
even Yudkowsky himself) who are very good rationalists but can quickly become
irrational and use several fallacies when arguing about history or religion. This most
commonly manifests when we take the dumbest and most fundamentalist young
Earth creationists as an example, winning easily against them, then claiming that we
disproved all arguments ever made by any theist. No, this article will not be about
whether God exists or not, or whether any real world religion is fundamentally right or
wrong. I strongly discourage any discussion about these two topics.
This article has two main purposes:
1. To show an interesting example where the scientiﬁc method can lead to
wrong conclusions
2. To overcome a certain speciﬁc bias, namely, that the pre-modern Catholic
Church was opposed to the concept of the Earth orbiting the Sun with the deliberate
purpose of hindering scientiﬁc progress and to keep the world in ignorance. I hope this
would prove to also be an interesting challenge for your rationality, because it is easy
to ﬁght against bias in others, but not so easy to ﬁght against bias on yourselves.
The basis of my claims is that I have read the book written by Galilei himself, and I'm
very interested (and not a professional, but well read) in early modern, but especially
16-17th century history.
 
Geocentrism versus Heliocentrism
I assume every educated person knows the name of Galileo Galilei. I won't waste the
space on the site and the time of the readers to present a full biography about his life,
there are plenty of on-line resources where you can ﬁnd more than enough biographic
information about him.

The controversy?
What is interesting about him is how many people have severe misconceptions about
him. Far too often he is celebrated as the one sane man in an era of ignorance, the
sole propagator of science and rationality when the powers of that era suppressed any
scientiﬁc thought and ridiculed everyone who tried to challenge the accepted theories
about the physical world. Some even go as far as claiming that people believed the
Earth was ﬂat. Although the ﬂat Earth theory was not propagated at all, it's true that
the heliocentric view of the Solar System (the Earth revolving around the Sun) was not
yet accepted.
However, the claim that the Church was suppressing evidence about heliocentrism "to
maintain its power over the ignorant masses" can be disproved easily:
- The common people didn't go to school where they could have learned about it, and
those commoners who did go to school, just learned to read and write, not much
more, so they wouldn't care less about what orbits around what. This diﬀers from 20-
21th century fundamentalists who want to teach young Earth creationism in schools -
back then in the 17th century, there would be no classes where either the geocentric
or heliocentric views could have been taught to the masses.
- Heliocentrism was not discovered by Galilei. It was ﬁrst proposed by Nicolaus
Copernicus almost 100 years before Galilei. Copernicus didn't have any aﬀairs with
the Inquisition. His theories didn't gain wide acceptance, but he and his followers
weren't persecuted either.
- Galilei was only sentenced to house arrest, and mostly because of insulting the pope
and doing other unwise things. The political climate in 17th century Italy was quite
messy, and Galilei did quite a few unfortunate choices regarding his alliances.
Actually, Galilei was the one who brought religion into the debate: his opponents were
citing Aristotle, not the Bible in their arguments. Galilei, however, wanted to redeﬁne
the Scripture based on his (unproven) beliefs, and insisted that he should have the
authority to push his own views about how people interpret the Bible. Of course this
pissed quite a few people oﬀ, and his case was not helped by publicly calling the pope
an idiot.
- For a long time Galilei was a good friend of the pope, while holding heliocentric
views. So were a couple of other astronomers. The heliocentrism-geocentrism debates
were common among astronomers of the day, and were not hindered, but even
encouraged by the pope.
- The heliocentrism-geocentrism debate was never an ateism-theism debate. The
heliocentrists were committed theists, just like  the defenders of geocentrism. The
Church didn't suppress science, but actually funded the research of most scientists.
- The defenders of geocentrism didn't use the Bible as a basis for their claims. They
used Aristotle and, for the time being, good scientiﬁc reasoning. The heliocentrists
were much more prone to use the "God did it" argument when they couldn't defend
the gaps in their proofs.
 

The birth of heliocentrism.
By the 16th century, astronomers have plotted the movements of the most important
celestial bodies in the sky. Observing the motion of the Sun, the Moon and the stars, it
would seem obvious that the Earth is motionless and everything orbits around it. This
model (called geocentrism) had only one minor ﬂaw: the planets would sometimes
make a loop in their motion, "moving backwards". This required a lot of very
complicated formulas to model their motions. Thus, by the virtue of Occam's razor, a
theory was born which could better explain the motion of the planets: what if the
Earth and everything else orbited around the Sun? However, this new theory
(heliocentrism) had a lot of issues, because while it could explain the looping motion
of the planets, there were a lot of things which it either couldn't explain, or the
geocentric model could explain it much better.
 
The proofs, advantages and disadvantages
The heliocentric view had only a single advantage against the geocentric one: it could
describe the motion of the planets by a much simper formula.
However, it had a number of severe problems:
- Gravity. Why do the objects have weight, and why are they all pulled towards the
center of the Earth? Why don't objects fall oﬀ the Earth on the other side of the
planet? Remember, Newton wasn't even born yet! The geocentric view had a very
simple explanation, dating back to Aristotle: it is the nature of all objects that they
strive towards the center of the world, and the center of the spherical Earth is the
center of the world. The heliocentric theory couldn't counter this argument.
- Stellar parallax. If the Earth is not stationary, then the relative position of the stars
should change as the Earth orbits the Sun. No such change was observable by the
instruments of that time. Only in the ﬁrst half of the 19th century did we succeed in
measuring it, and only then was the movement of the Earth around the Sun ﬁnally
proven.
- Galilei tried to used the tides as a proof. The geocentrists argued that the tides are
caused by the Moon even if they didn't knew by what mechanisms, but Galilei said
that it's just a coincidence, and the tides are not caused by the Moon: just as if we put
a barrel of water onto a cart, the water would be still if the cart was stationary and the
water would be sloshing around if the cart was pulled by a horse, so are the tides
caused by the water sloshing around as the Earth moves. If you read Galilei's book,
you will discover quite a number of such silly arguments, and you'll see that Galilei
was anything but a rationalist. Instead of changing his views against overwhelming
proofs, he used  all possible fallacies to push his view through.
Actually the most interesting author in this topic was Riccioli. If you study his writings
you will get deﬁnite proof that the heliocentrism-geocentrism debate was handled
with scientiﬁc accuracy and rationality, and it was not a religious debate at all. He
defended geocentrism, and presented 126 arguments in the topic (49 for
heliocentrism, 77 against), and only two of them (both for heliocentrism) had any
religious connotations, and he stated valid responses against both of them. This

means that he, as a rationalist, presented both sides of the debate in a neutral way,
and used reasoning instead of appeal to authority or faith in all cases. Actually this
was what the pope expected of Galilei, and such a book was what he commissioned
from Galilei. Galilei instead wrote a book where he caricatured the pope as a
strawman, and instead of presenting arguments for and against both world-views in a
neutral way, he wrote a book which can be called anything but scientiﬁc.
By the way, Riccioli was a Catholic priest. And a scientist. And, it seems to me, also a
rationalist. Studying the works of such people like him, you might want to change your
mind if you perceive a conﬂict between science and religion, which is part of today's
public consciousness only because of a small number of very loud religious
fundamentalists, helped by some committed atheists trying to suggest that all theists
are like them.
Finally, I would like to copy a short summary about this book:
Graney, Christopher M.
Journal for the History of Astronomy, Vol. 43, No. 2, p. 215-226
In 1651 the Italian astronomer Giovanni Battista Riccioli published within his
Almagestum Novum, a massive 1500 page treatise on astronomy, a discussion of
126 arguments for and against the Copernican hypothesis (49 for, 77 against). A
synopsis of each argument is presented here, with discussion and analysis. Seen
through Riccioli's 126 arguments, the debate over the Copernican hypothesis
appears dynamic and indeed similar to more modern scientiﬁc debates. Both sides
present good arguments as point and counter-point. Religious arguments play a
minor role in the debate; careful, reproducible experiments a major role. To
Riccioli, the anti-Copernican arguments carry the greater weight, on the basis of a
few key arguments against which the Copernicans have no good response. These
include arguments based on telescopic observations of stars, and on the apparent
absence of what today would be called "Coriolis Eﬀect" phenomena; both have
been overlooked by the historical record (which paints a picture of the 126
arguments that little resembles them). Given the available scientiﬁc knowledge in
1651, a geo-heliocentric hypothesis clearly had real strength, but Riccioli presents
it as merely the "least absurd" available model - perhaps comparable to the
Standard Model in particle physics today - and not as a fully coherent theory.
Riccioli's work sheds light on a fascinating piece of the history of astronomy, and
highlights the competence of scientists of his time.
The full article can be found under this link. I recommend it to everyone interested in
the topic. It shows that geocentrists at that time had real scientiﬁc proofs and real
experiments regarding their theories, and for most of them the heliocentrists had no
meaningful answers.
 
Disclaimers:
- I'm not a Catholic, so I have no reason to defend the historic Catholic church due to
"justifying my insecurities" - a very common accusation against someone perceived to
be defending theists in a predominantly atheist discussion forum.

- Any discussion about any perceived proofs for or against the existence of God would
be oﬀ-topic here. I know it's tempting to show oﬀ your best proofs against your
carefully constructed straw-men yet again, but this is just not the place for it, as it
would detract from the main purpose of this article, as summarized in its introduction.
- English is not my native language. Nevertheless, I hope that what I wrote was
comprehensive enough to be understandable. If there is any part of my article which
you ﬁnd ambiguous, feel free to ask.
I have great hopes and expectations that the LessWrong community is suitable to
discuss such ideas. I have experience with presenting these ideas on other,
predominantly atheist internet communities, and most often the reactions was
outright ﬂaming, a hurricane of unexplained downvotes, and prejudicial ad hominem
attacks based on what aﬃliations they assumed I was subscribing to. It is common for
people to decide whether they believe a claim or not, based solely by whether the
claim suits their ideological aﬃliations or not. The best quality of rationalists, however,
should be to be able to change their views when confronted by overwhelming proof,
instead of trying to come up with more and more convoluted explanations. In the time
I spent in the LessWrong community, I became to respect that the people here can
argue in a civil manner, listening to the arguments of others instead of discarding
them outright.
 

An alarming fact about the anti-aging
community
Past and Present
Ten years ago teenager me was hopeful. And stupid.
The world neglected aging as a disease, Aubrey had barely started spreading memes,
to the point it was worth it for him to let me work remotely to help with Metuselah
foundation. They had not even received that initial 1,000,000 donation from an
anonymous donor. The Metuselah prize was running for less than 400,000 if I
remember well. Still, I was a believer.
Now we live in the age of Larry Page's Calico, 100,000,000 dollars trying to tackle the
problem, besides many other amazing initiatives, from the research paid for by Life
Extension Foundation and Bill Faloon, to scholars in top universities like Steve Garan
and Kenneth Hayworth ﬁxing things from our models of aging to plastination
techniques. Yet, I am much more skeptical now.
Individual risk
I am skeptical because I could not ﬁnd a single individual who already used a simple
technique that could certainly save you many years of healthy life. I could not even
ﬁnd a single individual who looked into it and decided it wasn't worth it, or was too
pricy, or something of that sort.
That technique is freezing some of your cells now.
Freezing cells is not a far future hope, this is something that already exists, and has
been possible for decades. The reason you would want to freeze them, in case you
haven't thought of it, is that they are getting older every day, so the ones you have
now are the youngest ones you'll ever be able to use.
Using these cells to create new organs is not something that may help you if medicine
and technology continue progressing according to the law of accelerating returns in 10
or 30 years. We already know how to make organs out of your cells. Right now. Some
organs live longer, some shorter, but it can be done - for instance to bladders - and is
being done.
Hope versus Reason
Now, you'd think if there was an almost non-invasive technique already shown to work
in humans that can preserve many years of your life and involves only a few trivial
inconveniences - compared to changing diet or exercising for instance- the whole
longevist/immortalist crowd would be lining up for it and keeping back up tissue
samples all over the place.

Well I've asked them. I've asked some of the adamant researchers, and I've asked the
superwealthy; I've asked the cryonicists and supplement gorgers; I've asked those
who work on this 8 hour a day every day, and I've asked those who pay others to do
so. I asked it mostly for selﬁsh reasons, I saw the TEDs by Juan Enriquez and Anthony
Atala and thought: hey look, clearly beneﬁcial expected life length increase, yay! let
me call someone who found this out before me - anyone, I'm probably the last one,
silly me - and ﬁx this.
I've asked them all, and I have nothing to show for it.
My takeaway lesson is: whatever it is that other people are doing to solve their own
impending death, they are far from doing it rationally, and maybe most of the money
and psychology involved in this whole business is about buying hope, not about
staring into the void and ﬁnding out the best ways of dodging it. Maybe people are not
in fact going to go all-in if the opportunity comes.
How to ﬁx this?
Let me disclose ﬁrst that I have no idea how to ﬁx this problem. I don't mean the
problem of getting all longevists to freeze their cells, I mean the problem of getting
them to take information from the world of science and biomedicine and applying it to
themselves. To become users of the technology they are boasters of. To behave
rationally in a CFAR or even homo economicus sense.
I was hoping for a grandiose idea in this last paragraph, but it didn't come. I'll go with
a quote from this emotional song sung by us during last year's Secular Solstice
celebration
Do you realize? that everyone, you know, someday will die...
And instead of sending all your goodbyes
Let them know you realize that life goes fast
It's hard to make the good things last

The Value of a Life
This is a linkpost for http://mindingourway.com/the-value-of-a-life/
This post is cross-posted from MindingOurWay . It's about some of my reasons for
being an eﬀective altruist. It's targeted more towards people who aren't EAs or who
haven't heard of eﬀective altruism, but some people here may also ﬁnd it inspiring.
If you have money and want to save lives, you had better put a price on life. Scott
Alexander explains it better than I can.
But don't mix up the price of a life with the value of a life. I see this happen all too
frequently. To correct this mistake, I'm going to tell a little story.
 
Once upon a time, there was a village of peaceful immortal humans. They did not age
past their primes, but they could still die from starvation or injury. But perhaps
because their lives were so long and full, they all valued each other very highly and
lived in peace. Indeed, there were no lengths to which the villagers would not go in
order to save one of their fellows from unwanted annihilation.
Or, at least, that's how life was before the dragon came.
Dragons desire two things from people, as I'm sure you know: gold, and ﬂesh. And this
dragon, woe be upon the villagers, was powerful indeed — nigh invincible, with a
cunning to match. The dragon, easily capable of killing the entire village outright,
gave a grim ultimatum:
Each person in this village must pay a tax of gold, every year, in proportion to that
person's age. Anyone who cannot pay the tax will be eaten.
The villagers begged and pleaded, they wept and raged, but the dragon was
unmoved. It merely showed them a few heaps of rock that looked likely to make good
gold mines, and told them to get to work.
The villagers tried their best. They really did. They were not miners, but they were fast
learners. They worked themselves ragged, throwing aside stones, digging at the earth
with their bare hands until their ﬁngers bled, hunting and gathering as little as
possible, letting their shelters deteriorate — yet still, they could not make the
dragon's tax. At the end of a year, the dragon returned, and took all the gold they
had, and ten of the oldest villagers (for giving up the eldest villagers was the way to
save the most lives).
Distraught, the villagers resolved to try harder next time. They pushed themselves to
their limits and beyond. They raced against time. They grew gaunt and ragged. Their
eyes sank, their skin grew sallow, their arms thinned. They pushed themselves too
hard, until they were collapsing in the mines. The next time the dragon came, it took
all their gold and ﬁfty of their number.
Their strategy wasn't working.

But these villagers were born of humanity, and ingenuity is humanity's birthright. So
in their third year, the surviving villagers came to bitter terms with their situation, and
set to hunting and gathering and growing stronger, accepting that they had to take
care of themselves before they could take care of their friends. They set to building
picks and shovels, realizing that they could not save themselves with their hands
alone.
At the end of the third year, the dragon took all their gold and one hundred of their
number, for their infrastructure had not yet started paying oﬀ.
But by the end of the fourth year, the dragon only took two.
Shortly thereafter, the dragon (delighted by their progress) informed the villagers that
the tax would now begin increasing faster; exponentially in age.
This time, the villagers only nodded, and forged their hot fury into cold resolve.
It has been many, many years since the dragon came to the village. In fact, it is not a
village any more: the village grew to a city, and the city grew to a civilization.
The population is quite a bit younger now. The elders are wiser and more productive,
and can get more gold out of the ground per hour, but there simply comes a time
when this increased productivity is not worth the cost in lives. When that time comes,
the elders go willingly to their fate, for these people are not the type to buy their own
lives at the cost of two others.
In fact, hard tradeoﬀs such as these are commonplace. The villagers long ago
discovered specialization and economics, and now most of them don't work in the
mines. Some of them spend time growing or preparing food, others spend time
maintaining shelter, others spend time inventing new tools and mechanisms that can
keep pace with the dragon's dreadful tax. Indeed, some spend their lives on art and
entertainment — for the villagers have learned the importance of maintaining
motivation and morale.
(And some villagers, deep underground, far from the dragon's prying eyes, are
designing weapons.)
So you will ﬁnd, in this civilization, that there are people who dedicate their lives not
to mining gold, but to writing books — but if you look closely, you'll notice that this
only happens when the author can save more lives through increased morale and
productivity than they can through working in the mines directly. And so this
civilization, hellbent on saving as many people as it can every year, still produces
books and plays and movies.
Which means that in modern times, you can calculate the exact cost of saving an
additional life. It turns out that one life goes for about the same price as a thousand
movie tickets.
As it happens, two of the citizens of this dragon-ridden world, Alice and Bob, are
having a conversation about the value of a life, right now. Let's listen in:
Alice: So you see, the true value of a life is equivalent to about a thousand views on
the latest blockbuster.

Bob: Nonsense! A life is worth much more than two thousand hours of movie-viewing!
A life is nigh invaluable! You can't put a price tag on a human life!
Alice: What hollow indignation! If your actions are inconsistent with putting a price
tag on life, then there are ways you could shuﬄe money around to save more lives. If
you want to save as many people as possible with a limited amount of money, then
you must put a price on life!
Bob: But a thousand viewings of a movie simply isn't worth the same as a life! If I got
to choose between a thousand people watching another blockbuster and the life of my
mother, I'd choose the life of my mother any day!
Alice: Yes, but this intuition is inconsistent. The market for lives here is eﬀecient, and
the market has spoken, and the market says that a life is equal to about a thousand
views of the latest blockbuster. Your mother's life isn't worth more than the
accumulated pleasure that a thousand people experience when watching the latest
blockbuster! The viewing experience and your mother's life just turn out to have the
same value, and if your intuition disagrees, you'll have to ﬁx your intuition!
Do you see the errors here?
Alice and Bob are both right, and both wrong.
Alice is correct in that the villagers must treat a life as equivalent to a few thousand
hours worth of watching movies. Given that the villagers are all still trying to save
each other, those thousand people only go to the movies if the resulting boost in
motivation and morale leads them to collectively generate enough additional wealth
to save more than one additional person. If you stopped those people going to the
movies, and put their money towards producing gold instead, then less gold would be
produced overall, and more people would die. Bob must trade oﬀ two thousand movie-
hours against one life, if he wants to maximize lives saved.
But Bob is correct in that the value of a life is worth much more than two thousand
hours of viewing movies!
Alice's claim is that the sum experience of two thousand movie-hours is equal to the
intrinsic value of a life. The market has spoken, and so you must not protest, if you
want to save lives.
But in fact, the very reason that Bob must treat the thousand movie-viewings as
equivalent to a life is because those viewings lead to increased morale, which leads to
more than one life being saved. This fact does not equate the experience of a life lived
to the pleasure of the viewers.
What Alice has forgotten is that the village is plagued by a dragon.
Were it not for the dragon, these villagers would go to almost any lengths to save
each other from unwanted death. There might be some lengths to which they would
not go, some price they would not pay, in pain, sorrow, and decreased quality of life
among the rest of the villagers, in order to save a friend. But, in the absence of a
dragon, this cost would be a hell of a lot higher than two-thousand hours worth of
watching movies.

Enough analogies. Let's look at our universe, now. Our economy is not eﬃcient — it
costs a few million dollars to save a life in developed nations, and a few thousand
dollars to save a life in underdeveloped nations (where "save a life" really only means
"push death back a bit", in these dark times). Furthermore, our economy is not
maximizing for lives: humans are prone to scope insensitivity and a whole slew of
other biases that dampen their ability to care about other humans dying against their
will. Furthermore, it is important to care not only about the lives we save, but about
the lives we live.
Despite all this, we are not all that diﬀerent from those villagers in the lengths we
would go to save each other if death was not inevitable.
I don't know how the future will turn out. I don't know how we'll end up trading oﬀ the
preservation of a life against the improvement of a life against the creation of a life, if
and when we make it past this phase of scarcity. But I can tell you this: There may well
come a day when humanity would tear apart a thousand suns in order to prevent a
single untimely death.
That is the value of a life.
You still have to put a price tag on lives, and that price tag still has to somewhere
between a few thousand dollars and a few million dollars.
Imagine a button which, when pressed, picks a random number between 1 and a
million. If that number is 1, it kills a randomly selected person. How much would
somebody have to pay you to press that button?
Many people react with disgust, saying they wouldn't press such a button at any price.
They say that the value of a life is nigh inconceivable.
And this intuition is correct!
But when somebody oﬀers you ten dollars to press that button, press it anyway. Press
it, and worry about it less than you worry about driving a car for a year (which, if I did
my math right, is like pressing a button that has a one in ten thousand chance of
killing somebody each year, in return for the convenience of driving [1] [2]). If you
want to save the most lives, then you press that button for $10, and you put the
money towards saving lives.
But don't confuse the cost of a life with the value of a life!
In some parts of this world, it costs as little as a few thousand dollars to save a life. If
you act like the price on a life is higher than a few thousand dollars, if you actually
refuse a million dollars to press the button, or pay a billion dollars to save a single life,
then there were other things you could have done to save more lives. If you want to
save the most people, you must put a price tag on life according to the actual cost of
saving a life.
But you don't have to confuse the current cost of saving a life with the intrinsic value
of a life.
There is a gap there. There is a gap between how much a life is really worth, and the
price tag that you must assign. That gap is not there because your intuitions are
wrong. That gap is there because our village is being plagued by a godamn dragon.

That gap is a direct measure of the diﬀerence between the universe that is, and the
universe that should be.
That price diﬀerence, the diﬀerence between a few thousand dollars and a few
thousand suns, is a direct measure of how fucked up things are.
Most people start with an intuition that they should refuse to press the button at any
price, because lives are nigh invaluable. You can go to these people, and show them
that in order to save as many lives as possible with a bounded amount of money, they
must put a price on life. Most people, at that point, react one of two ways.
Some accept the logic and reject their intuitions. They see that, to save the most lives,
they must use a price tag. It sounds repugnant to say that the pleasure experienced
by a few million people drinking a can of soda is equivalent to the value of a life, but
(they think) that's exactly the sort of reasoning that leads someone to thinking that
life is invaluable, which is a deadly misconception. And so, wanting to save as many
people as they can with the money allotted to life-saving, they bite the bullet, and
conclude that lives were never worth all that much anyway.
Others reject the logic, and continue to claim that life is invaluable, and then try to
back up their intuitions with some strange version of ethics where saving as many
lives as possible with the money available is not the right thing to do, for convoluted
reasons.
But there's a third option here! All these people have forgotten about the dragon!
It is possible to live in a universe where it is both the case that (1) lives are nigh
invaluable, and (2) people are being annihilated constantly, against their will, in ways
that can be prevented using relatively small sums of money.
The universe is not fair! Pressing the button for $10 is the way to save the most lives,
and this very fact is a horrible thing. Lives are nigh invaluable, but you have to treat
them as if they're worth only a few thousand dollars.
This gap between price and value is unacceptable, but physics wasn't written
according to what we would accept. We live in a cold, uncaring universe; a universe
beyond the reach of God.
One day, we may slay the dragons that plague us. One day we, like the villagers in
their early days, may have the luxury of going to any length in order to prevent a
fellow sentient mind from being condemned to oblivion unwillingly. If we ever make it
that far, the worth of a life will be measured not in dollars, but in stars.
That is the value of a life. It will be the value of a life then, and it is the value of a life
now.
So when somebody oﬀers $10 to press that button, you press it. You press the hell out
of it. It's the best strategy available to you; it's the only way to save as many people
as you can. But don't ever forget that this very fact is a terrible tragedy.
Don't ever forget about the gap between how little a life costs and how much a life is
worth. For that gap is an account of the darkness in this universe, it is a measure of
how very far we have left to go.

I don't want to turn this into a sermon. But some of you, seeing the great abyss
between cost and worth clearly for the ﬁrst time, may decide that this gap is worth
closing, that our dragons are dragons are worth slaying. Some of you may be
wondering, what now? What next? This last part is for you.
Know that there are those of us who ﬁght.
Some of us work in the mines to make the dragon's tax. Others prepare for the day we
will confront the dragon — for the weapons we must bring to bear will be powerful
indeed, and may prove diﬃcult to aim.
And this is a ﬁght you can join. For some of you, ﬁghting means joining an eﬀective
cause. But for most of you, ﬁghting means putting a low price tag on lives, and then
honoring it — by purchasing lives wherever they are cheapest; by donating to highly
eﬀective causes. Remember that just as courage is about doing the right thing even
though you're afraid, caring is about doing the right thing even when you're not
overwhelmed by emotion.
If this is a ﬁght you wish to join, then I urge you to remember the ﬁrst lesson that the
villagers learned: you must care for yourself before you care for others. You do not
need to become destitute to struggle against the darkness in this universe. Any small
amount of money or eﬀort you can put towards saving lives is money and eﬀort well
spent. Pledging 10% of your earnings to an eﬀective cause is a diﬃcult achievement
worthy of great acclaim.
If you are going to stand beside us in this ﬁght, then I will welcome you no matter
what — but I would rather you join us ﬁlled with hot fury or cold resolve, rather than
with guilt or shame.
Oh, Death was never an enemy of ours!
We laughed with him, we leagued with him, old chum.
No soldier's paid to kick against his powers.
We laughed, knowing that better men would come,
And greater wars; when each proud ﬁghter brags
He wars on Death, for lives; not men, for ﬂags.
— Final stanza of The Next War, by Wilfred Owen
 

