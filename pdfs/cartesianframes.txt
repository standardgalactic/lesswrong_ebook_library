
Cartesian Frames
1. Introduction to Cartesian Frames
2. Additive Operations on Cartesian Frames
3. Biextensional Equivalence
4. Controllables and Observables, Revisited
5. Functors and Coarse Worlds
6. Subagents of Cartesian Frames
7. Multiplicative Operations on Cartesian Frames
8. Sub-Sums and Sub-Tensors
9. Additive and Multiplicative Subagents
10. Committing, Assuming, Externalizing, and Internalizing
11. Eight Deﬁnitions of Observability
12. Time in Cartesian Frames
13. Cartesian Frames and Factored Sets on ArXiv

Introduction to Cartesian Frames
Crossposted from the AI Alignment Forum. May contain more technical jargon than usual.
This is the ﬁrst post in a sequence on Cartesian frames, a new way of modeling agency that has recently
shaped my thinking a lot.
Traditional models of agency have some problems, like:
They treat the "agent" and "environment" as primitives with a simple, stable input-output relation. (See
"Embedded Agency.")
They assume a particular way of carving up the world into variables, and don't allow for switching
between diﬀerent carvings or diﬀerent levels of description.
Cartesian frames are a way to add a ﬁrst-person perspective (with choices, uncertainty, etc.) on top of a
third-person "here is the set of all possible worlds," in such a way that many of these problems either
disappear or become easier to address.
The idea of Cartesian frames is that we take as our basic building block a binary function which combines a
choice from the agent with a choice from the environment to produce a world history.
We don't think of the agent as having inputs and outputs, and we don't assume that the agent is an object
persisting over time. Instead, we only think about a set of possible choices of the agent, a set of possible
environments, and a function that encodes what happens when we combine these two.
This basic object is called a Cartesian frame. As with dualistic agents, we are given a way to separate out an
"agent" from an "environment." But rather than being a basic feature of the world, this is a "frame" — a
particular way of conceptually carving up the world.
We will use the combinatorial properties of a given Cartesian frame to derive versions of inputs, outputs and
time. One goal here is that by making these notions derived rather than basic, we can make them more
amenable to approximation and thus less dependent on exactly how one draws the Cartesian boundary.
Cartesian frames also make it much more natural to think about the world at multiple levels of description,
and to model agents as having subagents.
Mathematically, Cartesian frames are exactly Chu spaces. I give them a new name because of my speciﬁc
interpretation about agency, which also highlights diﬀerent mathematical questions.
Using Chu spaces, we can express many diﬀerent relationships between Cartesian frames. For example,
given two agents, we could talk about their sum (⊕), which can choose from any of the choices available to
either agent, or we could talk about their tensor (⊗), which can accomplish anything that the two agents
could accomplish together as a team.
Cartesian frames also have duals (−∗) which you can get by swapping the agent with the environment, and 
⊕ and ⊗ have De Morgan duals (& and ⅋  respectively), which represent taking a sum or tensor of the
environments. The category also has an internal hom, ⊸, where C ⊸D can be thought of as "D with a C-
shaped hole in it." These operations are very directly analogous to those used in linear logic.
 
1. Deﬁnition
Let W be a set of possible worlds. A Cartesian frame C over W is a triple C = (A, E, ⋅), where A represents a
set of possible ways the agent can be, E represents a set of possible ways the environment can be, and 
⋅: A × E →W is an evaluation function that returns a possible world given an element of A and an element of 
E.

We will refer to A as the agent, the elements of A as possible agents, E as the environment, the elements of E
 as possible environments, W as the world, and elements of W as possible worlds.
Deﬁnition: A Cartesian frame C over a set W is a triple (A, E, ⋅), where A and E are sets and ⋅: A × E →W. If 
C = (A, E, ⋅) is a Cartesian frame over W, we say Agent(C) = A, Env(C) = E, World(C) = W, and Eval(C) = ⋅.
A ﬁnite Cartesian frame is easily visualized as a matrix, where the rows of the matrix represent possible
agents, the columns of the matrix represent possible environments, and the entries of the matrix are possible
worlds:
E
e1
e2
e3
A
a1
a2
a3
⎛
⎜
⎝
w1
w2
w3
w4
w5
w6
w7
w8
w9
⎞
⎟
⎠
.
E.g., this matrix tells us that if the agent selects a3 and the environment selects e1, then we will end up in
the possible world w7.
Because we're discussing an agent that has the freedom to choose between multiple possibilities, the
language in the deﬁnition above is a bit overloaded. You can think of A as representing the agent before it
chooses, while a particular a ∈A represents the agent's state after making a choice.
Note that I'm speciﬁcally not referring to the elements of A as "actions" or "outputs"; rather, the elements of 
A are possible ways the agent can choose to be.
Since we're interpreting Cartesian frames as ﬁrst-person perspectives tacked onto sets of possible worlds,
we'll also often phrase things in ways that identify a Cartesian frame C with its agent. E.g., we will say "C0
 is a subagent of C1" as a shorthand for "C0's agent is a subagent of C1's agent."
We can think of the environment E as representing the agent's uncertainty about the set of counterfactuals,
or about the game that it's playing, or about "what the world is as a function of my behavior."
A Cartesian frame is eﬀectively a way of factoring the space of possible world histories into an agent and an
environment. Many diﬀerent Cartesian frames can be put on the same set of possible worlds, representing
diﬀerent ways of doing this factoring. Sometimes, a Cartesian frame will look like a subagent of another
Cartesian frame. Other times, the Cartesian frames may look more like independent agents playing a game
with each other, or like agents in more complicated relationships.
 
2. Normal-Form Games
When viewed as a matrix, a Cartesian frame looks much like the normal form of a game, but with possible
worlds rather than pairs of utilities as entries.
In fact, given a Cartesian frame over W, and a function from W to a set V , we can construct a Cartesian
frame over V  by composing them in the obvious way. Thus, if we had a Cartesian frame (A, E, ⋅) and a pair of
utility functions UA : W →R and UE : W →R, we could construct a Cartesian frame over R2, given by (A, E, ⋆),

where a ⋆e := (UA(a ⋅e), UE(a ⋅e)). This Cartesian frame will look exactly like the normal form of a game.
(Although it is a bit weird to think of the environment set as having a utility function.)
We can use this connection with normal-form games to illustrate three features of the ways in which we will
use Cartesian frames.
 
2.1. Coarse World Models
First, note that we can talk about a Cartesian frame over R2, even though one would not normally think of R2
 as a set of possible worlds.
In general, we will often want to talk about Cartesian frames over "coarse" models of the world, models that
leave out some details. We might have a world model W that fully speciﬁes the universe at the subatomic
level, while also wanting to talk about Cartesian frames over a set V  of high-level descriptions of the world.
We will construct Cartesian frames over V  by composing Cartesian frames over W with the function from W
 to V  that sends more reﬁned, detailed descriptions of the universe to coarser descriptions of the same
universe.
In this way, we can think of an element of (r1, r2) ∈R2 as the coarse, high-level possible world given by
"Those possible worlds for which UA = r1 and UE = r2."
Deﬁnition: Given a Cartesian frame C = (A, E, ⋅) over W, and a function f : W →V , let f ∘(C) denote the
Cartesian frame over V , f ∘(C) = (A, E, ⋆), where a ⋆e = f(a ⋅e).
 
2.2. Symmetry
Second, normal-form games highlight the symmetry between the players.
We do not normally think about this symmetry in agent-environment interactions, but this symmetry will be a
key aspect of Cartesian frames. Every Cartesian frame C = (A, E, ⋅) has a dual which swaps A and E and
transposes the matrix.
 
2.3. Relation to Extensive-Form Games
Third, much of what we'll be doing with Cartesian frames in this sequence can be summarized as "trying to
infer extensive-form games from normal-form games" (ignoring the "games" interpretation and just looking
at what this would entail formally).
Consider the ultimatum game. We can represent this game in extensive form:

Given any game in extensive form, we can then convert it to a game in normal form. In this case:
O f f e r   6 
O f f e r   3 
A c c e p t   6 , A c c e p t   3 
6 , 6 
9 , 3 
A c c e p t   6 , R e j e c t   3 
6 , 6 
0 , 0 
R e j e c t   6 , A c c e p t   3 
0 , 0 
9 , 3 
R e j e c t   6 , R e j e c t   3 
0 , 0 
0 , 0 
The strategies in the normal-form game are the policies in the extensive-form game.
If we then delete the labels, so now we just have a bunch of combinatorial structure about which things send
you to the same place, I want to know when we can infer properties of the original extensive-form game, like
time and information states.
Although we've used games to note some features of Cartesian frames, we should be clear that Cartesian
frames aren't about utilities or game-theoretic rationality. We are not trying to talk about what the agent
does, or what the agent should do. In fact, we are eﬀectively taking as our most fundamental building block
that an agent can freely choose from a set of available actions.
The theory of Cartesian frames is trying to understand what agents' options are. Utility functions and facts
about what the agent actually does can possibly later be placed on top of the Cartesian frame framework,
but for now we will be focusing on building up a calculus of what the agent could do.
 
3. Controllables

We would like to use Cartesian frames to reconstruct ideas like "an agent persisting over time," inputs (or
"what the agent can learn"), and outputs (or "what the agent can do"), by taking as basic:
1. an agent's ability to "freely choose" between options;
2. a collection of possible ways those options can correspond to world histories; and
3. a notion of when world histories are considered the same in some coarse world model.
In this way, we hope to ﬁnd new ways of thinking about partial and approximate versions of these concepts.
Instead of thinking of the agent as an object with outputs, I expect a more embedded view to think of all the
facts about the world that the agent can force to be true or false.
This includes facts of the form "I output foo," but it also includes facts that are downstream from immediate
outputs. Since we're working with "what can I make happen?" rather than "what is my output?", the theory
becomes less dependent on precisely answering questions like "Is my output the way I move my mouth, or is
it the words that I say?"
We will call the analogue of outputs in Cartesian frames controllables. The types of our versions of
"outputs" and "inputs" are going to be subsets of W, which we can think of as properties of the world. E.g., S
 might be the set of worlds in which woolly mammoths exist; we could then think of "controlling S" as
"controlling whether or not mammoths exist."
We'll deﬁne what an agent can control as follows. First, given a Cartesian frame C = (A, E, ⋅) over W, and a
subset S of W, we say that S is ensurable in C if there exists an a ∈A such that for all e ∈E, we have 
a ⋅e ∈S. Equivalently, we say that S is ensurable in C if at least one of the rows in the matrix only contains
elements of S.
Deﬁnition: Ensure(C) = {S ⊆W | ∃a ∈A,  ∀e ∈E,  a ⋅e ∈S}.
If an agent can ensure S, then regardless of what the environment does — and even if the agent doesn't
know what the environment does, or its behavior isn't a function of what the environment does — the agent
has some strategy which makes sure that the world ends up in S. (In the degenerate case where the agent is
empty, the set of ensurables is empty.)
Similarly, we say that S is preventable in C if at least one of the rows in the matrix contains no elements of S.
Deﬁnition: Prevent(C) = {S ⊆W | ∃a ∈A,  ∀e ∈E,  a ⋅e ∉S}.
If S is both ensurable and preventable in C, we say that S is controllable in C.
Deﬁnition: Ctrl(C) = Ensure(C) ∩Prevent(C).
 
3.1. Closure Properties
Ensurability and preventability, and therefore also controllability, are closed under adding possible agents to 
A and removing possible environments from E.
Claim: If A′ ⊇A and E′ ⊆E, and if for all a ∈A and e ∈E′ we have a ⋆e = a ⋅e, then Ctrl(A′, E′, ⋆) ⊇Ctrl(A, E, ⋅).
Proof: Trivial. □
Ensurables are also trivially closed under supersets. If I can ensure some set of worlds, then I can ensure
some larger set of worlds representing a weaker property (like "mammoths exist or cave bears exist").

Claim: If S1 ⊆S2 ⊆W, and S1 ∈Ensure(C), then S2 ∈Ensure(C).
Proof: Trivial. □
Prevent(C) is similarly closed under subsets. Ctrl(C) need not be closed under subsets or supersets.
Since Ensure(C) and Prevent(C) will often be large, we will sometimes write them using a minimal set of
generators.
Deﬁnition: Let ⟨S1, ... , Sn⟩⊃ denote the the closure of {S1, ... , Sn} under supersets. Let ⟨S1, ... , Sn⟩⊂ denote
the closure of {S1, ... , Sn} under subsets.
 
3.2. Examples of Controllables
Let us look at some simple examples. Consider the case where there are two possible environments, r for
rain, and s for sun. The agent independently chooses between two options, u for umbrella, and n for no
umbrella. A = {u, n} and E = {r, s}. There are four possible worlds, W = {ur, us, nr, ns}. We interpret ur as the
world where the agent has an umbrella and it is raining, and similarly for the other worlds. The Cartesian
frame, C1, looks like this:
C1 =      
r
s
u
n
(
ur
us
nr
ns ) .
Ensure(C1) = ⟨{ur, us}, {nr, ns}⟩⊃, or
{ { u r , u s } , { n r , n s } , { u r , u s , n r } , { u r , u s , n s } , { n r , n s , u r } , { n r , n s , u s } , W } ,
and Prevent(C1) = ⟨{ur, us}, {nr, ns}⟩⊂, or
{ { u r , u s } , { n r , n s } , { u r } , { u s } , { n r } , { n s } , { } } .
Therefore Ctrl(C1) = {{ur, us}, {nr, ns}}.
The elements of Ctrl(C1) are not actions, but subsets of W: rather than assuming a distinction between
"actions" and other events, we just say that the agent can guarantee that the actual world is drawn from the
set of possible worlds in which it has an umbrella ({ur, us}), and it can guarantee that the actual world is
drawn from the set of possible worlds in which it doesn't have an umbrella ({nr, ns}).
Next, let's modify the example to let the agent see whether or not it is raining before choosing whether or not
to carry an umbrella. The Cartesian frame will now look like this:

C2 =      
r
s
u
n
u ↔r
u ↔s
⎛
⎜ 
⎜ 
⎜
⎝
ur
us
nr
ns
ur
ns
nr
us
⎞
⎟ 
⎟ 
⎟
⎠
.
The agent is now larger, as there are two new possibilities: it can carry the umbrella if and only if it rains, or it
can carry the umbrella if and only if it is sunny. Ctrl(C2) will also be larger than Ctrl(C1). 
Ctrl(C2) = {{ur, us}, {nr, ns}, {ur, ns}, {nr, us}}.
Under one interpretation, the new options u ↔r and u ↔s feel diﬀerent from the old ones u and n. It feels like
the agent's basic options are to either carry an umbrella or not, and the new options are just incorporating u
 and n into more complicated policies.
However, we could instead view the agent's "basic options" as a choice between "I want my umbrella-
carrying to match when it rains" and "I want my umbrella-carrying to match when it's sunny." This makes u
 and n feel like the conditional policies, while u ↔r and u ↔s feel like the more basic outputs. Part of the point
of the Cartesian frame framework is that we are not privileging either interpretation.
Consider now a third example, where there is a third possible environment, m, for meteor. In this case, a
meteor hits the earth before the agent is even born, and there isn't a question about whether the agent has
an umbrella. There is a new possible world, which we will also call m, in which the meteor strikes. The
Cartesian frame will look like this:
C3 =      
r
s
m
u
n
u ↔r
u ↔s
⎛
⎜ 
⎜ 
⎜
⎝
ur
us
m
nr
ns
m
ur
ns
m
nr
us
m
⎞
⎟ 
⎟ 
⎟
⎠
.
Ensure(C3) = ⟨{ur, us, m}, {nr, ns, m}, {ur, ns, m}, {nr, us, m}⟩⊃, and  
Prevent(C3) = ⟨{ur, us}, {nr, ns}, {ur, ns}, {nr, us}⟩⊂. As a consequence, Ctrl(C3) = {}.
This example illustrates that nontrivial agents may be unable to control the world's state. Because the agent
can't prevent the meteor, the agent in this case has no controllables.
This example also illustrates that agents may be able to ensure or prevent some things, even if there are
possible worlds in which the agent was never born. While the agent of C3 cannot ensure that it exists, the
agent can ensure that if there is no meteor, then it carries an umbrella ({ur, us, m}).
If we wanted to, we could instead consider the agent's ensurables (or its ensurables and preventables) its
"outputs." This lets us avoid the counter-intuitive result that agents have no outputs in worlds where their
existence is contingent.
I put the emphasis on controllables because they have other nice features; and as we'll see later, there is an
operation called "assume" which we can use to say: "The agent, under the assumption that there's no
meteor, has controllables."
 

4. Observables
The analogue of inputs in the Cartesian frame model is observables. Observables can be thought of as a
closure property on the agent. If an agent is able to observe S, then the agent can take policies that have
diﬀerent eﬀects depending on S.
Formally, let S be a subset of W. We say that the agent of a Cartesian frame C = (A, E, ⋅) is able to observe
whether S if for every pair a0, a1 ∈A, there exists a single element a ∈A which implements the conditional
policy that copies a0 in possible worlds in S (i.e., for every e ∈E, if a ⋅e ∈S, then a ⋅e = a0 ⋅e) and copies a1
 in possible worlds outside of S.
When a implements the conditional policy "if S then do a0, and if not S then do a1" in this way, we will say
that a is in the set if(S, a0, a1).
Deﬁnition: Given C = (A, E, ⋅), a Cartesian frame over W, S a subset of W, and a0, a1 ∈A, let if(S, a0, a1)
 denote the set of all a ∈A such that for all e ∈E, (a ⋅e ∈S) →(a ⋅e = a0 ⋅e) and(a ⋅e ∉S) →(a ⋅e = a1 ⋅e).
Agents in this setting observe events, which are true or false, not variables in full generality. We will say that 
C's observables, Obs(C), are the set of all S such that              C's agent can observe whether S.
Deﬁnition: Obs(C) = {S ⊆W | ∀a0, a1 ∈A,  ∃a ∈A,  a ∈if(S, a0, a1)}.
Another option for talking about what the agent can observe would be to talk about when C's agent can
distinguish between two disjoint subsets S and T. Here, we would say that the agent of C = (A, E, ⋅) can
distinguish between S and T if for all a0, a1 ∈A, there exists an a ∈A such that for all e ∈E, either 
a ⋅e = a0 ⋅e or a ⋅e = a1 ⋅e, and whenever a ⋅e ∈S, a ⋅e = a0 ⋅e, and whenever a ⋅e ∈T, a ⋅e = a1 ⋅e. This
more general deﬁnition would treat our observables as the special case T = W∖S. Perhaps at some point we
will want to use this more general notion, but in this sequence, we will stick with the simpler version.
 
4.1. Closure Properties
Claim: Observability is closed under Boolean combinations, so if S, T ∈Obs(C) then W∖S, S ∪T, and S ∩T
 are also in Obs(C).
Proof: Assume S, T ∈Obs(C). We can see easily that W∖S ∈Obs(C) by swapping a0 and a1. It suﬃces to
show that S ∪T ∈Obs(C), since an intersection can be constructed with complements and union.
Given a0 and a1, since S ∈Obs(C), there exists an a2 ∈A such that for all e ∈E, we have a2 ∈if(S, a0, a1).
Then, since T ∈Obs(C), there exists an a3 ∈A such that for all e ∈E, we have a3 ∈if(T, a0, a2). Unpacking

and combining these, we get for all e ∈E, a3 ∈if(S ∪T, a0, a1). Since we could construct such an a3 from an
arbitrary a0, a1 ∈A, we know that S ∪T ∈Obs(C). □
This highlights a key diﬀerence between our version of "inputs" and the standard version. Agent models
typically draw a strong distinction between the agent's immediate sensory data, and other things the agent
might know. Observables, on the other hand, include all of the information that logically follows from the
agent's observations.
Similarly, agent models typically draw a strong distinction between the agent's immediate motor outputs,
and everything else the agent can control. In contrast, if an agent can ensure an event S, it can also ensure
everything that logically follows from S.
Since Obs(C) will often be large, we will sometimes write it using a minimal set of generators under union.
Since Obs(C) is closed under Boolean combinations, such a minimal set of generators will be a partition of W
 (assuming W is ﬁnite).
Deﬁnition: Let ⟨S1, ... , Sn⟩∪ denote the the closure of {S1, ... , Sn} under union (including {}, the empty
union).
Just like what's controllable, what's observable is closed under removing possible environments.
Claim: If E′ ⊆E, and if for all a ∈A and e ∈E′ we have a ⋆e = a ⋅e, then Obs(A, E′, ⋆) ⊇Obs(A, E, ⋅).
Proof: Trivial. □
It is interesting to note, however, that what's observable is not closed under adding possible agents to A.
 
4.2. Examples of Observables
Let's look back at our three examples from earlier. The ﬁrst example, C1, looked like this:
C1 =      
r
s
u
n
(
ur
us
nr
ns ) .
Obs(C1) = ⟨W⟩∪= {{}, W}. This is the smallest set of observables possible. The agent can act, but it can't
change its behavior based on knowledge about the world.
The second example looked like:
C2 =      
r
s
u
n
u ↔r
u ↔s
⎛
⎜ 
⎜ 
⎜
⎝
ur
us
nr
ns
ur
ns
nr
us
⎞
⎟ 
⎟ 
⎟
⎠
.
Here, Obs(C2) = ⟨{ur, nr}, {us, ns}⟩∪= {{}, {ur, nr}, {us, ns}, W}. The agent can observe whether or not it's
raining. One can verify that for any pair of rows, there is a third row (possibly equal to one or both of the ﬁrst

two) that equals the ﬁrst if it is ur or nr, and equals the second otherwise.
The third example looked like:
C3 =      
r
s
m
u
n
u ↔r
u ↔s
⎛
⎜ 
⎜ 
⎜
⎝
ur
us
m
nr
ns
m
ur
ns
m
nr
us
m
⎞
⎟ 
⎟ 
⎟
⎠
.
Here, Obs(C3) = ⟨{ur, nr}, {us, ns}, {m}⟩∪, which is
{ { } , { u r , n r } , { u s , n s } , { m } , { u r , n r , u s , n s } , { u r , n r , m } , { u s , n s , m } , W } .
This example has an odd feature: the agent is said to be able to "observe" whether the meteor strikes, even
though the agent is never instantiated in worlds in which it strikes. Since the agent has no control when the
meteor strikes, the agent can vacuously implement conditional policies.
Let's look at two more examples. First, let's modify C1 to represent the point of view of a powerless
bystander:
C4 =      
ur
nr
us
ns
1
( ur
nr
us
ns ) .
Here, the agent has no decisions, and everything is in the hands of the environment.
Alternatively, we can modify C1 to represent the point of view of the agent from C1 and environment from C1
 together. The resulting frame looks like this:
C5 =      
1
ur
nr
us
ns
⎛
⎜ 
⎜ 
⎜
⎝
ur
nr
us
ns
⎞
⎟ 
⎟ 
⎟
⎠
.
Ensure(C4) = ⟨W⟩⊃ and Prevent(C4) = ⟨{}⟩⊂, so Ctrl(C4) = {}. Meanwhile, Obs(C4) = ⟨{ur}, {nr}, {us}, {ns}⟩∪.
On the other hand, Obs(C5) = ⟨W⟩∪, Ensure(C5) and Prevent(C5) are the closure of {{ur}, {nr}, {us}, {ns}}
 under supersets and subsets respectively, and Ctrl(C5) = 2W∖{{}, W}.
In the ﬁrst case, the agent's ability to observe the world is maximal and its ability to control the world is
minimal; while in the second case, observability is minimal and controllability is maximal. An agent with full
control over what happens will not be able to observe anything, while an agent that can observe everything
can change nothing.
This is perhaps counter-intuitive. If S ∈Obs(C) meant "I can go look at something to check whether we're in
an S world," then one might look at C5 and say: "This agent is all-powerful. It can do anything. Shouldn't we
then think of it as all-seeing and all-knowing, rather than saying it 'can't observe anything'?" Similarly, one

might look at C4 and say: "This agent's choices can't change the world at all. But then it seems bizarre to say
that everything is 'observable' to the agent. Shouldn't we rather say that this agent is powerless and blind?"
The short answer is that, when working with Cartesian frames, we are in a very "What choices can you
make?" paradigm, and in that kind of paradigm, the thing closest to an "input" is "What can I condition my
choices on?" (Which is a closure property on the agent, rather than a discrete action like "turning on the
Weather Channel.")
In that context, an agent with only one option automatically has maximal "inputs" or "knowledge," since it
can vacuously implement every conditional policy. At the same time, an agent with too many options can't
have any "inputs," since it could then use its high level of control to diagonalize against the observables it is
conditioning on and make them false.
 
5. Controllables and Observables Are Disjoint
A maximally observable frame has minimal controllables, and vice versa. This turns out to be a special case
of our ﬁrst interesting result about Cartesian frames: an agent can't observe what it controls, and can't
control what it observes.
To see this, ﬁrst consider the following frame:
C6 =      
1
a0
a1
(
w0
w1 ) .
Here, if a ∈if({w1}, a0, a1), then a ⋅1 would not be able to be either w0 or w1. If it were w1, then it would
have to copy a0, and a0 ⋅1 = w0. But if it were w0, then it would have to copy a1, and a1 ⋅1 = w1. So 
if(S, a0, a1) is empty in this case.
Notice that in this example, if(S, a0, a1) isn't empty merely because our A lacks the right a to implement the
conditional policy. Rather, the conditional policy is impossible to implement even in principle.
Fortunately, before checking whether C's agent can observe S, we can perform a simpler check to rule out
these problematic cases. It turns out that if S ∈Obs(C), then every column in C consists either entirely of
elements of S or entirely of elements outside of S. (This is a necessary condition for being observable, not a
suﬃcient one.)
Deﬁnition: Given a Cartesian frame C = (A, E, ⋅) over W, and a subset S of W, let ES denote the subset 
{e ∈E | ∀a ∈A, e ⋅a ∈S}.
Lemma: If S ∈Obs((A, E, ⋅)), then for all e ∈E, it is either the case that e ∈ES or e ∈EW∖S.
Proof: Take S ∈Obs((A, E, ⋅)), and assume for contradiction that there exists an e ∈E in neither ES nor EW∖S.
Thus, there exists an a0 ∈A such that a0 ⋅e ∉S and an a1 ∈A such that a1 ⋅e ∈S. Since S ∈Obs((A, E, ⋅)),
there must exist an a ∈A such that a ∈if(S, a0, a1). Consider whether or not a ⋅e ∈S. If a ⋅e ∈S, then 
a ⋅e = a0 ⋅e ∉S. However, if a ⋅e ∉S, then a ⋅e = a1 ⋅e ∈S. Either way, this is a contradiction. □
This lemma immediately gives us the following theorem showing that in nontrivial Cartesian frames,
observables and controllables are disjoint.

Theorem: Let C be a Cartesian frame over W, with Env(C) nonempty. Then,Ctrl(C) ∩Obs(C) = {}.
Proof: Let e ∈Env(C), and suppose for contradiction that S ∈Ctrl(C) ∩Obs(C). Since S ∈Prevent(C), there
exists an a0 ∈A such that a0 ⋅e ∉S. Since S ∈Ensure(C), there exists an a1 ∈A such that a1 ⋅e ∈S. This
contradicts our lemma above. □
 
5.1. Properties That Are Both Observable and Ensurable Are Inevitable
We also have a one-sided result showing that if S is both observable and ensurable in C, then S must be
inevitable — i.e., the entire matrix must be contained in S.
We'll ﬁrst deﬁne a Cartesian frame's image, which is the subset of W containing every possible world that is
actually hit by the evaluation function — the set of worlds that show up in the matrix.
Deﬁnition: Image(C) = {w ∈W | ∃a ∈A,  ∃e ∈E   s.t.  a ⋅e = w}.
Image(C) ⊆S can be thought of as a degenerate form of either S ∈Ensure(C) or S ∈Obs(C), where in the
ﬁrst case, the agent must make it the case that S, and in the second case the agent can do conditional
policies because the a ⋅e ∉S condition is never realized.1 Conversely, if an agent can both observe and
ensure S, then the observability and the ensurability must both be degenerate.
Theorem: S ∈Ensure(C) ∩Obs(C) if and only if Image(C) ⊆S and Agent(C) is nonempty.
Proof: Let C = (A, E, ⋅) be a Cartesian frame over W. First, if Image(C) ⊆S, then S ∈Obs(C), since 
a0 ∈if(S, a0, a1) for all a0, a1 ∈A. If A is also nonempty, then S ∈Ensure(C), there exists an a ∈A, and for all 
e ∈E, a ⋅e ∈S.
Conversely, if A is empty, Ensure(C) is empty, so S ∉Ensure(C) ∩Obs(C). If Image(C) ⊈S , then there exist 
a0 ∈A and e ∈E such that a0 ⋅e ∉S. Then S ∉Ensure(C) ∩Obs(C), since if S ∈Ensure(C), there exists an a1
 such that in particular a1 ⋅e ∈S, so e is in neither ES nor EW∖S, which implies S ∉Obs(C). □
Corollary: If Agent(C) is nonempty, Ensure(C) ∩Obs(C) = ⟨Image(C)⟩⊃.
Proof: Trivial. □
 
5.2. Controllables and Observables in Degenerate Frames
All of the results so far have shown that an agent's observables and controllables cannot simultaneously be
too large. We also have some results that in some extreme cases, Obs(C) and Ctrl(C) cannot be too small. In
particular, if there are few possible agents, observables must be large, and if there are few possible
environments, controllables must be large.

Claim: If |Agent(C)| ≤1, Obs(C) = 2W.
Proof: If Agent(C) is empty, S ∈Obs(C) for all S ⊆W vacuously. If Agent(C) = {a} is a singleton, then 
S ∈Obs(C) for all S ⊆W, because a ∈if(S, a, a). □
Claim: If Agent(C) is nonempty and Env(C) is empty, then Ctrl(C) = Ensure(C) = 2W. If Agent(C) is nonempty
and Env(C) is a singleton, Ensure(C) = {S ⊆W | S ∩Image(C) ≠{}} and 
Ctrl(C) = {S ⊆W | S ∩Image(C) ≠{}, W∖S ∩Image(C) ≠{}}.
Proof: If Agent(C) is nonempty and Env(C) is empty, S ∈Ensure(C) for all S ⊆W vacuously.
If Agent(C) is nonempty and Env(C) = {e} is a singleton, every S ⊆W that intersects Image(C) nontrivially is
in Ensure(C), since if w ∈S ∩Image(C), there must be some a ∈A such that a ⋅e = w, this a satisﬁes a ⋅e′ ∈S
 for all e′ ∈E. Conversely, if S and Image(C) are disjoint, no a ∈A can satisfy this property. The result for Ctrl
 then follows trivially from the result for Ensure. □
 
5.3. A Suggestion of Time
Cartesian frames as we've been discussing them are agnostic about time. Possible agents, environments, and
worlds could represent snapshots of a particular moment in time, or they could represent lengthy processes.
The fact that an agent's controllables and observables are disjoint, however, suggests a sort of arrow of time,
where facts an agent can observe must be "before" the facts that agent has control over. This hints that we
may be able to use Cartesian frames to formally represent temporal relationships.
One reason it would be nice to represent time is that we could model agents that repeatedly learn things,
expanding their set of observables. Suppose that in some frame C, Agent(C) includes choices the agent
makes over an entire calendar year. Agent(C)'s observables would only include the facts the agent can
condition on at the start of the year, when it's ﬁrst able to act; we haven't deﬁned a way to formally
represent the agent learning new facts over the course of the year.
It turns out that this additional temporal structure can be elegantly expressed using Cartesian frames. We will
return to this topic in the very last post in this sequence. For now, however, we only have this hint that
particular Cartesian frames have something like a "before" and "after."
 
6. Why Cartesian Frames?
The goal of this sequence will be to set up the language for talking about problems using Cartesian frames.
Concretely, I'm writing this sequence because:
I've recently found that I have a new perspective to bring to a lot of other MIRI researchers' work. This
perspective seems to me to be captured in the mathematical structure of Cartesian frames, but it's the
new perspective rather than the mathematical structure per se that seems important to me. I want to
try sharing this mathematical object and the accompanying philosophical interpretation, to see if it
successfully communicates the perspective.
I want collaborators to work with on Cartesian frames. If you're a math person who ﬁnds the things in
this sequence exciting, I'd be interested in talking about it more. You can comment, PM, or email me.

I want help with paradigm-building, but I also want there to be an ecosystem where people do normal
science within this paradigm. I would consider it a good outcome if there existed a decent-sized group
of people on the AI Alignment Forum and LessWrong for whom it makes just as much sense to pull out
the Cartesian frames paradigm as it makes to pull out the cybernetic agent paradigm.
Below, I will say more about the cybernetic agent model and other ideas that helped motivate Cartesian
frames, and I will provide an overview of upcoming posts in the  sequence.
 
6.1. Cybernetic Agent Model
The cybernetic agent model describes an agent and an environment interacting over time:
In "Embedded Agency," Abram Demski and I noted that cybernetic agents like Marcus Hutter's AIXI are
dualistic, whereas real-world agents will be embedded in their environment. Like a Cartesian soul, AIXI is
crisply separated from its environment.
The dualistic model is often useful, but it's clearly a simpliﬁcation that works better in some contexts than in
others. One thing it would be nice to have is a way to capture the useful things about this simpliﬁcation, while
treating it as a high-level approximation with known limitations — rather than treating it as ground truth.
Cartesian frames carve up the world into a separate "agent" and "environment," and thereby adopt the basic
conceit of dualistic Hutter-style agents. However, they treat this as a "frame" imposed on a more embedded,
naturalistic world.2
Cartesian frames serve the same sort of intellectual function as the cybernetic agent model, and are
intended to supersede this model. Our hope is that a less discrete version of ideas like "agent," "action," and
"observation" will be better able to tolerate edge cases. E.g., we want to be able to model weirder, loopier
versions of "inputs" that operate across multiple levels of description.
We will also devote special attention in this sequence to subagents, which are very diﬃcult to represent in
traditional dualistic models. In game theory, for example, we carve the world into diﬀerent "agent" and "non-
agent" parts, but we can't represent nontrivial agents that intersect other agents. A large part of the theory
in this sequence will be giving us a language for talking about subagents.
 
6.2. Deriving Functional Structure
Another way of summarizing this sequence is that we'll be applying reasoning like Pearl's to objects like game
theory's, with a motivation like Hutter's.
In Judea Pearl's causal models, you are given a bunch of variables, and an enormous joint distribution over
the variables. The joint distribution is a large object that has a relational structure as opposed to a functional
structure.

You then deduce something that looks like time and causality out of the combinatorial properties of the joint
distribution. This takes the form of causal diagrams, which give you functions and counterfactuals.
This has some similarities to how we'll be using Cartesian frames, even though the formal objects we'll be
working with are very diﬀerent from Pearl's. We want a model that can replace the cybernetic agent model
with something more naturalistic, and our plan for doing this will involve deriving things like time from the
combinatorial properties of possible worlds.
We can imagine the real world as an enormous static object, and we can imagine zooming in on diﬀerent
levels of the physical world and sometimes seeing things that look like local functions. ("Ah, no matter what
the rest of the world looks like, I can compute the state of Y  from the state of X, relative to my uncertainty.")
Switching which part of the world we're looking at, or switching which things we're lumping together versus
splitting, can then change which things look like functions.
Agency itself, as we normally think about it, is functional in this way: there are multiple "possible" inputs, and
whichever "option" we pick yields a deterministic result.
We want an approach to agency that treats this functional behavior less like a unique or fundamental feature
of the world, and more like a special case of the world's structure in general — and one that may depend on
what we're splitting or lumping together.

"We want to apply Pearl-like methods to Cartesian frames" is also another way of saying "we want to do the
formal equivalent of inferring extensive-form games from normal-form games," our summary from before.
The analogy is:
 
 
base information
derived information
causality joint probability distribution causal diagram
games
normal-form game
extensive-form game
agency
Cartesian frame
control, observation, subagents, time, etc.
 
The game theory analogy is more relevant formally, while the Pearl analogy better explains why we're
interested in this derivation.
Just as notions of time and information state are basic in causal diagrams and extensive-form games, so are
they basic in the cybernetic agent model; and we want to make these aspects of the cybernetic agent model
derived rather than basic, where it's possible to derive them. We also want to be able to represent things like
subagents that are entirely missing from the cybernetic agent model.
Because we aren't treating high-level categories like "action" or "observation" as primitives, we can hope to
end up with an agent model that will let us model more edge cases and odd states of the system. A more
derived and decomposable notion of time, for example, might let us better handle settings where two agents
are both trying to reach a decision based on their model of the other agent's future behavior.
We can also hope to distinguish features of agency that are more description-invariant from features that
depend strongly on how we carve up the world.
One philosophical diﬀerence between our approach and Pearl's is that we will avoid the assumption that the
space of possible worlds factors nicely into variables that are given to the agent. We want to instead just
work with a space of possible worlds, and derive the variables for ourselves; or we may want to work in an
ontology that lets us reason with multiple incompatible factorizations into variables.3
 
6.3. Contents
The rest of the sequence will cover these topics:
2. Additive Operations on Cartesian Frames - We talk about the category of Chu spaces, and introduce
two additive operations one can do on Cartesian frames: sum ⊕, and product &. We talk about how to
interpret these operations philosophically, in the context of agents making choices to aﬀect the world. We
also introduce the small Cartesian frame 0, and its dual 0∗= ⊤.
3. Biextensional Equivalence - We deﬁne homotopy equivalence ≃ for Cartesian frames, and introduce the
small Cartesian frames null, 1S, and ⊥S.
4. Controllables and Observables, Revisited - We use our new language to redeﬁne controllables and
observables.
5. Functors and Coarse Worlds - We show how to compare frames over a detailed world model W and
frames over a coarse version of that world model V . We demonstrate that observability is a function not only
of the observer and the observed, but of the level of description of the world.
6. Subagents of Cartesian Frames - We introduce the notion of a frame C whose agent is the subagent of
a frame D, written C ◃D. A subagent is an agent playing a game whose stakes are another agent's possible
choices. This notion turns out to yield elegant descriptions of a variety of properties of agents.
7. Multiplicative Operations on Cartesian Frames - We introduce three new binary operations on
Cartesian frames: tensor ⊗, par ⅋ , and lollipop ⊸.

8. Sub-Sums and Sub-Tensors - We discuss spurious environments, and introduce variants of sum, ⊞, and
tensor, ⊠, that can remove some (but not too many) spurious environments.
9. Additive and Multiplicative Subagents - We discuss the diﬀerence between additive subagents, which
are like future versions of the agent after making some commitment; and multiplicative subagents, which are
like agents acting within a larger agent.
10. Committing, Assuming, Externalizing, and Internalizing - We discuss the additive notion of
producing subagents and sub-environments by committing or assuming, and the multiplicative notion of
externalizing (moving part of the agent into the environment) and internalizing (moving part of the
environment into the agent).
11. Eight Deﬁnitions of Observability - We use our new tools to provide additional deﬁnitions and
interpretations of observables. We talk philosophically about the diﬀerence between deﬁning what's
observable using product and deﬁning what's observable using tensor, which corresponds to the diﬀerence
between updateful and updateless observations.
12. Time in Cartesian Frames - We show how to formalize temporal relations with Cartesian frames.
I'll be releasing new posts most non-weekend days between now and November 11.
As Ben noted in his announcement post, I'll be giving talks and holding oﬃce hours this Sunday at 12-2pm PT
and the following three Sundays at 2-4pm PT, to answer questions and discuss Cartesian frames. Everyone is
welcome.
The online talks, covering much of the content of this sequence, will take place this Sunday at 12pm PT
(Zoom link added: recording of the talk) and next Sunday at 2pm PT.
 
This sequence is communicating ideas I have been developing slowly over the last year. Thus, I have gotten a
lot of help from conversation with many people. Thanks to Alex Appel, Rob Bensinger, Tsvi Benson-Tilsen,
Andrew Critch, Abram Demski, Sam Eisenstat, David Girardo, Evan Hubinger, Edward Kmett, Alexander
Gietelink Oldenziel, Steve Rayhawk, Nate Soares, and many others.
Footnotes
1. This assumes a non-empty Agent(C). Otherwise, Image(C) could be empty and therefore a subset of S,
even though S is not ensurable (because you need an element of Agent(C) in order to ensure anything). ↩
2. This is one reason for the name "Cartesian frames." Another reason for the name is to note the connection
to Cartesian products. In linear algebra, a frame of an inner product space is a generalization of a basis of a
vector space to sets that may be linearly dependent. With Cartesian frames, then, we have a Cartesian
product that projects onto the world, not necessarily injectively. (Cartesian frames aren't actually "frames" in
the linear-algebra sense, so this is only an analogy.) ↩
3. This, for example, might let us talk about a high-level description of a computation being "earlier" in some
sort of logical time than the exact details of that same computation.
Problems like agent simulates predictor make me think that we shouldn't treat the world as factorizing into a
single "true" set of variables at all, though I won't attempt to justify that claim here. ↩

Additive Operations on Cartesian
Frames
Crossposted from the AI Alignment Forum. May contain more technical jargon than
usual.
The mathematical object (but not the philosophical interpretation) of a Cartesian
Frame is studied under the name "Chu space."
(In category theory, Chu spaces are usually studied in the special case of W = 2. To
learn more about Chu spaces, see Vaughan Pratt's guide to papers and nLab's page on
the Chu construction.)
In this post and the next one, I'll mostly be discussing standard facts about Chu
spaces. I'll also discuss how to interpret the standard deﬁnitions as statements about
agency.
Chu spaces form a category as a special case of the Chu construction. You may notice
a strong similarity between operations on Cartesian frames and operations in linear
logic, coming from the fact that the Chu construction is also intimately related to
linear logic, and is used in the semantics for linear logic.
Linear logic has a large number of operations—additive conjunction (&), multiplicative
conjunction (⊗), and so on—and many of those symbols will turn out to have
interpretations for Cartesian frames, and they're actually going to be meaningful
interpretations in this setting. For that reason, we'll be stealing much of our notation
from linear logic, though this sequence won't assume familiarity with linear logic.
Deﬁnition: Chu(W) is the category whose objects are Cartesian frames over W,
whose morphisms from C = (A, E, ⋅) to D = (B, F, ⋆) are pairs of functions 
(g : A →B, h : F →E), such that a ⋅h(f) = g(a) ⋆f for all a ∈A and f ∈F, and whose
composition of morphisms is given by (g1, h1) ∘(g0, h0) = (g1 ∘g0, h0 ∘h1).
The composition of two morphisms C0 →C1 and C1 →C2, then, sends the agent of C0
 to C2 and sends the environment of C2 to C0.
Claim: Chu(W) is a category.
Proof: It suﬃces to show that composition is well-deﬁned and associative and there
exist identity morphisms. For identity, (idA, idE) is clearly an identity on C = (A, E, ⋅),

where idX is the identity map from X to itself.
The composition (g1, h1) ∘(g0, h0) of (g0, h0) : C0 →C1 with (g1, h1) : C1 →C2 is 
(g1 ∘g0, h0 ∘h1) : C0 →C2. To verify that this is a morphism, we just need that 
a0 ⋅0 h0(h1(e2)) = g1(g0(a0)) ⋅2 e2 for all a0 ∈Agent(C0), and e2 ∈Env(C2), where 
⋅i = Eval(Ci). Indeed, 
a 0 ⋅ 0 h 0 ( h 1 ( e 2 ) )  = g 0 ( a 0 ) ⋅ 1 h 1 ( e 2 ) 
 = g 1 ( g 0 ( a 0 ) ) ⋅ 2 e 2 , 
since each component is a morphism.
Associativity of the composition follows from the fact that it is just a pair of
compositions of functions on sets, and composition is associative for sets. □
 
1. What Do These Morphisms Represent?
1.1. Morphisms as Interfaces
A Cartesian frame is a ﬁrst-person perspective. The agent A ﬁnds itself in a certain
situation or game, where it expects to encounter an environment E. The morphisms
in Chu(W) allow the agent of one Cartesian frame to play the game of another
Cartesian frame.
We can think of the morphisms from C = (A, E, ⋅) to D = (B, F, ⋆) as ways of ﬁtting the
agent of C into the environment of D. Indeed, for every morphism (g, h) : C →D, one
can construct a Cartesian frame (A, F, ⋄), whose agent matches C's agent, and whose
environment matches D's environment, with ⋄ given by a ⋄f = a ⋅h(f) = g(a) ⋆f. (The
morphism from C to D can actually be viewed as the composition of 
(idA, h) : C →(A, F, ⋄) with (g, idF) : (A, F, ⋄) →D.)
Two random large Cartesian frames will typically have no morphisms between them.
When there is a morphism, the morphism functions as an interface that allows the
agent A to interact with some other environment F. However, we aren't just randomly

throwing A and F together. A's interaction with F factors through the function h : F →E
, so A can in a sense still be thought of as using an interface where it interacts with E.
It just interacts with an e ∈E that is of the form h(f) for some f ∈F. But this is
happening simultaneously with the dual view in which F can be thought of as still
interacting with B!
Since a Cartesian frame is a ﬁrst-person perspective, you can imagine A having the
internal experience of interacting with E, while F has the "experience" of interacting
with B. The morphism's job is to be the translation interface that allows this A and F to
interact with each other, while preserving their respective internal experiences in such
a way that they feel like they're interacting with E and B respectively. A gets to play B
's game, while still thinking that it is playing its own game.
 
1.2. Morphisms as Diﬀerences in Agents' Strength
We can also interpret the existence of a morphism from C = (A, E, ⋅) to D = (B, F, ⋆) as
saying something like "D's agent is at least as strong as C's agent."
This is easiest to see for a morphism (g, h) : C →D where g and h are both injective. In
this case, it is as though A ⊆B and F ⊆E, so D's agent has more options to choose
between and fewer environments it has to worry about.
Since some of the environments in E∖F might have been good for the agent,
the agent isn't necessarily strictly better oﬀ in D; but in a zero-sum game, the agent
will indeed be strictly better oﬀ. I think this justiﬁes saying that C's agent is in some
sense weaker than D's agent.
If g or h is not injective, we could duplicate elements of B and E to make it injective,
so the interpretation "C's agent is no stronger than D's agent" is reasonable in that
case as well. In particular, the existence of a morphism from C to D implies that 
Ensure(C) ⊆Ensure(D) (and thus Ctrl(C) ⊆Ctrl(D)).

However, the existence of a morphism is stronger than just saying the set of
ensurables is larger. The morphism from C to D can be thought of as telling D's agent
how to strategy-steal from C's agent, and thus do anything that C's agent can do.
We now provide a few examples to illustrate morphisms between Cartesian frames. (If
you're ready to forge ahead, skip to §2 instead.)
 
1.3. Simple Examples of Morphisms
Imagine a student who is deciding between staying up late studying for a test (as) or
ignoring the test (ai). We will represent the student with a Cartesian frame over letter
grades, where W = {A+, A, A-, B+, B, B-, C+, C, C-, D+, D, D-, F}.
If the student doesn't study, her ﬁnal grade is always a C+, represented by the
possible world C+. If she does study, she may oversleep and get a bad grade
(represented by the environment selecting eo and putting her in D-). If she studies and
doesn't oversleep, she is uncertain about whether her teacher is typical (et, resulting
in A-) or unusually demanding (ed, resulting in B+). We represent this with the frame
CT =
et  
ed  
eo
as
ai
(
A-
B+
D-
C+
C+
C+ ) .
Let us also suppose that yesterday, the student had the extra option of copying
another student's answers on test day to get a sure A+. However, she decided not to
cheat. We represent the student's options yesterday, prior to precommitting, with the
frame
CY =
ft  
fd  
fo
bs
bi
bc
⎛
⎜
⎝
A-
B+
D-
C+
C+
C+
A+
A+
A+
⎞
⎟
⎠
.
There is a morphism from the student's frame today to her frame yesterday,
representing the fact that Agent(CT) can be plugged into Agent(CY )'s game, or that
the student was "stronger" yesterday than she is today.

Let us also suppose that the student's teacher is in fact demanding. If the student
today knew this fact, we would instead represent her perspective with the frame
CT ′ =
e
′
d  
e
′
o
a
′
s
a
′
i
(
B+
D-
C+
C+ ) .
Here, we have a morphism from the student today (CT) to her perspective if she had
an additional promise from the environment (CT ′). This represents the fact that CT ′
 can strategy-steal from a version of herself who knows strictly less.
Given two Cartesian frames C0 and C1, I am not aware of an eﬃcient universal
method for determining whether there exists a morphism from C0 to C1. Indeed, I
conjecture that this problem might be NP-complete. In the above cases, however, we
can see that there exist morphisms from CT to the other two frames by observing
that CT is eﬀectively CY  with a row deleted, or CT ′ with a column added.
While Agent(CY ) and Agent(CT ′) are both stronger than Agent(CT), we have no
morphisms between CY  and CT ′; their options are diﬀerent enough that we can't
compare their strength directly.
 
1.4. Examples of Morphisms Going Both Ways
Every Cartesian frame has an identity morphism pointing to itself; and as we'll discuss
in the next post, whenever two Cartesian frames C and D are equivalent (in a sense to
be deﬁned), there will be a morphism going from C to D and another going from D to 
C. But not all pairs of Cartesian frames with morphisms going both ways are
equivalent. Consider, for example,
C1 =
e0
e1
a0
a1
(
w0
w0
w0
w1 )  and  D1 =
f0
b0
( w0 ) .
In C1 = (A, E, ⋅), the default outcome is w0, but the agent and environment can
handshake to produce w1. In D1 = (B, F, ⋆), there are no choices, and there's only one

possible world, w0.
It turns out that there is a morphism (g, h) : C1 →D1, where g is the constant function 
b0 and h is the constant function e0; and there is a second morphism (g′, h′) : D1 →C1,
 where g′ is the constant function a0 and h′ is the constant function f0. We can
interpret these like so:
There is a morphism C1 →D1 because D1 is eﬀectively C1 plus a promise from
the environment "I'll choose e0." The agent in D1 is "stronger" in the sense that
it has fewer possible environments to worry about. There is less the environment
can do to interfere with the agent's choices.
There is a morphism D1 →C1 because C1's agent has strictly more options than 
D1's agent: moving from D1 to C1 lets you retain the option to produce w0 if you
want, but it also lets you try for w1.
So we can view the smaller matrix as the larger matrix plus a promise from the
environment "I'll choose e0," or we can view it as the larger matrix plus a commitment
from the agent "I'll choose a0."
This example demonstrates that my intuitive statement "wherever there's a morphism
from C to D, D is at least as strong as C" conﬂates two diﬀerent notions of "stronger."
These notions often go together, but come apart in situations such as the handshake
example. Like the hypothetical student in CT ′, the agent of D1 is "stronger" in the
sense that the environment can't do as much to get in the way. But like the not-yet-
precommitted student in CY , the agent of C1 is "stronger" in the sense that it has
more options.
 
2. Self-Duality
A key property of Chu(W) is that it is self-dual.
Deﬁnition: Let −∗: Chu(W) →Chu(W)op be the functor given by (A, E, ⋅)∗= (E, A, ⋆),
where e ⋆a = a ⋅e, and (g, h)∗= (h, g).

The more standard notation for dual in linear logic would be −⊥, but this is horrible
notation.1
Claim: −∗ is an isomorphism between Chu(W) and Chu(W)op.
Proof: First, we show −∗ is a functor. The objects in Chu(W)op are the same as in 
Chu(W), the morphisms from D to C in Chu(W)op are the morphisms from C to D in 
Chu(W), and composition is the same, but with the order reversed. −∗ clearly
preserves identity morphisms. To show that −∗ preserves composition, we have
( g 0 , h 0 ) ∗ ∘ op ( g 1 , h 1 ) ∗  = ( h 1 , g 1 ) ∘ ( h 0 , g 0 ) 
 = ( h 1 ∘ h 0 , g 0 ∘ g 1 ) 
 = ( ( g 0 , h 0 ) ∘ ( g 1 , h 1 ) ) ∗ . 
To see that it is an isomorphism, we need a left and right inverse. We will abuse
notation and also write −∗ for the functor from Chu(W)op to Chu(W) given by 
(E, A, ⋆)∗= (A, E, ⋅), where a ⋅e = e ⋆a, and (h, g)∗= (g, h). Clearly, we have 
−∗: Chu(W) →Chu(W)op and −∗: Chu(W)op →Chu(W) composing to the identity in
both orders, so −∗ is an isomorphism. □
Going back to our visualization of Cartesian frames as matrices, −∗ just takes the
transpose of the matrix, swapping agent with environment. "Chu(W) is self-dual" is
another way of saying that transposing a Cartesian frame always gives you another
Cartesian frame.
Philosophically, depending on our interpretation, this may be doing something weird.
We talk about possible agents and possible environments, but we may mean
something diﬀerent by "possible" in those two cases.
Since we are imagining events from the point of view of the agents, "possible agents"
is referring to all of the ways the agent can choose to be by exercising its "free will."
We could think of "possible environments" similarly, or we could think of possible
environments as representing the agent's uncertainty.
Under the view where possible environments represent uncertainty, −∗ is pointing to
an interesting duality that swaps choices with uncertainty, swaps the "could" of "I
could do X" with the "could" of "The world could have property Y," and (if we add
probability to the mix) swaps mixed strategies with probabilistic uncertainty. "What

will I do?" becomes "What game am I playing?", or "What is the world-as-a-function-of-
my-action like?"
I will introduce many operations on Cartesian frames, so it will help to highlight even
the basic properties as I go. Here, I'll note:
Claim: For any Cartesian frame C, (C ∗)∗= C.
Proof: Trivial. □
 
3. Sums of Cartesian Frames
The ﬁrst binary operation on Cartesian frames I want to introduce is the sum, ⊕.
Deﬁnition: For Cartesian frames C = (A, E, ⋅) and D = (B, F, ⋆) over W, C ⊕D is the
Cartesian frame (A ⊔B, E × F, ⋄), where a ⋄(e, f) = a ⋅e if a ∈A, and a ⋄(e, f) = a ⋆f if 
a ∈B.
The sum takes the disjoint union of the agents and the Cartesian product of the
environments, and does the obvious thing with the evaluation function. The agent can
choose any strategy from A or from B, and the environment has to respond to that
strategy. We can interpret this as an agent that can choose between two diﬀerent
ﬁrst-person perspectives: it can decide to interact with the environment as the agent
of C, or as the agent of D.
Maybe "Rebecca the chess player" is considering which chess opening to employ,
whereas "Rebecca the food-eater" is considering putting her plate down on the chess
board and having lunch instead. "Rebecca the agent that can choose between playing
chess and having lunch" is the sum of the other two Rebeccas.
If Rebecca tunnel-visions on the chess game, she may not consider her other options.
Likewise if she tunnel-visions on lunch. If she inhabits the perspective of the third
Rebecca, she can instead decide between chess moves and decide whether she wants
to be playing chess at all.
Meanwhile, the environment must use a policy that selects an option from E if the
agent chooses from A, and selects an option from F if the agent chooses from B.
In the chess example: The environment must be able to respond to diﬀerent chess
moves, but it must also be able to respond to Rebecca deciding to play a diﬀerent
game.

To give a formal example, let C2 = (A, E, ⋅) and D2 = (B, F, ⋆) be given by the matrices
C2 =
e0
e1
a0
a1
(
w0
w1
w2
w3 )  and  D2 =
f0 
f1 
f2
b0
b1
b2
⎛
⎜
⎝
w4
w5
w6
w7
w8
w9
w10
w11
w12
⎞
⎟
⎠
.
Here, C2 ⊕D2 is given by
C2 ⊕D2 =
e0f0 
e0f1 
e0f2 
e1f0 
e1f1 
e1f2
a0
a1
b0
b1
b2
⎛
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜
⎝
 w0 
 w0 
 w0 
 w1 
 w1 
 w1 
 w2 
 w2 
 w2 
 w3 
 w3 
 w3 
 w4 
 w5 
 w6 
 w4 
 w5 
 w6 
 w7 
 w8 
 w9 
 w7 
 w8 
 w9 
 w10 
 w11 
 w12 
 w10 
 w11 
 w12 
⎞
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟
⎠
.
If we wish to interpret C2 ⊕D2 temporally, we can say: The agent ﬁrst chooses what
game to play. The environment then, as a function of which game was chosen,
"chooses" what it does; and the agent simultaneously chooses its own move within
the game it picked.
Deﬁnition: Let 0 be given by the Cartesian frame 0 = ({}, {e}, ⋅), where Agent(0) is
the empty set, Env(0) = {e} is any singleton set, and Eval(0) is trivial, since it has
empty domain.
Claim: ⊕ is commutative and associative, and 0 is the identity of ⊕ (up to
isomorphism).
Proof: Trivial. □
Returning to our interpretation of morphisms as diﬀerences in agents' strength: The
agent of C ⊕D can choose between being the agent from C or the agent from D, and
so is stronger than either. Indeed, we can think of C ⊕D's agent as the weakest agent

that is stronger than both C's agent and D's agent. Mathematically, this translates to 
⊕ being the categorical coproduct in Chu(W).
Theorem: C0 ⊕C1 is the coproduct of C0 and C1 in Chu(W), and 0 is initial in Chu(W).
Proof: First, we show that 0 is initial. We want to show that there exists a unique
morphism from 0 to a given C. Indeed, a morphism from 0 to C = (A, E, ⋅) is a function
from {} to A along with a function from E to {e}, and there is always exactly one such
pair of functions, regardless of what A and E are. It is also easy to see that this pair of
functions is a morphism, since the condition for morphism is empty, since Agent(0) is
empty. Thus 0 is initial.
Let Ci = (Ai, Ei, ⋅i), and let C0 ⊕C1 = (A0 ⊔A1, E0 × E1, ⋄). We want to show that there
exist inclusion morphisms ι0 : C0 →C0 ⊕C1 and ι1 : C1 →C0 ⊕C1 such that for any
Cartesian frame D = (B, F, ⋆), and any pair of morphisms ϕ0 : C0 →D and ϕ1 : C1 →D,
 we have that there exists a unique morphism ϕ : C0 ⊕C1 →D such that ϕ ∘ι0 = ϕ0
 and ϕ ∘ι1 = ϕ1.
First, we need to specify ιi : (Ai, Ei, ⋅i) →(A0 ⊔A1, E0 × E1, ⋄). We let ιi = (ji, ki), where 
ji : Ai →A0 ⊔A1 is just the the obvious inclusion of Ai into A0 ⊔A1, and ki : E0 × E1 →Ei
 is just the obvious projection. This is clearly a morphism.
Given ϕ0 = (g0, h0) : C0 →D and ϕ1 = (g1, h1) : C1 →D, we let ϕ = (g, h), where 
g : A0 ⊔A1 →B is given by g(a) = gi(a) where i is such that a ∈Ai, and h : F →E0 × E1 is
given by h(f) = (h0(f), h1(f)). This is a morphism because for all a ∈A0 ⊔A1 and f ∈F,
we have
a ⋄ h ( f )  = a ⋅ i h i ( f ) 
 = g i ( a ) ⋆ f 
 = g ( a ) ⋆ f , 

where i is such that a ∈Ai. It is clear from the deﬁnitions that ϕ ∘ιi = ϕi.
Finally, we need to show the uniqueness of this ϕ. Let ϕ′ = (g′, h′) : C0 ⊕C1 →D be a
morphism such that ϕ′ ∘ιi = ϕi for both i = 1, 2. This means that g′(a) = gi(a) when 
a ∈Ai, so g′(a) = g(a) for all a ∈A0 ⊔A1. Similarly, h′(f) must project to h0(f) and h1(f),
so
h ′ ( f )  = ( h 0 ( f ) , h 1 ( f ) ) 
 = h ( f ) 
for all f ∈F. Thus ϕ′ = ϕ. □
 
4. Products of Cartesian Frames
Dual to sum, we have the product operation, &. This operation is a product. It is also in
the section on additive operations. There are many counterintuitive things about the
notation of Chu spaces and linear logic.
Deﬁnition: For Cartesian frames C = (A, E, ⋅) and D = (B, F, ⋆) over W, C&D is the
Cartesian frame (A × B, E ⊔F, ⋄), where (a, b) ⋄e = a ⋅e if e ∈E, and (a, b) ⋄e = b ⋆e if 
e ∈F.
C&D means that the agent might have to be the agent of C, and might have to be the
agent of D, but does not get to decide which one. Thus, it will have to choose a pair, 
(a, b), where a says how to behave in a C situation, and b says how to behave in a D
 situation. The environment will "choose" to either be C's environment or D's
environment. When the agent and environment interact, the agent uses the
component of its pair that matches the environment's choice.
Instead of thinking of the agent as choosing a pair, we could again think about the
situation temporally. C&D is equivalent to an interaction where the environment ﬁrst
chooses which Cartesian frame, C or D, to play; then the agent observes this choice,
and the agent and environment simultaneously behave as though they were in the
chosen frame, either C or D.

(In fact, if Image(C) and Image(D) are disjoint, we can see this interpretation in the
formalism by noting that Image(C) ∈Obs(C&D)—that is, the agent can change its
behavior on the basis of whether the environment selected from C or from D.)
For example, if we let C2 and D2 be as the example in §3,
C2 =
e0
e1
a0
a1
(
w0
w1
w2
w3 )  and  D2 =
f0 
f1 
f2
b0
b1
b2
⎛
⎜
⎝
w4
w5
w6
w7
w8
w9
w10
w11
w12
⎞
⎟
⎠
,
then C2&D2 is given by
C2&D2 =
  e0  
e1  
f0  
f1  
f2  
a0b0
a0b1
a0b2
a1b0
a1b1
a1b2
⎛
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜
⎝
w0
w1
w4
w5
w6
w0
w1
w7
w8
w9
w0
w1
w10
w11
w12
w2
w3
w4
w5
w6
w2
w3
w7
w8
w9
w2
w3
w10
w11
w12
⎞
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟
⎠
.
A second example: Suppose that we have two Cartesian frames, C3 and D3.  C3 is a
frame in which it's raining, and the agent chooses whether to carry an umbrella. D3 is
a frame in which it's sunny, and the agent chooses whether to carry an umbrella.
C 3 = 
r  
u 
n  
( 
u r 
n r  )   and    D 3 = 
s  
u 
n  
( 
u s 
n s  ) 
It turns out that the second example we provided in "Introduction to Cartesian
Frames" §3.2 (Examples of Controllables) is exactly equal to the product of these two
Cartesian frames, 

r
s
uu = u
nn = n
un = u ↔r
nu = u ↔s
⎛
⎜ 
⎜ 
⎜
⎝
ur
us
nr
ns
ur
ns
nr
us
⎞
⎟ 
⎟ 
⎟
⎠
.
The environment is the disjoint union of the rain and sun environments, and the
policies of the agent can be viewed as "I get to choose what to do as a function of
what game we're playing," where "what game we're playing" is "what the weather is."
Deﬁnition: Let ⊤ be given by the Cartesian frame ⊤= ({a}, {}, ⋅), where Agent(⊤) is
a singleton, Env(⊤) is the empty set, and Eval(⊤) is trivial, since it has empty domain.
Claim: & is commutative and associative, and ⊤ is the identity of & (up to
isomorphism).
Proof: Trivial. □
& is essentially just ⊕ from the point of view of the environment. Thus, since −∗
 swaps agent and environment, we can express & using ⊕ and −∗.
Claim: C&D = (C ∗⊕D∗)∗, ⊤= 0∗, C ⊕D = (C ∗&D∗)∗, and 0 = ⊤∗.
Proof: Trivial. □
In other words, ⊕ and & are De Morgan dual with respect to −∗.
In the same way that we interpreted C ⊕D as having the weakest agent that is
stronger than the agents of C and D, we can interpret C&D's agent as the strongest
agent that is weaker than the agents of C and D.
Theorem: C0&C1 is the product of C and D in Chu(W), and ⊤ is terminal in Chu(W).
Proof: Since ⊕ is the coproduct in Chu(W), it is the product in Chu(W)op. Since −∗ is
an isomorphism between Chu(W) and Chu(W)op, we can take a product in Chu(W) of 

C0 and C1 by sending them to Chu(W)op via this isomorphism, taking a product, and
sending them back. Thus (C
∗
0 ⊕C
∗
1 )∗= C0&C1 is the product in Chu(W) of C0 and C1.
Similarly, since 0 is initial in Chu(W), it is terminal in Chu(W)op. Thus, 0∗= ⊤ is
terminal in Chu(W). □
 
Our next post will discuss equivalence relations between Cartesian frames. We will
introduce a homotopy equivalence on Cartesian frames, and employ these relations to
classify small Cartesian frames up to homotopy.
 
Footnotes
1. One important reason −⊥ is bad notation for dual is that AB normally represents 
B →A, where → is your category's internal hom functor. For Chu spaces, → is ⊸. Since 
⊥ will be the name for an object in our category, one would reasonably expect C ⊥ to
represent ⊥⊸C, but it doesn't. Worse still, C ∗ does happen to be equivalent to C ⊸⊥,
and this will be an important fact to understand. To minimize confusion, we instead
use the common notation −∗ for dual. ↩

Biextensional Equivalence
Crossposted from the AI Alignment Forum. May contain more technical jargon than
usual.
This is the third post in the Cartesian frames sequence. Read the ﬁrst post here.
This post will introduce the standard equivalence relations we'll be using for Cartesian
frames. Our primary interest will be in homotopy equivalence, which will allow us to
classify frames according to their agents' and environments' eﬀect on possible worlds.
 
1. Isomorphism
Before deﬁning homotopy equivalence, I want to deﬁne isomorphism between
Cartesian frames.
Deﬁnition: A morphism (g, h) : C →D is an isomorphism if both g and h are bijective.
If there is an isomorphism between C and D, we say C ≅D.
Claim: ≅ is an equivalence relation.
Proof: Reﬂexivity is trivial because the identity is an isomorphism. For symmetry, we
have that if (g, h) is an isomorphism from C to D, then (g−1, h−1) is an isomorphism
from D to C. Transitivity follows from the fact that bijection is transitive. □
Claim: C ≅D if and only if there is a pair of morphisms ϕ : C →D and ψ : D →C that
compose to the identity morphism in both orders.
Proof: If C ≅D, we have (g, h) : C →D with both g and h bijective, and we can take 
ϕ = (g, h) and ψ = (g−1, h−1).
Conversely, if (g1, h1) ∘(g0, h0) is the identity morphism on C = (A, E, ⋅), then g1 ∘g0 is
the identity on A, so g0 must be injective. Similarly, h0 ∘h1 is the identity on E, so h0
 must be surjective. Surjectivity of g0 and injectivity of h0 follow similarly from the fact
that (g0, h0) ∘(g1, h1) is the identity on D. □
Isomorphism is pretty intuitive. It is basically saying that it doesn't matter what the
possible agents and possible environments are, other than how they interact with the

evaluation function.
We will basically always be working up to at least isomorphism. For example, in the
last post ("Additive Operations on Cartesian Frames"), we noted that ⊕ and & are
commutative and associative up to isomorphism.
 
2. Homotopy Equivalence
2.1. Homotopic Morphisms
Our initial deﬁnition of homotopy equivalence will be devoid of interpretation, but the
meaning will become clear later.
We say that two morphisms from C to D are homotopic if you can take the ﬁrst
function from the ﬁrst morphism and the second function from the second morphism,
and the resulting object is still a morphism.
Deﬁnition: Two morphisms (g0, h0), (g1, h1) : C →D with the same source and target
are called homotopic if (g0, h1) is also a morphism.
Note that the mere existence of two morphisms from C to D doesn't entail that those
morphisms are homotopic. Consider the frame C0 = (A, E, ⋅) given by
C0 =
e0
e1
a0
a1
(
w1
w0
w0
w1 ) .
There are two morphisms from C0 to itself: the identity morphism (idA, idE) : C0 →C0,
and a morphism (g, h) : C0 →C0 that ﬂips C0's rows and columns, sending a0 to a1, a1
 to a0, e0 to e1, and e1 to e0. These two morphisms are not homotopic, because
neither (idA, h) nor (g, idE) is a morphism.
Being homotopic is an equivalence relation on morphisms. (As such, in the above
example it would have been superﬂuous to demonstrate that both (idA, h) and (g, idE)
 aren't morphisms.)
Claim: Homotopic is an equivalence relation.

Proof: Let (gi, hi) : (A, E, ⋅) →(B, F, ⋆).
Reﬂexivity is trivial. For symmetry, we want to show that if (g0, h0), (g1, h1), and 
(g0, h1) are all morphisms, then so is (g1, h0). Indeed, for all a ∈A and f ∈F,
g 1 ( a ) ⋆ f  = a ⋅ h 1 ( f ) 
 = g 0 ( a ) ⋆ f 
 = a ⋅ h 0 ( f ) . 
For transitivity, we want to show that if (g0, h0), (g0, h1), (g1, h1), (g1, h2), and (g2, h2)
 are all morphisms, then so is (g0, h2). Indeed, for all a ∈A and f ∈F,
g 0 ( a ) ⋆ f  = a ⋅ h 1 ( f ) 
 = g 1 ( a ) ⋆ f 
 = a ⋅ h 2 ( f ) . 
□
Being homotopic is also respected by composition. 
Claim: If ϕ0 : C0 →C1 is homotopic to ϕ1 : C0 →C1, and ψ0 : C1 →C2 is homotopic to 
ψ0 : C1 →C2, then ψ0 ∘ϕ0 is homotopic to ψ1 ∘ϕ1.
Proof: Let Ci = (Ai, Ei, ⋅i), let ϕi = (gi, hi), and let ψi = (ji, ki). We want to show that 
(j0 ∘g0, h1 ∘k1) is a morphism. Indeed, since (g0, h1) and (j0, k1) are morphisms,
j 0 ( g 0 ( a ) ) ⋅ 2 f  = g 0 ( a ) ⋅ 1 k 1 ( f ) 
 = a ⋅ 0 h 1 ( k 1 ( f ) ) . 
□
Next, we deﬁne when two Cartesian frames are homotopy equivalent in the standard
way.
 
2.2. Homotopy Equivalence

Homotopy equivalence relies on the existence of morphisms between C and D that we
can compose in either order and end up with something that is homotopic to the
identity morphism.
Deﬁnition: C is homotopy equivalent to D, written C ≃D, if there exists a pair of
morphisms ϕ : C →D and ψ : D →C such that ψ ∘ϕ is homotopic to the identity on C
 and ϕ ∘ψ is homotopic to the identity on D.
Claim: ≃ is an equivalence relation.
Proof: Reﬂexivity is trivial, by taking ψ = ϕ to be the identity. Symmetry is also trivial
by swapping ϕ and ψ.
For transitivity, assume that for i = 0, 1, we have ϕi : Ci →Ci+1 and ψi : Ci+1 →Ci such
that ϕi ∘ψi and ψi ∘ϕi are homotopic to the identity. It suﬃces to show that 
ϕ0 ∘ϕ1 ∘ψ1 ∘ψ0 and ψ1 ∘ψ0 ∘ϕ0 ∘ϕ1 are both homotopic to the identity. In both cases,
since composition respects what is homotopic, we have that the inner pair of
morphisms cancels, and then the outer pair of morphisms cancels. □
Note that homotopy equivalence is weaker than isomorphism.
Claim: If C ≅D, then C ≃D.
Proof: Trivial. □
We now have the homotopy equivalence relation on Cartesian frames, but no real
philosophical interpretation. To understand the meaning of ≃, we will ﬁrst need to
deﬁne biextensional collapse.
 
3. Biextensional Equivalence
3.1. Biextensionality
Deﬁnition: A Cartesian frame C = (A, E, ⋅) is called biextensional if whenever 
a0, a1 ∈A are such that a0 ⋅e = a1 ⋅e, for all e ∈E, we have a0 = a1, and whenever 
e0, e1 ∈E are such that a ⋅e0 = a ⋅e1, for all a ∈A, we have e0 = e1.

This is basically saying that a Cartesian frame is biextensional if all of its possible
agents and possible environments are distinct when viewed as functions from
environment to world and functions from agent to world respectively. The agent
doesn't have two options that invariably produce the same outcomes as each other,
nor does the environment.
Viewed as a matrix, C is biextensional if all of its rows and columns are distinct.
We have the following lemma that hints at the relationship between biextensionality
and homotopy equivalence.
Lemma: Let C and D be biextensional Cartesian frames. Then, C ≃D if and only if 
C ≅D.
Proof: The "if" direction is trivial. For the "only if" direction, let C = (A, E, ⋅) and 
D = (B, F, ⋆) be two biextensional Cartesian frames, and let C ≃D. Thus, there is a pair
of morphisms (g, h) : C →D and (j, k) : D →C such that (j ∘g, h ∘k) is homotopic to the
identity on C, and (g ∘j, k ∘h) is homotopic to the identity on D. Thus (j ∘g, idE) and 
(g ∘j, idF) are both morphisms, where idS is the identity on the set S. This means that 
j(g(a)) ⋅e = a ⋅e for all a and e, which since C is biextensional implies that j ∘g is the
identity on A. Similarly, since (g ∘j, idF) is a morphism, we have that g ∘j is the
identity on B. Thus g : A →B is a bijection.
By the symmetry of homotopic, we also have that (idA, k ∘h) and (idB, h ∘k), which
similarly gives us that k ∘h is the identity on E and h ∘k is the identity of F, so 
h : F →E is a bijection. Thus, C ≅D. □
Thus, we now understand how to interpret homotopy equivalence for biextensional
Cartesian frames: it is equivalent to isomorphism.
To understand homotopy equivalence in general, we will ﬁrst show how to collapse
any Cartesian frame into a biextensional one.
 
3.2. Biextensional Collapse
Given a Cartesian frame C = (A, E, ⋅), we can deﬁne an equivalence relation on A that
says two possible agents are equivalent if they implement the same function from E

 to W; and we can similarly say that two elements of E are equivalent if they
implement the same function from A to W.
Deﬁnition: Given a Cartesian frame C = (A, E, ⋅), for a0, a1 ∈A, we say a0 ∼a1 if 
a0 ⋅e = a1 ⋅e for all e ∈E. For e0, e1 ∈E, we say that e0 ∼e1 if a ⋅e0 = a ⋅e1 for all 
a ∈A.
Claim: ∼ is an equivalence relation on A and on E .
Proof: Trivial. □
Deﬁnition: Given a Cartesian frame C = (A, E, ⋅), for a ∈A, let ^
a  denote the
equivalence class of a up to ∼. Let  ^
A  denote the set of equivalence classes of ∼ in A.
Similarly, for e ∈E, let ^
e  denote the equivalence class of e up to ∼, and let  ^
E  denote
the set of equivalence classes of ∼ in E.
Deﬁnition: Given a Cartesian frame C = (A, E, ⋅), the biextensional collapse of C,
denoted  ^
C , is the Cartesian frame ( ^
A , ^
E , ^⋅), where ^
a ^⋅^
e = a ⋅e.
Claim:  ^
C  is well-deﬁned.
Proof: We need to show that ^⋅ is well deﬁned, meaning we need to show that for all 
a0 ∼a1 and e0 ∼e1, we have that a0 ⋅e0 = a1 ⋅e1. This is immediate from the
deﬁnition of ∼. □
Viewed as a matrix,  ^
C  is basically formed from C by deleting any duplicate rows and
any duplicate columns. It doesn't matter whether you delete duplicate rows or
duplicate columns ﬁrst. After doing both, you will end up with a matrix with no
duplicates.
Claim:  ^
C  is biextensional for all Cartesian frames C.
Proof: Let C = (A, E, ⋅). We want to show that for all  ^
a0 ≠^
a1 ∈^
A , there exists an 
^
e ∈^
E  such that  ^
a0^⋅^
e ≠^
a1^⋅^
e . Indeed, since  ^
a0 ≠^
a1, we have that a0 ≁a1, so there

exists an e ∈E such that a0 ⋅e ≠a1 ⋅e, which gives us that  ^
a0^⋅^
e ≠^
a1^⋅^
e . Similarly,
for all  ^
e0 ≠^
e1 ∈^
E , there exists an ^
e ∈^
E  such that ^
a ^⋅^
e0 ≠^
a ^⋅^
e1. □
Claim: C is biextensional if and only if C ≅^
C .
Proof: If C is biextensional, then all equivalence classes up to ∼ on both A and E are
singletons. Thus, the morphism (g, h) : C →^
C  given by g(a) = ^
a  and h(^
e ) = e is well-
deﬁned, and both g and h are bijective, so C ≅^
C .
Conversely, if C ≅^
C , then C is isomorphic to a biextensional Cartesian frame, and
since biextensionality is clearly preserved by isomorphism, C is also biextensional. □
 
3.3. Biextensional Equivalence
We can now (ﬁnally) use biextensional collapse to give an intuitive meaning to
homotopy equivalence.
Claim: C ≃D if and only if  ^
C ≅^
D .
Proof: It suﬃces to show that C ≃^
C  for all Cartesian frames C. Then, we will have
that if C ≃D, then  ^
C ≃C ≃D ≃^
D . Since homotopy equivalence is the same as
isomorphism on biextensional Cartesian frames, this gives  ^
C ≅^
D . And conversely, if 
^
C ≅^
D  then C ≃^
C ≅^
D ≃D, so C ≃D.
Let C = (A, E, ⋅). We want to show that C ≃^
C . We do this by constructing a pair of
morphisms (g, h) : C →^
C , and (j, k) : ^
C →C. We will deﬁne g : A →^
A  by a ↦^
a , and 
k : E →^
E  by e ↦^
e . For h : ^
E →E, and j : ^
A →A, we can send each equivalence class
to any one member of that class. The choice does not matter.
Now, we want to show that (g ∘j, k ∘h) is homotopic to the identity on  ^
C , and that 
(j ∘g, h ∘k) is homotopic to the identity on C. The ﬁrst case is trivial, since g ∘j and 

k ∘h are the identity on  ^
A  and  ^
E  respectively. j ∘g and h ∘k need not be the identity
on A and E, but j(g(a)) ∼a and h(k(e)) ∼e for all a ∈A and e ∈E. To show that 
(j ∘g, h ∘k) is homotopic to the identity on C, we just need to show that (j ∘g, idE) is a
morphism, where idE is the identity on E. However, this just means that 
j(g(a)) ⋅e = a ⋅e for all a ∈A and e ∈E, which follows from the fact that j(g(a)) ∼a. □
We now have that two Cartesian frames are homotopy equivalent if and only if their
biextensional collapses are isomorphic. Thus, when C and D are homotopy equivalent,
we will also call them biextensionally equivalent.
Deﬁnition: We say C and D are biextensionally equivalent if C ≃D.
When working up to biextensional equivalence, we are basically saying that we are
ignoring any multiplicity in the space of possible worlds and possible environments.
Claim: Each biextensional equivalence class contains a unique biextensional
Cartesian frame.
Proof: Each biextensional equivalence class has at least one element, C, and  ^
C  is in
the same equivalence class as C and is biextensional, so there must be at least one
biextensional Cartesian frame in the class. If there were two biextensional Cartesian
frames, they would have to be isomorphic, because isomorphic is equivalent to
biextensional equivalence on biextensional Cartesian frames. □
From my perspective, the value of this equivalence relation is that it lets us be less
realist about possible agents and possible environments, and instead just care about
diﬀerences between possible worlds.
This ﬁts well with our general approach in this sequence. Cartesian frames are
particular ways of looking at the world and mentally carving it up into an agent
component and an environment component, but we allow many diﬀerent carvings,
and we do not give any one carving privileged status as the "true" carving. Thus, we
put less weight on our conception of the agent and environment, and more weight on
the worlds themselves.
Giving less realism to possible agents/environments also ﬁts with the fact that
"worlds" may include details about the agent and environment, "possible agents" may
specify features of the agent beyond its "actions," and so on.
Imagine an agent with two unrelated choices: which color to think about (green G, or
red R) and whether to go for a walk or stay home (W or H). This yields the possible

agents A = {GH, GW, RH, RW}. The environment either is safe or has bears: E = {S, B}.
If we represent this scenario with the Cartesian frame
C0 =
S
B
GH
GW
RH
RW
⎛
⎜ 
⎜ 
⎜
⎝
w0
w1
w2
w3
w4
w5
w6
w7
⎞
⎟ 
⎟ 
⎟
⎠
,
then the possible worlds w0 and w4 diﬀer only in which thought the agent is thinking;
likewise w1 and w5, etc.
We could have instead described a frame
C1 =
S
B
GH
GW
RH
RW
⎛
⎜ 
⎜ 
⎜
⎝
w8
w9
w10
w11
w8
w9
w10
w11
⎞
⎟ 
⎟ 
⎟
⎠
,
in which case we would not be treating the agent's thoughts as a relevant diﬀerence
between possible worlds.1 But we have the option of fully representing "agent-
internal" properties using possible worlds, just the same as "environment-internal"
properties. As such, we don't need to separately reify possible agents or possible
environments.
 
3.4. Example
One reason there are two deﬁnitions here is because the homotopy deﬁnition is easier
to work with categorically, while the biextensionality deﬁnition is easier to work with
directly with matrices.
Let C0 and C1 be the Cartesian frames given by:

C0 ≅
⎛
⎜
⎝
w0
w1
w1
w2
w3
w3
w0
w1
w1
⎞
⎟
⎠
 and C1 ≅
⎛
⎜
⎝
w2
w3
w2
w0
w1
w0
w2
w3
w2
⎞
⎟
⎠
.
Note that when working up to isomorphism, there is no need to label the rows or
columns.
We can then see that C0 ≃C1 because
^
C 0 ≅^
C 1 ≅(
w0
w1
w2
w3 ).
To verify the equivalence using the the homotopy deﬁnition would be far more
tedious.
 
3.5. Relationship to Additive Operations
Since we will often want to work with Cartesian frames up to biextensional
equivalence, it will be helpful to know that all of our additive operations respect
biextensional equivalence.
Claim: If C0 ≃C1 and D0 ≃D1, then C
∗
0 ≃C
∗
1 , C0 ⊕D0 ≃C1 ⊕D1, and C0&D0 ≃C1&D1
.
Proof: It is clear from the deﬁnition of biextensional collapse that ^
− commutes with 
−∗. Thus since  ^
C0 ≅^
C1, we have 
^
C
∗
0 ≅
^
C
∗
1 , so C
∗
0 ≃C
∗
1 .
For the rest, it suﬃces to show that if C0 ≃C1, then C0 ⊕D ≃C1 ⊕D. Then, since ⊕ is
symmetric up to isomorphism, we have 
C 0 ⊕ D 0  ≃ C 1 ⊕ D 0 
 
 
                                  ≅ 
                                
 D 0 ⊕ C 1 
 ≃ D 1 ⊕ C 1 
 
 
                                  ≅ 
                                
 C 1 ⊕ D 1 , 

and using the fact that ⊕ and & are De Morgan dual, we have
C 0 & D 0  
 
                                  ≅ 
                                
 ( C 
∗
0  ⊕ D 
∗
0  ) ∗ 
 ≃ ( C 
∗
1  ⊕ D 
∗
1  ) ∗ 
 
 
                                  ≅ 
                                
 C 1 & D 1 . 
We will use the homotopy equivalence deﬁnition. Let Ci = (Ai, Ei, ⋅i) and let D = (B, F, ⋆)
. Let (g0, h0) : C0 →C1 and (g1, h1) : C1 →C0 compose to something homotopic to the
identity in both orders. We want to construct a (g
′
0, h
′
0) : C0 ⊕D →C1 ⊕D and 
(g
′
1, h
′
1) : C1 ⊕D →C0 ⊕D, that similarly compose to something homotopic to the
identity in both orders. We will take g
′
i : Ai ⊔B →A1−i ⊔B to be given by g
′
i(a) = gi(a) if 
a ∈Ai, and g
′
i(a) = a if a ∈B. Similarly, we will take h
′
i : E1−i × F →Ei × F to be given
by h
′
i(e, f) = (hi(e), f).
Without loss of generality, it suﬃces to show that (g
′
0, h
′
0) is a morphism and that 
(g
′
1, h
′
1) ∘(g
′
0, h
′
0) is homotopic to the identity on C0 ⊕D. The fact that (g
′
1, h
′
1) is a
morphism and (g
′
0, h
′
0) ∘(g
′
1, h
′
1) is homotopic to the identity will follow symmetrically.
Let ⋄i = Eval(Ci ⊕D).
To show that (g
′
0, h
′
0) is a morphism, observe that for all a ∈A0 and (e, f) ∈E1 × F, we
have

g 
′
0 ( a ) ⋄ 1 ( e , f )  = g 0 ( a ) ⋅ 1 e 
 = a ⋅ 0 h 0 ( e ) 
 = a ⋄ 0 ( h 0 ( e ) , f ) 
 = a ⋄ 0 h 
′
0 ( e , f ) . 
Similarly, for all a ∈B and (e, f) ∈E1 × F, we have
g 
′
0 ( a ) ⋄ 1 ( e , f )  = a ⋆ f 
 = a ⋄ 0 ( h 0 ( e ) , f ) 
 = a ⋄ 0 h 
′
0 ( e , f ) . 
To show that (g
′
1, h
′
1) ∘(g
′
0, h
′
0) is homotopic to the identity on C0 ⊕D, we just need that
for all a ∈A0 ⊔B and all (e, f) ∈E0 × F, we have a ⋄0 (e, f) = g
′
1(g
′
0(a)) ⋄0 (e, f). Indeed,
if a ∈B, then a = g
′
1(g
′
0(a)), and if a ∈A0, then
a ⋄ 0 ( e , f )  = a ⋅ 0 e 
 = g 1 ( g 0 ( a ) ) ⋅ 0 e 
 = g 
′
1 ( g 
′
0 ( a ) ) ⋄ 0 ( e , f ) . 
□
Image is also clearly preserved by biextensional equivalence.
Claim: If C ≃D, then Image(C) = Image(D).
Proof: Trivial from the biextensional collapse deﬁnition. □
 
4. Some Small Cartesian Frames
We will now classify all biextensional Cartesian frames (and thus biextensional
equivalence classes of Cartesian frames) in which the agent's size is at most one

and/or the environment's size is at most one.
Deﬁnition: null is the Cartesian frame ({}, {}, ⋅) with empty agent, empty
environment, and empty evaluation function.
If you have an empty Cartesian frame—one with no image, no elements of W—then it
must be biextensionally equivalent to either null, 0, or ⊤.
Claim: If |Agent(C)| = 0 and |Env(C)| ≠0, then C ≃0. If |Env(C)| = 0 and 
|Agent(C)| ≠0, then C ≃⊤. If |Agent(C)| = |Env(C)| = 0, then C ≃null.
Proof: If |Agent(C)| = 0 and |Env(C)| ≠0, then all environments are equivalent up to 
∼, so  ^
C  has one possible environment and no possible agents, so  ^
C ≅0, so C ≃0.
Similarly, if |Env(C)| = 0 and |Agent(C)| ≠0, all agents are equivalent up to ∼, so 
^
C ≅⊤ and C ≃⊤. If |Agent(C)| = |Env(C)| = 0, then C is already equal to null. □
Claim: The only three biextensional Cartesian frames C with Image(C) = {} are 0, ⊤,
and null.
Proof: A Cartesian frame has empty image if and only if it has empty agent or empty
environment. All three of 0, ⊤, and null are clearly biextensional, and any other
Cartesian frame with empty image is biextensionally equivalent to one of them, and
so cannot be biextensional. □
We now understand all biextensional Cartesian frames with empty agent or empty
environment. Let's look at the case where either the agent or environment is a
singleton.
1S is the biextensional Cartesian frame you get when the agent has only one option,
and the frame's image is some set of possible worlds S. Since Env(1S) will be in
bijective correspondence with S = Image(1S) and the labels on Env(1S) don't matter,
we will identify Env(1S) with S.
Deﬁnition: Given S ⊆W, 1S is the Cartesian frame 1S = ({a}, S, ⋆), where a ⋆s = s for
all s ∈S. 1 is the Cartesian frame 1W.

We can think of 1S as the perspective of a bystander who has no control, and is just
observing which world the environment brings about.
⊥S is the transpose of 1S, where the environment has only one option and the agent's
options are S. You can think of ⊥S as a powerful agent facing no obstacles, beyond
being constrained to S: it gets to choose exactly what world we're in.
Deﬁnition: Given S ⊆W, ⊥S is the Cartesian frame ⊥S = (S, {e}, ⋆), where s ⋆e = s
 for all s ∈S. ⊥ is the Cartesian frame ⊥W.
The names 1 and ⊥ will make more sense later, when we deﬁne multiplicative
operations on Cartesian frames.2
We can think of 1 as a powerless, all-knowing agent, and 1S as 1 with a promise from
the environment that the world will be in S. Similarly, we can think of ⊥ as an all-
powerful agent, and ⊥S as ⊥ with a commitment to do S.
The class of frames where the agent has only one option, 1S, contains 1 at one
extreme (where S = W) and ⊤ at the other extreme (where S = {}). Meanwhile, the
class of frames where the environment has only one option, ⊥S, contains ⊥ at one
extreme (where S = W) and 0 at the other (where S = {}).
Claim: 1∗= ⊥, ⊥∗= 1, 1
∗
S = ⊥S, ⊥
∗
S = 1S, 1{} = ⊤, ⊥{} = 0.
Proof: Trivial. □
Claim: If |Agent(C)| = 1, then C ≃1S, where S = Image(C). If |Env(C)| = 1, then 
C ≃⊥S, where S = Image(C).
Proof: If Agent(C) = {a}, then equivalence classes of environments are given by
where they send a. There will be one such equivalence class for each s ∈Image(C),
and it will send a to s. Thus  ^
C = 1S, so C ≃1S. The |Env(C)| = 1 case is the same with
agent and environment swapped. □

 
Now that we have built up language for talking about Cartesian frames categorically,
we are ready to revisit controllables and observables and interpret them through the
lens of category theory. This will be the focus of our next post.
 
 
Footnotes
1. Similarly, we could have decided that we don't care about certain things about the
environment. For example, if we only care whether there are bears in possible worlds
where the agent went for a walk and might therefore encounter them, then we could
construct a frame
C2 =
S
B
GH
GW
RH
RW
⎛
⎜ 
⎜ 
⎜
⎝
w12
w12
w13
w14
w15
w15
w16
w17
⎞
⎟ 
⎟ 
⎟
⎠
.
↩
2. Indeed, this section on small Cartesian frames would make more sense as part of
our discussion of multiplicative operations on Cartesian frames; our motivation for
discussing these objects will be provided there. I'm introducing these objects early
because they will be useful in a few contexts before we get to multiplicative
operations. ↩

Controllables and Observables,
Revisited
Crossposted from the AI Alignment Forum. May contain more technical jargon than
usual.
This is the fourth post in the Cartesian frames sequence. Read the ﬁrst post here.
Previously, we deﬁned controllables as the sets of possible worlds an agent can both
ensure and prevent, and we deﬁned observables as the sets of possible worlds such
that the agent can implement all conditional policies.
Now that we have built up more language, we can redeﬁne controllables and
observables more categorically.
 
1. Controllables
1.1. Ensurables and Preventables
The categorical deﬁnition of ensurables is very simple.
Deﬁnition: Ensure(C) is the set of all S ⊆W such that there exists a morphism 
ϕ : 1S →C.
As an example, let C0 = (A, E, ⋅). Recall that 1S = ({b}, S, ⋆), where b ⋆s = s for all 
s ∈S. E.g., if S0 = {w0, w3, w4}, then
1S0 =
w0  
w3  
w4
b
( w0 
 w3 
 w4 ) .
If there is a morphism (g, h) from 1S0 to C0, this means that:
There is a function g from 1S0's agent {b} to C0's agent A, i.e., a function that
always outputs a speciﬁc a ∈A.
There is a function h from C0's environment E to 1S0's environment S0.
The speciﬁc a ∈A picked out by g exactly implements that function h : E →S0.

That function h : E →S0 is exactly like the function you get by looking at that row, so a
morphism (g, h) : 1S0 →C0 is like a row in C0 that is entirely contained in S0. If there
are multiple such rows, then there will be multiple distinct morphisms 1S0 →C0 picking
out diﬀerent a ∈A.
In "Biextensional Equivalence," we noted that 1S is like a passive observer who has a
promise from the environment that the world will be in S. The existence of a
morphism 1S →C means that there's an interface that allows a powerless bystander
who has been promised S to play C's game. Since Agent(1S) only has one option, this
interface must send that one option to some option for C's agent that is compatible
with this promise.
Claim: This deﬁnition is equivalent to the one in "Introduction to Cartesian Frames": 
Ensure(C) = {S ⊆W | ∃a ∈A, ∀e ∈E, a ⋅e ∈S}.
Proof: Let C = (A, E, ⋅) and let 1S = ({b}, S, ⋆), where b ⋆s = s for all s ∈S. First,
assume there exists a morphism (g, h) : 1S →C. Here, g : {b} →A and h : E →S.
Consider the element g(b) ∈A. It suﬃces to show that g(b) ⋅e ∈S for all e ∈E.
Indeed, g(b) ⋅e = b ⋆h(e) ∈S.
Conversely, assume that there exists an a ∈A, such that a ⋅e ∈S for all e ∈E. Then,
there is a morphism (g, h) : 1S →C given by g(b) = a, and h(e) = a ⋅e. This is a
morphism because
g ( b ) ⋅ e  = a ⋅ e 
 = h ( e ) 
 = b ⋆ h ( e ) 
for all b ∈{b} and e ∈E. □
Deﬁnition: Prevent(C) is the set of all S ⊆W such that there exists a morphism 
ϕ1 : 1W∖S →C.

Claim: This deﬁnition is equivalent to the one in "Introduction to Cartesian Frames": 
Prevent(C) = {S ⊆W | ∃a ∈A,  ∀e ∈E,  a ⋅e ∉S}.
Proof: This follows from the proof for Ensure(C), substituting W∖S for S. □
Our categorical deﬁnition gives us a bunch of facts about how ensurability interacts
with various operations on Cartesian frames. First, ensurability is monotonic in the
existence of morphisms.
Claim: If there exists a morphism ϕ : C →D, then Ensure(C) ⊆Ensure(D).
Proof: If S ∈Ensure(C), there exists a morphism ψ : 1S →C, so we have ϕ ∘ψ : 1S →D,
 so S ∈Ensure(D). □
This fact justiﬁes our interpretation of the existence of a morphism from C to D as
saying that "D is at least as strong as C."
We also have that ensurables interact very strongly with sums and products. The
ensurables of a product are the intersection of the original two agents' ensurables,
and the ensurables of a sum are (usually) the union of the original two agents'
ensurables.
This makes sense when we think of C ⊕D as "there are two games, and the agent
gets to choose which one we play," and C&D as "there are two games, and the
environment gets to choose which one we play." The agent of C ⊕D can make sure
something happens if either C or D's agent could, whereas the agent of C&D can only
ensure things that are ensurable across both games.
Claim: Ensure(C&D) = Ensure(C) ∩Ensure(D).
Proof: Since & is a categorical product, if there exists a morphism from 1S to C and a
morphism from 1S to D, there must exist a morphism from 1S to C&D. Thus 
Ensure(C&D) ⊇Ensure(C) ∩Ensure(D). Conversely, since & is a categorical product,
there exist projection morphisms from C&D to C and from C&D to D, so 
Ensure(C&D) ⊆Ensure(C) ∩Ensure(D). □
Claim: If C ≠null and D ≠null, then Ensure(C ⊕D) = Ensure(C) ∪Ensure(D).

Proof: Let C = (A, E, ⋅), and let D = (B, F, ⋆). Since C is not null, if E were empty, then A
 would have to be nonempty, and Ensure(C) would be the full set 2W. C ⊕D would also
have empty environment and nonempty agent, and so Ensure(C ⊕D) would also be
the full set 2W. Thus, we are done in the case where E is empty. Similarly, we are done
in the case where F is empty. Assume E and F are nonempty.
It is clear that Ensure(C ⊕D) ⊇Ensure(C) ∪Ensure(D) because C ⊕D is a coproduct, so
there are canonical injection morphisms from C to C ⊕D and from D to C ⊕D.
Conversely, if S ∈Ensure(C ⊕D), then there is a morphism (g, h) : 1S →C ⊕D. Since 
g : Agent(1S) →A ⊔B, and Agent(1S) = {b′} is a singleton, the image of g must be
entirely in A or in B. Without loss of generality, assume it is in A. Then, let f be any
element of F. There is a morphism (g′, h′) : 1S →C given by g′(b′) = g(b′), and 
h′(e) = h(e, f). This is a morphism because
b ′ ⋄ h ′ ( e )  = b ′ ⋄ h ( e , f ) 
 = g ( b ′ ) ∙ ( e , f ) 
 = g ′ ( b ′ ) ⋅ e , 
where ⋄= Eval(1S) and ∙= Eval(C ⊕D). Thus, S ∈Ensure(C). □
The condition that C and D are not null is annoying. It is also not very informative. It is
reasonable to just think of null as not a real Cartesian frame, and not worry about it.
To see what concretely goes wrong, let C = ({a}, {e}, ⋅), where a ⋅e = w, and let 
D = null. Ensure(C) = ⟨{w}⟩⊇ and Ensure(D) = {}. However, C ⊕D = ({a}, {}, ⋆), so 
Ensure(C ⊕D) = 2W, since the a ensures everything. The null brought us into the
degenerate case where there are no possible environments, but since it had no
possible agents, it had no ensurables until it was combined with C.
We also have that ensurables are preserved by biextensional equivalence.

Claim: If C ≃D, Ensure(C) = Ensure(D).
Proof: From the homotopy equivalence deﬁnition, we have that if C ≃D, there exist
morphisms from C to D and vice versa. □
Finally, we have that there is a tradeoﬀ between a Cartesian frame's ability to ensure
things and its dual's ability to prevent things.
Claim: Ensure(C) ∩Prevent(C ∗) = {}.
Proof: Trivial. □
 
1.2. Controllables
Controllables also have a simple categorical deﬁnition.
Deﬁnition: Let 2S denote the Cartesian frame 1S ⊕1W∖S. 
Again, C ⊕D represents a game where the agent chooses whether to play C or D, and
the environment must be able to respond in either case. While 1S has one possible
agent, 2S has two possible agents, representing the choice between S and W∖S.
2S's environments are all possible pairs of exactly one s ∈S and exactly one s ∈W∖S.
For example, if S0 = {w0, w3, w4} (as in our earlier example of a 1S) and 
W = {w0, w1, w2, w3, w4}, then
2S0 =
w0w1
w0w2
w3w1
w3w2
w4w1
w4w2
bS0
bW∖S0
(
 w0   
 w0   
 w3   
 w3   
 w4   
 w4 
 w1   
 w2   
 w1   
 w2   
 w1   
 w2  ) .
So the agent decides whether we're in S, and the environment picks a strategy for S
 and another for the complement of S.
Deﬁnition: Ctrl(C) is the set of all S ⊆W such that there exists a morphism ϕ : 2S →C
.

Claim: This deﬁnition is equivalent to the one in "Introduction to Cartesian Frames": 
Ctrl(C) = Ensure(C) ∩Prevent(C).
Proof: Since ⊕ is the categorical coproduct, there exists a morphism from 
2S = 1S ⊕1W∖S to C if and only if there exist a pair of morphisms ϕ0 : 1S →C and 
ϕ1 : 1W∖S →C, which by the above deﬁnitions of ensurables and preventables is true if
and only if S is in both Ensure(C) and Prevent(C). □
Since Ctrl(C) is the set of all S ⊆W with both S and W∖S in Ensure(C), we immediately
have that the following closure properties on ensurables also apply to controllables.
Claim: If there exists a morphism ϕ : C →D, then Ctrl(C) ⊆Ctrl(D).
Proof: Trivial. □
Claim: Ctrl(C&D) = Ctrl(C) ∩Ctrl(D).
Proof: Trivial. □
Claim: If C ≃D, then Ctrl(C) = Ctrl(D).
Proof: Trivial. □
Note that although Ensure(C ⊕D) = Ensure(C) ∪Ensure(D) is usually true, there isn't a
corresponding result for controllables.
 
2. Observables
We also have a new deﬁnition of observables, but it is not nearly as trivial as the
deﬁnition of controllables.
Deﬁnition: Obs(C) is the set of all S ⊆W such that there exist C0 and C1 with 
Image(C0) ⊆S and Image(C1) ⊆W∖S such that C ≃C0&C1.
Claim: This deﬁnition is equivalent to the one in "Introduction to Cartesian Frames": 
Obs(C) = {S ⊆W | ∀a0, a1 ∈A,  ∃a ∈A,  a ∈if(S, a0, a1)}.

Proof: Throughout the proof, we will let Obsold(−) refer to observables as they were
originally deﬁned, and let Obs(−) refer to observables under our categorical deﬁnition.
The proof will be broken into three parts:
First, we will show that Obsold(−) is closed under biextensional equivalence.
Second, we will show that if Image(C0) ⊆S and Image(C1) ⊆W∖S, then 
S ∈Obsold(C0&C1). In combination with the ﬁrst part, this implies that 
Obs(C) ⊆Obsold(C).
Third, we will show that if S ∈Obsold(A, E, ⋅), then (A, E, ⋅) ≃(A, ES, ⋅)&(A, EW∖S, ⋅).
This gives us that Obsold(C) ⊆Obs(C), by taking C0 = (A, ES, ⋅) and C1 = (A, EW∖S, ⋅).
 
Part 1.
We want to show that Obsold(−) is closed under biextensional equivalence.
Let C = (A, E, ⋅), let D = (B, F, ⋆), and let C ≃D. We will use the homotopy equivalence
deﬁnition, so let (g0, h0) : C →D and (g1, h1) : D →C be such that (g0, h0) ∘(g1, h1) and 
(g1, h1) ∘(g0, h0) are both homotopic to the identity. Given S ∈Obsold(C), we want to
show that S ∈Obsold(D).
Given b0, b1 ∈B, we want to show that there exists a b ∈B such that for all f ∈F, if 
b ⋆f ∈S, then b ⋆f = b0 ⋆f, and otherwise b ⋆f = b1 ⋆f. Letting ai = g1(bi), the fact
that S ∈Obsold(C) gives that there exists an a ∈A, such that for all e ∈E, if a ⋅e ∈S,
then a ⋅e = a0 ⋅e, and otherwise, a ⋅e = a1 ⋅e. We will take b = g0(a).
For all f ∈F, we have that
b ⋆ f  = g 0 ( a ) ⋆ f 
 = a ⋅ h 0 ( f ) . 

Further, since (g0, h0) ∘(g1, h1) is homotopic to the identity, we also have that for all 
f ∈F,
b i ⋆ f  = g 0 ( g 1 ( b i ) ) ⋆ f 
 = g 1 ( b i ) ⋅ h 0 ( f ) 
 = a i ⋅ h 0 ( f ) . 
Together these give that if b ⋆f ∈S, then a ⋅h0(f) ∈S, so
b ⋆ f  = a ⋅ h 0 ( f ) 
 = a 0 ⋅ h 0 ( f ) 
 = b 0 ⋆ f , 
 and if b ⋆f ∉S, then a ⋅h0(f) ∉S, so
b ⋆ f  = a ⋅ h 0 ( f ) 
 = a 1 ⋅ h 0 ( f ) 
 = b 1 ⋆ f . 
Thus S ∈Obsold(D), so Obsold(−) is closed under biextensional equivalence.
 
Part 2.
We want to show that if Image(C0) ⊆S and Image(C1) ⊆W∖S, then S ∈Obsold(C0&C1).
Let C0 = (A, E, ⋅), let C1 = (B, F, ⋆), and let C0&C1 = (A × B, E ⊔F, ⋄). Given 
(a0, b0), (a1, b1) ∈A × B, we want to show that there exists an (a, b) ∈A × B such that
if (a, b) ⋄e ∈S, then (a, b) ⋄e = (a0, b0) ⋄e, and otherwise (a, b) ⋄e = (a1, b1) ⋄e. We
will take (a, b) = (a0, b1).
For all f ∈F, (a0, b1) ⋄f = b1 ⋆f ∉S, since Image(C1) ⊆W∖S. Thus, if (a0, b1) ⋄e ∈S,
then e ∈E, so

( a 0 , b 1 ) ⋄ e  = a 0 ⋅ e 
 = ( a 0 , b 0 ) ⋄ e . 
Similarly, if (a0, b1) ⋄e ∉S, then e ∈F, so
( a 0 , b 1 ) ⋄ e  = b 1 ⋅ e 
 = ( a 1 , b 1 ) ⋄ e . 
Thus, S ∈Obsold(C0&C1).
 
Part 3.
We want to show that if S ∈Obsold(A, E, ⋅), then (A, E, ⋅) ≃(A, ES, ⋅)&(A, EW∖S, ⋅).
Let C = (A, E, ⋅), let C0 = (A, ES, ⋅), and let C1 = (A, EW∖S, ⋅). (Here the ⋅ in C0 and C1 is
the restriction of ⋅ in C to the respective domain.) Let ⋆= Eval(C0&C1).
First, let's quickly deal with the degenerate case where A is empty. In this case 
ES = EW∖S = E. If E is also empty, then C ≃null ≃null&null ≃C0&C1. If E is nonempty,
then C ≃0 ≃0&0 ≃C0&C1. Thus, we can restrict our attention to the case where A is
nonempty. Note that in this case, ES and EW∖S are disjoint, and as we saw before they
cover E, so E = ES ⊔EW∖S.
We need to construct a (g0, h0) : C →C0&C1 and a (g1, h1) : C0&C1 →C, which compose
to something homotopic to the identity in both orders. Since E = ES ⊔EW∖S, we can
just take h0 and h1 to be the identity on E. We will take g0 : A →A × A to be the
diagonal given by g0(a) = (a, a). Finally, for g1 : A × A →A, we will use the fact that 
S ∈Obsold(C). We will let g1(a0, a1) be chosen such that g1(a0, a1) ⋅e = a0 ⋅e if 
g1(a0, a1) ⋅e ∈S, and g1(a0, a1) ⋅e = a1 ⋅e otherwise. We can always choose such a 
g1(a0, a1), by the deﬁnition of Obsold(C).

To see that (g0, h0) is a morphism, observe that for all a ∈A and e ∈ES ⊔EW∖S, we
have
g 0 ( a ) ⋆ e  = ( a , a ) ⋆ e 
 = a ⋅ e 
 = a ⋅ h 0 ( e ) , 
regardless of which half e is in.
To see that (g1, h1) is a morphism, observe that for all (a0, a1) ∈A × A and e ∈E, if 
e ∈ES, then
g 1 ( a 0 , a 1 ) ⋅ e  = a 0 ⋅ e 
 = ( a 0 , a 1 ) ⋆ e 
 = ( a 0 , a 1 ) ⋆ h 1 ( e ) , 
 while if e ∈EW∖S, then 
g 1 ( a 0 , a 1 ) ⋅ e  = a 1 ⋅ e 
 = ( a 0 , a 1 ) ⋆ e 
 = ( a 0 , a 1 ) ⋆ h 1 ( e ) . 
Finally, the fact that (g0, h0) and (g1, h1) compose to something homotopic to the
identity in both orders is trivial, since h0 ∘h1 and h1 ∘h0 are both the identity, so
trivially a ⋅e = a ⋅h0(h1(e)), and (a0, a1) ⋆e = (a0, a1) ⋆h1(h0(e)). (Technically, this is
verifying that the identity is homotopic each composition, but since being homotopic
is symmetric, this is ﬁne.)
 
Putting it together.
If S ∈Obs(C), then C ≃C0&C1, where Image(C0) ⊆S and Image(C1) ⊆W∖S. By part
2, S ∈Obsold(C0&C1), which by part 1, means that S ∈Obsold(C). Conversely, if 
S ∈Obsold(A, E, ⋅), then by part 3, (A, E, ⋅) ≃(A, ES, ⋅)&(A, EW∖S, ⋅), which since 
Image(A, ES, ⋅) ⊆S and Image(A, EW∖S, ⋅) ⊆W∖S, implies that S ∈Obs(A, E, ⋅). □

 
Note that from the above proof, if S ∈Obs(C), we know how to construct the C0 and 
C1 such that C ≃C0&C1. In particular, every column of C must be entirely contained
in S or entirely outside of S, and C0 just takes the subset of columns in S while C1
 takes the subset of columns outside of S.
One thing to like about this new deﬁnition is that it shows that when an agent can
observe S, you can actually break it up into two diﬀerent agents. The ﬁrst agent
chooses how to behave in worlds in S and is promised that the world will in fact be in 
S, and the second does the same for the worlds not in S. These two agents combine
using & to form the original agent.
Observables are much less well-behaved than controllables, so there is much less to
say about them at this point. We do have that observability is preserved under
biextensional equivalence, which is trivial under the new deﬁnition and was proven
within the previous proof for the old deﬁnition.
Claim: If C ≃D, then Obs(C) = Obs(D).
Proof: Trivial. □
 
3. Controllables and Observables Are Still
Disjoint
To become more used to our new deﬁnitions, let us reprove the incompatibility
theorems from before. First, a lemma.
Lemma: Let C ≃C0&C1, with Image(C0) ⊆S and Image(C1) ⊆W∖S. If S ∈Ensure(C),
 then C1 ≃⊤. If S ∈Prevent(C), then C0 ≃⊤.
Proof: If S ∈Ensure(C), there exists a morphism from 1S to C, so there exists a
morphism from 1S to C0&C1. Composing this with the canonical projection from C0&C1
 to C1 gives a morphism (g, h) : 1S →C1. Let C1 = (A, E, ⋅), and let 1S = ({b}, S, ⋆). If
there were an e ∈E, then g(b) ⋅e = b ⋆h(e) would be in both S and W∖S, a

contradiction. Therefore C1 has empty environment. Also, since g(b) ∈A, C1 has
nonempty agent. Therefore C1 ≃⊤.
Symmetrically, if S ∈Prevent(C), then W∖S ∈Ensure(C), so C0 ≃⊤. □
Now we can reprove (a slightly stronger version of) our main incompatibility theorem.
Theorem: If C ≄⊤, then Ctrl(C) ∩Obs(C) = {}.
Proof: We prove the contrapositive. Assume S ∈Ctrl(C) ∩Obs(C). Let C ≃C0&C1,
with Image(C0) ⊆S and Image(C1) ⊆W∖S. By the above lemma, both C0 ≃⊤ and 
C1 ≃⊤. Thus C ≃⊤&⊤≅⊤. □
We also reprove (the important direction of) the one-sided result.
Theorem: If S ∈Ensure(C) ∩Obs(C), then Image(C) ⊆S.
Proof: If S ∈Ensure(C) ∩Obs(C), then C ≃C0&C1, with Image(C0) ⊆S and 
Image(C1) ⊆W∖S. By the above lemma, C1 ≃⊤, so C ≃C0&⊤≅C0, so Image(C) ⊆S. 
□
 
In our next post, we will move to discussing Cartesian frames over diﬀerent worlds, or
diﬀerent world models. E.g., W might be the set of all possible microphysical states of
a room, while V  is the smaller set of all possible arrangements of macroscopic objects
in the room. We will describe how to translate between frames over W and frames
over V .
In the process, we will note some surprising facts about coarser and more reﬁned
models of the world, as they relate to observables.

Functors and Coarse Worlds
Crossposted from the AI Alignment Forum. May contain more technical jargon than usual.
This is the ﬁfth post in the Cartesian frames sequence. Read the ﬁrst post here.
Up until this point, we have only been working with Cartesian frames over a ﬁxed world 
W. Now, we are going to start talking about Cartesian frames over diﬀerent worlds.
 
1. Functors from Functions Between Worlds
In the Cartesian frames framework, a world is a set of possible worlds w that can all
potentially occur in the same frame.
I ﬁnd it useful to think about "diﬀerent worlds" W and V  in the case where W and V  are
diﬀerent world models that carve up a situation in two diﬀerent ways. W might be a
reﬁned world model, one that describes a situation in more detail; while V  is a coarser
model of the same situation that elides some distinctions in W.
Returning to an example from "Biextensional Equivalence," 
W = {w0, w1, w2, w3, w4, w5, w6, w7} could be a world model that includes details about
what the agent is thinking (G for a thought about the color green, R for red), as shown in
C0 =
S
B
GH
GW
RH
RW
⎛
⎜ 
⎜ 
⎜
⎝
w0
w1
w2
w3
w4
w5
w6
w7
⎞
⎟ 
⎟ 
⎟
⎠
,
while V = {w8, w9, w10, w11} could be a world model that leaves out this information,
representing the same real-world situation with the frame

C1 =
S
B
GH
GW
RH
RW
⎛
⎜ 
⎜ 
⎜
⎝
w8
w9
w10
w11
w8
w9
w10
w11
⎞
⎟ 
⎟ 
⎟
⎠
.
To move between frames like C0 and C1 and compare their properties, we will need a way
to send agents and environments of frames deﬁned over one world, to agents and
environments of frames over an entirely diﬀerent world. Functors will allow us to do this.
Deﬁnition: Given two sets W and and V , and a function p : W →V , let 
p∘: Chu(W) →Chu(V ) denote the functor that sends the object (A, E, ⋅) ∈Chu(W) to the
object (A, E, ⋆) ∈Chu(V ), where a ⋆e = p(a ⋅e), and sends the morphism (g, h) to the
morphism with the same underlying functions, (g, h).
To visualize this functor, you can imagine Chu(W) as a graph, with matrices as nodes (in
the ﬁnite case) and arrows representing morphisms. Chu(V ) is another graph made of
matrices and arrows. To move each frame C from Chu(W) to Chu(V ), we use p to
entrywise replace the possible worlds in C's matrix with elements of V , without changing
the functional properties of the rows and columns; and then we move all the arrows from 
Chu(W) to Chu(V ), which is possible because no functional properties of the original
matrices were lost. (Frames and morphisms may or may not be added when we move to 
Chu(V ).)
In the cases where we say "W is a reﬁned version of V " or "V  is a coarse version of W,"
all we mean is that the function p : W →V  is surjective.
Claim: p∘ is well-deﬁned.
Proof: We need to show that p∘ actually sends objects and morphisms of Chu(W) to
objects and morphisms of Chu(V ), and that it preserves identity morphisms and
composition. p∘ clearly sends objects to objects. To see that p∘ sends morphisms to

morphisms, observe that if (g, h) : (A0, E0, ⋅0) →(A1, E1, ⋅1), and p∘(Ai, Ei, ⋅i) = (Ai, Ei, ⋆i),
then for all a ∈A0 and e ∈E1,
g ( a ) ⋆ 1 e  = p ( g ( a ) ⋅ 1 e ) 
 = p ( a ⋅ 0 h ( e ) ) 
 = a ⋆ 0 h ( e ) , 
so p∘(g, h) = (g, h) is a morphism. It is clear that p∘ preserves identity  and composition,
since it has no eﬀect on morphisms. □
We also have that p∘ preserves all of our additive operations.
Claim: p∘(C ⊕D) = p∘(C) ⊕p∘(D), p∘(C&D) = p∘(C)&p∘(D), p∘(C ∗) = p∘(C)∗, p∘(0) = 0, 
p∘(⊤) = ⊤, and p∘(null) = null.
Proof: Trivial. □
Our new functor's relationship with 1 and ⊥ is more interesting. In particular, we can
deﬁne 1S and ⊥S from 1 and ⊥ using functors.
Claim: Let S ⊆W and let ι : S →W be the inclusion of S in W. Then 1S = ι∘(1) and 
⊥S = ι∘(⊥). (Here, the 1 and ⊥ are from Chu(S), not Chu(W).)
Proof: Trivial. □
This gives us a more categorical deﬁnition of 1S and ⊥S from 1 and ⊥. We will give a
more categorical deﬁnition of 1 and ⊥ later, when we talk about multiplicative
operations.
p∘ also preserves biextensional equivalence in one direction. (Two equivalent frames in 
W will always be equivalent in V , but two inequivalent frames in W won't necessarily be
inequivalent in V .)
Claim: If C ≃D, then p∘(C) ≃p∘(D).

Proof: Let C = (A, E, ⋅) and let D = (B, F, ⋆). Let (g0, h0) : C →D and (g1, h1) : D →C
 compose to something homotopic to the identity in both orders. We want to show that 
(g0, h0) : p∘(C) →p∘(D) and (g1, h1) : p∘(D) →p∘(C) compose to something homotopic to
the identity in both orders. Indeed p(g1(g0(a)) ⋅e) = p(a ⋅e) for all a ∈A and e ∈E, and 
p(g0(g1(b)) ⋆f) = p(b ⋆f) for all b ∈B and f ∈F. □
We also have that p∘ preserves what's ensurable, where we transition from subsets of W
 to subsets of V  in the obvious way.
Claim: Let p : W →V , and let p(S) = {v ∈V  | ∃w ∈S, p(w) = v}. If S ∈Ensure(C), then 
p(S) ∈Ensure(p∘(C)).
Proof: Trivial from the original deﬁnition of ensurables. □
We also get a stronger result when dealing with subsets of W and V  that correspond
exactly.
Claim: Let p : W →V , and let S ⊆W and T ⊆V  be such that for all w ∈W, we have 
p(w) ∈T if and only if w ∈S. Then S ∈Ensure(C) if and only if T ∈Ensure(p∘(C)), and 
S ∈Ctrl(C) if and only if T ∈Ctrl(p∘(C)).
Proof: Trivial from the original deﬁnitions of ensurables and controllables. □
The relationship between observability and functors is quite interesting. We will devote
the next section to discussing this relationship and its philosophical consequences.
 
2. What's Observable is Relative to a Coarse
World Model
Since observability is not closed under supersets, we can only really hope to get a result
for observables in the stronger case where S ⊆W and T ⊆V  correspond exactly; but
interestingly, even then, the preservation result for observables is only one-directional.
Claim: Let p : W →V  and let S ⊆W and T ⊆V  be such that for all w ∈W, we have 
p(w) ∈T if and only if w ∈S. Then if S ∈Obs(C), then T ∈Obs(p∘(C)).

Proof: If C ≃C0&C1, with Image(C0) ⊆S and Image(C1) ⊆W∖S, then 
p∘(C) ≃p∘(C0)&p∘(C1), and Image(p∘(C0)) = p(Image(C0)) ⊆p(S) ⊆T, while 
Image(p∘(C1)) = p(Image(C1)) ⊆p(W∖S) ⊆V ∖T. □
The most interesting thing here is that the converse is not also true. There are examples
where T ∈Obs(p∘(C)), even though S ∉Obs(C).
When p is surjective, we think of V  as a coarse world model that forgets some details
from W. Sometimes, an agent can be able to observe S relative to a coarse description of
the world, but not in the more reﬁned description, even in cases where S is deﬁnable in
both the coarse and reﬁned descriptions.
 
2.1. Example
Let us look at an example. In this example, the agent is an AI that will be given a number
and asked whether it is prime or not. There are two possible environments 
E = {Prime, Nonprime}.
The agent A has six strategies:
It can compute whether the number is prime and answer correctly (AccurateHot), or
it can compute whether the number is prime and answer incorrectly 
(InaccurateHot). In both of these cases, it has to use a lot of energy and will
become hotter.
It can also just not think and say that the number is prime (PrimeCool), or it can not
think and say that the number is not prime (NonprimeCool).
Finally, it can deliberately waste a lot of energy for no reason and say the number is
prime or waste a lot of energy and say the number is not prime (PrimeHot and 
NonprimeHot respectively).
Finally, W = {PAH, PAC, PIH, PIC, NAH, NAC, NIH, NIC}, where the ﬁrst letter indicates
whether the AI was given a prime or nonprime number, the second letter indicates
whether the AI's answer was accurate or inaccurate, and the third letter indicates
whether the AI is hot. The Cartesian frame, C, looks like this.

C = 
Prime 
Nonprime  
AccurateHot 
InaccurateHot 
PrimeCool 
NonprimeCool 
PrimeHot 
NonprimeHot 
 
⎛
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜
⎝
 
  PAH   
  NAH   
  PIH   
  NIH   
  PAC   
  NIC   
  PIC   
  NAC   
  PAH   
  NIH   
  PIH   
  NAH   
 
⎞
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟
⎠
 
We will let V  be the coarse description of the world in which we only pay attention to the
input/output behavior of the AI and ignore whether or not it becomes hot. 
V = {PA, PI, NA, NI}, and we will let p : W →V  be the function that deletes the third letter.
This gives us the following for p∘(C).
p ∘ ( C ) = 
Prime 
Nonprime  
AccurateHot 
InaccurateHot 
PrimeCool 
NonprimeCool 
PrimeHot 
NonprimeHot 
 
⎛
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜
⎝
 
  PA   
  NA   
  PI   
  NI   
  PA   
  NI   
  PI   
  NA   
  PA   
  NI   
  PI   
  NA   
 
⎞
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟
⎠
  ≃ 
Prime 
Nonprime  
Accurate 
Inaccurate 
Prime 
Nonprime 
 
⎛
⎜ 
⎜ 
⎜
⎝
 
  PA   
  NA   
  PI   
  NI   
  PA   
  NI   
  PI   
  NA   
 
⎞
⎟ 
⎟ 
⎟
⎠
 
The important thing to notice here is that {PA, PI} ∈Obs(p∘(C))—when we ignore heat,
the agent can base conditional strategies on whether the number is prime—but 
{PAH, PAC, PIH, PIC} ∉Obs(C).
In particular, p∘(C) ≃C0&C1, where
C0 =
Prime
Accurate
Inaccurate
(
 PA 
 PI  )  and C1 =
Nonprime
Accurate
Inaccurate
(
 NA 
 NI  )
,

while it is easy to see that {PAH, PAC, PIH, PIC} ∉Obs(C), because there is no 
a ∈if({PAH, PAC, PIH, PIC}, PrimeCool, NonprimeCool).
 
2.2. Discussion
The above example illustrates something interesting about observables. It shows that
what's observable is not only a function of the observing agent and the thing that is
observed. It is also a function of the level of description of the world!
This makes sense because we are thinking of observation as the ability to implement
conditional policies. To implement a conditional policy is to be indistinguishable from the
constant policy a0 in worlds in S and indistinguishable from the constant policy a1 in
worlds outside of S. This indistinguishability makes observables relative to the level of
description of the world.
There is something internal to the agent that is diﬀerent between the world where it
implements a conditional policy and the world where it implements a constant policy.
However, when we talk of S being an observable for the agent, we are working relative to
a level of description that does not track that internal diﬀerence.
 
3. Functors from Cartesian Frames
When p : W →V  is surjective, p∘ will send Cartesian frames over the more reﬁned W to
Cartesian frames over the less reﬁned V . What if we want to go in the other direction?
While there is a unique function from less reﬁned worlds to more reﬁned worlds, there
are many functions in the other direction. Luckily, we have an object that lets us deal
with many functions at once.
Deﬁnition: Let C = (V , E, ⋅) be a Cartesian frame over W, with Agent(C) = V . Then 
C ∘: Chu(V ) →Chu(W) is the functor that sends (B, F, ⋆) to (B, F × E, ⋄), where 
b ⋄(f, e) = (b ⋆f) ⋅e, and sends the morphism (g, h) to (g, h′), where h′(f, e) = (h(f), e).
(Notice how this deﬁnition looks a bit like currying.)
Claim: C ∘ is well-deﬁned.
Proof: We need to show that C ∘ actually sends objects and morphisms of Chu(V ) to
objects and morphisms of Chu(W), and that it preserves identity morphisms and

composition.
C ∘ clearly sends objects to objects. To see that it sends morphisms to morphisms, let 
(g, h) : (B0, F0, ⋆0) →(B1, F1, ⋆1) be a morphism in Chu(V ), let (Bi, Fi × E, ⋄i) = C ∘(Bi, Fi, ⋆i),
and let (g, h′) = C ∘(g, h).
We want to show that (g, h′) : (B0, F0 × E, ⋄0) →(B1, F1 × E, ⋄1) is a morphism, which is true
because
g ( b ) ⋄ 1 ( f , e )  = ( g ( b ) ⋆ 1 f ) ⋅ e 
 = ( b ⋆ 0 h ( f ) ) ⋅ e 
 = b ⋄ 0 ( h ( f ) , e ) 
 = b ⋄ 0 h ′ ( f , e ) 
for all b ∈B0 and (f, e) ∈F1 × E. C ∘ clearly preserves identity morphisms and
composition. □
The coarse-to-reﬁned functor C ∘ preserves &, ⊤, and null, but not ⊕, 0, or −∗, which
make sense, since C ∘ is violating the symmetry between agent and environment.
Claim: C ∘(⊤) = ⊤, and C ∘(null) = null.
Proof: Trivial. □
Claim: C ∘(D0&D1) = C ∘(D0)&C ∘(D1).
Proof: Let C = (V , E, ⋅) and let Di = (Bi, Fi, ⋆i). We have that 
C ∘(D0&D1) = (B0 × B1, (F0 ⊔F1) × E, ⋄) and 
C ∘(D0)&C ∘(D1) = (B0 × B1, (F0 × E) ⊔(F1 × E), ∙). The agent and environment are the
same, so we just need to check that ⋄= ∙.
Take (b0, b1) ∈B0 × B1 and (f, e) ∈(F0 ⊔F1) × E = (F0 × E) ⊔(F1 × E). Without loss of
generality, assume f ∈F0. Observe that

( b 0 , b 1 ) ⋄ ( f , e )  = ( b 0 ⋆ 0 f ) ⋅ e 
 = ( b 0 , b 1 ) ∙ ( f , e ) . 
□
One way to see that C ∘ does not preserve ⊕ is to see that the environments are
diﬀerent, since C ∘(D0 ⊕D1) has one copy of E in the environment, while C ∘(D0) ⊕C ∘(D1)
 has two copies.
We also have that C ∘ preserves biextensional equivalence.
Claim: if D0 ≃D1, then C ∘(D0) ≃C ∘(D1).
Proof: Let Di = (Bi, Fi, ⋆i), and let C ∘(Di) = (Bi, Fi × E, ⋄i). Let (g0, h0) : D0 →D1 and 
(g1, h1) : D1 →D0 compose to something homotopic to the identity in both orders. It
suﬃces to show that C ∘(g1, h1) ∘C ∘(g0, h0) is homotopic to the identity on C ∘(D0), since
the other composition will be symmetric. Indeed
g 1 ( g 0 ( b ) ) ⋄ 0 ( f , e )  = g 1 ( g 0 ( b ) ) ⋆ 0 f 
 = b ⋆ 0 f 
 = b ⋄ 0 ( f , e ) 
 for all b ∈B0, and (f, e) ∈F0 × E. □
Before we talk about the relationship between functors from functions and functors from
Cartesian frames, I want to pause to talk about how to view Cartesian frames as sets of
functions.
 
4. Cartesian Frames as Sets of Functions
One way to view (some) Cartesian frames is as sets of functions.
Deﬁnition: Given a set P of functions from E to W, let CF(P) denote the Cartesian frame
over W given by (P, E, ⋅), where p ⋅e = p(e).
Claim: CF(P) is well-deﬁned.

Proof: Trivial. □
Not every Cartesian Frame is expressible this way: every Cartesian frame is
biextensionally equivalent to a Cartesian frame with duplicate columns and rows, and
these uncollapsed frames are excluded because sets do not allow multiplicity.
Claim: For every Cartesian frame C over W, there exists a set of functions 
P : Env(C) →W, such that C ≃CF(P).
Proof: Take C = (A, E, ⋅), and take P to be the set of all p : E →W such that there exists
an a ∈A such that for all e ∈E, p(e) = a ⋅e. Take (g0, h0) : C →CF(P) and 
(g1, h1) : CF(P) →C, given as follows: h0 = h1 is the identity on E, g0(a) is the function 
e ↦a ⋅e, and g1(p) is some a ∈A such that p(−) = a ⋅−. These are both clearly
morphisms, and they compose to something homotopic to the identity, since h0 ∘h1 and 
h1 ∘h0 are both the identity. □
This give us an alternate deﬁnition of Cartesian frames up to biextensional equivalence.
This almost gives a complete alternate deﬁnition of Cartesian frames; if we instead took 
P to be a multiset, then we could identify the Cartesian frame CF(P) with the multiset P.
Note that this is not as symmetric as our original deﬁnition of Cartesian frames. The "sets
of functions" approach here thinks of a Cartesian frame as a set of functions from the
environment to the world, but we could instead think of it as a set of functions from the
agent to the world.
Deﬁnition: Given a set P of functions for A to W, let CF∗(P) denote the Cartesian frame
over W given by (A, P, ⋅), where a ⋅p = p(a).
Claim: CF∗(P) = (CF(P))∗.
Proof: Trivial. □
Thinking of Cartesian frames in this way is not particularly diﬀerent from our original
deﬁnition. It is just thinking about a function with two inputs as a parameterized function
with one input and one parameter. However, this way of understanding Cartesian frames
will allow us to more easily relate functors from functions to functors from Cartesian
frames.
 

5. Relationship Between the Two Functor
Deﬁnitions
Functors from functions are a special case of functors from Cartesian frames. Indeed,
they correspond when Env(C) is a singleton.
Claim: For any p : V →W, p∘= (CF∗({p}))∘. Conversely, if C = (V , {e}, ⋅) is a Cartesian
frame over W with singleton environment, then C ∘= p∘, where p(v) = v ⋅e.
Proof: Observe that CF∗({p}) = (V , {e}, ⋅), where v ⋅e = p(e). That p∘= (CF∗({p}))∘ is
trivial from considering the deﬁnition of C ∘ in the special case where E is a singleton. □
However, we can do a lot more with functors from Cartesian frames. In the case where 
p : W →V  is a surjection, p∘ shows how to send Cartesian frames over the more reﬁned 
W to the less reﬁned V . We want to go in the other direction using an inverse of p.
Since p is a surjection, it has a right inverse, but it might have many right inverses. If we
want to go from Cartesian frames over V  to Cartesian frames over W, we could pick any
right inverse to p, but since we have functors from Cartesian frames, we don't have to.
Claim: For any surjective p : W →V , let Q be the set of all q : V →W such that p ∘q is
the identity on V . Then for any Cartesian frame C over V , (p∘∘(CF∗(Q))∘)(C) ≃C. Thus 
(CF∗(Q))∘ is right inverse to p∘ up to biextensional equivalence.
Proof: Let C = (A, E, ⋅). Then (CF∗(Q))∘(C) = (A, E × Q, ⋆), where a ⋆(e, q) = q(a ⋅e), and 
(p∘∘(CF∗(Q))∘)(C) = (A, E × Q, ⋄), where
a ⋄ ( e , q ) = p ( q ( a ⋅ e ) ) 
 = a ⋅ e . 
(Viewed as a matrix, (p∘∘(CF∗(Q))∘)(C) is isomorphic to C with |Q| copies of each
column.)
To explicitly see the homotopy equivalence, take (g0, h0) : (A, E, ⋅) →(A, E × Q, ⋄) by 
g0(a) = a and g1(e, q) = e, and take (g1, h1) : (A, E × Q, ⋄) →(A, E, ⋅) by g1(a) = a and 

h1(e) = (e, q) for some ﬁxed q ∈Q. These are clearly morphisms and clearly compose to
something homotopic to the identity in both orders, since the gi are the identity. Note
that we used the surjectivity of p when we said "for some ﬁxed q ∈Q," since the
surjectivity of p is what makes Q nonempty. □
 
Functors from Cartesian frames will prove useful in the next section, when we ﬁnally
introduce the concept of subagent.

Subagents of Cartesian Frames
Crossposted from the AI Alignment Forum. May contain more technical jargon than
usual.
Here, we introduce and discuss the concept of a subagent in the Cartesian Frames
paradigm.
Note that in this post, as in much of the sequence, we are generally working up to
biextensional equivalence. In the discussion, when we informally say that a frame has
some property or is some object, what we'll generally mean is that this is true of its
biextensional equivalence class.
 
1. Deﬁnitions of Subagent
1.1. Categorical Deﬁnition
Deﬁnition: Let C and D be Cartesian frames over W. We say that C's agent is a
subagent of D's agent, written C ◃D, if for every morphism ϕ : C →⊥ there exists a
pair of morphisms ϕ0 : C →D and ϕ1 : D →⊥ such that ϕ = ϕ1 ∘ϕ0.
Colloquially, we say that every morphism from C to ⊥ factors through D. As a
shorthand for "C's agent is a subagent of D's agent," we will just say "C is a subagent
of D."
At a glance, it probably isn't clear what this deﬁnition has to do with subagents. We'll
ﬁrst talk philosophically about what we mean by "subagent", and then give an
alternate deﬁnition that will make the connection more clear.
When I say "subagent," I am actually generalizing over two diﬀerent relationships that
may not immediately seem like they belong together.
First, there is the relationship between the component and the whole. One football
player is a subagent of the entire football team.
Second, there is the relationship between an agent before and after making a
precommitment or a choice. When I precommit not to take a certain action, I am
eﬀectively replacing myself with a weaker agent that has fewer options. The new
agent with the commitment is a subagent of the original agent.
These are the two notions I am trying to capture with the word "subagent". I am
making the philosophical claim that we should think of them primarily as one concept,
and am partially backing up this claim by pointing to the simplicity of the above
deﬁnition. In a future post, we will discuss the formal diﬀerences between these two

kinds of subagent, but I think it is best to view them as two special cases of the one
simple concept.
(My early drafts of the "Embedded Agency" sequence used the word "subagent" in the
title for both the Subsystem Alignment and Robust Delegation sections.)
 
1.2. Currying Deﬁnition
Deﬁnition: Let C and D be Cartesian frames over W. We say that C ◃D if there exists
a Cartesian frame Z over Agent(D) such that C ≃D∘(Z).
Assume for this discussion that we only care about frames up to biextensional
equivalence. In eﬀect, the above deﬁnition is saying that "C is a subagent of D" means
"C's agent is playing a game, Z, where the stakes are to help decide what D's agent
does." (And this game may or may not have multiple players, and may or may not
fully cover all the options of D's agent.)
Letting C = (A, E, ⋅) and D = (B, F, ⋆), it turns out (as we will see later) that we can
explicitly construct Z. Z = (A, X, ⋄), where X is the set of all morphisms from C to D,
and ⋄: A × X →B is given by a ⋄(g, h) = g(a).
We will later prove the categorical and currying deﬁnitions equivalent, but let's ﬁrst
interpret this deﬁnition using examples.
Z is a Cartesian frame whose agent is the agent of C and whose world is the agent of 
D. This seems like the kind thing we would have when C is a subagent of D.
Thinking about the football example: We have the football player A as the agent in a
Cartesian frame C over the world W. We also have the football team B as the agent in
a Cartesian frame D over the same world W.
Z is a Cartesian frame over the football team; and the agent of this frame is again the
football player A. X, the environment of Z, represents the rest of the football team: the
player's eﬀect on the team as a whole (here treated as the player's world) is a
function of what the player chooses and what the rest of the team chooses. We can
think of Z as representing a  "zoomed-in" picture of A interacting with its local
environment (the team), while C represents a "zoomed-out" picture of A interacting
with its teammates and the larger world (rival teams, referees, etc.).

D∘(Z) = (A, X × F, ∙), so E is equivalent to X × F, which is saying that the environment
for the football player in its original frame (C) is equivalent to the Cartesian product of
the rest of the team X with the team's environment F.
Thinking about the precommitment example: C has made a precommitment, so there
is an inclusion morphism ι : A →B, which shows that C's agent's options are a subset
of D's agent's options. Z is just CF∗({ι}), so X = {ι} is a singleton. D∘(Z) = (A, X × F, ∙)
, so E is equivalent to X × F = F, so here A is a subset of B and E is equivalent to F.
Although the word "precommitment" suggests a speciﬁc (temporal, deliberative)
interpretation, formally, precommitment just looks like deleting rows from a matrix (up
to biextensional equivalence), which can represent a variety of other situations.
A Cartesian frame Z = (A, X, ⋄) over B is like a nondeterministic function from A to B,
where X represents the the nondeterministic bits. When changing our frame from 
(B, F, ⋆) to (A, E, ⋅) ≃(A, X × F, ∙), we are identifying with A and externalizing the
nondeterministic bits X into the environment.
 
1.3. Covering Deﬁnition
The categorical deﬁnition is optimized for elegance, while the currying deﬁnition is
optimized to be easy to understand in terms of agency. We have a third deﬁnition, the
covering deﬁnition, which is optimized for ease of use.
Deﬁnition. Let C = (A, E, ⋅) and D = (B, F, ⋆) be Cartesian frames over W. We say that 
C ◃D if for all e ∈E, there exists an f ∈F and a (g, h) : C →D such that e = h(f).
We call this the covering deﬁnition because the morphisms from C to D cover the set 
E.
 
2. Equivalence of Deﬁnitions
2.1. Equivalence of Categorical and Covering Deﬁnitions

The equivalence of the categorical and covering deﬁnitions follows directly from the
fact that the morphisms from C to ⊥ are exactly the elements of Env(C).
Claim: The categorical and covering deﬁnitions of subagent are equivalent.
Proof: Let C = (A, E, ⋅) and let D = (B, F, ⋆). First, observe that the morphisms from C
 to ⊥ correspond exactly to the elements of E. For each e ∈E, it is easy to see that 
(g, h) : C →(W, {j}, ⋄), given by h(j) = e and g(a) = a ⋅e, is a morphism, and every
morphism is uniquely deﬁned by h(j), so there are no other morphisms. Let ϕe denote
the morphisms with h(j) = e.
Similarly, the morphisms from D to ⊥ correspond to the elements of F. Let ψf denote
the morphisms corresponding to f ∈F.
Thus, the categorical deﬁnition can be rewritten to say that for every morphism 
ϕe : C →⊥, there exist morphisms (g, h) : C →D and ψf : D →⊥, such that 
ϕe = ψf ∘(g, h). However, ψf ∘(g, h) : C →(W, {j}, ⋄) sends j to h(f), and so equals ϕe if
and only if e = h(f). Thus the categorical deﬁnition is equivalent to the covering
deﬁnition. □
 
2.2. Equivalence of Covering and Currying Deﬁnitions
Claim: The covering deﬁnition of subagent implies the currying deﬁnition of subagent.
Proof: Let C = (A, E, ⋅) and D = (B, F, ⋆) be Cartesian frames over W. Assume that 
C ◃D according to the covering deﬁnition.
Let X be the set of all morphisms from C to D, and let Z = (A, X, ⋄) be a Cartesian
frame over B, with ⋄ given by a ⋄(g, h) = g(a). We have that D∘(Z) = (A, X × F, ∙), with
a ∙ ( ( g , h ) , f )  = ( a ⋄ ( g , h ) ) ⋆ f 
 = g ( a ) ⋆ f 
for all a ∈A, (g, h) ∈X, and f ∈F.

To show that C ≃D∘(Z), we need to construct morphisms g0, h0 : C →D∘(Z) and 
g1, h1 : D∘(Z) →C which compose to something homotopic to the identity in both
orders.
We will let g0 and g1 be the identity on A, and we let h0 : X × F →E be given by 
h0((g, h), f) = h(f). Finally, we let h1(e) = ((g, h), f) such that h(f) = e. We can always
choose such a (g, h) ∈X and f ∈F by the covering deﬁnition of subagent.
We have that (g0, h0) is a morphism, since
g 0 ( a ) ∙ ( ( g , h ) , f )  = a ∙ ( ( g , h ) , f ) 
 = g ( a ) ⋆ f 
 = a ⋅ h ( f ) 
 = a ⋅ h 0 ( ( g , h ) , f ) . 
Similarly, we have that (g1, h1) is a morphism since h1(e) = ((g, h), f), where h(f) = e,
so
g 1 ( a ) ⋅ e  = a ⋅ e 
 = a ⋅ h ( f ) 
 = g ( a ) ⋆ f 
 = a ∙ ( ( g , h ) , f ) 
 = a ∙ h 1 ( e ) . 
It is clear that (g0, h0) and (g1, h1) compose to something homotopic to the identity in
both orders, since g0 and g1 are the identity on A. Thus, C ≃D∘(Z). □
Claim: The currying deﬁnition of subagent implies the covering deﬁnition of subagent.
Proof: Let C = (A, E, ⋅) and D = (B, F, ⋆) be Cartesian frames over W. Let Z = (Y , X, ⋄)
 be a Cartesian frame over B, and let C ≃D∘(Z). Our goal is to show that for every 

e ∈E, there exists a (g, h) : C →D and f ∈F such that e = h(f). We will start with the
special case where C = D∘(Z).
We have that D∘(Z) = (Y , X × F, ∙), where y ∙(x, f) = (y ⋄x) ⋆f. First, note that for
every x ∈X, there exists a morphism (gx, hx) : D∘(Z) →D given by gx(y) = y ⋄x, and 
hx(f) = (x, f). To see that this is a morphism, observe that
g x ( y ) ⋆ f  = ( y ⋄ x ) ⋆ f 
 = y ∙ ( x , f ) 
 = f ∙ h x ( f ) 
for all y ∈Y  and f ∈F.
To show that D∘(Z) ◃D according to the covering deﬁnition, we need that for all 
(x, f) ∈X × F, there exists an f ′ ∈F and a (g, h) : D∘(Z) →D such that h(f ′) = (x, f).
Indeed we can take (g, h) = (gx, hx) and f ′ = f.
Now, we move to the case where C ≃D∘(Z), but C ≠D∘(Z). It suﬃces to show that
under the covering deﬁnition of subagent, if C0 ◃D, and C1 ≃C0, then C1 ◃D.
Let Ci = (Ai, Ei, ⋅i), and let (g0, h0) : C0 →C1 and (g1, h1) : C1 →C0 compose to
something homotopic to the identity in both orders. Assume that C0 ◃D. To show that 
C1 ◃D, let the possible environment e ∈E1 be arbitrary.
h0(e) ∈E0, so there exists an f ∈F and (g, h) : C0 →D such that h(f) = h0(e). Consider
the morphism (g′, h′) : C1 →D, where g′ = g ∘g1, and h′(f) = e and h′(f ′) = (h1 ∘h)(f ′)
 on all f ′ ≠f. To see that this is a morphism, observe that for all a ∈A1, we have

g ′ ( a ) ⋆ f  = g ( g 1 ( a ) ) ⋆ f 
 = a ⋅ 1 h 1 ( h ( f ) ) 
 = a ⋅ 1 h 1 ( h 0 ( e ) ) 
 = a ⋅ 1 e 
 = a ⋅ 1 h ′ ( f ) , 
while for f ′ ∈F, f ′ ≠f, we have
g ′ ( a ) ⋆ f ′  = g ( g 1 ( a ) ) ⋆ f ′ 
 = a ⋅ 1 h 1 ( h ( f ′ ) ) 
 = a ⋅ 1 h ′ ( f ′ ) . 
Now, notice that for our arbitrary e ∈E1, (g′, h′) : C1 →D and f ∈F satisfy h′(f) = e, so 
C1 ◃D according to the to the covering deﬁnition.
Thus, whenever C ≃D∘(Z), we have C ◃D according to the covering deﬁnition, so the
currying deﬁnition implies the covering deﬁnition of subagent. □
 
3. Mutual Subagents
The subagent relation is both transitive and reﬂexive. Surprisingly, this relation is not
anti-symmetric, even up to biextensional equivalence.
Claim: ◃ is reﬂexive. Further, if C ≃D, then C ◃D.
Proof: Let C = (A, E, ⋅) and D = (B, F, ⋅) be Cartesian Frames over W, with C ≃D.
Consider the Cartesian frame Z over B given by Z = (B, {x}, ⋄), where b ⋄x = b.
Observe that D ≅D∘(Z). Thus C ≃D∘(Z), so C ◃D, according to the currying deﬁnition. 
□
Claim: ◃ is transitive.

Proof: We will use the categorical deﬁnition. Let C0 ◃C1 and C1 ◃C2. Given a
morphism, ϕ0 : C0 →⊥, since C0 ◃C1, we know that ϕ0 = ϕ1 ∘ϕ2 with ϕ1 : C1 →⊥ and 
ϕ2 : C0 →C1. Further, since C1 ◃C2, we know that ϕ1 = ϕ3 ∘ϕ4 with ϕ3 : C2 →⊥ and 
ϕ4 : C1 →C2. Thus,
ϕ 0  = ( ϕ 3 ∘ ϕ 4 ) ∘ ϕ 2 
 = ϕ 3 ∘ ( ϕ 4 ∘ ϕ 2 ) , 
with ϕ3 : C2 →⊥ and ϕ4 ∘ϕ2 : C0 →C2, so C0 ◃C2. □
As a corollary, we have that subagents are well-deﬁned up to biextensional
equivalence.
Corollary: If C0 ≃C1, D0 ≃D1, and C0 ◃D0, then C1 ◃D1.
Proof: C1 ◃C0 ◃D0 ◃D1. □
Sometimes, there are Cartesian frames C ≄D with C ◃D and D ◃C. We can use this
fact to deﬁne a third equivalence relation on Cartesian frames over W, weaker than
both ≅ and ≃.
Deﬁnition: For Cartesian frames C and D over W, we say C ⋈D if C ◃D and D ◃C.
Claim: ⋈ is an equivalence relation.
Proof: Reﬂexivity and transitivity follow from reﬂexivity and transitivity of ◃.
Symmetry is trivial. □
This equivalence relation is less natural than ≅ and ≃, and is not as important. We
discuss it mainly to emphasize that two frames can be mutual subagents without
being biextensionally equivalent.
Claim: ⋈ is strictly weaker than ≃, which is strictly weaker than ≅.
Proof: We already know that ≃ is weaker than ≅. To see that ⋈ is weaker than ≃,
observe that if C ≃D, then C ◃D and D ◃C, so C ⋈D.

To see that ≃ is strictly weaker than ≅, observe that ⊤⊕⊤≃⊤ (both have empty
environment and nonempty agent), but ⊤⊕⊤≆⊤ (the agents have diﬀerent size).
To see that ⋈ is strictly weaker than ≃, observe that ⊤⋈null (vacuous by covering
deﬁnition), but ⊤≄null (there are no morphisms from null to ⊤). □
I do not have a simple description of exactly when C ⋈D, but there are more cases
than just the trivial ones like C ≃D and vacuous cases like ⊤⋈null. As a quick
example:
(
x
y ) ⋈
⎛
⎜
⎝
x
x
y
y
x
y
⎞
⎟
⎠
.
To visualize this, imagine an agent that is given the choice between cake and pie. This
agent can be viewed as a team consisting of two subagents, Alice and Bob, with Alice
as the leader.
Alice has three choices. She can choose cake, she can choose pie, or she can delegate
the decision to Bob. We represent this with a matrix where Bob is in Alice's
environment, and the third row represents Alice letting the environment make the call:
⎛
⎜
⎝
x
x
y
y
x
y
⎞
⎟
⎠
.
If we instead treat Alice-and-Bob as a single superagent, then their interaction across
the agent-environment boundary becomes agent-internal deliberation, and their
functional relationship to possible worlds just becomes a matter of "What does the
group decide?". Thus, Alice is a subagent of the Alice-and-Bob team:
⎛
⎜
⎝
x
x
y
y
x
y
⎞
⎟
⎠
◃(
x
y ).
However, Alice also has the ability to commit to not delegating to Bob. This produces
a future version of Alice that doesn't choose the third row. This new agent is a
precommitment-style subagent of the original Alice, but using biextensional collapse,
we can also see that this new agent is equivalent to the smaller matrix. Thus:

(
x
y ) ≃(
x
x
y
y ) ◃
⎛
⎜
⎝
x
x
y
y
x
y
⎞
⎟
⎠
.
It is also easy to verify formally that these are mutual subagents using the covering
deﬁnition of subagent.
I'm reminded here of the introduction and deletion of mixed strategies in game theory.
The third row of Alice's frame is a mix of the ﬁrst two rows, so we can think of Bob as
being analogous to a random bit that the environment cannot see. I informally
conjecture that for ﬁnite Cartesian frames, C ⋈D if and only if you can pass between 
C and D by doing something akin to deleting and introducing mixed strategies for the
agent.
However, this informal conjecture is not true for inﬁnite Cartesian frames:
⎛
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜
⎝
z
x
z
z
z
⋯
z
y
z
z
z
⋯
z
z
x
z
z
⋯
z
z
y
z
z
⋯
z
z
z
x
z
⋯
z
z
z
y
z
⋯
z
z
z
z
x
⋯
z
z
z
z
y
⋯
⋮
⋮
⋮
⋮
⋮
⋱
⎞
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟
⎠
⋈
⎛
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜
⎝
z
y
z
z
z
⋯
z
z
x
z
z
⋯
z
z
y
z
z
⋯
z
z
z
x
z
⋯
z
z
z
y
z
⋯
z
z
z
z
x
⋯
z
z
z
z
y
⋯
⋮
⋮
⋮
⋮
⋮
⋱
⎞
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟
⎠
.
We can see that these frames are mutual subagents by noting that one can transition
back and forth by repeatedly committing not to take the top row.
I do not know of any examples of ⋈ that look qualitatively diﬀerent from those
discussed here, but I do not have a good understanding of exactly what the
equivalence classes look like.
 

4. Universal Subagents and Superagents
We can view ⊤ as a universal subagent and ⊥ as a universal superagent.
Claim: ⊤◃C ◃⊥ for all Cartesian frames C.
Proof: We use the categorical deﬁnition. That ⊤◃C is vacuous, since there is no
morphism from ⊤ to ⊥. That C ◃⊥ is also trivial, since any ϕ : C ◃⊥ is equal to ϕ ∘id⊥. 
□
Since null ⋈⊤, we also have null ◃C for all C.
We also have a that ⊥S is a superagent of all Cartesian frames with image in S.
Claim: C ◃⊥S if and only if Image(C) ⊆S.
Proof: Let C = (A, E, ⋅), and let ⊥S = (S, {f}, ⋆), with s ⋆f = s.
First, assume Image(C) ⊆S. We will use the covering deﬁnition. Given an e ∈E, let 
(g, h) : C →⊥S be given by g(a) = a ⋅e and h(f) = e. We have that g is well-deﬁned
because Image(C) ⊆S, and (g, h) is a morphism because for all a ∈A, 
a ⋅ h ( f )  = a ⋅ e 
 = g ( a ) 
 = g ( a ) ⋆ f . 
Thus, there is a morphism (g, h) : C →⊥S and an element f ∈{f} such that h(f) = e for
an arbitrary e ∈E, so C ◃⊥S.
Conversely, assume Image(C) ⊈S, so let a ∈A and e ∈E be such that a ⋅e ∉S. If we
assume for contradiction that C ◃⊥S, then by the covering deﬁnition, there must be a
morphism (g, h) : C →⊥S such that h(f) = e. But then we have that

a ⋅ e  = a ⋅ h ( f ) 
 = g ( a ) ⋆ f 
 = g ( a ) 
must be both inside and outside of S, a contradiction. □
Convention: We will usually write C ◃⊥S instead of Image(C) ⊆S, as it is shorter.
Corollary: S ∈Obs(C) if and only if C ≃C0&C1 for some C0 ◃⊥S and C1 ◃⊥W∖S.
Proof: This is just rewriting our deﬁnition of observables from "Controllables and
Observables, Revisited." □
 
In the coming posts, we will introduce multiplicative operations on Cartesian frames,
and use these to distinguish between additive and multiplicative subagents and
superagents.

Multiplicative Operations on Cartesian
Frames
Crossposted from the AI Alignment Forum. May contain more technical jargon than
usual.
This is the seventh post in the Cartesian frames sequence.
Here, we introduce three new binary operations on Cartesian frames, and discuss their
properties.
 
1. Tensor
Our ﬁrst multiplicative operation is the tensor product, ⊗.
One way we can visualize our additive operations from before, ⊕ and &, is to imagine
two robots (say, a mining robot Agent(C) and a drilling robot Agent(D)) that have an
override mode allowing an AI supervisor to take over that robot's decisions.
C ⊕D represents the supervisor deciding which robot to take control of, then
selecting that robot's action. (The other robot continues to run autonomously.)
C&D represents something in the supervisor's environment (e.g., its human
operator) deciding which robot the supervisor will take control of. Then the
supervisor selects that robot's action (while the other robot runs autonomously).
C ⊗D represents an AI supervisor that controls both robots simultaneously. This lets 
Agent(C ⊗D) direct Agent(C) and Agent(D) to work together as a team.
Deﬁnition: Let C = (A, E, ⋅) and D = (B, F, ⋆) be Cartesian frames over W. The tensor
product of C and D, written C ⊗D, is given by C ⊗D = (A × B, hom(C, D∗), ⋄), where 
hom(C, D∗) is the set of morphisms (g, h) : C →D∗ (i.e., the set of all pairs 
(g : A →F, h : B →E) such that b ⋆g(a) = a ⋅h(b) for all a ∈A, b ∈B), and ⋄ is given by 
(a, b) ⋄(g, h) = b ⋆g(a) = a ⋅h(b).
Let us meditate for a moment on why this deﬁnition represents two agents working
together on a team. The following will be very informal.

Let Alice be an agent with Cartesian frame C = (A, E, ⋅), and let Bob be an agent with
Cartesian frame D = (B, F, ⋆). The team consisting of Alice and Bob should have agent 
A × B, since the team's choices consist of deciding what Alice does and also deciding
what Bob does.
The environment is a bit more complicated. Starting from Alice, to construct the team,
we want to internalize Bob's choices: instead of just being choices in A's environment,
Bob's choices will now be additional options for the team A × B.
To do this, we want to ﬁrst see Bob as being embedded in Alice's environment. This
embedding is given by a function h : B →E, which extends each b ∈B to a full
environment e ∈E. We will view Alice's possible environments as being constructed
by combining a choice by Bob (that is, a b ∈B) with a function from Bob's choices to
possible environments (h : B →E). Then, we will move the B part across the Cartesian
boundary into the agent.
Now, the agent looks like A × B, while the environment looks like B →E. However, we
must have been able to do this starting from Bob as well, so a possible environment
can also be viewed as function g : A →F.
Since we should get the same world regardless of whether we think of the team as
starting with Alice or with Bob, these functions g and h should agree with each other.
This looks a bit like currying. The environment for an Alice-Bob team should be able to
take in a Bob to create an environment for Alice, and it should also be able to take in
an Alice to create an environment for Bob.
 
1.1. Example
We will illustrate this new operation using a simple formal example.
Jack, Kate, and Luke are simultaneously casting votes on whether to have a party.
Each agent can vote for or against the party. The possible worlds are encoded as
strings listing which people vote for the party, W = {ε, J, K, L, JK, JL, KL, JKL}. Jack's
perspective is given by the frame
CJ = (
J
JK
JL
JKL
ε
K
L
KL ),
Kate's perspective is given by the frame

CK = (
K
JK
KL
JKL
ε
J
L
JL ),
and Luke's perspective is given by the frame
CL = (
L
JL
KL
JKL
ε
J
K
JK ).
Since Luke's environment can be thought of as the team consisting of Jack and Kate,
one might expect that CJ ⊗CK ≅C
∗
L . Indeed, we will show this is the case.
Let CJ = (A, E, ⋅), and let CK = (B, F, ⋆). We label the elements of A, E, B, and F as
follows:
CJ =
eε
eK
eL
eKL
aJ
aε
(
J
JK
JL
JKL
ε
K
L
KL ) , and CK =
fε
fJ
fL
fJL
bK
bε
(
K
JK
KL
JKL
ε
J
L
JL ) .
We will ﬁrst enumerate all of the morphisms from CJ to C
∗
K . A morphism 
(g, h) : CJ →C
∗
K  consists of a function g : A →F and a function h : B →E. There are 16
functions from A to F and 16 functions from B to E, but most of the 256 pairs do not
form morphisms.
Let us break the possibilities into cases based on g(aJ). Observe that 
bK ⋆g(aJ) = aJ ⋅h(bK): the possible worlds where (from Kate's perspective) Kate votes
for the party and Jake-interfacing-with-Kate's-perspective votes for the party too, are
the same as the possible worlds where (from Jake's perspective) Jake votes for the
party and Kate-interfacing-with-Jake's-perspective does too. These possible worlds
must have a J in them, so g(aJ) must be either fJ or fJL.
If g(aJ) = fJ, then
a J ⋅ h ( b K )  = b K ⋆ g ( a J ) 
 = JK , 

so h(bK) = eK. Similarly,
a J ⋅ h ( b ε )  = b ε ⋆ g ( a J ) 
 = J , 
so h(bε) = eε, and
b K ⋆ g ( a ε )  = a ε ⋅ h ( b K ) 
 = K , 
so g(aε) = fε.
Similarly, if g(aJ) = fJL, then h(bK) = eKL, h(bε) = eL, and g(aε) = fL.
Thus, there are only two candidate morphisms:
The ﬁrst, which we will call ϕε = (gε, hε), is given by gε(aε) = fε, gε(aJ) = fJ, 
hε(bε) = eε, and hε(bK) = eK.
The second, ϕL = (gL, hL), is given by gL(aε) = fL, gL(aJ) = fJL, hL(bε) = eL, and 
hL(bK) = eKL.
It is easy to see that these are both indeed morphisms, by checking the deﬁnition of
morphism on all four pairs in A × B.
Thus, Env(CJ ⊗CK) = {ϕε, ϕL}, and Agent(CJ ⊗CK) = A × B, and we can compute 
Eval(CJ ⊗CK) from the deﬁnitions of the morphisms. The result is as follows:
CJ ⊗CK =
ϕε
ϕL
(aJ, bK)
(aJ, bε)
(aε, bK)
(aε, bε)
⎛
⎜ 
⎜ 
⎜
⎝
JK
JKL
J
JL
K
KL
ε
L
⎞
⎟ 
⎟ 
⎟
⎠
.
This is clearly C
∗
L , up to reordering and relabeling rows and columns.

 
2. Properties of Tensor
Tensor introduces a lot of categorical structure to Chu spaces, in fact giving us a star-
autonomous category. This post and the ones to come will be ignoring connections to
larger topics in category theory, but only because my time and my familiarity with
category theory are limited, not because these connections are unimportant.
I encourage the interested reader to learn more about the structure of Chu spaces on
the excellent category theory wiki nLab, beginning with their article on the Chu
construction.
 
2.1. Commutativity, Associativity, and Identity
Claim: ⊗ is commutative and associative, and 1 is the identity of ⊗ (up to
isomorphism).
Proof: Commutativity is clear from the deﬁnition of ⊗, once one unpacks the
deﬁnition of hom(C, D∗).
To see that 1 is the identity of ⊗, let C = (A, E, ⋅), let 1 = ({b}, W, ⋆), and let 
C ⊗1 = (A × {b}, hom(C, 1∗), ⋄).
Consider the isomorphism (ι0, ι1) : C →C ⊗1 given by ι0(a) = (a, b) and ι1(g, h) = h(b).
 We need to show that (ι0, ι1) is a morphism, and that both ι0 and ι1 are bijective. To
see that (ι0, ι1) is a morphism, observe that for all a ∈A and (g, h) : C →1∗,
ι 0 ( a ) ⋄ ( g , h )  = a ⋅ h ( b ) 
 = a ⋅ ι 1 ( g , h ) . 
 Clearly, ι0 is a bijection, so all that remains to show is that ι1 is bijective.
To see that ι1 is injective, observe that if ι1(g0, h0) = ι1(g1, h1), then h0(b) = h1(b), so 
h0 = h1, and

g 0 ( a )  = b ⋆ g 0 ( a ) 
 = a ⋅ h 0 ( b ) 
 = a ⋅ h 1 ( b ) 
 = b ⋆ g 1 ( a ) 
 = g 1 ( a ) 
for all a ∈A, so g0 = g1.
To see that ι1 is surjective, observe that for every e ∈E, there exists a morphism 
(ge, he) : C →1∗, given by he(b) = e and ge(a) = a ⋅e. This is clearly a morphism, since 
b ⋆ g e ( a )  = g e ( a ) 
 = a ⋅ e 
 = a ⋅ h e ( b ) , 
and ι1(ge, he) = e.
Next, we need to show that ⊗ is associative, which will be much more tedious. Let 
Ci = (Ai, Ei, ⋅). Since we have already established commutativity, it suﬃces to show
that (C0 ⊗C1) ⊗C2 ≅(C0 ⊗C2) ⊗C1.
Let D = (A0 × A1 × A2, F, ⋆), where F is the set of all triples of functions 
(g0 : A1 × A2 →E0, g1 : A0 × A2 →E1, g2 : A0 × A1 →E2), such that for all ai ∈Ai, we
have
a 0 ⋅ 0 g 0 ( a 1 , a 2 )  = a 1 ⋅ 1 g 1 ( a 0 , a 2 ) 
 = a 2 ⋅ 2 g 2 ( a 0 , a 1 ) , 
 and ⋆ is given by
( a 0 , a 1 , a 2 ) ⋆ ( g 0 , g 1 , g 2 )  = a 0 ⋅ 0 g 0 ( a 1 , a 2 ) 
 = a 1 ⋅ 1 g 1 ( a 0 , a 2 ) 
 = a 2 ⋅ 2 g 2 ( a 0 , a 1 ) . 

We will show that (C0 ⊗C1) ⊗C2 ≅D, and since the deﬁnition of D is symmetric in
swapping C1 and C2, it will follow that (C0 ⊗C2) ⊗C1 ≅D, so 
(C0 ⊗C1) ⊗C2 ≅(C0 ⊗C2) ⊗C1.
We construct a morphism (ι0, ι1) from (C0 ⊗C1) ⊗C2 to D as follows. ι0 is just the
identity on A0 × A1 × A2. We will let ι1(g0, g1, g2) be the morphism 
(g2, h) : C0 ⊗C1 →C
∗
2 , where h : A2 →hom(C0, C
∗
1 ) is given by 
h(a2) = (h
a2
0 , h
a2
1 ) : C0 →C
∗
1 , where h
a2
0 (a0) = g1(a0, a2), and h
a2
1 (a1) = g0(a1, a2).
First, we need to show that ι1 is well-deﬁned, by showing that h(a2) is a morphism
from C0 to C
∗
1 , and that (g2, h) is a morphism from C0 ⊗C1 →C
∗
2 . To see that 
h(a2) = (h
a2
0 , h
a2
1 ) is a morphism, observe that for a0 ∈A0 and a1 ∈A1,
a 1 ⋅ 1 h 
a 2
0  ( a 0 )  = a 1 ⋅ 1 g 1 ( a 0 , a 2 ) 
 = a 0 ⋅ 0 g 0 ( a 1 , a 2 ) 
 = a 0 ⋅ 0 h 
a 2
1  ( a 1 ) . 
To see that (g2, h) is a morphism, observe for all (a0, a1) ∈A0 × A1 and all a2 ∈A2,
a 2 ⋅ 2 g 2 ( a 0 , a 1 )  = a 0 ⋅ 0 g 0 ( a 1 , a 2 ) 
 = a 0 ⋅ 0 h 
a 2
1  ( a 1 ) 
 = ( a 0 , a 1 ) ⋄ ( h 
a 2
0  , h 
a 2
1  ) 
 = ( a 0 , a 1 ) ⋄ h ( a 2 ) , 
where ⋄= Eval(C0 ⊗C1).

Now that we know ι1 is well-deﬁned, we need to show that (ι0, ι1) is a morphism.
Indeed, for all (a0, a1, a2) ∈A0, A1, A2, and for all (g0, g1, g2) ∈F, we have
ι 0 ( a 0 , a 1 , a 2 ) ⋆ ( g 0 , g 1 , g 2 )  = a 2 ⋅ 2 g 2 ( a 0 , a 1 ) 
 = ( a 0 , a 1 , a 2 ) ∙ ( g 2 , h ) 
 = ( a 0 , a 1 , a 2 ) ∙ ι 1 ( g 0 , g 1 , g 2 ) , 
where ∙= Eval((C0 ⊗C1) ⊗C2).
Finally, to show that (ι0, ι1) is an isomorphism, we need to show that ι0 and ι1 are
bijective. ι0 is trivial, since it is the identity, so it suﬃces to show that ι1 is bijective.
To see that ι1 is surjective, let (g, h) be a morphism from C0 ⊗C1 to C
∗
2 , so 
g : A0 × A1 →E2, and h : A2 →hom(C0, C
∗
1 ). Again, let h(a2) = (h
a2
0 , h
a2
1 ). We will deﬁne 
(g0, g1, g2) by g2 = g, g1(a0, a2) = h
a2
0 (a0), and g0(a1, a2) = h
a2
1 (a1).
We need to show that (g0, g1, g2) ∈F, by showing that for all (a0, a1, a2) ∈A0 × A1 × A2
, we have
a 0 ⋅ 0 g 0 ( a 1 , a 2 )  = a 1 ⋅ 1 g 1 ( a 0 , a 2 ) 
 = a 2 ⋅ 2 g 2 ( a 0 , a 1 ) . 
Observe that since (g, h) is a morphism,
a 2 ⋅ 2 g 2 ( a 0 , a 1 )  = a 2 ⋅ 2 g ( a 0 , a 1 ) 
 = ( a 0 , a 1 ) ⋆ h ( a 2 ) 
 = ( a 0 , a 1 ) ⋆ ( h 
a 2
0  , h 
a 2
1  ) , 
where ⋆= Eval(C0 ⊗C1). Also, by the deﬁnition of C0 ⊗C1, we have that

( a 0 , a 1 ) ⋆ ( h 
a 2
0  , h 
a 2
1  )  = a 0 ⋅ 0 h 
a 2
1  ( a 1 ) 
 = a 0 ⋅ 0 g 0 ( a 1 , a 2 ) , 
and similarly
( a 0 , a 1 ) ⋆ ( h 
a 2
0  , h 
a 2
1  )  = a 1 ⋅ 1 h 
a 2
0  ( a 1 ) 
 = a 1 ⋅ 1 g 1 ( a 0 , a 2 ) . 
Thus,
a 0 ⋅ 0 g 0 ( a 1 , a 2 )  = a 1 ⋅ 1 g 1 ( a 0 , a 2 ) 
 = a 2 ⋅ 2 g 2 ( a 0 , a 1 ) , 
so (g0, g1, g2) ∈F. Finally, observe that ι1(g0, g1, g2) is in fact (g, h).
To show that ι1 is injective, assume ι1(g0, g1, g2) = ι1(g
′
0, g
′
1, g
′
2) = (g, h), and given an 
a2 ∈A2, let h(a2) = (h
a2
0 , h
a2
1 ). Clearly, this means g2 = g = g
′
2. Further, for all a0 ∈A0, 
a1 ∈A1, and a2 ∈A2,
g 0 ( a 1 , a 2 )  = h 
a 2
1  ( a 1 ) 
 = g 
′
0 ( a 1 , a 2 ) 
and
g 1 ( a 0 , a 2 )  = h 
a 2
0  ( a 0 ) 
 = g 
′
1 ( a 0 , a 2 ) . 
Thus (g0, g1, g2) = (g
′
0, g
′
1, g
′
2). Thus, ι1 is bijective, so (ι0, ι1) is an isomorphism, so 
(C0 ⊗C1) ⊗C2 ≅D ≅(C0 ⊗C2) ⊗C1. □
 
2.2. Biextensional Equivalence

Since many of our intuitions about Cartesian frames are up to biextensional
equivalence, we should verify that tensor is well-deﬁned up to biextensional
equivalence.
Claim: If C0 ≃C1 and D0 ≃D1, then C0 ⊗D0 ≃C1 ⊗D1.
Proof: It suﬃces to show that for all D, C0 ⊗D ≃C1 ⊗D. Then, by commutativity of
tensor, 
C 0 ⊗ D 0  ≃ C 0 ⊗ D 1 
 
 
                                  ≅ 
                                
 D 1 ⊗ C 0 
 ≃ D 1 ⊗ C 1 
 ≡ C 1 ⊗ D 1 . 
Let Ci = (Ai, Ei, ⋅i), and let D = (B, F, ⋆). Since C0 ≃C1, there must exist morphisms 
(g0, h0) : C0 →C1 and (g1, h1) : C1 →C0 such that (g1 ∘g0, idE0) : C0 →C0 and 
(g0 ∘g1, idE1) : C1 →C1 are both morphisms.
Let Ci ⊗D = (Ai × B, hom(Ci, D∗), ⋄i). Consider the morphisms (g
′
i, h
′
i) : Ci ⊗D →C1−i ⊗D
, where g
′
i : Ai × B →A1−i × B is given by g
′
i(a, b) = (gi(a), b) and 
h
′
i : hom(C1−i, D∗) →hom(CI, D∗) is given by h
′
i(g, h) = (g, h) ∘(gi, hi).
To see that these are morphisms, observe that for any (a, b) ∈Ai × B and 
(g, h) : C1−i →D∗, we have
g 
′
i ( a , b ) ⋄ 1 − i ( g , h )  = ( g i ( a ) , b ) ⋄ 1 − i ( g , h ) 
 = b ⋆ g ( g i ( a ) ) 
 = b ⋆ ( g ∘ g i ) ( a ) ) 
 = ( a , b ) ⋄ i ( g ∘ g i , h i ∘ h ) 
 = ( a , b ) ⋄ i h 
′
i ( g , h ) . 

Finally, we need to show that (g
′
0, h
′
0) and (g
′
1, h
′
1) compose to something homotopic to
the identity in both orders. This is equivalent to saying that (g
′
0 ∘g
′
1, idhom(C1,D∗)) and 
(g
′
1 ∘g
′
0, idhom(C0,D∗)) are both morphisms. Indeed, for all (a, b) ∈Ai × B and 
(g, h) : Ci →D∗, since (g1−i ∘gi, idEi) is a morphism, we have
g 
′
1 − i ( g 
′
i ( a , b ) ) ⋄ i ( g , h )  = ( g 1 − i ( g i ( a ) ) , b ) ⋄ i ( g , h ) 
 = g 1 − i ( g i ( a ) ) ⋅ i h ( b ) 
 = a ⋅ i h ( b ) 
 = ( a , b ) ⋄ i ( g , h ) . 
□
 
2.3. Distributivity
Claim: ⊗ distributes over ⊕, so for all Cartesian frames C0, C1, and D,
(C0 ⊕C1) ⊗D ≅(C0 ⊗D) ⊕(C1 ⊗D).
Proof: Since ⊕ is the categorical coproduct, there exist morphisms ι0 : C0 →C0 ⊕C1
 and ι1 : C1 →C0 ⊕C1 such that for any morphisms ϕ0 : C0 →D∗ and ϕ1 : C1 →D∗,
there exists a unique morphism ϕ : C0 ⊗C1 →D∗such that ϕi = ϕ ∘ιi.
Let Ci = (Ai, Ei, ⋅i), and let D = (B, F, ⋆). Consider the isomorphism 
(g, h) : (C0 ⊗D) ⊕(C1 ⊗D) →(C0 ⊕C1) ⊗D, where g : (A0 × B) ⊔(A1 × B) →(A0 ⊔A1) × B
 is the natural bijection that sends (a, b) to (a, b), and 
h : hom(C0 ⊕C1, D∗) →hom(C0, D∗) × hom(C1, D∗) is given by h(ϕ) = (ϕ ∘ι0, ϕ ∘ι1).
Clearly, g is an bijection. h is also a bijection, since it is inverse to the function that
sends (ϕ0, ϕ1) to the unique ϕ as above. Thus, all that remains to show is that (g, h) is
a morphism.

Let ⋄= Eval((C0 ⊗D) ⊕(C1 ⊗D)) and let ∙= Eval((C0 ⊕C1) ⊗D). Given 
(a, b) ∈(A0 × B) ⊔(A1 × B) and (g′, h′) ∈hom(C0 ⊕C1, D∗), without loss of generality,
assume that a ∈A0. Let (g
′
0, h
′
0) = (g′, h′) ∘ι0. Observe that since the function on
agents in ι0 is the inclusion of A0 into A0 ⊔A1, we have that g
′
0 is g′ restricted to A0.
Thus, we have
g ( a , b ) ∙ ( g ′ , h ′ )  = ( a , b ) ∙ ( g ′ , h ′ ) 
 = b ⋆ g ′ ( a ) 
 = b ⋆ g 
′
0 ( a ) 
 = ( a , b ) ⋄ ( g 
′
0 , h 
′
0 ) 
 = ( a , b ) ⋄ h ( g ′ , h ′ ) . 
□
 
2.4. Tensor is for Disjoint Agents
It doesn't really make sense to talk about C ⊗D when C and D's agents are the same
agent, or otherwise overlap. This is because C ⊗D's agent can make choices for both 
C and D, and if C and D overlap, C ⊗D's agent could make choices for the intersection
in two contradictory ways.
If you try to take the tensor of two frames whose agents overlap, you get a frame with
an agent but no possible worlds.
Claim: If Ensure(C) ∩Prevent(D) is nonempty, then C ⊗D ≃⊤.
Proof: Let C = (A, E, ⋅), and let D = (B, F, ⋆). Consider some S ∈Ensure(C) ∩Prevent(D)
. There is some a ∈A such that a ⋅e ∈S for all e ∈E, and some b ∈B such that 
b ⋆f ∉S for all f ∈F. First, observe that Agent(C ⊗D) is nonempty, since it contains 
(a, b). Next, observe that Env(C ⊗D) is empty, since if there were a morphism 
(g, h) : C →D∗, it would need to satisfy b ⋆g(a) = a ⋅h(b), which is impossible since the

left hand side is not in S, while the right hand side is in S. Thus, C ⊗D has empty
environment and nonempty agent, so C ⊗D ≃⊤. □
Tensoring an agent with itself lets you play "both" agents, which has the neat
consequence that if the agent has any control, you can have the agent make two
diﬀerent choices that put you in two diﬀerent possible worlds, which is a contradiction.
The result is that the agent has no possible worlds.
Corollary: If Ctrl(C) is nonempty, then C ⊗C ≃⊤.
Proof: Trivial. □
 
3. Tensor is Relative to a Coarse World Model
Recall that for any function p : W →V , the functor p∘: Chu(W) →Chu(V ) preserves
sums and products, meaning that for any Cartesian frames C and D over W, 
p∘(C ⊕D) = p∘(C) ⊕p∘(D) and p∘(C&D) = p∘(C)&p∘(D). However, the same is not true
for ⊗. To see this, let's go back to the voting example above.
Let's assume that Jack, Kate, and Luke have a party if and only if a majority vote in
favor, and let V = {Y, N} be the two-element world that only tracks whether or not
they have a party. Let p : W →V  be the function such that p(ε) = p(J) = p(K) = p(L) = N
 and p(JK) = p(JL) = p(KL) = p(JKL) = Y. Then, 
p∘(CJ) ≅p∘(CK) ≅(
N
Y
Y
Y
N
N
N
Y ) ≃(
N
Y
Y
N
N
Y ),
and
p∘(CJ ⊗CK) ≅p∘(C
∗
L ) ≅
⎛
⎜ 
⎜ 
⎜
⎝
Y
Y
N
Y
N
Y
N
N
⎞
⎟ 
⎟ 
⎟
⎠
≃
⎛
⎜
⎝
Y
Y
N
Y
N
N
⎞
⎟
⎠
,
but

(
N
Y
Y
Y
N
N
N
Y ) ⊗(
N
Y
Y
Y
N
N
N
Y ) /≄
⎛
⎜ 
⎜ 
⎜
⎝
Y
Y
N
Y
N
Y
N
N
⎞
⎟ 
⎟ 
⎟
⎠
.
We can see that p∘(CJ ⊗CK) is not equivalent to p∘(CJ) ⊗p∘(CK) by observing that the
latter has a constant N environment while the former doesn't.
Let p∘(CJ) ≅p∘(CK) ≅(A, E, ⋅), and let eN ∈E denote the environment such that 
a ⋅eN = N for both a ∈A. (In the matrix representation above, this is the ﬁrst column.)
Observe that there exists a morphism (g, h) : (A, E, ⋅) →(A, E, ⋅)∗, where g and h are
both the constant eN function. This is a morphism because for all a0, a1 ∈A, 
a0 ⋅h(a1) = a1 ⋅g(a0) = N. This gives an environment in  p∘(CJ) ⊗p∘(CK), all of whose
entries must be N. p∘(CJ ⊗CK) has no such environment, so p∘(CJ ⊗CK) cannot be
isomorphic to p∘(CJ) ⊗p∘(CK), or even biextensionally equivalent. Indeed:
p∘(CJ) ⊗p∘(CK) ≃
⎛
⎜ 
⎜ 
⎜
⎝
N
Y
Y
Y
Y
Y
N
N
N
Y
Y
Y
N
N
Y
N
Y
Y
N
N
N
N
N
Y
⎞
⎟ 
⎟ 
⎟
⎠
.
To see what is going on here, consider another example where Jack and Kate and Luke
vote on whether to have a party, but whether or not the party happens is not just a
function of the majority's vote. Instead, after the three people cast their votes, a coin
is ﬂipped:
If heads, the votes are tallied and majority wins as normal.
If tails, one of the three voters is selected at random to be dictator, and the
party happens if and only if they voted in favor.
Let us work up to biextensional collapse. Let DJ be the Cartesian frame over V
 representing Jack's perspective. We have

DJ ≃(
N
Y
Y
N
N
Y ),
where the top row represents voting for the party, and the bottom row represents
voting against.
The ﬁrst column represents environments where the party does not happen and Jack's
vote didn't matter—either the coin came up heads and the others both voted against,
or Kate or Luke became dictator and voted against. The third column similarly
represents outcomes where the party happens regardless of how Jack votes. The
second column represents all environments in which Jack's vote matters, so either he
is dictator, or Kate and Luke's votes were split.
Similarly, let DK be the Cartesian frame over V  representing Kate's perspective,
DK ≃(
N
Y
Y
N
N
Y ).
Then,
DJ ⊗DK ≃
⎛
⎜ 
⎜ 
⎜
⎝
N
Y
Y
Y
Y
Y
N
N
N
Y
Y
Y
N
N
Y
N
Y
Y
N
N
N
N
N
Y
⎞
⎟ 
⎟ 
⎟
⎠
.
The rows represent, in order: both voting in favor; Jack voting in favor but Kate voting
against; Kate voting in favor but Jack voting against; and both voting against.
The columns represent, in order: Luke is dictator and votes against; majority rules and
Luke votes against; Kate is dictator; Jack is dictator; majority rules and Luke votes in
favor; and Luke is dictator and votes in favor.
Here, DJ ⊗DK looks more like what we would expect Jack and Kate working together
on a team to look like. However, up to biextensional equivalence, DJ and DK are the
same as p∘(CJ) and p∘(CK).
When we forget the actual votes and only look at whether the party happens, then up
to biextensional collapse, the Cartesian frame representing Jack's perspective no
longer has any way to distinguish between the simple majority rule vote and the
complicated voting system with coins and dictators.
In general, just looking at two Cartesian frames does not tell you all of the information
about the relationships between the people we might be using the frames to model.

The Cartesian frames over V  representing Jack and Kate's perspectives do not have
any information that distinguishes between the two vote counting schemes.
When taking a tensor, we automatically include all of the possible ways the two
agents can embed in each other's environments, even if a given embedding doesn't
make sense in a given interpretation.
 
4. Par
Our next multiplicative operation is ⅋ , which is pronounced "par."
Deﬁnition: Let C = (A, E, ⋅) and D = (B, F, ⋆) be Cartesian frames over W. 
C⅋ D = (hom(C ∗, D), E × F, ⋄), where (g, h) ⋄(e, f) = g(e) ⋆f = h(f) ⋅e.
Claim: ⅋  is De Morgan dual to ⊗, so C⅋ D = (C ∗⊗D∗)∗.
Proof: Trivial. □
⅋  has much less of an intuitive interpretation than ⊗. One reason for this is that in
order to par two agents together, they have to be large enough that each other's
environments embed within them. If C and D are not large enough, we will have that 
C⅋ D ≃0. (I am being informal with the word "large" here.)
One way that C and D can fail to be large enough is if Ensure(C ∗) ∩Prevent(D∗) is
nonempty, which is dual to the above result about tensor being for disjoint agents. It
is actually pretty diﬃcult for C and D to be large enough. If there is any fact about the
world that is determined outside of both agents, C⅋ D will be trivial.
We had a dual restriction for ⊗, but it didn't get in the way nearly as often: simple
intuitive examples tend to be about small agents interacting with a large environment,
so it is easy to imagine two agents that are disjoint. It is much harder to imagine
simple examples of two agents that cover, which (informally) is what you would have
to have for ⅋  to be nontrivial.
I expect to not use ⅋  very often, but I am including it here for completeness.

Claim: ⅋  is commutative and associative, and ⊥ is the identity of ⅋  (up to
isomorphism).
Proof: Trivial from the fact that ⅋  is De Morgan dual to ⊗ and 1∗≅⊥. □
Claim: If C0 ≃C1 and D0 ≃D1, then C0⅋ D0 ≃C1⅋ D1.
Proof: Trivial from the fact that ⅋  is De Morgan dual to ⊗, and ≃ is preserved by −∗. 
□
Claim: ⅋  distributes over &, so for all Cartesian frames C0, C1, and D, we have 
(C0&C1)⅋ D ≅(C0⅋ D)&(C1⅋ D).
Proof: Trivial from the fact that ⅋  is De Morgan dual to ⊗, and & is De Morgan dual to 
⊕. □
 
5. Lollipop
We have one more operation to introduce, ⊸ (pronounced "lollipop"), which is a
Cartesian frame that can be thought of as representing the collection of morphisms
between two Cartesian frames.
Deﬁnition: Given two Cartesian frames over W, C = (A, E, ⋅) and D = (B, F, ⋆), we let 
C ⊸D denote the Cartesian frame C ⊸D = (hom(C, D), A × F, ⋄), where ⋄ is given by 
(g, h) ⋄(a, f) = g(a) ⋆f = a ⋅h(f).
One way to interpret C ⊸D is as "D with a C-shaped hole in it." Indeed, let us think
about Agent(C ⊸D). and Env(C ⊸D) separately. 
Agent(C ⊸D) = hom(C, D) is the collection of morphisms from C to D. Morphisms from 
C to D are exactly interfaces through which the agent of C can interact with the
environment of D. We can also think of this as the collection of interfaces that allow
the agent of C to ﬁll the role of the agent of D. This makes sense. The collection of

ways that a "D with a C-shaped hole in it" can be is exactly the collection of interfaces
that allow us to get a possible agent of D from a possible agent of C.
Similarly, Env(C ⊸D) = A × F makes sense as the environment of a "D with a C-
shaped hole in it." The environment needs to supply an environment for D, and also
ﬁll in the hole with an agent for C.
Previously, C's agent might have been part of D's agent; in C ⊸D, however, this part
of D gets moved into the environment.
Imagine a football team D with one team member, C, removed—the team with a
football-player-shaped hole in it. Its environment, naturally, is pairs of "the kind of
environment you get for a football team" and "the removed teammate".
Lollipop can be easily constructed from our other operations.
Claim: C ⊸D ≅C ∗⅋ D ≅(C ⊗D∗)∗.
Proof: Trivial. □
Lollipop is well-deﬁned up to biextensional equivalence.
Claim: If C0 ≃C1 and D0 ≃D1, then C0 ⊸D0 ≃C1 ⊸D1.
Proof: Trivial. □
Lollipop also has some identity-like properties.
Claim: For all Cartesian Frames C, C ≅1 ⊸C and C ∗≅C ⊸⊥.
Proof: 1 ⊸C ≅(1 ⊗C ∗)∗≅C ∗∗≅C and C ⊸⊥≅(C ⊗1)∗≅C ∗. □
This last result is especially interesting because we can actually think of C ⊸⊥ as an
alternative deﬁnition for C ∗.
 
In "Tensor is Relative to a Coarse World Model" above, we noted that two agents
working together might sometimes have strictly fewer possible environments than
show up in the tensor. In the next post, we will introduce the concept of a sub-tensor,

which allows us to represent teams that have fewer possible environments than the
tensor. Similarly, sub-sum will be sum with spurious possible environments removed.

Sub-Sums and Sub-Tensors
Crossposted from the AI Alignment Forum. May contain more technical jargon than usual.
This is the eighth post in the Cartesian frames sequence. Here, we deﬁne new versions of the sum and
tensor of Cartesian frames that can delete spurious possible environments from the frame.
 
1. Motivating Examples
The sum C ⊕D of C and D is supposed to represent an agent that can do anything either C or D can do,
while the tensor, C ⊗D, is supposed to represent an agent that can do anything C and D can do working
freely together on a team. However, sometimes these operations produce Cartesian frames with more
environments than we would expect.
Consider two players, Alice and Bob, in a prisoner's dilemma. We will let W = {0, 1, 2, 3} be the space of
utilities for Alice. The Cartesian frame for Alice looks like
C0 = (
2
0
3
1 ),
where the top row represents Alice cooperating, and the left column represents Bob cooperating.
Let C1 = ( 2
0 ) represent Alice committed to cooperating, and let C2 = ( 3
1 ) represent Alice
committed to defecting. Since the real Alice can either cooperate or defect, one might expect that Alice
(C0) would equal the sum (C1 ⊕C2) of Alice cooperating with Alice defecting. However,
C1 ⊕C2 = (
2
0
2
0
3
1
1
3 ).
The last two columns are spurious environments that represent Bob copying Alice's move, and Bob
doing the opposite of Alice's move. However, since Bob cannot see Alice's move, Bob should not be able
to implement these policies: Bob can only choose to cooperate or defect.
Next, consider a unilateralist's curse game where two players each have access to a button that
destroys the Earth. If either player pushes the button, the Earth is destroyed. Otherwise, the Earth is not
destroyed. W = {0, 1}, where 0 represents the world being destroyed and 1 represents the world not
being destroyed.
Here, both players have the Cartesian frame
D1 = (
0
0
0
1 ),
where the ﬁrst row represents pressing the button, and the ﬁrst column represents the other player
pressing the button.
The two players together can be expressed with the Cartesian frame

D2 =
⎛
⎜ 
⎜ 
⎜
⎝
0
0
0
1
⎞
⎟ 
⎟ 
⎟
⎠
,
where the rows in order represent: both players pressing the button; the ﬁrst player pressing the
button; the second player pressing the button; and neither player pressing the button.
One might expect that D1 ⊗D1 would be D2, but in fact,
D1 ⊗D1 =
⎛
⎜ 
⎜ 
⎜
⎝
0
0
0
0
0
0
1
0
⎞
⎟ 
⎟ 
⎟
⎠
.
The second possible environment, in which the earth is just destroyed regardless of what the players
do, is spurious.
In both of the above examples, the spurious environments are only spurious because of our
interpretation. In the prisoner's dilemma case, C1 ⊕C2 would be correct if Alice and Bob were playing a
modiﬁed dilemma where Bob can see Alice's choice. In the unilateralist's curse example, D1 ⊗D1 would
be correct if there were three people playing the game. The problem is that the ⊕ and ⊗ operations do
not see our interpretation, and so include all possible environments.
 
2. Deleting Spurious Environments
We introduce two new concepts, called sub-sum and sub-tensor, which represents sum and tensor with
some (but not too many) spurious environments removed.
Deﬁnition: Let C = (A, E, ⋅), and let D = (B, F, ⋆). A sub-sum of C and D is a Cartesian frame of the form 
(A ⊔B, X, ⋄), where X ⊆Env(C ⊕D) and ⋄ is Eval(C ⊕D) restricted to (A ⊔B) × X, such that C ≃(A, X, ⋄C)
 and D ≃(B, X, ⋄D), where ⋄C is ⋄ restricted to A × X and ⋄D is ⋄ restricted to B × X. Let C ⊞D denote the
set of all sub-sums of C and D.
Deﬁnition: Let C = (A, E, ⋅), and let D = (B, F, ⋆). A sub-tensor of C and D is a Cartesian frame of the
form (A × B, X, ∙), where X ⊆Env(C ⊗D) and ∙ is Eval(C ⊗D) restricted to (A × B) × X, such that 
C ≃(A, B × X, ∙C) and D ≃(B, A × X, ∙D), where ∙C and ∙D are given by a ∙C (b, x) = (a, b) ∙x and 
b ∙D (a, x) = (a, b) ∙x. Let C ⊠D denote the set of all sub-tensors of C and D.

Thus, we deﬁne C ⊞D and C ⊠D to be sets of Cartesian frames that can be obtained by deleting
columns from from C ⊕D and C ⊗D, respectively, but we have an extra restriction to ensure that we do
not delete too many columns.
We will discuss later how to interpret the extra restriction, but ﬁrst let us go back to our above
examples.
If C1 = ( 2
0 ) and C2 = ( 3
1 ), then C1 ⊞C2 has 7 elements:
( 
2 
0 
2 
0 
3 
1 
1 
3  ) , ( 
2 
0 
2 
3 
1 
1  ) , ( 
2 
0 
0 
3 
1 
3  ) , ( 
2 
2 
0 
3 
1 
3  ) , ( 
0 
2 
0 
1 
1 
3  ) , ( 
2 
0 
3 
1  ) , ( 
2 
0 
1 
3  )
The 9 Cartesian frames that can be obtained by deleting columns from C ⊕D that are not in C1 ⊞C2
 are:
(
2
2
3
1 ) , (
2
0
3
3 ) , (
0
2
1
1 ) , (
0
0
1
3 ) , (
2
3 ) , (
0
1 ) , (
2
1 ) , (
0
3 ) , ( ).
The Cartesian frames above in C1 ⊞C2 are exactly those with all four entries, 0, 1, 2, and 3. This is
because the extra restriction to be in C1 ⊞C2 is exactly that if you delete the bottom row, you get an
object biextensionally equivalent to ( 2
0 ), and if you delete the top row, you get an object
biextensionally equivalent to ( 3
1 ).
Similarly, from the unilateralist's curse example,
D1 ⊠D1 =
⎧
⎪ 
⎪ 
⎪
⎨
⎪ 
⎪ 
⎪
⎩
⎛
⎜ 
⎜ 
⎜
⎝
0
0
0
1
⎞
⎟ 
⎟ 
⎟
⎠
,
⎛
⎜ 
⎜ 
⎜
⎝
0
0
0
0
0
0
1
0
⎞
⎟ 
⎟ 
⎟
⎠
⎫
⎪ 
⎪ 
⎪
⎬
⎪ 
⎪ 
⎪
⎭
.
It is easy to see that there are no other Cartesian frames in D1 ⊠D1, since there are only four subsets of
the two element environment of D1 ⊗D1, and the Cartesian frames corresponding to the other two
subsets do not have 1 in their image, so we cannot build anything biextensionally equivalent to D1 out
of them.
Conversely, let C = (A, E, ⋅) and D = (B, F, ⋆) both be D1, and notice that if

(A × B, X, ∙) =
⎛
⎜ 
⎜ 
⎜
⎝
0
0
0
1
⎞
⎟ 
⎟ 
⎟
⎠
,
then (A, B × X, ∙C) and (B, A × X, ∙D) are both two-by-two matrices with a single 1 entry and three 0
 entries, and so must be isomorphic to D1. Similarly, if
(A × B, X, ∙) =
⎛
⎜ 
⎜ 
⎜
⎝
0
0
0
0
0
0
1
0
⎞
⎟ 
⎟ 
⎟
⎠
,
then (A, B × X, ∙C) and (B, A × X, ∙D) are both two-by-four matrices with a single 1 entry and seven 0
 entries, and so must by biextensionally equivalent to D1.
 
3. Properties of Sub-Sums and Sub-Tensors
3.1. Sub-Sums and Sub-Tensors Are Commutative
Claim: For any Cartesian frames C0 and C1, there is a bijection between C0 ⊞C1 and C1 ⊞C0 that
preserves Cartesian frames up to isomorphism. Similarly, there is a bijection between C0 ⊠C1 and 
C1 ⊠C0 that preserves Cartesian frames up to isomorphism.
Proof: Trivial. □
 
3.2. Tensors Need Not Be Sub-Tensors
For any Cartesian frames C and D with nonempty environments, we have that C ⊕D ∈C ⊞D. However,
sometimes C ⊗D ∉C ⊠D. Indeed, sometimes C ⊠D = {}.
For example, if C and D both have nonempty image, but there are no morphisms from C to D∗, then 
C ⊗D has no environments, and it is easy to see that C ⊠D must be empty.
 
3.3. Sub-Sums and Sub-Tensors Are Superagents

Claim: For any Cartesian frames C0 and C1, and for any D0 ∈C0 ⊞C1, we have C0 ◃D0 and C1 ◃D0.
Similarly, for any D1 ∈C0 ⊠C1, we have C0 ◃D1 and C1 ◃D1.
Proof: Let Ci = (Ai, Ei, ⋅i) and Di = (Bi, Fi, ⋆i). First, we show C0 ◃D0 using the currying deﬁnition of
subagent. Observe B0 = A0 ⊔A1. Consider the Cartesian frame (A0, {e}, ⋄) over B0, where ⋄ is given by 
a ⋄e = a. Observe that the deﬁnition of sub-sum says that C0 ≃D
∘
0(A0, {e}, ⋄), so C0 ◃D0. Therefore, 
C0 ◃D0, and by commutativity, we also have C1 ◃D0 .
Similarly, we show C0 ◃D1 using the currying deﬁnition of subagent. Observe that B1 = A0 × A1.
Consider the Cartesian frame (A0, A1, ∙) over B1, where ∙ is given by a0 ∙a1 = (a0, a1). Observe that the
deﬁnition of sub-tensor says that C0 ≃D
∘
1(A0, A1, ∙). Therefore, C0 ◃D1, and by commutativity, we also
have C1 ◃D1. □
Observe that in the above proof, the Cartesian frame over B0 we constructed to show that sub-sums are
superagents had a singleton environment, and the Cartesian frame over B1 we constructed to show that
sub-tensors are superagents had a surjective evaluation function. The relevance of this observation will
become clear later.
 
3.4. Biextensional Equivalence
As we do with most of our deﬁnitions, we will now show that sub-sums and sub-tensors are well-deﬁned
up to biextensional equivalence.
Claim: Given two Cartesian frames over W, C0 and C1, and given any D ∈C0 ⊞C1, we have that for all 
C
′
0 ≃C0 and C
′
1 ≃C1, there exists a D′ ≃D, with D′ ∈C
′
0 ⊞C
′
1.
Proof: Let C0 = (A0, E0, ⋅0), let C1 = (A1, E1, ⋅1), and let D = (A0 ⊔A1, X, ⋆) be an element of C0 ⊞C1, so 
X ⊆E0 × E1, and a ⋆(e0, e1) = a ⋅0 e0 if a ∈A0, and a ⋆(e0, e1) = a ⋅1 e1 if a ∈A1.
The fact that D ∈C0 ⊞C1 tells us that for i ∈{0, 1}, Di ≃Ci, where Di = (Ai, X, ⋆i) with ⋆i given by 
a ⋆0 (e0, e1) = a ⋅0 e0 and a ⋆1 (e0, e1) = a ⋅0 e1.
For i ∈{0, 1}, let C
′
i = (A
′
i, E
′
i, ⋅
′
i) satisfy C
′
i ≃Ci. Thus, there exist morphisms (gi, hi) : Ci →C
′
i, and 
(g
′
i, h
′
i) : C
′
i →Ci, such that (g0, h0) ∘(g
′
0, h
′
0), (g
′
0, h
′
0) ∘(g0, h0), (g1, h1) ∘(g
′
1, h
′
1), and (g
′
1, h
′
1) ∘(g1, h1) are
all homotopic to the identity.

We deﬁne a function f : E0 × E1 →E
′
0 × E
′
1 by f(e0, e1) = (h
′
0(e0), h
′
1(e1)). Then, we deﬁne X′ ⊆E
′
0 × E
′
1 by 
X′ = {f(x) | x ∈X}, and let D′ = (A
′
0 ⊔A
′
1, X′, ⋆′), where a ⋆′ (e0, e1) = a ⋅
′
0 e0 if a ∈A
′
0, and 
a ⋆′ (e0, e1) = a ⋅
′
1 e1 if a ∈A
′
1. We need to show D′ ∈C
′
0 ⊞C
′
1, and that D′ ≃D.
To show that D′ ≃D, we will construct a pair of morphisms (j, k) : D →D′ and (j′, k′) : D′ →D that compose
to something homotopic to the identity in both orders. We deﬁne j : A0 ⊔A1 →A
′
0 ⊔A
′
1 by j(a) = g0(a) if 
a ∈A0, and j(a) = g1(a) if a ∈A1. We similarly deﬁne j′ : A
′
0 ⊔A
′
1 →A0 ⊔A1 by j′(a) = g
′
0(a) if a ∈A
′
0, and 
j′(a) = g
′
1(a) if a ∈A
′
1. We deﬁne k′ : X →X′ by k′(x) = f(x), which is clearly a function into X′, by the
deﬁnition of X′. Further, k′ is surjective, and thus has a right inverse. We choose k : X′ →X to be any
right inverse to k′, so f(k(x)) = x for all x ∈X′.
To see that (j′, k′) is a morphism, observe that for a ∈A
′
0 ⊔A
′
1, and (e0, e1) ∈X, if a ∈A
′
i, then
j ′ ( a ) ⋆ ( e 0 , e 1 )  = g 
′
i ( a ) ⋅ i e i 
 = a ⋅ 
′
i h 
′
i ( e i ) 
 = a ⋆ ′ ( h 
′
0 ( e 0 ) , h 
′
1 ( e 1 ) ) 
 = a ⋆ ′ k ′ ( e 0 , e 1 ) ) . 
To see that (j, k) is a morphism, consider an arbitrary a ∈A0 ⊔A1 and (e
′
0, e
′
1) ∈X′, and let 
(e0, e1) = k(e
′
0, e
′
1). Then, if a ∈Ai, we have
j ( a ) ⋆ ′ ( e 
′
0 , e 
′
1 )  = j ( a ) ⋆ ′ f ( e 0 , e 1 ) 
 = j ( a ) ⋆ ′ ( h 
′
0 ( e 0 ) , h 
′
1 ( e 1 ) ) 
 = g i ( a ) ⋅ 
′
i h 
′
i ( e i ) 
 = g 
′
i ( g i ( a ) ) ⋅ i e i 
 = a ⋅ i e i 
 = a ⋆ ( e 0 , e 1 ) 
 = a ⋆ k ( e 
′
0 , e 
′
1 ) . 

To see that (j′, k′) ∘(j, k) is homotopic to the identity on D, observe that for all a ∈A0 ⊔A1 and 
(e0, e1) ∈X, we have that if a ∈Ai,
j ′ ( j ( a ) ) ⋆ ( e 0 , e 1 )  = g 
′
i ( g i ( a ) ) ⋅ i e i 
 = a ⋅ i e i 
 = a ⋆ ( e 0 , e 1 ) . 
Similarly, to see that (j, k) ∘(j′, k′) is homotopic to the identity on D′, observe that for all a ∈A
′
0 ⊔A
′
1 and 
(e0, e1) ∈X′, we have that if a ∈A
′
i,
j ( j ′ ( a ) ) ⋆ ′ ( e 0 , e 1 )  = g i ( g 
′
i ( a ) ) ⋅ 
′
i e i 
 = a ⋅ 
′
i e i 
 = a ⋆ ′ ( e 0 , e 1 ) . 
Thus, D′ ≃D.
To see D′ ∈C
′
0 ⊞C
′
1, we need to show that D
′
i ≃C
′
i, where D
′
i = (A
′
i, X′, ⋆
′
i) with ⋆
′
i given by 
a ⋆
′
0 (e0, e1) = a ⋅
′
0 e0 and a ⋆
′
1 (e0, e1) = a ⋅
′
1 e1. It suﬃces to show that D
′
i ≃Di, since Di ≃Ci ≃C
′
i.
For i ∈{0, 1}, we construct morphisms (ji, ki) : Di →D
′
i, and (j
′
i, k
′
i) : D
′
i →Di. We deﬁne ji = gi, j
′
i = g
′
i, ki = k
, and k
′
i = k′.
To see that (ji, ki) is a morphism, observe that for all a ∈Ai and x ∈X′, we have
j i ( a ) ⋆ 
′
i x  = g i ( a ) ⋆ 
′
i x 
 = j ( a ) ⋆ ′ x 
 = a ⋆ k ( x ) 
 = a ⋆ i k i ( x ) , 
and to see that (j
′
i, k
′
i) is a morphism, observe that for all a ∈A
′
i, and x ∈X, we have

j 
′
i ( a ) ⋆ i x  = g 
′
i ( a ) ⋆ i x 
 = j ′ ( a ) ⋆ x 
 = a ⋆ ′ k ′ ( x ) 
 = a ⋆ 
′
i k 
′
i ( x ) . 
To see (j
′
i, k
′
i) ∘(ji, ki) is homotopic to the identity on Di, observe that for all a ∈Ai and x ∈X, we have
j 
′
i ( j i ( a ) ) ⋆ i x  = g 
′
i ( g i ( a ) ) ⋆ i x 
 = j ′ ( j ( a ) ) ⋆ x 
 = a ⋆ x 
 = a ⋆ i x , 
and similarly, to show that (ji, ki) ∘(j
′
i, k
′
i) is homotopic to the identity on D
′
i, observe that for all a ∈A
′
i
 and x ∈X′, we have
j i ( j 
′
i ( a ) ) ⋆ 
′
i x  = g i ( g 
′
i ( a ) ) ⋆ 
′
i x 
 = j ( j ′ ( a ) ) ⋆ ′ x 
 = a ⋆ ′ x 
 = a ⋆ 
′
i x . 
Thus, we have that D
′
i ≃Di, completing the proof. □
We have a similar result for sub-tensors, whose proof directly mirrors the proof for sub-sums:
Claim: Given two Cartesian frames over W, C0 and C1, and any D ∈C0 ⊠C1, we have that for all 
C
′
0 ≃C0 and C
′
1 ≃C1, there exists a D′ ≃D, with D′ ∈C
′
0 ⊠C
′
1.
Proof: Let C0 = (A0, E0, ⋅0), let C1 = (A1, E1, ⋅1), and let D = (A0 × A1, X, ⋆) be an element of C0 ⊠C1, so 
X ⊆hom(C0, C
∗
1 ), and
( a , b ) ⋆ ( g , h )  = a ⋅ 0 h ( b ) 
 = b ⋅ 1 g ( a ) . 
The fact that D ∈C0 ⊠C1 tells us that for i ∈{0, 1}, Di ≃Ci, where Di = (Ai, A1−i × X, ⋆i) with ⋆i given by
a ⋆ 0 ( b , ( g , h ) )  = b ⋆ 1 ( a , ( g , h ) ) 
 = ( a , b ) ⋆ ( g , h ) . 

For i ∈{0, 1}, let C
′
i = (A
′
i, E
′
i, ⋅
′
i) satisfy C
′
i ≃Ci. Thus, there exist morphisms (gi, hi) : Ci →C
′
i, and 
(g
′
i, h
′
i) : C
′
i →Ci, such that (g0, h0) ∘(g
′
0, h
′
0), (g
′
0, h
′
0) ∘(g0, h0), (g1, h1) ∘(g
′
1, h
′
1), and (g
′
1, h
′
1) ∘(g1, h1) are
all homotopic to the identity.
We deﬁne a function f : hom(C0, C1
∗) →hom(C
′
0, C
′
1
∗) by f(g, h) = (h
′
1, g
′
1) ∘(g, h) ∘(g
′
0, h
′
0). This function
is well-deﬁned, since (h
′
1, g
′
1) = (g
′
1, h
′
1)∗∈hom(C
∗
1 , C
′
1
∗) and (h
′
0, g
′
0) ∈hom(C
′
0, C0).
Then, we deﬁne X′ ⊆hom(C
′
0, C
′
1
∗) by X′ = {f(g, h) | (g, h) ∈X}, and let D′ = (A
′
0 × A
′
1, X′, ⋆′), where
( a , b ) ⋆ ′ ( g , h )  = a ⋅ 
′
0 h ( b ) 
 = b ⋅ 
′
1 g ( a ) . 
We need to show that D′ ∈C
′
0 ⊠C
′
1, and that D′ ≃D.
To show that D′ ≃D, we will construct a pair of morphisms (j, k) : D →D′ and (j′, k′) : D′ →D that compose
to something homotopic to the identity in both orders. We deﬁne j : A0 × A1 →A
′
0 × A
′
1 by 
j(a, b) = (g0(a), g1(b)), and we similarly deﬁne j′ : A
′
0 × A
′
1 →A0 × A1 by j′(a, b) = (g
′
0(a), g
′
1(b)). We deﬁne 
k′ : X →X′ by k′(x) = f(x), which is clearly a function into X′, by the deﬁnition of X′. Further, k′ is
surjective, and thus has a right inverse. We choose k : X′ →X to be any right inverse to k′, so f(k(x)) = x
 for all x ∈X′.
To see (j′, k′) is a morphism, observe that for (a, b) ∈A
′
0 × A
′
1, and (g, h) ∈X, we have
j ′ ( a , b ) ⋆ ( g , h )  = ( g 
′
0 ( a ) , g 
′
1 ( b ) ) ⋆ ( g , h ) 
 = g 
′
1 ( b ) ⋅ 1 g ( g 
′
0 ( a ) ) 
 = b ⋅ 
′
1 h 
′
1 ( g ( g 
′
0 ( a ) ) ) 
 = ( a , b ) ⋆ ′ ( h 
′
1 ∘ g ∘ g 
′
0 , h 
′
0 ∘ h ∘ g 
′
1 ) 
 = ( a , b ) ⋆ ′ k ′ ( g , h ) . 
To see that (j, k) is a morphism, consider an arbitrary (a, b) ∈A0 × A1 and (g′, h′) ∈X′, and let 
(g, h) = k(g′, h′). Then, we have:

j ( a , b ) ⋆ ′ ( g ′ , h ′ )  = ( g 0 ( a ) , g 1 ( b ) ) ⋆ ′ f ( g , h ) 
 = ( g 0 ( a ) , g 1 ( b ) ) ⋆ ′ ( h 
′
1 , h 
′
1 ) ∘ ( g , h ) ∘ ( g 
′
0 , h 
′
0 ) 
 = g 1 ( b ) ⋅ 
′
1 h 
′
1 ( g ( g 
′
0 ( g 0 ( a ) ) ) ) 
 = g 
′
1 ( g 1 ( b ) ) ⋅ 1 g ( g 
′
0 ( g 0 ( a ) ) ) 
 = b ⋅ 1 g ( g 
′
0 ( g 0 ( a ) ) ) 
 = g 
′
0 ( g 0 ( a ) ) ⋅ 0 h ( b ) 
 = a ⋅ 0 h ( b ) 
 = ( a , b ) ⋆ ( g , h ) 
 = ( a , b ) ⋆ k ( g ′ , h ′ ) . 
To see that (j′, k′) ∘(j, k) is homotopic to the identity on D, observe that for all (a, b) ∈A0 × A1 and 
(g, h) ∈X, we have:
j ′ ( j ( a , b ) ) ⋆ ( g , h )  = ( g 
′
0 ( g 0 ( a ) ) , g 
′
1 ( g 1 ( b ) ) ) ⋆ ( g , h ) 
 = g 
′
1 ( g 1 ( b ) ) ⋅ 1 g ( g 
′
0 ( g 0 ( a ) ) ) 
 = b ⋅ 1 g ( g 
′
0 ( g 0 ( a ) ) ) 
 = g 
′
0 ( g 0 ( a ) ) ⋅ 0 h ( b ) 
 = a ⋅ 0 h ( b ) = ( a , b ) ⋆ ( g , h ) . 
Similarly, to see that (j, k) ∘(j′, k′) is homotopic to the identity on D′, observe that for all (a, b) ∈A
′
0 × A
′
1
 and (g, h) ∈X, we have:
j ( j ′ ( a , b ) ) ⋆ ′ ( g , h )  = ( g 0 ( g 
′
0 ( a ) ) , g 1 ( g 
′
1 ( b ) ) ) ⋆ ′ ( g , h ) 
 = g 1 ( g 
′
1 ( b ) ) ⋅ 
′
1 g ( g 0 ( g 
′
0 ( a ) ) ) 
 = b ⋅ 
′
1 g ( g 0 ( g 
′
0 ( a ) ) ) 
 = g 0 ( g 
′
0 ( a ) ) ⋅ 
′
0 h ( b ) 
 = a ⋅ 
′
0 h ( b ) 
 = ( a , b ) ⋆ ′ ( g , h ) . 
Thus, D′ ≃D.

To see D′ ∈C
′
0 ⊠C
′
1, we need to show that D
′
i ≃C
′
i, where D
′
i = (A
′
i, A
′
1−i × X′, ⋆
′
i) with ⋆
′
i given by
a ⋆ 
′
0 ( b , ( g , h ) )  = b ⋆ 
′
1 ( a , ( g , h ) ) 
 = ( a , b ) ⋆ ′ ( g , h ) . 
It suﬃces to show that D
′
i ≃Di, since Di ≃Ci ≃C
′
i.
For i ∈{0, 1}, we construct morphisms (ji, ki) : Di →D
′
i, and (j
′
i, k
′
i) : D
′
i →Di. We deﬁne ji = gi and j
′
i = g
′
i.
We deﬁne ki : (A
′
1−i × X′) →(A1−i × X) by ki(a, x) = (g
′
1−i(a), k(x)), and similarly deﬁne 
k
′
i : (A1−i × X) →(A
′
1−i × X′) by k
′
i(a, x) = (g1−i(a), k′(x)).
To see that (j0, k0) is a morphism, observe that for all a ∈A0 and (a1, (g, h)) ∈A
′
1 × X′, we have:
a ⋆ 0 k 0 ( b , ( g , h ) )  = a ⋆ 0 ( g 
′
1 ( b ) , k ( g , h ) ) 
 = ( a , g 
′
1 ( b ) ) ⋆ k ( g , h ) 
 = j ( a , g 
′
1 ( b ) ) ⋆ ′ ( g , h ) 
 = ( g 0 ( a ) , g 1 ( g 
′
1 ( b ) ) ) ⋆ ′ ( g , h ) 
 = g 1 ( g 
′
1 ( b ) ) ⋅ 
′
1 g ( g 0 ( a ) ) 
 = b ⋅ 
′
1 g ( g 0 ( a ) ) 
 = ( g 0 ( a ) , b ) ⋆ ′ ( g , h ) 
 = j 0 ( a ) ⋆ 
′
0 ( b , ( g , h ) ) . 
To see that (j1, k1), (j
′
0, k
′
0), and (j
′
1, k
′
1) are morphisms is similar. 
To see (j
′
0, k
′
0) ∘(j0, k0) is homotopic to the identity on D0, observe that for all a ∈A0 and 
(b, (g, h)) ∈A1 × X, we have

j 
′
i ( j i ( a ) ) ⋆ i x  = ( g 
′
i ( g i ( a ) ) , b ) ⋆ ( g , h ) 
 = g 
′
i ( g i ( a ) ) ⋅ 0 h ( b ) 
 = a ⋅ 0 h ( b ) 
 = ( a , b ) ⋆ ( g , h ) 
 = a ⋆ 0 ( b , ( g , h ) ) , 
and seeing that (j
′
1, k
′
1) ∘(j1, k1), (j0, k0) ∘(j
′
0, k
′
0), and (j1, k1) ∘(j
′
1, k
′
1) are homotopic to the identity is
similar.
Thus, we have that D
′
i ≃Di, completing the proof. □
 
In our next post, we will use sub-sum and sub-tensor to deﬁne additive subagents, which are like agents
that have committed to restrict their class of options; and multiplicative subagents, which are like
agents that are contained inside other agents. We will also introduce the concept of sub-environments.

Additive and Multiplicative Subagents
Crossposted from the AI Alignment Forum. May contain more technical jargon than
usual.
This is the ninth post in the Cartesian frames sequence. Here, we reﬁne our notion of
subagent into additive and multiplicative subagents. As usual, we will give many
equivalent deﬁnitions. 
The additive subagent relation can be thought of as representing the relationship
between an agent that has made a commitment, and the same agent before making
that commitment. The multiplicative subagent relation can be thought of as
representing the relationship between a football player and a football team.
Another way to think about the distinction is that additive subagents have fewer
options, while multiplicative subagents have less reﬁned options.
We will introduce these concepts with a deﬁnition using sub-sums and sub-tensors.
 
1. Deﬁnitions of Additive and Multiplicative
Subagent
1.1. Sub-Sum and Sub-Tensor Deﬁnitions
Deﬁnition: C is an additive subagent of D, written C ◃+ D, if there exists a C ′ and a 
D′ ≃D with D′ ∈C ⊞C ′.
Deﬁnition: C is a multiplicative subagent of D, written C ◃× D, if there exists a C ′ and 
D′ ≃D with D′ ∈C ⊠C ′.
These deﬁnitions are nice because they motivate the names "additive" and
"multiplicative." Another beneﬁt of these deﬁnitions is that they draw attention to the
Cartesian frames given by C′. This feature is emphasized more in the below (clearly
equivalent) deﬁnition.
 
1.2. Brother and Sister Deﬁnitions
Deﬁnition: C ′ is called a brother to C in D if D ≃D′ for some D′ ∈C ⊞C ′. Similarly, C ′
 is called a sister to C in D if D ≃D′ for some D′ ∈C ⊠C ′.
E.g., one "sister" of a football player will be the entire rest of the football team. One
"brother" of a person that precommitted to carry an umbrella will be the

counterfactual version of themselves that instead precommitted to not carry an
umbrella.
This allows us to trivially restate the above deﬁnitions as:
Deﬁnition: We say C ◃+ D if C has a brother in D and C ◃× D if C has a sister in D.
Claim: This deﬁnition is equivalent to the ones above.
Proof: Trivial. □
 
1.3. Committing and Externalizing Deﬁnitions
Next, we will give the committing deﬁnition of additive subagent and an externalizing
deﬁnition of multiplicative subagent. These deﬁnitions are often the easiest to work
with directly in examples.
We call the following deﬁnition the "committing" deﬁnition because we are viewing C
 as the result of D making a commitment (up to biextensional equivalence).
Deﬁnition: Given Cartesian frames C and D over W, we say C ◃+ D if there exist three
sets X, Y , and Z, with X ⊆Y , and a function f : Y × Z →W such that C ≃(X, Z, ⋄) and 
D ≃(Y , Z, ∙), where ⋄ and ∙ are given by x ⋄z = f(x, z) and y ∙z = f(y, z).
Claim: This deﬁnition is equivalent to the sub-sum and brother deﬁnitions of ◃+.
Proof: First, assume that C has a brother in D. Let C = (A, E, ⋅), and let D = (B, F, ⋆).
Let C ′ = (A′, E′, ⋅′) be brother to C in D. Let D′ = (B′, F ′, ⋆′) be such that  D′ ≃D and 
D′ ∈C ⊞C ′. Then, if we let X = A, let Y = B′ = A ⊔A′, let Z = F ′, and let f(y, z) = y ⋆′ z,
we get D ≃D′ = (Y , Z, ∙), where y ∙z = f(y, z), and by the deﬁnition of sub-sum, 
C ≃(X, Z, ⋄), where  x ⋄z = f(x, z).
Conversely, let X, Y , and Z be arbitrary sets with X ⊆Y , and let f : Y × Z →W.  Let 
C ≃C0 = (X, Z, ⋄0), and let D ≃D′ = (Y , Z, ∙), where x ⋄0 z = f(x, z) and y ∙z = f(y, z).
We want to show that C has a brother in D. It suﬃces to show that C0 has a brother in 

D, since sub-sum is well-deﬁned up to biextensional equivalence. Indeed, we will show
that C1 = (Y ∖X, Z, ⋄1) is brother to C0 in D, where ⋄1 is given by x ⋄1 z = f(x, z). 
Observe that C0 ⊕C1 = (Y , Z × Z, ∙′), where ∙′ is given by
y ∙ ′ ( z 0 , z 1 )  = y ⋄ 0 z 0 
 = y ∙ z 0 
if y ∈X, and is given by
y ∙ ′ ( z 0 , z 1 )  = y ⋄ 1 z 1 
 = y ∙ z 1 
otherwise. Consider the diagonal subset S ⊆Z × Z given by S = {(z, z) | z ∈Z}.
Observe that the map z ↦(gz, hz) is a bijection from Z to S. Observe that if we restrict 
∙′ to Y × S, we get ∙′′ : Y × S →W given by y ∙′′ (z, z) = y ∙z. Thus (Y , S, ∙′′) ≅(Y , Z, ∙),
 with the isomorphism coming from the identity on Y , and the bijection between S
 and Z.
If we further restrict ∙′′ to X × S or (Y ∖X) × S, we get ∙0 and ∙1 respectively, given by 
x ∙0 = x ⋄0 z and x ∙1 (z, z) = x ⋄1 z. Thus (X, S, ∙0) ≅(X, Z, ⋄0) and 
(Y ∖X, S, ∙1) ≅(Y ∖X, Z, ⋄1), with the isomorphisms coming from the identities on Y  and 
X∖Y , and the bijection between S and Z.
Thus (Y , S, ∙′′) ∈C0 ⊞C1, and (Y , S, ∙′′) ≅D′ ≃D, so C1 is brother to C0 in D, so C has a
brother in D. □
Next, we have the externalizing deﬁnition of multiplicative subagent. Here, we are
viewing C as the result of D sending some of its decisions into the environment (up to
biextensional equivalence).
Deﬁnition: Given Cartesian frames C and D over W, we say C ◃× D if there exist three
sets X, Y , and Z, and a function f : X × Y × Z →W such that C ≃(X, Y × Z, ⋄) and 

D ≃(X × Y , Z, ∙), where ⋄ and ∙ are given by x ⋄(y, z) = f(x, y, z) and 
(x, y) ∙z = f(x, y, z).
Claim: This deﬁnition is equivalent to the sub-tensor and sister deﬁnitions of ◃×.
Proof: First, assume that C has a sister in D. Let C = (A, E, ⋅), and let D = (B, F, ⋆). Let 
C ′ = (A′, E′, ⋅′) be sister to C in D. Let D′ = (B′, F ′, ⋆′) be such that  D′ ≃D and 
D′ ∈C ⊠C ′. Then, if we let X = A, let Y = A′, let Z = F ′ ⊆hom(C, C ′∗), and let
f ( x , y , ( g , h ) )  = x ⋅ h ( y ) 
 = y ⋅ ′ g ( x ) , 
we get D ≃D′ = (X × Y , Z, ∙), where (x, y) ∙z = f(x, y, z), and by the deﬁnition of sub-
tensor, C ≃(X, Y × Z, ⋄), where  x ⋄(y, z) = f(x, y, z).
Conversely, let X, Y , and Z be arbitrary sets, and let f : X × Y × Z →W. Let 
C ≃C0 = (X, Y × Z, ⋄0), and let D ≃D′ = (X × Y , Z, ∙), where 
x ⋄0 (y, z) = (x, y) ∙z = f(x, y, z). We will assume for now that at least one of X and Y  is
nonempty, as the case where both are empty is degenerate. 
We want to show that C has a sister in D. It suﬃces to show that C0 has a sister in D,
since sub-tensor is well-deﬁned up to biextensional equivalence. Indeed, we will show
that C1 = (Y , X × Z, ⋄1) is sister to C0 in D, where ⋄1 is given by y ⋄1 (x, z) = f(x, y, z). 
Observe that C0 ⊗C1 = (X × Y , hom(C0, C
∗
1 ), ∙′), where ∙′ is given by
( x , y ) ∙ ′ ( g , h )  = x ⋄ 0 h ( y ) 
 = y ⋆ 1 g ( x ) . 
For every z ∈Z, there is a morphism (gz, hz) : C0 →C
∗
1 , where gz : X →X × Z is given
by gz(x) = (x, z), and gz : Y →Y × Z is given by gz(x) = (x, z). This is clearly a
morphism. Consider the subset S ⊆hom(C0, C
∗
1 ) given by S = {(gz, hz) | z ∈Z}.

Observe that the map z ↦(gz, hz) is a bijection from Z to S. (We need that at least one
of X and Y  is nonempty here for injectivity.)
If we restrict ∙′ to (X × Y ) × S, we get ∙′′ : (X × Y ) × S →W given by y ∙′′ (gz, hz) = y ∙z.
Thus, (X × Y , S, ∙′′) ≅(X × Y , Z, ∙), with the isomorphism coming from the identity on 
X × Y , and the bijection between S and Z.
To show that (X × Y , S, ∙′′) ∈C0 ⊠C1, we need to show that C0 ≃(X, Y × S, ∙0) and 
C1 ≃(Y , X × S, ∙1), where ∙0 and ∙1 are given by
x ∙ 0 ( y , ( g h , z h ) )  = y ∙ 1 ( x , ( g h , z h ) ) 
 = ( x , y ) ∙ ′ ′ ( g z , h z ) . 
Indeed,  x ∙0 (y, (gh, zh)) = x ⋄0 (y, z) and y ∙1 (x, (gh, zh)) = y ⋄1 (x, z), so 
(X, Y × S, ∙0) ≅(X, Y × Z, ⋄0) = C0 and (Y , X × S, ∙1) ≅(Y , X × Z, ⋄1) = C1, with the
isomorphisms coming from the identities on X and Y , and the bijection between S
 and Z.
Thus (X × Y , S, ∙′′) ∈C0 ⊞C1, and (Y , S, ∙′′) ≅D′ ≃D, so C1 is sister to C0 in D, so C has
a sister in D.
Finally, in the case where X and Y  are both empty, C ≅null, and either D ≃null or 
D ≃0, depending on whether Z is empty. It is easy to verify that null ⊠null = {0, null},
since null ⊗null ≅0, taking the two subsets of the singleton environment in 0 yields 0
 and null as candidate sub-tensors, and both are valid sub-tensors, since either way,
the conditions reduce to null ≃null. □
Next, we have some deﬁnitions that more directly relate to our original deﬁnitions of
subagent.
 
1.4. Currying Deﬁnitions

Deﬁnition: We say C ◃+ D if there exists a Cartesian frame M over Agent(D) with 
|Env(M)| = 1, such that C ≃D∘(M).
Claim: This deﬁnition is equivalent to all of the above deﬁnitions of ◃+.
Proof: We show equivalence to the committing deﬁnition. 
First, assume that there exist three sets X, Y , and Z, with X ⊆Y , and a function 
p : Y × Z →W such that C ≃(X, Z, ⋄) and D ≃(Y , Z, ∙), where ⋄ and ∙ are given by 
x ⋄z = p(x, z) and y ∙z = p(y, z). 
Let D = (B, F, ⋆), and let (g0, h0) : D →(Y , Z, ∙) and (g1, h1) : (Y , Z, ∙) →D compose to
something homotopic to the identity in both orders. 
We deﬁne M, a Cartesian frame over B, by M = (X, {e}, ⋅), where ⋅ is given  
x ⋅e = g1(x). Observe that D∘(M) = (X, {e} × F, ⋆′), where ⋆′ is given by 
x ⋆ ′ ( e , f )  = ( x ⋅ e ) ⋆ f 
 = g 1 ( x ) ⋆ f 
 = x ∙ h 1 ( f ) . 
To show that (X, Z, ⋄) ≃D∘(M), we construct morphisms (g2, h2) : (X, Z, ⋄) →D∘(M) and 
(g3, h3) : D∘(M) →(X, Z, ⋄) that compose to something homotopic to the identity in
both orders. Let g2 and g3 both be the identity on X. Let h2 : {e} × F →Z be given by 
h2(e, f) = h1(f), and let h3 : Z →{e} × F be given by h3(z) = (e, h0(z)).
We know (g2, h2) is a morphism, since for all x ∈X and (e, f) ∈{e} × F, we have 
g 2 ( x ) ⋆ ′ ( e , f )  = x ⋆ ′ ( e , f ) 
 = x ∙ h 1 ( f ) 
 = x ⋄ h 1 ( f ) 
 = x ⋄ ( h 2 ( e , f ) ) . 

We also have that (g3, h3) is a morphism, since for all x ∈X and z ∈Z, we have
g 3 ( x ) ⋄ z  = x ⋄ z 
 = x ∙ z 
 = x ∙ h 1 ( h 0 ( z ) ) 
 = x ⋆ ′ ( e , h 0 ( z ) ) 
 = x ⋆ ′ h 3 ( z ) . 
Observe that (g2, h2) and (g3, h3) clearly compose to something homotopic to the
identity in both orders, since g2 ∘g3 and g3 ∘g2 are the identity on X.
Thus, C ≃(X, Z, ⋄) ≃D∘(M), and |Env(M)| = 1.
Conversely, assume C ≃D∘(M), with |Env(M)| = 1.  We deﬁne Y = Agent(D) and 
Z = Env(D). We deﬁne f : Y × Z →W by f(y, z) = y ∙z, where ∙= Eval(D).
Let X ⊆Y  be given by X = Image(M). Since |Env(M)| = 1, we have M ≃⊥X. Thus, 
C ≃D∘(M) ≃D∘(⊥X). Unpacking the deﬁnition of D∘(⊥X), we get 
D∘(⊥X) = (X, {e} × Z, ⋅), where ⋅ is given by x ⋅(e, z) = f(x, z), which is  isomorphic to 
(X, Z, ⋄), where ⋄ is given by x ⋄z = f(x, z). Thus C ≃(X, Z, ⋄) and D = (Y , Z, ∙), as in
the committing deﬁnition. □
Deﬁnition: We say C ◃× D if there exists a Cartesian frame M over Agent(D) with 
Image(M) = Agent(D), such that C ≃D∘(M).
Claim: This deﬁnition is equivalent to all of the above deﬁnitions of ◃×.
Proof: We show equivalence to the externalizing deﬁnition. 
First, assume there exist three sets X, Y , and Z, and a function p : X × Y × Z →W such
that C ≃(X, Y × Z, ⋄) and D ≃(X × Y , Z, ∙), where ⋄ and ∙ are given by 
x ⋄(y, z) = (x, y) ∙z = p(x, y, z). 

Let D = (B, F, ⋆), and let (g0, h0) : D →(X × Y , Z, ∙) and (g1, h1) : (X × Y , Z, ∙) →D
 compose to something homotopic to the identity in both orders.
We deﬁne B′ = B ⊔{a}, and we deﬁne M, a Cartesian frame over B, by 
M = (X, Y × B′, ⋅), where ⋅ is given by x ⋅(y, b) = b if b ∈B and g0(b) = (x, y), and 
x ⋅(y, b) = g1(x, y) otherwise. Clearly, Image(M) = B, since for any b ∈B, if we let 
(x, y) = g0(b), we have x ⋅(y, b) = b.
Observe that for all x ∈X, y ∈Y , b ∈B′ and f ∈F, if b ∈B and g0(b) = (x, y), then
( x ⋅ ( y , b ) ) ⋆ f  = b ⋆ f 
 = g 1 ( g 0 ( b ) ) ⋆ f 
 = g 1 ( x , y ) ⋆ f , 
and on the other hand, if b = a or g0(b) ≠(x, y), we also have 
(x ⋅(y, b)) ⋆f = g1(x, y) ⋆f.
Thus, we have that D∘(M) = (X, Y × B′ × F, ⋆′), where ⋆′ is given by
x ⋆ ′ ( y , b , f )  = ( x ⋅ ( y , b ) ) ⋆ f 
 = g 1 ( x , y ) ⋆ f 
 = ( x , y ) ∙ h 1 ( f ) . 
To show that (X, Y × Z, ⋄) ≃D∘(M), we construct morphisms 
(g2, h2) : (X, Y × Z, ⋄) →D∘(M) and (g3, h3) : D∘(M) →(X, Y × Z, ⋄) that compose to
something homotopic to the identity in both orders. Let g2 and g3 both be the identity
on X. Let h2 : Y × B′ × F →Y × Z be given by h2(y, b, f) = (y, h1(f)), and let 
h3 : Y × Z →Y × B′ × F be given by h3(y, z) = (y, a, h0(z)).
We know (g2, h2) is a morphism, since for all x ∈X and (y, b, f) ∈Y × B′ × F,

g 2 ( x ) ⋆ ′ ( y , b , f )  = x ⋆ ′ ( y , b , f ) 
 = ( x , y ) ∙ h 1 ( f ) 
 = p ( x , y , h 1 ( f ) ) 
 = x ⋄ ( y , h 1 ( f ) ) 
 = x ⋄ ( h 2 ( y , b , f ) ) . 
We also have that (g3, h3) is a morphism, since for all x ∈X and (y, z) ∈Y × Z, we
have
g 3 ( x ) ⋄ ( y , z )  = x ⋄ z 
 = x ⋄ ( y , z ) 
 = p ( x , y , z ) 
 = ( x , y ) ∙ z 
 = ( x , y ) ∙ h 1 ( h 0 ( z ) ) 
 = ( x , y ) ⋆ ′ ( y , a , h 0 ( z ) ) 
 = x ⋆ ′ h 3 ( y , z ) . 
Observe that (g2, h2) and (g3, h3) clearly compose to something homotopic to the
identity in both orders, since g2 ∘g3 and g3 ∘g2 are the identity on X.
Thus, C ≃(X, Z, ⋄) ≃D∘(M), where Image(M) = Agent(D). 
Conversely, assume C ≃D∘(M), with  Image(M) = Agent(D). Let X = Agent(M), let 
Y = Env(M), and let Z = Env(D). Let f : X × Y × Z →W be given by f(x, y, z) = (x ⋅y) ⋆z,
where ⋅= Eval(M) and ⋆= Eval(D).
Thus C ≃D∘(M) ≅(X, Y × Z, ⋄), where ⋄ is given by x ⋄(y, z) = (x ⋅y) ⋆z = f(x, y, z). All
that remains to show is that D ≃(X × Y , Z, ∙), where (x, y) ∙z = f(x, y, z). Let 
D = (B, Z, ⋆).

We construct morphisms (g0, h0) : D →(X × Y , Z, ∙) and (g1, h1) : D →(X × Y , Z, ∙) that
compose to something homotopic to the identity in both orders. Let h0 and h1 be the
identity on Z. Let g1 : X × Y →B be given by g1(x, y) = x ⋅y. Since g1 is surjective, it
has a right inverse. Let g0 : B →X × Y  be any choice of right inverse of g1, so 
g1(g0(b)) = b for all b ∈B. 
We know (g1, h1) is a morphism, since for all (x, y) ∈X × Y  and z ∈Z,
g 1 ( x , y ) ⋆ z  = ( x ⋅ y ) ⋆ z 
 = f ( x , y , z ) 
 = ( x , y ) ∙ z 
 = ( x , y ) ∙ h 1 ( z ) . 
To see that (g0, h0) is a morphism, given b ∈B and z ∈Z, let (x, y) = g0(b), and
observe
g 0 ( b ) ∙ z  = ( x , y ) ∙ z 
 = f ( x , y , z ) 
 = ( x ⋅ y ) ⋆ z 
 = g 1 ( x , y ) ⋆ z 
 = g 1 ( g 0 ( b ) ) ⋆ z 
 = b ⋆ h 0 ( z ) . 
(g0, h0) and (g1, h1) clearly compose to something homotopic to the identity in both
orders, since h0 ∘h1 and h1 ∘h0 are the identity on Z. Thus D ≃(X × Y , Z, ∙),
completing the proof. □
Consider two Cartesian frames C and D, and let M be a frame whose possible agents
are Agent(C) and whose possible worlds are Agent(D). When C is a subagent of D, (up
to biextensional equivalence) there exists a function from Agent(C), paired with 
Env(M), to Agent(D).

Just as we did in "Subagents of Cartesian Frames" §1.2 (Currying Deﬁnition), we can
think of this function as a (possibly) nondeterministic function from Agent(C) to 
Agent(D), where Env(M) represents the nondeterminism. In the case of additive
subagents, Env(M) is a singleton, meaning that the function from Agent(C) to  
Agent(D) is actually deterministic. In the case of multiplicative subagents, the
(possibly) nondeterministic function is surjective.
Recall that in "Sub-Sums and Sub-Tensors" §3.3 (Sub-Sums and Sub-Tensors Are
Superagents), we constructed a frame with a singleton environment to prove that sub-
sums are superagents, and we constructed a frame with a surjective evaluation
function to prove that sub-tensors are superagents. The currying deﬁnitions of ◃+ and 
◃× show why this is the case.
 
1.5. Categorical Deﬁnitions
We also have deﬁnitions based on the categorical deﬁnition of subagent. The
categorical deﬁnition of additive subagent is almost just swapping the quantiﬁers from
our original categorical deﬁnition of subagent. However, we will also have to weaken
the deﬁnition slightly in order to only require the morphisms to be homotopic.
Deﬁnition: We say C ◃+ D if there exists a single morphism ϕ0 : C →D such that for
every morphism ϕ : C →⊥ there exists a morphism ϕ1 : D →⊥ such that ϕ is
homotopic to ϕ1 ∘ϕ0 .
Claim: This deﬁnition is equivalent to all the above deﬁnitions of ◃+.
Proof: We show equivalence to the committing deﬁnition. 
First, let C = (A, E, ⋅) and D = (B, F, ∙) be Cartesian frames over W, and let 
(g0, h0) : C →D be such that for all (g, h) : C →⊥, there exists a (g′, h′) : D →⊥ such
that (g, h) is homotopic to (g′, h′) ∘(g0, h0). Let ⊥= (W, {i}, ⋆).
Let Y = B, let Z = F, and let X = {g0(a) | a ∈A}. Let f : Y × Z →W be given by 
f(y, z) = y ∙z. We already have D = (Y , Z, ∙), and our goal is to show that C ≃(X, Z, ⋄),
 where ⋄ is given by x ⋄z = f(x, z).

We construct (g1, h1) : C →(X, Z, ⋄) and (g2, h2) : (X, Z, ⋄) →C that compose to
something homotopic to the identity in both orders.
We deﬁne g1 : A →X by g1(a) = g0(a). g1 is surjective, and so has a right inverse. We
let g2 : X →A be any right inverse to g1, so g1(g2(x)) = x for all x ∈X. We let h1 : Z →E
 be given by h1(z) = h0(z).
Deﬁning h2 : E →Z will be a bit more complicated.  Given an e ∈E, let (ge, he) be the
morphism from C to ⊥, given by he(i) = e and ge(a) = a ⋅e. Let (g
′
e, h
′
e) : D →⊥ be such
that (ge, he) is homotopic to (g
′
e, h
′
e) ∘(g0, h0). We deﬁne h2 by h2(e) = h
′
e(i).
We trivially have that (g1, h1) is a morphism, since for all a ∈A and z ∈Z,
g 1 ( a ) ⋄ z  = g 0 ( a ) ∙ z 
 = a ⋅ h 0 ( z ) 
 = a ⋅ h 1 ( z ) . 
To see that (g2, h2) is a morphism, consider x ∈X and e ∈E, and deﬁne (ge, he) and 
(g
′
e, h
′
e) as above. Then,
x ⋄ h 2 ( e )  = g 1 ( g 2 ( x ) ) ⋄ h 
′
e ( i ) 
 = g 
′
e ( g 0 ( g 2 ( x ) ) ) ⋆ i 
 = g 2 ( x ) ⋅ h e ( i ) 
 = g 2 ( x ) ⋅ e . 
We trivially have that (g1, h1) ∘(g2, h2) is homotopic to the identity, since g1 ∘g2 is the
identity on X. To see that (g2, h2) ∘(g1, h1) is homotopic to the identity on C, observe
that for all a ∈A and e ∈E, deﬁning (ge, he) and (g
′
e, h
′
e) as above,

g 2 ( g 1 ( a ) ) ⋅ e  = g 1 ( a ) ⋄ h 2 ( e ) 
 = g 0 ( a ) ⋄ h 
′
e ( i ) 
 = g 
′
e ( g 0 ( a ) ) ⋆ i 
 = a ⋆ h e ( i ) 
 = a ⋅ e . 
Thus C ≃(X, Z, ⋄), and C ◃+ D according to the committing deﬁnition.
Conversely, let X, Y , and Z be arbitrary sets with X ⊆Y , let f : Y × Z →W, and let 
C ≃(X, Z, ⋄) and D ≃(Y , Z, ∙), where ⋄ and ∙ are given by x ⋄z = f(x, z) and 
y ∙z = f(y, z).
Let (g1, h1) : C →(X, Z, ⋄) and (g2, h2) : (X, Z, ⋄) →C compose to something homotopic
to the identity in both orders, and let (g3, h3) : D →(Y , Z, ∙) and (g4, h4) : (Y , Z, ∙) →D
 compose to something homotopic to the identity in both orders. Let 
(g0, h0) : (X, Z, ⋄) →(Y , Z, ∙) be given by g0 is the embedding of X in Y  and h0 is the
identity on Z. (g0, h0) is clearly a morphism.
We let ϕ : C →D = (g4, h4) ∘(g0, h0) ∘(g1, h1).
Given a (g, h) : C →⊥, our goal is to construct a (g′, h′) : D →⊥ such that (g, h) is
homotopic to (g′, h′) ∘ϕ. 
Let ⊥= (W, {i}, ⋆), let C = (A, E, ⋅0), and let D = (B, F, ⋅1). Let h′ : {i} →F be given by 
h′ = h3 ∘h2 ∘h. Let g′ : B →W be given by g′(b) = b ⋅1 h′(i). This is clearly a morphism,
since for all b ∈B and i ∈{i},
g ′ ( b ) ⋆ i  = g ′ ( b ) 
 = b ⋅ h ′ ( i ) . 

To see that (g, h) is homotopic to (g′, h′) ∘(g4, h4) ∘(g0, h0) ∘(g1, h1), we just need to
check that (g, h1 ∘h0 ∘h4 ∘h′) : C →⊥ is a morphism. Or, equivalently, that 
(g, h1 ∘h4 ∘h3 ∘h2 ∘h) : C →⊥, since h0 is the identity, and h′ = h3 ∘h2 ∘h. 
Indeed, for all a ∈A and i ∈{i},
g ( a ) ⋆ i  = a ⋅ 0 h ( a ) 
 = a ⋅ 0 h 1 ( h 2 ( h ( a ) ) ) 
 = g 1 ( a ) ⋄ h 2 ( h ( a ) ) 
 = g 1 ( a ) ∙ h 2 ( h ( a ) ) 
 = g 1 ( a ) ∙ h 4 ( h 3 ( h 2 ( h ( a ) ) ) ) 
 = g 1 ( a ) ⋄ h 4 ( h 3 ( h 2 ( h ( a ) ) ) ) 
 = a ⋅ 0 h 1 ( h 4 ( h 3 ( h 2 ( h ( a ) ) ) ) ) . 
Thus (g, h) is homotopic to (g′, h′) ∘ϕ, completing the proof. □
Deﬁnition: We say C ◃× D if for every morphism ϕ : C →⊥, there exist morphisms 
ϕ0 : C →D and ϕ1 : D →⊥ such that ϕ = ϕ1 ∘ϕ0, and for every morphism ψ : 1 →D,
there exist morphisms ψ0 : 1 →C and ψ1 : C →D such that ψ = ψ1 ∘ψ0.
Before showing that this deﬁnition is equivalent to all of the above deﬁnitions, we will
give one ﬁnal deﬁnition of multiplicative subagent.
 
1.6. Sub-Environment Deﬁnition
First, we deﬁne the concept of a sub-environment, which is dual to the concept of a
sub-agent.
Deﬁnition: We say C is a sub-environment of D, written C ◃∗D, if D∗◃C ∗.
We can similarly deﬁne additive and multiplicative sub-environments.
Deﬁnition: We say C is an additive sub-environment of D, written C ◃
∗
+ D, if D∗◃+ C ∗.
We say C is an multiplicative sub-environment of D, written C ◃
∗
× D, if D∗◃× C ∗.

This deﬁnition of a multiplicative sub-environment is redundant, because the set of
frames with multiplicative sub-agents is exactly the set of frames with multiplicative
sub-environments, as shown below:
Claim: C ◃× D if and only if C ◃
∗
× D.
Proof: We prove this using the externalizing deﬁnition of ◃×.
If C ◃× D, then for some X, Y , Z, and f : X × Y × Z →W, we have C ≃(X, Y × Z, ⋄) and 
D ≃(X × Y , Z, ∙), where ⋄ and ∙ are given by x ⋄(y, z) = f(x, y, z) and 
(x, y) ∙z = f(x, y, z).
Observe that D∗≃(Z, Y × X, ⋅) and C ∗≃(Z × Y , X, ⋆), where ⋅ and ⋆ are given by 
z ⋅(y, x) = f(x, y, z) and (z, y) ⋆x = f(x, y, z). Taking X′ = Z, Y ′ = Y , Z′ = X, and 
f ′(x, y, z) = f(z, y, x), this is exactly the externalizing deﬁnition of D∗◃× C ∗, so C ◃
∗
× D.
Conversely, if C ◃
∗
× D, then D∗◃× C ∗, so C ≅{C ∗}∗◃× {D∗}∗≅D. □
We now give the sub-environment deﬁnition of multiplicative subagent:
Deﬁnition: We say C ◃× D if C ◃D and C ◃∗D. Equivalently, we say C ◃× D if C ◃D and 
D∗◃C ∗.
Claim: This deﬁnition is equivalent to the categorical deﬁnition of ◃×.
Proof: The condition that for every morphism ϕ : C →⊥, there exist morphisms 
ϕ0 : C →D and ϕ1 : D →⊥ such that ϕ = ϕ1 ∘ϕ0, is exactly the categorical deﬁnition of 
C ◃D.  
The condition that for every morphism ψ : 1 →D, there exist morphisms ψ0 : 1 →C and 
ψ1 : C →D such that ψ = ψ1 ∘ψ0, is equivalent to saying that for every morphism  
ψ∗: D∗→⊥, there exist morphisms ψ
∗
0 : C ∗→⊥ and ψ
∗
1 : D∗→C ∗ such that 
ψ∗= ψ
∗
1 ∘ψ
∗
0 . This is the categorical deﬁnition of D∗◃C ∗. □

Claim: The categorical and sub-environment deﬁnitions of ◃× are equivalent to the
other four deﬁnitions of multiplicative subagent above: sub-tensor, sister,
externalizing, and currying.
Proof: We show equivalence between the externalizing and sub-environment
deﬁnitions. First, assume that C = (A, E, ⋅) and D = (B, F, ⋆) are Cartesian frames over 
W with C ◃D and C ◃∗D.
We deﬁne X = A, Z = F, and Y = hom(C, D). We deﬁne p : X × Y × Z →W by
p ( a , ( g , h ) , f )  = g ( a ) ⋆ f 
 = a ⋅ h ( f ) . 
We want to show that C ≃(X, Y × Z, ⋄), and D ≃(X × Y , Z, ∙), where ⋄ and ∙ are given
by x ⋄(y, z) = (x, y) ∙z = p(x, y, z). 
To see C ≃(X, Y × Z, ⋄), we construct (g0, h0) : C →(X, Y × Z, ⋄) and 
(g1, h1) : (X, Y × Z, ⋄) →C that compose to something homotopic to the identity in both
orders. Let g0 and g1 be the identity on X and let h0 : Y × Z →E be deﬁned by 
h0((g, h), f) = h(f). By the covering deﬁnition of subagent, h0 is surjective, and so has a
right inverse. Let h1 : E →Y × Z be any right inverse of h0, so h0(h1(e)) = e for all 
e ∈E.
We know (g0, h0) is a morphism, because for all a ∈A and ((g, h), f) ∈Y × Z,
g 0 ( a ) ⋄ ( ( g , h ) , f )  = a ⋄ ( ( g , h ) , f ) 
 = p ( a , ( g , h ) , f ) 
 = a ⋅ h ( f ) 
 = a ⋅ h 0 ( ( g , h ) , f ) . 
We know (g1, h1) is a morphism, since for x ∈X and e ∈E, if ((g, h), f) = h1(e),

g 1 ( x ) ⋅ e  = x ⋅ h 0 ( ( g , h ) , f ) 
 = x ⋅ h ( f ) 
 = p ( x , ( g , h ) , f ) 
 = x ⋄ ( ( g , h ) , f ) 
 = x ⋄ h 1 ( e ) . 
(g0, h0) and (g1, h1) clearly compose to something homotopic to the identity in both
orders, since g0 ∘g1 and g1 ∘g0 are the identity on X.
To see D ≃(X × Y , Z, ∙), we construct (g2, h2) : D →(X × Y , Z, ∙) and 
(g3, h3) : (X × Y , Z, ∙) →D that compose to something homotopic to the identity in both
orders. Let h2 and h3 be the identity on Z and let g3 : X × Y →B be deﬁned by 
g3(a, (g, h)) = g(a). By the covering deﬁnition of subagent and the fact that D∗◃C ∗, g3
 is surjective, and so has a right inverse. Let g2 : B →X × Y  be any right inverse of g3,
so g3(g2(b)) = b for all b ∈B.
We know (g3, h3) is a morphism, because for all f ∈F and (a, (g, h)) ∈X × Y ,
g 3 ( a , ( g , h ) ) ⋆ f  = g ( a ) ⋆ f 
 = p ( a , ( g , h ) , f ) 
 = ( a , ( g , h ) ) ∙ f 
 = ( a , ( g , h ) ) ∙ h 3 ( f ) . 
We know (g2, h2) is a morphism, since for z ∈Z and b ∈B, if (a, (g, h)) = g2(b),
g 2 ( b ) ∙ z  = ( a , ( g , h ) ) ∙ z 
 = p ( a , ( g , h ) , z ) 
 = g ( a ) ⋆ z 
 = g 3 ( a , ( g , h ) ) ⋆ z 
 = b ⋆ h 2 ( z ) . 

Observe that (g2, h2) and (g3, h3) clearly compose to something homotopic to the
identity in both orders, since h2 ∘h3 and h3 ∘h2 are the identity on Z.
Thus,  C ≃(X, Y × Z, ⋄), and D ≃(X × Y , Z, ∙).
Conversely, if C ◃× D according to the externalizing deﬁnition, then we also have 
D∗◃× C ∗. However, by the currying deﬁnitions of multiplicative subagent and of
subagent, multiplicative subagent is stronger than subagent, so C ◃D and D∗◃C ∗. □
 
2. Basic Properties
Now that we have enough deﬁnitions of additive and multiplicative subagent, we can
cover some basic properties.
First: Additive and multiplicative subagents are subagents.
Claim: If C ◃+ D, then C ◃D. Similarly, if C ◃× D, then C ◃D.
Proof: Clear from the currying deﬁnitions. □
Additive and multiplicative subagent are also well-deﬁned up to biextensional
equivalence.
Claim: If C ◃+ D, C ′ ≃C, and D′ ≃D, then C ′ ◃+ D′. Similarly, if C ◃× D, C ′ ≃C, and 
D′ ≃D, then C ′ ◃× D′.
Proof: Clear from the committing and externalizing deﬁnitions. □
Claim: Both ◃+ and ◃× are reﬂexive and transitive.
Proof: Reﬂexivity is clear from the categorical deﬁnitions. Transitivity of  ◃× is clear
from the transitivity of ◃ and the sub-environment deﬁnition. Transitivity of ◃+ can be
seen using the categorical deﬁnition, by composing the morphisms and using the fact
that being homotopic is preserved by composition. □
 
3. Decomposition Theorems

We have two decomposition theorems involving additive and multiplicative subagents.
 
3.1. First Decomposition Theorem
Theorem: C0 ◃C1 if and only if there exists a C2 such that C0 ◃× C2 ◃+ C1.
Proof: We will use the currying deﬁnitions of subagent and multiplicative subagent,
and the committing deﬁnition of additive subagent. Let C0 = (A0, E0, ⋅0) and 
C1 = (A1, E1, ⋅1). If C0 ◃C1, there exists some Cartesian frame D over A1 such that 
C0 = C
∘
1 (D).
Let C2 = (Image(D), E1, ⋅2), where ⋅2 is given by a ⋅2 e = a ⋅1 e. C2 is created by deleting
some possible agents from C1, so by the committing deﬁnition of additive subagent 
C2 ◃+ C1.
Also, if we let D′ be the Cartesian frame over Image(D) which is identical to D, but on a
restricted codomain, then we clearly have that C
∘
1 (D) ≅C
∘
2 (D′). Thus C0 ≃C
∘
2 (D′) and 
Image(D′) = Agent(C2), so C0 ◃× C2.
The converse is trivial, since subagent is weaker than additive and multiplicative
subagent and is transitive. □
Imagine that that a group of kids, Alice, Bob, Carol, etc., is deciding whether to start a
game of baseball or football against another group. If they choose baseball, they form
a team represented by the frame CB, while if they choose football, they form a team
represented by the frame CF. We can model this by imagining that C0 is the group's
initial state, and CB and CF are precommitment-style subagents of C0.
Suppose the group chooses football. CF's choices are a function of Alice-the-football-
player's choices, Bob-the-football-player's choices, etc. (Importantly, Alice here has
diﬀerent options and a diﬀerent environment than if the original group had chosen
baseball. So we will need to represent Alice-the-football-player, CAF, with a diﬀerent
frame than Alice-the-baseball-player, CAB; and likewise for Bob and the other team
members.)

It is easy to see in this case that the relationship between Alice-the-football-player's
frame (CAF) and the entire group's initial frame (C0) can be decomposed into the
additive relationship between C0 and CF and the multiplicative relationship between 
CF and CAF, in that order.
The ﬁrst decomposition theorem tells us that every subagent relation, even ones that
don't seem to involve a combination of "making a commitment" and "being a team,"
can be decomposed into a combination of those two things. I've provided an example
above where this factorization feels natural, but other cases may be less natural.
Using the framing from our discussion of the currying deﬁnitions: this decomposition is
always possible because we can always decompose a possibly-nondeterministic
function f into (1) a possibly-nondeterministic surjective function onto f's image, and
(2) a deterministic function embedding f's image in f's codomain.
 
3.2. Second Decomposition Theorem
Theorem: There exists a morphism from C0 to C1 if and only if there exists a C2 such
that C0 ◃
∗
+ C2 ◃+ C1. 
Proof: First, let C0 = (A, E, ⋅), let C1 = (B, F, ⋆), and let (g, h) : C0 →C1. We let 
C2 = (A, F, ⋄), where a ⋄f = g(a) ⋆f = a ⋅h(f). 
First, we show C2 ◃+ C1, To do this, we let B′ ⊆B be the image of g, and let 
C
′
2 = (B′, F, ⋆′), where ⋆′ is given by b ⋆′ f = b ⋆f. By the committing deﬁnition of
additive subagent, it suﬃces to show that C
′
2 ≃C2. 
We deﬁne (g0, h0) : C2 →C
′
2 and (g1, h1) : C
′
2 →C2 as follows. We let h0 and h1 be the
identity on F. We let g0 : A →B′ be given by g0(a) = g(a). Observe that g0 is surjective,
and thus has a right inverse. Let g1 be any right inverse to g0, so g0(g1(b)) = b for all 
b ∈B′. 
We know (g0, h0) is a morphism, since for all a ∈A and f ∈F, we have

g 0 ( a ) ⋆ ′ f  = g ( a ) ⋆ f 
 = a ⋄ f 
 = a ⋄ h 0 ( f ) . 
Similarly, we know (g1, h1) is a morphism, since for all b ∈B′ and f ∈F, we have
g 1 ( b ) ⋄ f  = g 1 ( b ) ⋄ h 0 ( f ) 
 = g 0 ( g 1 ( b ) ) ⋆ ′ f 
 = b ⋆ ′ f 
 = b ⋆ ′ h 1 ( f ) . 
Clearly, (g0, h0) ∘(g1, h1) and  (g1, h1) ∘(g0, h0) are homotopic to the identity, since 
h0 ∘h1 and h1 ∘h0 are the identity on F. Thus, C
′
2 ≃C2. 
The fact that C0 ◃
∗
+ C2, or equivalently C
∗
2 ◃+ C
∗
0 , is symmetric, since the relationship
between C
∗
2  and C
∗
0  is the same as the relationship between C2 and C1.
Conversely, if C2 ◃+ C1, there is a morphism from C2 to C1 by the categorical deﬁnition
of additive subagent. Similarly, if C0 ◃
∗
+ C2, then C
∗
2 ◃+ C
∗
0 , so there is a morphism from
 C
∗
2  to C
∗
0 , and thus a morphism from C0 to C2. These compose to a morphism from C0
 to C1. □
When we introduced morphisms and described them as "interfaces," we noted that
every morphism (g, h) : C0 →C1 implies the existence of an intermediate frame C2 that
represents Agent(C0) interacting with Env(C1). The second decomposition theorem
formalizes this claim, and also notes that this intermediate frame is a super-
environment of C0 and a subagent of C1.
 
In our next post, we will provide several methods for constructing additive and
multiplicative subagents: "Committing, Assuming, Externalizing, and Internalizing."

Committing, Assuming, Externalizing,
and Internalizing
Crossposted from the AI Alignment Forum. May contain more technical jargon than
usual.
This is the tenth post in the Cartesian frames sequence.
Here, we deﬁne a bunch of ways to construct new (additive/multiplicative)
(sub/super)-(agents/environments) from a given Cartesian frame. Throughout this
post, we will start with a single Cartesian frame over W, C = (A, E, ⋅).
We will start by deﬁning operations from taking subsets and partitions of A and E. We
will then deﬁne similar operations from taking subsets and partitions of W.
 
1. Deﬁnitions from Agents and Environments
1.1. Committing
Deﬁnition: Given a subset B ⊆A, let CommitB(C) denote the Cartesian frame (B, E, ⋆),
with ⋆ given by b ⋆e = b ⋅e. Let Commit∖B(C) denote the Cartesian frame (A∖B, E, ⋄),
with ⋄ given by a ⋄e = a ⋅e.
CommitB(C) represents the perspective you get when the agent of C makes a
commitment to choose an element of B, while Commit∖B(C) represents the
perspective you get when the agent of C makes a commitment to choose an element
outside of B.
Claim: For all B ⊆A, CommitB(C) ◃+ C and Commit∖B(C) ◃+ C. Further, Commit∖B(C)
 and CommitB(C) are brothers in C.
Proof: That CommitB(C) ◃+ C and Commit∖B(C) ◃+ C is trivial from the committing
deﬁnition of additive subagent.

Observe that CommitB(C) ⊕Commit∖B(C) = (A, E × E, ∙), where ∙ is given by 
a ∙(e, f) = a ⋅e if a ∈B, and a ∙(e, f) = a ⋅f if a ∉B. Let D ⊂E × E be the diagonal, 
{(e, e) | e ∈E}. We clearly have that (A, D, ∙′) is in CommitB(C) ⊞Commit∖B(C), where 
∙′ is the restriction of ∙ to A × D, and that (A, D, ∙′) ≅C; so Commit∖B(C) ◃+ C and 
CommitB(C) ◃+ C are brothers in C. □
Claim: Commit∖B(C) ≅CommitA∖B(C)
Proof: Trivial. □
 
1.2. Assuming
Assuming is the dual operation to committing.
Deﬁnition: Given a subset F ⊆E, let AssumeF(C) denote the Cartesian frame (A, F, ⋆),
with ⋆ given by a ⋆f = a ⋅f. Let Assume∖F(C) denote the Cartesian frame (A, E∖F, ⋄),
with ⋄ given by a ⋄e = a ⋅e.
AssumeF(C) represents the perspective you get when you assume the environment is
chosen from F, while Assume∖F(C) represents the perspective you get when you
assume the environment is chosen from outside of F.
In "Introduction to Cartesian Frames" §3.2 (Examples of Controllables), I noted the
counter-intuitive result that agents have no control in worlds where a meteor (or other
event) could have prevented their existence:
C0 =      
r
s
m
u
n
u ↔r
u ↔s
⎛
⎜ 
⎜ 
⎜
⎝
ur
us
m
nr
ns
m
ur
ns
m
nr
us
m
⎞
⎟ 
⎟ 
⎟
⎠
.

Here, we see that we can use Assume∖F(C) to recover the more intuitive idea of
"control." The subagent modiﬁed by the assumption "there's no meteor" can have
controllables, even though the original agent has no controllables:
Assume∖{m}(C0) =      
r
s
u
n
u ↔r
u ↔s
⎛
⎜ 
⎜ 
⎜
⎝
ur
us
nr
ns
ur
ns
nr
us
⎞
⎟ 
⎟ 
⎟
⎠
.
Claim: For all F ⊆E, (AssumeF(C))∗≅CommitF(C ∗) and 
(Assume∖F(C))∗≅Commit∖F(C ∗). Similarly, for all B ⊆A, 
(CommitB(C))∗≅AssumeB(C ∗) and (Commit∖B(C))∗≅Assume∖B(C ∗).
Proof: Trivial. □
Claim: For all F ⊆E, C ◃
∗
+ AssumeF(C) and C ◃
∗
+ Assume∖F(C). 
Proof: Trivial. □
 
1.3. Externalizing
Note that for the following deﬁnitions, when we say "X is a partition of Y ," we
mean that X is a set of nonempty subsets of Y , such that for each y ∈Y , there exists
a unique x ∈X such that y ∈x. 
Deﬁnition: Given a partition X of Y , let Y /X denote the set of all functions q from X
 to Y  such that q(x) ∈x for all x ∈X.
Deﬁnition: Given a partition B of A, let ExternalB(C) denote the Cartesian Frame 
(A/B, B × E, ⋆), where ⋆ is given by q ⋆(b, e) = q(b) ⋅e. Let External/B(C) denote the
Cartesian Frame (B, A/B × E, ⋄), where ⋄ is given by b ⋄(q, e) = q(b) ⋅e.

We say "externalizing B" for ExternalB and "externalizing mod B" for External/B.
ExternalB(C) can be thought of the result of the agent of C ﬁrst factoring its choice
into choosing an equivalence class in B, and choosing an element of each equivalence
class, and then externalizing the part of itself that chooses an equivalence class. I.e.,
we are drawing a new Cartesian frame which treats the choice of equivalence class as
part of the environment, rather than part of the agent.
Similarly, External/B(C) can be thought of the result of the agent of C factoring as
above, then externalizing the part of itself that chooses an element of each
equivalence class.
Claim: For all partitions B of A, ExternalB(C) ◃× C and External/B(C) ◃× C. Further, 
ExternalB(C) and External/B(C) are sisters in C.
Proof: Let ExternalB(C) = (A/B, B × E, ⋆) and External/B(C) = (B, A/B × E, ⋄).
First, observe that for every e ∈E, there exists a morphism 
(ge, he) : ExternalB(C) →(External/B(C))∗, with ge :→A/B × E given by ge(q) = (q, e),
and he : B →B × E given by he(b) = (b, e). To see that this is a morphism, observe that
for all q ∈A/B and b ∈B,
g e ( q ) ⋄ b  = q ( b ) ⋅ e 
 = q ⋆ h e ( b ) . 
Let E′ ⊆hom(ExternalB(C), (External/B(C))∗) be given by E′ = {(ge, he) | e ∈E}, and
let D = (A/B × B, E′, ∙), where
( q , b ) ∙ ( g e , h e )  = g e ( q ) ⋄ b 
 = q ⋆ h e ( b ) 
 = q ( b ) ⋅ e . 
Our goal is to show that D ∈ExternalB(C) ⊠External/B(C), and that D ≃C.

To see D ≃C, we deﬁne (g0, h0) : D →C and (g1, h1) : C →D as follows.
First, g0 : A/p × B →A is given by g0(q, b) = q(b). We ﬁrst need to conﬁrm that g0 is
surjective. Given any a ∈A, we can let b ∈B be the set with a ∈b and construct
a function q ∈A/B by saying q(b) = a, and for each b′ ≠b, choosing an a′ ∈b′, and
saying q(b′) = a′. Observing that g0(q, b) = a, we have that g0 is surjective and thus
has a right inverse.
We choose g1 : A →A/B × B to be any right inverse to g0. Similarly, we deﬁne 
h0 : E →E′ by h0(e) = (ge, he), which is clearly surjective, and deﬁne h1 : E′ →E to be
any right inverse to h0. (Indeed, h0 is bijective as long as A is nonempty.)
Then, for all (q, b) ∈A/B × B and e ∈E, we have
g 0 ( q , b ) ⋅ e  = q ( b ) ⋅ e 
 = ( q , b ) ∙ ( g e , h e ) 
 = q , b ∙ h 0 ( e ) , 
so (g0, h0) is a morphism. This also gives us that for all a ∈A and e′ ∈E′ we have
g 1 ( a ) ∙ e ′  = g 1 ( a ) ∙ h 0 ( h 1 ( e ′ ) ) 
 = g 0 ( g 1 ( a ) ) ⋅ h 1 ( e ) 
 = a ⋅ h 1 ( e ) , 
so (g1, h1) is a morphism. We know (g0, h0) ∘(g1, h1) is homotopic to the identity on C,
since g0 ∘g1 is the identity on A, and we know that (g1, h1) ∘(g0, h0) is homotopic to
the identity on D, since h0 ∘h1 is the identity on E′. Thus, D ≃C.
To show that D ∈ExternalB(C) ⊠External/B(C), it suﬃces to show that
External B ( C )  = ( A / B , B × E , ⋆ ) 
 ≃ ( A / B , B × E ′ , ⋆ ′ ) , 

and
External / B ( C )  = ( B , A / B × E , ⋄ ) 
 ≃ ( B , A / B × E ′ , ⋄ ′ ) , 
where ⋆′ and ⋄′ are given by
q ⋆ ′ ( b , ( g e , h e ) )  = b ⋄ ′ ( q , ( g e , h e ) ) 
 = q ⋆ h e ( b ) 
 = b ⋄ g e ( q ) 
 = q ( b ) ⋅ e . 
Indeed, we show that if A is nonempty, (A/B, B × E, ⋆) ≅(A/B, B × E′, ⋆′), and 
(B, A/B × E, ⋄) ≅(B, A/B × E′, ⋄′).
If A is nonempty, then the function from E to E′ given by e ↦(ge, he) is a bijection,
since it is clearly surjective, and is injective because e is uniquely deﬁned by 
ge(a) = (a, e). This gives a bijection between B × E and B × E′, and we have that for all 
q ∈A/B, b ∈B, and e ∈E,
q ⋆ ′ ( b , ( g e , h e ) )  = q ( b ) ⋅ e 
 = q ⋆ ( b , e ) . 
Similarly, we have a bijection between A/B × E and A/B × E′, and for all q ∈A/B, b ∈B,
and e ∈E,
b ⋄ ′ ( q , ( g e , h e ) )  = q ( b ) ⋅ e 
 = b ⋄ ( q , e ) . 
If A is empty, then B is empty, and A/p is a singleton empty function, so 
(A/B, B × E, ⋆) ≃(A/B, B × E′, ⋆′) ≃⊤, and we either have 
(B, A/B × E, ⋄) ≃(B, A/B × E′, ⋄′) ≃0 or (B, A/B × E, ⋄) ≃(B, A/B × E′, ⋄′) ≃null, depending
on whether or not E is empty.

Thus, D ∈ExternalB(C) ⊠External/B(C), so ExternalB(C) and External/B(C) are sisters
in C. □
 
1.4. Internalizing
Deﬁnition: Given a partition F of E, let InternalF(C) denote the Cartesian Frame 
(F × A, E/F, ⋆), where ⋆ is given by (f, a) ⋆q = a ⋅q(f). Let  Internal/F(C) denote the
Cartesian Frame (E/F × A, F, ⋄), where ⋄ is given by (q, a) ⋄f = a ⋅q(f). 
We say "internalizing p" for Internalp and "internalizing mod p" for Internal/p.
Claim: For all partitions F of E, (InternalF(C))∗≅ExternalF(C ∗) and 
(Internal/F(C))∗≅External/F(C ∗). Similarly, for all partitions B of A, 
(ExternalB(C))∗≅InternalB(C ∗) and (External/B(C))∗≅Internal/B(C ∗). 
Proof: Trivial. □
Claim: For all partitions F of E, C ◃× InternalF(C) and C ◃× Internal/F(C).
Proof: This follows from the fact that (InternalF(C))∗≅ExternalF(C ∗) ◃× C ∗ and 
(Internal/F(C))∗≅External/F(C ∗) ◃× C ∗, and the fact that multiplicative subagent is
equivalent to multiplicative sub-environment. □
 
2. Deﬁnitions from Worlds
The above deﬁnitions are dependent on subsets and partitions of a given A and E, and
thus do not represent a single operation that can be applied to an arbitrary Cartesian
frame over W. We will now use the above eight deﬁnitions to deﬁne another eight
operations that instead use subsets and partitions of W.
Once we have the following deﬁnitions in hand, our future references to committing,
assuming, externalizing, and internalizing will use the deﬁnitions from worlds unless

noted otherwise.
 
2.1. Committing
Deﬁnition: Given a set S ⊆W, we deﬁne CommitS(C) = CommitB(C) and 
Commit∖S(C) = Commit∖B(C), where B ⊆A is given by B = {a ∈A | ∀e ∈E, a ⋅e ∈S}.
Claim: For all S ⊆W, CommitS(C) ◃+ C and Commit∖S(C) ◃+ C. Further, Commit∖S(C)
 and CommitS(C) are brothers in C.
Proof: Trivial. □
Unlike before, it is not necessarily the case that Commit∖S(C) ≅CommitW∖S(C). This is
because there might be rows that contains both elements of S and elements of W∖S.
 
2.2. Assuming
Deﬁnition: Given S ⊆W, we deﬁne AssumeS(C) = AssumeF(C) and 
Assume∖S(C) = Assume∖F(C), where F ⊆E is given by F = {e ∈E | ∀a ∈A, a ⋅e ∈S}.
Claim: For all S ⊆W, (AssumeS(C))∗≅CommitS(C ∗) and 
(Assume∖S(C))∗≅Commit∖S(C ∗), (CommitS(C))∗≅AssumeS(C ∗) and 
(Commit∖S(C))∗≅Assume∖S(C ∗).
Proof: Trivial. □
Claim: For all S ⊆W, C ◃
∗
+ AssumeS(C) and C ◃
∗
+ Assume∖S(C).
Proof: Trivial. □
 
2.3. Externalizing

Deﬁnition: Given a partition V  of W, let v : W →V  send each element w ∈W to the
part that contains it. We deﬁne ExternalV (C) = ExternalB(C) and 
External/V (C) = External/B(C), where B = {{a′ ∈A | ∀e ∈E,  v(a′ ⋅e) = v(a ⋅e)} | a ∈A}
.
Claim: For all partitions V  of W, ExternalV (C) ◃× C and External/V (C) ◃× C. Further, 
ExternalV (C) and External/V (C) are sisters in C.
Proof: Trivial. □
 
2.4. Internalizing
Deﬁnition: Given a partition V  of W, let v : W →V  send each element w ∈W to the
part that contains it. We deﬁne InternalV (C) = InternalF(C) and 
Internal/V (C) = Internal/F(C), where F = {{e′ ∈E | ∀a ∈a,  v(a ⋅e′) = v(a ⋅e)} | e ∈E}.
Claim: For all partitions V  of W, C ◃× InternalV (C) and C ◃× Internal/V (C). 
Proof: Trivial. □
Claim: For all partitions V  of W, (InternalV (C))∗≅ExternalV (C ∗), 
(Internal/V (C))∗≅External/V (C ∗), (ExternalV (C))∗≅InternalV (C ∗), and 
(External/V (C))∗≅Internal/V (C ∗). 
Proof: Trivial. □
 
3. Basic Properties
3.1. Biextensional Equivalence
Committing and assuming are well-deﬁned up to biextensional equivalence.

Claim: If C0 ≃C1 are Cartesian frames over W, then for any subset S ⊆W, 
CommitS(C0) ≃CommitS(C1), Commit∖S(C0) ≃Commit∖S(C1),
AssumeS(C0) ≃AssumeS(C1), and Assume∖S(C0) ≃Assume∖S(C1).
Proof: Let Ci = (Ai, Ei, ⋅i), and let (g0, h0) : C0 →C1 and (g1, h1) : C1 →C0 compose to
something homotopic to the identity in both orders. Let Bi ⊂Ai be deﬁned by 
Bi = {a ∈Ai | ∀e ∈Ei,  a ⋅i e ∈S}.
Observe that if b ∈B0, then for all e ∈E1, g0(b) ⋅1 e = b ⋅0 h0(e) ∈S, so g0(b) ∈B1.
Similarly, if b ∈B1, then g1(b) ∈B0. Thus, if we let g
′
i : Bi →B1−i be given by 
g
′
i(b) = gi(b), we get morphisms (g
′
i, hi) : CommitS(Ci) →CommitS(C1−i), which are
clearly morphisms, since they are restrictions of our original morphisms (gi, hi).
Since (g0, h0) and (g1, h1) compose to something homotopic to the identity in both
orders, (idAi, h1−i ∘hi) : Ci →Ci is a morphism, so 
(idBi, h1−i ∘hi) : CommitS(Ci) →CommitS(Ci) is a morphism, so (g
′
0, h0) and (g
′
1, h1)
 compose to something homotopic to the identity in both orders. Thus 
CommitS(C0) ≃CommitS(C1).
Similarly, if b ∈A0∖B0, then there exists an e ∈E0 such that b ⋅0 e ∉S. But then
g 0 ( b ) ⋅ 1 h 1 ( e )  = g 1 ( g 0 ( b ) ) ⋅ 0 e 
 = b ⋅ 0 e 
∉S, so g0(b) ∈A1∖B1. Similarly, if b ∈A1∖B1, then g1(b) ∈A0∖B0. Thus, if we let 
g
′′
i : Ai∖Bi →A1−i∖B1−i be given by g
′′
i (b) = gi(b), we get morphisms 
(g
′′
i , hi) : Commit∖S(Ci) →Commit∖S(C1−i), which (similarly to above) compose to
something homotopic to the identity in both orders. Thus, 
Commit∖S(C0) ≃Commit∖S(C1).

We know that AssumeS(C0) ≃AssumeS(C1) and Assume∖S(C0) ≃Assume∖S(C1),
because
( Assume S ( C 0 ) ) ∗  
 
                                  ≅ 
                                
 Commit S ( C 
∗
0  ) 
 ≃ Commit S ( C 
∗
1  ) 
 
 
                                  ≅ 
                                
 Assume S ( C 1 ) 
and
( Assume ∖ S ( C 0 ) ) ∗  
 
                                  ≅ 
                                
 Commit ∖ S ( C 
∗
0  ) 
 ≃ Commit ∖ S ( C 
∗
1  ) 
 
 
                                  ≅ 
                                
 Assume ∖ S ( C 1 ) . 
□
Externalizing and internalizing are also well-deﬁned up to biextensional equivalence.
Claim: If C0 ≃C1 are Cartesian frames over W, then for all partitions V  of W, 
ExternalV (C0) ≃ExternalV (C1), External/V (C0) ≃External/V (C1), 
InternalV (C0) ≃InternalV (C1), and Internal/V (C0) ≃Internal/V (C1).
Proof: Let Ci = (Ai, Ei, ⋅i), and let (g0, h0) : C0 →C1 and (g1, h1) : C1 →C0 compose to
something homotopic to the identity in both orders. Let V  be a partition of W, and let 
v : W →V  send each element w ∈W to the part that contains it. Let Bi be the partition
of Ai deﬁned by Bi = {{a′ ∈Ai | ∀e ∈Ei,  v(a′ ⋅e) = v(a ⋅e)} | a ∈Ai}. 
Let βi : Ai →Bi, send each element of Ai to its part in Bi, so 
βi(a) = {a′ ∈Ai | ∀e ∈Ei,  v(a′ ⋅e) = v(a ⋅e)}. Since βi is surjective, it has a right

inverse. Let αi : Bi →Ai be any choice of right inverse to βi. This gives a pair of
functions ιi : Bi →B1−i given by ιi = β1−i ∘gi ∘αi.
We start by showing that ι0 and ι1 are inverses, and thus bijections between B0 and B1
. We do this by showing that βi ∘g1−i ∘gi = βi, and that ιi ∘βi = β1−i ∘gi , and thus we
will have
ι 1 − i ∘ ι i  = ι 1 − i ∘ β 1 − i ∘ g i ∘ α i 
 = β i ∘ g 1 − i ∘ g i ∘ α i 
 = β i ∘ α i , 
which is the identity on Bi.
To see that βi ∘g1−i ∘gi = βi, observe that for all a ∈Ai, we have that for all e ∈Ei, 
v(a ⋅i e) = v(g1−i(gi(a)) ⋅i e), so, βi(a) = βi(g1−i(gi(a))). Thus, βi = βi ∘g1−i ∘gi.
To see that ιi ∘βi = β1−i ∘gi, ﬁrst observe that for all a ∈Ai, we have that 
βi(αi(βi(a))) = βi(a), and thus, for all e ∈E1−i,
v ( g i ( a ) ⋅ 1 − i e )  = v ( a ⋅ i h i ( e ) ) 
 = v ( α i ( β i ( a ) ) ⋅ i h i ( e ) ) 
 = v ( g i ( α i ( β i ( a ) ) ) ⋅ 1 − i e ) . 
Thus, β1−i(gi(a)) = β1−i(gi(αi(βi(a)))). Thus, we have
β 1 − i ∘ g i  = β 1 − i ∘ g i ∘ α i ∘ β i 
 = ι i ∘ β i . 
This also gives us functions fi : Ai/Bi →A1−i/B1−i, by fi(q) = gi ∘q ∘ι1−i. To ehow that
these functions are well-deﬁned, we need to show that for all q ∈Ai/Bi,  fi(q) is in fact
in A1−i/B1−i, by showing that for all b ∈B1−i,  gi(q(ι1−i(b))) ∈b, or equivalently that 
β1−i ∘gi ∘q ∘ι1−i is the identity on B1−i. Since q ∈Ai/Bi, we already have that βi ∘q is
the identity of Bi. Thus, we have that

β 1 − i ∘ g i ∘ q ∘ ι 1 − i  = ι i ∘ β i ∘ q ∘ ι 1 − i 
 = ι i ∘ ι 1 − i 
is the identity on B1−i.
We are now ready to demonstrate that ExternalV (C0) ≃ExternalV (C1).
Let ExternalV (Ci) = (Ai/Bi, Bi × Ei, ⋆i), and deﬁne
( g 
′
i , h 
′
i ) : ( A i / B i , B i × E i , ⋆ i ) → ( A 1 − i / B 1 − i , B 1 − i × E 1 − i , ⋆ 1 − i )
by g
′
i = fi, while h
′
i : B1−i × E1−i →Bi × Ei is given by h
′
i(b, e) = (ι1−i(b), hi(e)).
To see that (g
′
i, h
′
i) is a morphism, observe that for all q ∈Ai/Bi, and (b, e) ∈B1−i × E1−i,
 we have
g 
′
i ( q ) ⋆ 1 − i ( b , e )  = f i ( q ) ⋆ 1 − i ( b , e ) 
 = f i ( q ) ( b ) ⋅ 1 − i e 
 = g i ( q ( ι 1 − i ( b ) ) ) ⋅ 1 − i e 
 = q ( ι 1 − i ( b ) ) ⋅ i h i ( e ) 
 = q ⋆ i ( ι 1 − i ( b ) , h i ( e ) ) 
 = q ⋆ i h 
′
i ( b , e ) . 
To see that (g
′
1−i, h
′
1−i) ∘(g
′
i, h
′
i) is homotopic to the identity, we show that
( id A i / B i , h 
′
i ∘ h 
′
1 − i ) : ( A i / B i , B i × E i , ⋆ i ) → ( A i / B i , B i × E i , ⋆ i )
is a morphism. Indeed, for all q ∈Ai/Bi and (b, e) ∈Bi × Ei,

q ⋆ i h 
′
i ( h 
′
1 − i ( b , e ) )  = q ⋆ i ( b , h i ( h 1 − i ( e ) ) ) 
 = q ( b ) ⋅ i h i ( h 1 − i ( e ) ) 
 = q ( b ) ⋅ i e = q ⋆ i ( b , e ) . 
Thus, ExternalV (C0) ≃ExternalV (C1)
Similarly, let External/V (Ci) = (Bi, Ai/Bi × Ei, ⋄i), and deﬁne
( g 
′ ′
i  , h 
′ ′
i  ) : ( B i , A i / B i × E i , ⋄ i ) → ( B 1 − i , A 1 − i / B 1 − i × E 1 − i , ⋄ 1 − i )
by g
′′
i = ιi, and h
′′
i : A1−i/B1−i × E1−i →Ai/Bi × Ei is given by h
′′
i (q, e) = (f1−i(q), hi(e)).
To see that (g
′′
i , h
′′
i ) is a morphism, observe that for all q ∈Bi, and 
(q, e) ∈A1−i/B1−i × E1−i, we have 
g 
′ ′
i  ( b ) ⋄ 1 − i ( q , e )  = ι i ( b ) ⋄ 1 − i ( q , e ) 
 = q ( ι i ( b ) ) ⋅ 1 − i e 
 = q ( ι i ( b ) ) ⋅ 1 − i h 1 − i ( h i ( e ) ) 
 = g 1 − i ( q ( ι i ( b ) ) ) ⋅ i h i ( e ) 
 = f 1 − i ( q ) ( b ) ⋅ i h i ( e ) 
 = b ⋄ i ( f 1 − i ( q ) , h i ( e ) ) 
 = b ⋄ i h 
′ ′
i  ( q , e ) . 
Clearly, (g
′′
1−i, h
′′
1−i) ∘(g
′′
i , h
′′
i ) is homotopic to the identity, since g
′′
1−i ∘g
′′
i  is the identity
on Bi. Thus, External/V (C0) ≃External/V (C1).
We know that InternalV (C0) ≃InternalV (C1) and Internal/V (C0) ≃Internal/V (C1),
because

( Internal V  ( C 0 ) ) ∗  
 
                                  ≅ 
                                
 External V  ( C 
∗
0  ) 
 ≃ External V  ( C 
∗
1  ) 
 
 
                                  ≅ 
                                
 Internal V  ( C 1 ) 
and
( Internal / V  ( C 0 ) ) ∗  
 
                                  ≅ 
                                
 External / V  ( C 
∗
0  ) 
 ≃ External / V  ( C 
∗
1  ) 
 
 
                                  ≅ 
                                
 Internal / V  ( C 1 ) . 
□
 
3.2. Committing and Assuming Can Be Deﬁned Using Lollipop and Tensor
Claim: CommitS(C) ≅1S ⊸C and AssumeS(C) ≅1S ⊗C.
Proof: Let C = (A, E, ⋅), and let 1S = ({a}, S, ⋄). 
Let CommitS(C) = (B, E, ⋆), where B = {b ∈A | ∀e ∈e,  b ⋅e ∈S}, and b ⋆e = b ⋅e. 
Let 1S ⊸C = (hom(1S, C), {a} × E, ∙), where
( g , h ) ∙ ( a , e )  = g ( a ) ⋅ e 
 = a ⋄ h ( e ) 
 = h ( e ) . 
We construct an isomorphism (g0, h0) : (1S ⊸C) →CommitS(C), by deﬁning 
g0 : hom(1S, C) →B by g0(g, h) = g(a), and by deﬁning h0 : E →{a} × E by h0(e) = (a, e)

.
First, we need to show that g0 is a well-deﬁned function into B. Observe that for all 
(g, h) ∈hom(1S, C), and for all e ∈E,
g 0 ( g , h ) ⋅ e  = g ( a ) ⋅ e 
 = h ( e ) 
∈S, and so g0(g, h) ∈B.
Next, we show that (g0, h0) is a morphism, by showing that for all (g, h) ∈hom(1S, C)
 and e ∈E,
g 0 ( g , h ) ⋆ e  = g ( a ) ⋆ e 
 = g ( a ) ⋅ e 
 = a ⋄ h ( e ) 
 = ( g , h ) ∙ ( a , e ) 
 = ( g , h ) ∙ h 0 ( e ) . 
Finally, to show that (g0, h0), we need to show that g0 and h0 are bijections. Clearly, h0
 is a bijection. To see that g0 is injective, observe that if g0(g, h) = g0(g′, h′), then 
g(a) = g′(a), so g = g′. Further, for all e ∈E, 
h ( e )  = a ⋄ h ( e ) 
 = g ( a ) ⋅ e 
 = g ′ ( a ) ⋅ e 
 = a ⋄ h ′ ( e ) 
 = h ′ ( e ) , 
so h = h′. Thus g0 is injective. To see that g0 is surjective, observe that for all b ∈B,
there exists a morphism (gb, hb) : 1S →C, given by gb(a) = b, and hb(e) = b ⋆e. This is
a morphism because, for all a ∈{a} and e ∈E,

g b ( a ) ⋆ e  = b ⋆ e 
 = h b ( e ) 
 = a ⋄ h b ( e ) . 
Since
g 0 ( g b , h b )  = g b ( a ) 
 = b , 
we have that g0 is surjective, and thus (g0, h0) is an isomorphism between 1S ⊸C and 
CommitS(C).
To see that AssumeS(C) ≅1S ⊗C, observe that
Assume S ( C )  
 
                                  ≅ 
                                
 Commit S ( C ∗ ) ∗ 
 
 
                                  ≅ 
                                
 ( 1 S → C ∗ ) ∗ 
 
 
                                  ≅ 
                                
 ( 1 
∗
S  
 
                                      ⅋ 
                                    
   C ∗ ) ∗ 
 
 
                                  ≅ 
                                
 1 S ⊗ C . 
□
Recall that we can think of 1S as a powerless agent that has been promised S. 1S ⊗C,
then, is a team consisting of Agent(C) alongside an agent that has been promised S.
In order for these two to form a team, the promise S must still hold for the team as a
whole; and since Agent(1S) is powerless, the resultant team is exactly Agent(C) joined
with the promise, i.e., AssumeS(C).

CommitS(C) ≅1S ⊸C is less intuitive. 1S ⊸C is "C with a hole in it shaped like a
promise that S happens." In eﬀect, an agent-and-hole can only "ﬁt" such a promise
into itself by being the kind of agent-and-hole that always guarantees S will happen.
It will sometimes be helpful to think about assuming and committing in terms of 1S, as
this highlights the close relationship between these operations and the other objects
and operations we've been working with.1
 
4. Idempotence
We will show that all eight of the new deﬁnition from worlds are idempotent (up to
isomorphism). We will do this by in each case describing the subset of Cartesian
frames over W that each operation projects onto, and showing that the operation is
indeed ﬁxed on that subset.
 
4.1. Committing and Assuming
Claim: For any Cartesian frame C = (A, E, ⋅) over W and subset S of W, 
CommitS(C) ◃⊥S and AssumeS(C) ◃⊥S.
Proof: Trivial. □
Claim: For any Cartesian frame C = (A, E, ⋅) over W and subset S of W, with C ◃⊥S, 
CommitS(C) ≅AssumeS(C) ≅C.
Proof: Trivial. □
Corollary: For any subset S of W, CommitS and AssumeS are idempotent.
Proof: Trivial. □
Claim: For any Cartesian frame C = (A, E, ⋅) over W and subset S of W, if 
Commit∖S = (A′, E′, ⋅′), then for all a′ ∈A′, there exists an e′ ∈E′ such that a′ ⋅′ e′ ∉S.
Proof: Trivial. □

Claim: For any Cartesian frame C = (A, E, ⋅) over W and subset S of W, if for all a ∈A,
there exists an e ∈E such that a ⋅e ∉S, then Commit∖S(C) ≅C.
Proof: Trivial. □
Corollary: For any subset S of W, Commit∖S is idempotent.
Proof: Trivial. □
Claim: For any Cartesian frame C = (A, E, ⋅) over W and subset S of W, if 
Assume∖S(C) = (A′, E′, ⋅′), then for all e′ ∈E′, there exists an a′ ∈A′ such that a′ ⋅′ e′ ∉S
.
Proof: Trivial. □
Claim: For any Cartesian frame C = (A, E, ⋅) over W and subset S of W, if for all e ∈E,
there exists an a ∈A such that a ⋅e ∉S, then Assume∖S(C) ≅C.
Proof: Trivial. □
Corollary: For any subset S of W, Assume∖S(C) is idempotent.
Proof: Trivial. □
 
4.2. Externalizing
Claim: For any Cartesian frame C = (A, E, ⋅) over W and partition V  of W, let v : W →V
 send each element of W to its part in V . If ExternalV (C) = (A′, E′, ⋅′), then A′ is
nonempty and for all a
′
0, a
′
1 ∈A′ and e′ ∈E′, we have v(a
′
0 ⋅′ e′) = v(a
′
1 ⋅′ e′).
Proof: Let B be deﬁned, as in the deﬁnition of ExternalV , as 
B = {{a′ ∈A | ∀e ∈E,  v(a′ ⋅e) = v(a ⋅e)} | a ∈A}. A′ is A/B, the set of functions from B
 to A that sends each part in B to an element of that part, and E′ = B × E. A′ is clearly

nonempty. Consider an arbitrary a
′
0, a
′
1 ∈A′ and (e, b) ∈E′. Since a
′
0(b), a
′
0(b) ∈b are in
the same part, we have that a
′
0(b) ⋅e = a
′
0(b) ⋅e, and thus v(a
′
0 ⋅′ (b, e)) = v(a
′
1 ⋅′ (b, e)). 
□
Claim: For any Cartesian frame C = (A, E, ⋅) over W and partition V  of W, let v : W →V
 send each element of W to its part in V . If A is nonempty and for all a0, a1 ∈A and 
e ∈E, we have v(a0 ⋅e) = v(a1 ⋅e), then ExternalV (C) ≅C.
Proof: Let B be deﬁned, as in the deﬁnition of ExternalV , as 
B = {{a′ ∈A | ∀e ∈E,  v(a′ ⋅e) = v(a ⋅e)} | a ∈A}. If A is nonempty and for all 
a0, a1 ∈A and e ∈E, we have v(a0 ⋅e) = v(a1 ⋅e), then B has only one part, B = {A}.
Thus, ExternalV (C) = (A/{A}, {A} × E, ⋆), where ⋆ is given by q ⋆(A, e) = q(A) ⋅e.
Let (g, h) : ExternalV (C) →C be given by g(q) = q(A), and h(e) = (A, e). This is trivially a
morphism, and both g and h are trivially bijections, so ExternalV (C) ≅C.□
Corollary: For any partition V  of W, ExternalV  is idempotent.
Proof: Trivial. □
Claim: For any Cartesian frame C = (A, E, ⋅) over W and partition V  of W, let v : W →V
 send each element of W to its part in V . If External/V = (A′, E′, ⋅′), then for all 
a
′
0 ≠a
′
1 ∈A′ there exists an e′ ∈E′, such that v(a
′
0 ⋅′ e′) ≠v(a
′
1 ⋅′ e′).
Proof: Let B be deﬁned once again as 
B = {{a′ ∈A | ∀e ∈E,  v(a′ ⋅e) = v(a ⋅e)} | a ∈A}. A′ = B and E′ = A/B × E. Since A/B is
clearly nonempty, ﬁx any q ∈A/B. Observe that if a
′
0 ≠a
′
1, then q(a
′
0) and q(a
′
1) are in

diﬀerent parts in B, so there exists an e ∈E such that v(q(a
′
0) ⋅e) ≠v(q(a
′
1) ⋅e). Thus 
v(a
′
0 ⋅′ (q, e)) ≠v(a
′
1 ⋅′ (q, e)). □
Claim: For any Cartesian frame C = (A, E, ⋅) over W and partition V  of W, let v : W →V
 send each element of W to its part in V . If for all a0 ≠a1 ∈A there exists an e ∈E
, such that v(a0 ⋅e) ≠v(a1 ⋅e), then ExternalV (C) ≅C.
Proof: Again, let B be deﬁned again as 
B = {{a′ ∈A | ∀e ∈E,  v(a′ ⋅e) = v(a ⋅e)} | a ∈A}. If for all a0 ≠a1 ∈A there exists an 
e ∈E such that v(a0 ⋅e) ≠v(a1 ⋅e), then every element of B is a singleton. Thus 
A/B = {q} is a singleton, and q is a bijection.
External/V (C) = (B, {q} × E, ⋆), where ⋆ is given by b ⋆(q, e) = q(b) ⋅e. Let 
(g, h) : External/V (C) →C be given by g(b) = q(b), and h(e) = (q, e). This is trivially a
morphism and both g and h are trivially bijections, so External/V (C) ≅C. □
Corollary: For any partition V  of W, External/V (C) is idempotent.
Proof: Trivial. □
 
4.3. Internalizing
Using duality, we also get all of the following analogous results for internalizing.
Claim: For any Cartesian frame C = (A, E, ⋅) over W and partition V  of W, let v : W →V
 send each element of W to its part in V . If InternalV (C) = (A′, E′, ⋅′), then E′ is
nonempty and for all e
′
0, e
′
1 ∈E′ and a′ ∈A′, we have v(a′ ⋅′ e
′
0) = v(a′ ⋅′ e
′
1).
Proof: Trivial. □

Claim: For any Cartesian frame C = (A, E, ⋅) over W and partition V  of W, let v : W →V
 send each element of W to its part in V . If for all e0, e1 ∈E and a ∈A we have 
v(a ⋅e0) = v(a ⋅e1), then InternalV (C) ≅C.
Proof: Trivial. □
Corollary: For any partition V  of W, InternalV (C) is idempotent.
Proof: Trivial. □
Claim: For any Cartesian frame C = (A, E, ⋅) over W and partition V  of W, let v : W →V
 send each element of W to its part in V . If Internal/V (C) = (A′, E′, ⋅′), then for all 
e
′
0 ≠e
′
1 ∈E′ there exists an a′ ∈A′, such that v(a′ ⋅′ e
′
0) ≠v(a′ ⋅′ e
′
0).
Proof: Trivial. □
Claim: For any Cartesian frame C = (A, E, ⋅) over W and partition V  of W, let v : W →V
 send each element of W to its part in V . If for all e0 ≠e1 ∈A there exists an a ∈A
, such that v(a ⋅e0) ≠v(a ⋅e1), then InternalV (C) ≅C.
Proof: Trivial. □
Corollary: For any partition V  of W, Internal/V (C) is idempotent.
Proof: Trivial. □
 
Our new assuming, internalizing, and externalizing operations will also provide a new
lens for us to better understand observables. We turn to this in our next post, "Eight
Deﬁnitions of Observability."
Footnotes

1. This section is a good distillation of 1S as it relates to multiplicative operations. The
additive role of 1S is quite diﬀerent from this, and quite varied. There isn't a single
interpretation for 1S in additive contexts, beyond the basic interpretation we provided
in "Biextensional Equivalence" that 1S is "a powerless, all-knowing agent... plus a
promise from the environment that the world will be in S." ↩

Eight Deﬁnitions of Observability
Crossposted from the AI Alignment Forum. May contain more technical jargon than usual.
This is the eleventh post in the Cartesian frames sequence. Here, we compare eight equivalent deﬁnitions of observables, which
emphasize diﬀerent philosophical interpretations.
Throughout this post, we let C = (A, E, ⋅) be a Cartesian frame over a nonempty set W, we let V = {S1, ... , Sn} be a ﬁnite partition
of W, and we let v : W →V  send each element of W to its part in V .
The condition that V  is ﬁnite is an important one. Many of the deﬁnitions below can be extended to inﬁnite partitions, and the
theory of observability for inﬁnite partitions is probably nice, but we are not discussing it here. The condition that W is nonempty
is just ruling out some degenerate cases
 
1. Deﬁnition from Subsets
The deﬁnitions in this post will talk about when a ﬁnite partition V  of W is observable in C. This will make some of the deﬁnitions
more elegant, and it is easy to translate back and forth between the new deﬁnitions of the observability of a ﬁnite partition and
the old deﬁnitions of the observability of a subset. 
Deﬁnition: We say C's agent can observe a ﬁnite partition V  of W if for all parts Si ∈V , Si ∈Obs(C). We let Obs′(C) denote the
set of all ﬁnite partitions of W that are observable in C.
Claim: For any nonempty strict subset S ⊂W, C's agent can observe S if and only if C'sagent can observe {S, (W∖S)}.
Proof: If C's agent can observe {S, (W∖S)}, then clearly C's agent can observe S. If C'sagent can observe S, then since
observability is closed under complements, C's agent can observe W∖S, and so can observe {S, (W∖S)}. □
 
1.1. Example
In "Introduction to Cartesian Frames," we gave the example of an agent that can choose between unconditionally carrying an
umbrella, unconditionally carrying no umbrella, carrying an umbrella iﬀ it's raining, and carrying an umbrella iﬀ it's sunny:
C 0 =       
r 
s  
u 
n 
u ↔ r 
u ↔ s 
 
⎛
⎜ 
⎜ 
⎜
⎝
 
u r 
u s 
n r 
n s 
u r 
n s 
n r 
u s 
 
⎞
⎟ 
⎟ 
⎟
⎠
 
Here, Obs(C0) = {{}, {ur, nr}, {us, ns}, W}, so the partition V = {R, S} is observable in C0, where R = {ur, nr} and S = {us, ns}.
As we go through the deﬁnitions in this post, we will repeatedly return to C0 and show how to understand C0's observables in
terms of our new deﬁnitions.
Before presenting fundamentally new deﬁnitions, we will modify our two old deﬁnitions to be about ﬁnite partitions instead of
subsets.
 
2. Conditional Policies Deﬁnition
Deﬁnition: We say that C's agent can observe a ﬁnite partition V  of W if for all functions f : V →A, there exists an element af ∈A
 such that for all e ∈E, f(v(af ⋅e)) ⋅e = af ⋅e.
Claim: This deﬁnition is equivalent to the deﬁnition from subsets.

Proof: We work by induction on the number of parts in V . Since W is nonempty, V  has at least one part. If V = {W} has one part,
we clearly have that C's agent can observe V  under the deﬁnition from subsets. For the conditional policies deﬁnition, we also
have that C's agent can observe V , since we can take af = f(W), and thus, for all e ∈E,
f ( v ( a f ⋅ e ) ) ⋅ e  = f ( W ) ⋅ e 
 = a f ⋅ e . 
If V = {S1, ... , Sn} has n parts, consider the partition V ′ = {S1 ∪S2, S3, ... , Sn} which unions together the ﬁrst two parts S1 and S2
 of V . Let v′ : W →V ′ send each element of W to its part in V ′.
First, assume that C's agent can observe V  according to the deﬁnition from subsets. Then, since observability of subsets is closed
under unions, C's agent can also observe V ′ under the deﬁnition from subsets, and thus also under the conditional policies
deﬁnition.
Given a function f : V →A, let f ′ : V ′ →A be given by f ′(S1 ∪S2) = f(S2), and f ′(Si) = f(Si) on all other inputs. Since C's agent can
observe V ′ under the conditional policies deﬁnition, we can let af ′ be such that for all e ∈E, f ′(v′(af ′ ⋅e)) ⋅e = af ′ ⋅e.
Choose an af ∈A such that af ∈if(S1, f(S1), a
′
f), which we can do because S1 is observable in C. Observe that for all e ∈E, we have
that if af ⋅e ∈S1, then
f ( v ( a f ⋅ e ) ) ⋅ e  = f ( S 1 ) ⋅ e 
 = a f ⋅ e , 
if af ⋅e ∈S2, we have af ⋅e = af ′ ⋅e, and thus
f ( v ( a f ⋅ e ) ) ⋅ e  = f ( S 2 ) ⋅ e 
 = f ′ ( S 1 ∪ S 2 ) ⋅ e 
 = f ′ ( v ′ ( a f ′ ⋅ e ) ) ⋅ e 
 = a f ′ ⋅ e 
 = a f ⋅ e , 
and ﬁnally if af ⋅e ∈Si for some i ≠1, 2, we still have have af ⋅e = af ′ ⋅e, and thus
f ( v ( a f ⋅ e ) ) ⋅ e  = f ( S i ) ⋅ e 
 = f ′ ( S i ) ⋅ e 
 = f ′ ( v ′ ( a f ′ ⋅ e ) ) ⋅ e 
 = a f ′ ⋅ e 
 = a f ⋅ e . 
Thus, C's agent can observe V  according to the conditional policies deﬁnition.
Conversely, if C's agent can observe V  according to the conditional policies deﬁnition, then to show that C's agent can observe V
 according to the deﬁnition from subsets, it suﬃces to show that the agent can observe Si for all Si ∈V . Thus, we need to show
that for any a0, a1 ∈A, there exists an a2 ∈A with a2 ∈if(Si, a0, a1).
Indeed, if we let f : V →A send Si to a0, and send all other inputs to a1, then we can take an af such that for all e ∈E, 
f(v(af ⋅e)) ⋅e = af ⋅e. But then, if af ⋅e ∈Si, then

a f ⋅ e  = f ( v ( a f ⋅ e ) ) ⋅ e 
 = f ( S 1 ) ⋅ e 
 = a 0 ⋅ e , 
and otherwise,
a f ⋅ e  = f ( v ( a f ⋅ e ) ) ⋅ e 
 = a 1 ⋅ e . 
Thus, C's agent can observe V  according to the deﬁnition from subsets. □
 
2.1. Example
Let C0 = (A, E, ⋅) be deﬁned as in the §1.1 example, with R = {ur, nr}, S = {us, ns}, and  V = {R, S}.
A = {u, n, u ↔r, u ↔s} is a four-element set, and V = {R, S} is a two-element set, so there are sixteen functions f : V →A. For each
function, there is a possible agent af ∈A that satisﬁes f(v(af ⋅e)) ⋅e = af ⋅e for all e ∈E. We can illustrate the sixteen functions and
the corresponding af ∈A in a sixteen-row table:
f ( R ) f ( S )
a f
u
u
u
u
n
u ↔ r
u
u ↔ r u ↔ r
u
u ↔ s u
n
u
u ↔ s
n
n
n
n
u ↔ r n
n
u ↔ s u ↔ s
u ↔ r u
u
u ↔ r n
u ↔ r
u ↔ r u ↔ r u ↔ r
u ↔ r u ↔ s u
u ↔ s u
 u ↔ s
u ↔ s n
n
u ↔ s u ↔ r n
u ↔ s u ↔ s u ↔ s
Since there is an af ∈A for each function, C0's agent can observe V  according to the conditional policies deﬁnition.
 
3. Additive Deﬁnitions
Next, we give an additive deﬁnition of observables. This is a version of our categorical deﬁnition of observables from "Controllables
and Observables, Revisited," modiﬁed to be about ﬁnite partitions.
Deﬁnition: We say C's agent can observe a ﬁnite partition V = {S1, ... , Sn} of W if there exist C1, ⋯Cn, Cartesian frames over W,
with Ci ◃⊥Si such that C ≃C1& ... &Cn.
This can also be strengthened to a constructive version of the additive deﬁnition, which we will call the assuming deﬁnition.

Deﬁnition: We say C's agent can observe a ﬁnite partition V = {S1, ... , Sn} of W if C ≃AssumeS1(C)& ... &AssumeSn(C).
Claim: These deﬁnitions are equivalent to each other and the deﬁnitions above.
Proof: We assume that n ≥2, and that A is nonempty. The case where n = 1 and the case where A = {} are trivial.
If C's agent can observe V  according to the assuming deﬁnition of observables, then it can also clearly observe V  according to the
additive deﬁnition, since AssumeS1(C) ◃⊥S1. 
Next, assume that C's agent can observe V  according to the additive deﬁnition. We will show that C's agent can observe S1.
Consider the pair of Cartesian frames C1 and C2& ... &Cn. Observe that C1 ◃⊥S1 and that C2& ... &Cn ◃⊥W∖S1, and that 
C ≃C1&(C2& ... &Cn). Thus, S1 is observable in C. Symmetrically, Si is observable in C for all i = 1, ... n, and thus V  is observable in 
C according to the deﬁnition from subsets.
Finally, assume that C's agent can observe V  according to the conditional policies deﬁnition (and also the deﬁnition from subsets).
We will show that C ≃C1& ... &Cn, where Ci = AssumeSi(C).
We have C1& ... &Cn = (An, E1 ⊔⋯⊔En, ⋆), where Ci = (A, Ei, ⋅i), and ⋆ is given by (a1, ... , an) ⋆e = ai ⋅e, where e ∈Ei.
First observe that for every e ∈E, there is a unique i ∈{1, ... , n} such that e ∈Ei. This is because there exists an a0 ∈A, and from
the deﬁnition from subsets, C's agent can observe each Si, and so given an e ∈E, if a0 ⋅e ∈Si, it must be the case that for all 
a ∈A, a ⋅e ∈Si. Thus, we have that that E = E1 ⊔⋯⊔En.
We construct (g0, h0) : (An, E, ⋆) →C and (g1, h1) : C →(An, E, ⋆) which compose to something homotopic to the identity in each
order. Let g1 : A →An  be the diagonal, given by g1(a) = (a, ... , a). Let h0 and h1 be the identity on E. Let g0 be given by 
g0(a1, ... , an) = af, where f : V →A is given by f(Si) = ai, and af satisﬁes f(v(af ⋅e)) ⋅e = af ⋅e for all e ∈E, which is possible by the
conditional policies deﬁnition.
To see that (g1, h1) is a morphism, observe that for all a ∈A and e ∈E,
g 1 ( a ) ⋆ e  = ( a , ... , a ) ⋆ e 
 = a ⋅ e 
 = a ⋅ h 1 ( e ) . 
To see that (g0, h0) is a morphism, observe that for all (a1, ... , an) ∈A, and e ∈E, if we let f : V →A be given by f(Si) = ai, we have
g 0 ( a 1 , ... , a n ) ⋅ e  = f ( v ( g 0 ( a 1 , ... , a n ) ⋅ e ) ) ⋅ e 
 = f ( S i ) ⋅ e 
 = a i ⋅ e 
 = ( a 1 , ... , a n ) ⋆ e 
 = ( a 1 , ... , a n ) ⋆ h 0 ( e ) , 
where i is such that e ∈Ei. The fact that (g0, h0) and (g1, h1) compose to something homotopic to the identity in both orders
follows from the fact that h0 ∘h1 and h1 ∘h0 are the identity on E. Thus, C ≃AssumeS1(C)& ... &AssumeSn(C), and so V  is
observable in C according to the assuming deﬁnition. □
 
3.1. Example
Let C0 be deﬁned as in the previous examples, with R = {ur, nr} and S = {us, ns}. By the assuming deﬁnition, there exist two
frames

C 1 = Assume R ( C 0 ) =       
r  
u 
n  
( 
u r 
n r  ) 
and
C 2 = Assume S ( C 0 ) =       
s  
u 
n  
( 
u s 
n s  ) 
such that C0 ≃C1&C2.
This example both illustrates the idea behind the additive deﬁnitions, and shows the construction used in the assuming deﬁnition.
This is also the same example we provided to illustrate products of Cartesian frames in "Additive Operations on Cartesian Frames."
Another way of thinking about the additive deﬁnition of observables: Recall "Committing, Assuming, Externalizing, and
Internalizing" §3.2 (Committing and Assuming Can Be Deﬁned Using Lollipop and Tensor), where we saw that AssumeS(C) ≅1S ⊗C.
This means that (up to isomorphism) we can restate  C0 ≃C1&C2 as C0 ≃(1R ⊗C0) &(1S ⊗C0), i.e.,
⎛
⎜ 
⎜ 
⎜
⎝
ur
us
nr
ns
ur
ns
nr
us
⎞
⎟ 
⎟ 
⎟
⎠
   ≃
( ur 
 nr ) ⊗
⎛
⎜ 
⎜ 
⎜
⎝
ur
us
nr
ns
ur
ns
nr
us
⎞
⎟ 
⎟ 
⎟
⎠
   &
( us 
 ns ) ⊗
⎛
⎜ 
⎜ 
⎜
⎝
ur
us
nr
ns
ur
ns
nr
us
⎞
⎟ 
⎟ 
⎟
⎠
.
This (equivalent) framing makes it easier to keep track of what "assuming" is doing categorically, so that we can see what
interfaces between frames we are relying on when we say that something is "observable" using an additive deﬁnition.
 
4. Multiplicative Deﬁnitions
Our multiplicative deﬁnitions will depend on a notion of agents being powerless outside of a subset.
 
4.1. Powerless Outside of a Subset
Deﬁnition: Given a subset S of W, we say that C's agent is powerless outside S if for all e ∈E, and all a0, a1 ∈A, if a0 ⋅e ∉S,
then a0 ⋅e = a1 ⋅e.
To say that C's agent is powerless outside S is to say that the if the world is at all dependent on C's agent, then the world must be
in S.
Here are some lemmas about being powerless outside of a subset, which we will use later.
Lemma: If C's agent is powerless outside S and T ⊇S, then C's agent is powerless outside T.
Proof: Trivial. □
Lemma: If C and D's agents are both powerless outside S, then C ⊗D's agent is powerless outside S.
Proof: Let D = (B, F, ⋆), and let C ⊗D = (A × B, hom(C, D∗), ⋄). Consider some (a0, b0), (a1, b1) ∈A × B and (g, h) ∈hom(C, D∗). We
will use the fact that if a0 ⋅h(b0) ∉S then a0 ⋅h(b0) = a1 ⋅h(b0), and the fact that if b0 ⋆g(a1) ∉S then b0 ⋆g(a1) = b1 ⋆g(a1).
Observe that if (a0, b0) ⋄(g, h) ∉S, then

( a 0 , b 0 ) ⋄ ( g , h )  = a 0 ⋅ h ( b 0 ) 
 = a 1 ⋅ h ( b 0 ) 
 = b 0 ⋆ g ( a 1 ) 
 = b 1 ⋆ g ( a 1 ) 
 = ( a 1 , b 1 ) ⋆ ( g , h ) . 
□
Now, we are ready for our ﬁrst truly new deﬁnition of the observability of a ﬁnite partition.
 
4.2. Multiplicative Deﬁnitions of Observables
Deﬁnition: We say that C's agent can observe a ﬁnite partition V = {S1, ... , Sn} of W if C ≃C1 ⊗⋯⊗Cn, where each Ci's agent is
powerless outside Si.
Again, we also have a constructive version of this deﬁnition:
Deﬁnition: We say that C's agent can observe a ﬁnite partition V = {S1, ... , Sn} of W if C ≃C1 ⊗⋯⊗Cn, where 
Ci = AssumeSi(C)&1Ti, where Ti = (W∖Si) ∩Image(C).
Claim: These deﬁnitions are equivalent to each other and equivalent to the deﬁnitions above.
Proof: First, observe that if C's agent can observe V  according to the constructive version of the multiplicative deﬁnition, it can
also observe V  according to the nonconstructive version of the multiplicative deﬁnition, since the agent of AssumeSi(C)&1Ti is
clearly powerless outside Si.
Next, we show that if C's agent can observe V  according to the nonconstructive multiplicative deﬁnition, it can also observe V
 according to the deﬁnition from subsets. Let C ≃D = C1 ⊗⋯⊗Cn, where each Ci's agent is powerless outside Si. It suﬃces to
show that D's agent can observe V , since the deﬁnition from subsets is equivalent to the additive deﬁnition, and thus closed under
biextensional equivalence. Thus, it suﬃces to show that D's agent can observe Si for all i = 1, ... , n. We will show that D's agent
can observe S1, and the rest will follows by symmetry. 
Let C1 = (A1, E1, ⋅1), and let D1 = (B1, F1, ⋆1) = C2 ⊗⋯⊗Cn. We start by showing that D1's agent is powerless outside W∖S1. We
have that the agents of C2, ... , Cn are all powerless outside W∖S1, since being powerless outside something is closed under
supersets. Thus we have that D1's agent is powerless outside W∖S1, since being powerless outside W∖S1 is closed under tensor.
Thus, we have D = (A1 × B1, hom(C, D∗), ⋄) = C1 ⊗D1, with C1's agent powerless outside S1 and D1's agent powerless outside 
W∖S1. Given an arbitrary (a1, b1), (a2, b2) ∈A1 × B1 , we will show that (a1, b2) ∈if(S1, (a1, b1), (a2, b2)), and thus show that D
's agent can observe S1.
It suﬃces to show that for all (g, h) : C →D∗, if  (a1, b2) ⋄(g, h) ∈S1, then (a1, b2) ⋄(g, h) = (a1, b1) ⋄(g, h), and if  
(a1, b2) ⋄(g, h) ∉S1, then (a1, b2) ⋄(g, h) = (a2, b2) ⋄(g, h). Indeed, if (a1, b2) ⋄(g, h) ∈S1, then, since D1's agent is powerless
outside W∖S1, we have
( a 1 , b 2 ) ⋄ ( g , h )  = b 2 ⋆ 1 g ( a 1 ) 
 = b 1 ⋆ 1 g ( a 1 ) 
 = ( a 1 , b 1 ) ⋄ ( g , h ) . 
Similarly, if (a1, b2) ⋄(g, h) ∉S1, then, since C1's agent is powerless outside S, we have

( a 1 , b 2 ) ⋄ ( g , h )  = a 1 ⋅ 1 h ( b 2 ) 
 = a 2 ⋅ 1 h ( b 2 ) 
 = ( a 2 , b 2 ) ⋄ ( g , h ) . 
Thus, D's agent can observe S1, so C's agent can observe V  according to the deﬁnition from subsets.
Finally, we assume that C's agent can observe V  according to the assuming deﬁnition, and show that C's agent can observe V
 according to the constructive version of the multiplicative deﬁnition.
We work by induction on n, the number of parts. The case where n = 1 is trivial. Let C ≃AssumeS1(C)& ... &AssumeSn(C). Thus, we
also have that C ≃AssumeS1∪S2(C)&AssumeS3(C)& ... &AssumeSn(C), and so by induction, we have that 
C ≃(AssumeS1∪S2(C)&1T1∩T2) ⊗C3 ⊗⋯⊗Cn, where Ci and Ti are as in the constructive multiplicative deﬁnition. Thus, it suﬃces to
show that
Assume S 1 ∪ S 2 ( C ) & 1 T 1 ∩ T 2  ≃ C 1 ⊗ C 2 
 = ( Assume S 1 ( C ) & 1 T 1 ) ⊗ ( Assume S 2 ( C ) & 1 T 2 ) . 
First, observe that we have C ≃D1&D2&D3, where D1 = AssumeS1(C), D2 = AssumeS2(C), and D3 = AssumeS3(C)& ... &AssumeSn(C)
. Let Di = (Bi, Fi, ⋆i). Let Ri = Image(Di).
Observe that T1 = R2 ∪R3, T2 = R1 ∪R3, and T1 ∪T2 = R3, and observe that AssumeS1∪S2(C) ≃D1&D2. Thus it suﬃces to show
that (D1&1R2∪R3) ⊗(D2&1R1∪R3) ≃D1&D2&1R3.
Let D1&1R2∪R3 = (B1, F1 ⊔R2 ⊔R3, ∙1), let D2&1R1∪R3 = (B2, F2 ⊔R1 ⊔R3, ∙2), and let D1&D2&1R3 = (B1 × B2, F1 ⊔F2 ⊔R3, ∙3) where 
∙1, ∙2, and ∙3 are all given by b ∙i f = b ⋆1 f if f ∈F1, b ∙i f = b ⋆2 f if f ∈F2, and b ∙i f = f otherwise.
Let H = hom(B1&1R2∪R3, (D2&1R1∪R3)∗). Let (D1&1R2∪R3) ⊗(D2&1R1∪R3) = (B1 × B2, H, ∙4)), where
( b 1 , b 2 ) ∙ 4 ( g , h )  = b 1 ∙ 1 h ( b 2 ) 
 = b 2 ∙ 2 g ( b 1 ) . 
Observe that for any f1 ∈F1, there is a (gf1, hf1) ∈H, given by gf1(b1) = b1 ⋅1 f1 and hf1(b2) = f1. This is clearly a morphism, since
b 1 ∙ 1 h f 1 ( b 2 )  = b 1 ∙ 1 f 1 
 = b 1 ⋅ 1 f 1 
 = g f 1 ( b 1 ) 
 = b 2 ∙ 2 g f 1 ( b 1 ) . 
Similarly, for any f2 ∈F2, there is a morphism (gf2, hf2) ∈H given by  gf2(b1) = f2 and hf2(b2) = b2 ⋅2 f2. Finally, for any r ∈R3, there
is a morphism (gr, hr) ∈H, given by gr(b1) = hr(b2) = r, which is also clearly a morphism. 
We show that these are in fact all of the morphisms in H. Indeed, let (g, h) be a morphism in H, let b1 be an element of B1, and let 
b2 be an element of b2. Let
r  = b 2 ∙ 2 g ( b 1 ) 
 = b 1 ∙ 1 h ( b 2 ) . 
If r ∈R3, then g(b1) = h(b2) = r, so given any b
′
1 ∈B1,

b 2 ∙ 2 g ( b 
′
1 )  = b 
′
1 ∙ 1 h ( b 2 ) 
 = r 
 ∈R3, and so
g ( b 
′
1 )  = b 2 ∙ 2 g ( b 
′
1 ) 
 = r . 
Similarly, for any b
′
2 ∈B2, h(b
′
2) = r and so (g, h) = (gr, hr).
If r ∈R1, then g(b1) = r, and h(b2) ∈F1. Let f1 = h(b2). Given any b
′
1 ∈B1, 
b 2 ∙ 2 g ( b 
′
1 )  = b 
′
1 ∙ 1 h ( b 2 ) 
 = b 
′
1 ∙ 1 f 1 
∈R1, so
g ( b 
′
1 )  = b 2 ∙ 2 g ( b 
′
1 ) 
 = b 
′
1 ∙ 1 f 1 
 = b 
′
1 ⋅ 1 f 1 . 
Given any b
′
2 ∈B2,
b 1 ∙ 1 h ( b 
′
2 )  = b 
′
2 ∙ 2 g ( b 1 ) 
 = b 
′
2 ∙ 2 r 
 = r 
 ∈R1, and so
h ( b 
′
2 )  = b 1 ∙ 1 h ( b 
′
2 ) 
 = r . 
Thus, 
  
 
                          ( 
                        
  
 
                          g 
                        
  
 
                          , 
                        
  
 
                          h 
                        
  
 
                          ) 
                        
  
 
                          = 
                        
  
 
                          (
                        
.
Finally, if r ∈R2, we similarly have (g, h) = (gf2, hf2), where f2 = g(b1) ∈F2.
We construct a pair of morphisms
( g 0 , h 0 ) : ( B 1 × B 2 , H , ∙ 4 ) → ( B 1 × B 2 , F 1 ⊔ F 2 ⊔ R 3 , ∙ 3 ) 
and
( g 1 , h 1 ) : ( B 1 × B 2 , F 1 ⊔ F 2 ⊔ R 3 , ∙ 3 ) → ( B 1 × B 2 , H , ∙ 4 ) , 
by letting g0 and g1 be the identity on B1 × B2, letting h0 : F1 ⊔F2 ⊔R3 →H be given by h0(f) = (gf, hf) as above. Since we have
shown that h0 is surjective, we let h1 be any right inverse to h0. It is easy to show that both of these are morphisms by the

construction of (gf, hf), and they compose to something homotopic to the identity in both orders since g0 ∘g1 and g1 ∘g0 are the
identity of B1 × B2.
Thus (D1&1R2∪R3) ⊗(D2&1R1∪R3) ≃D1&D2&1R3, so C's agent can observe V  according to the constructive multiplicative deﬁnition,
completing the proof. □
You may have noticed that the last part of the proof would have been much simpler if ⊗ distributed over &, but ⊗ does not in
general distribute over &. (⊗ distributes over ⊕ and ⅋  distributes over &.)
In this case, however, ⊗ does distribute over &. I do not plan on going over it now, but there is actually an interesting relationship
between observables and cases where ⊗ distributes over &.
 
4.3. Example
Let C0 be deﬁned as in the previous examples, with R = {ur, nr} and S = {us, ns}. Let TX = (W∖X) ∩Image(C0), so that 1TR = 1S
 and 1TS = 1R. By the multiplicative deﬁnitions of observables, there then exist two frames
C 1 = Assume R ( C )   &   1 S =       
r 
u s 
n s  
r → u 
r → n  
( 
u r 
u s 
n s 
n r 
u s 
n s  ) 
and
C 2 = Assume S ( C )   &   1 R =       
s 
u r 
n r  
s → u 
s → n  
( 
u s 
u r 
n r 
n s 
u r 
n r  ) 
such that C0 ≃C1 ⊗C2.
Here, C1 is an agent that treats the "makes decisions when it's sunny" part of itself as though it were an external process.
Similarly, C2 externalizes its ability to make decisions when it's rainy.
This example illustrates both multiplicative deﬁnitions, and also shows the construction used in the constructive multiplicative
deﬁnition.
Appealing again to the fact that AssumeS(C) ≅1S ⊗C, we also have the option of restating C0 ≃C1 ⊗C2 here as 
C0  ≃ ((1R ⊗C0) & 1S)  ⊗ ((1S ⊗C0) & 1R). In words, this says that Agent(C0) is (biextensionally equivalent to) a team consisting
of:
1. that very agent, picking an action after the environment either (a) gives it a promise it will rain or (b) makes it powerless and
doesn't rain; and
2. that very agent, picking an action after the environment either (a) gives it a promise it won't rain or (b) makes it powerless
and rains.
 
4.4. Updatelessness
The relationship between observables' additive and multiplicative deﬁnitions is interesting. You can think of the additive deﬁnition
as updateful, while the multiplicative deﬁnition is updateless.
The Ci in the additive deﬁnition are basically given a promise that the world will end up in Si. The Ci in the multiplicative deﬁnition,
however, are instead given a promise that their choices have no eﬀect on worlds outside of Si.
I think the updateless factorization is better, and thus prefer the multiplicative deﬁnition in spite of the fact that it is more
complicated. 
When an updateless agent observes something, it becomes the version of itself that only aﬀects the worlds in which it makes that
observation. When an updateful agent observes something, we assume that all the worlds in which it does not make that
observation do not exist. The fact that the additive and multiplicative deﬁnitions above are equivalent illustrates the equivalence
of the updateful and updateless views in the simple cases where there is true observation. However, they diverge as soon as you

want to try to approximate observation. The updateless view approximates better, as it makes sense to think of a subagent that
has only a very small eﬀect on worlds in which it does not make the observation that it makes.
Also, note that the Ci in the additive deﬁnition are not subagents of C, but they are additive sub-environments. The Ci in the
multiplicative deﬁnition are multiplicative subagents of C.
 
5. Internalizing-Externalizing Deﬁnitions
Next, we have the nonconstructive internalizing-externalizing deﬁnition of observables.
Deﬁnition: We say that C's agent can observe a ﬁnite partition V  of W if either A = {} or C is biextensionally equivalent to
something in the image of ExternalV ∘InternalV .
Again, we have a constructive version of this deﬁnition.
Deﬁnition: We say that C's agent can observe a ﬁnite partition V  of W if either A = {} or C ≃ExternalV (InternalV (C)).
Claim: These deﬁnitions are equivalent to each other and to the deﬁnitions above.
Proof: The case where A = {} is trivial, so we assume that A is nonempty. Clearly if C's agent can observe V  under the
constructive internalizing-externalizing deﬁnition, then V  is also observable in C under the non-constructive version.
Next, assume that C is in the image of ExternalV ∘InternalV  (up to biextensional equivalence). Recall that the image of InternalV
 up to biextensional equivalence is exactly those Cartesian frames (B, F, ⋆) such then F is nonempty and for all f0, f1 ∈F and b ∈B,
 we have v(b ⋆f0) = v(b ⋆f1). Thus,  C ≃ExternalV (B, F, ⋆), where (B, F, ⋆) is of this form. Let vB : B →V  send each element b ∈B to
the unique vb ∈V  such that v(b ⋆f) = vb for all f ∈F, and let VB be the image of vB. Then, ExternalV (B, F, ⋆) = (B/X, X × F, ⋄),
where X = {{b ∈B | vB(b) = v′} | v′ ∈VB}, and q ⋄(x, f) = q(x) ⋆f. 
Let VB = {v1, ... , vm}, and let Bi = {b ∈B | vB(b) = vi}. Then, we clearly have that ExternalV (B, F, ⋆) ≅(B1 × ⋯× Bm, VB × F, ∙),
where (b1, ... , bm) ∙(vi, f) = bi ⋆f. But this is clearly isomorphic to D1& ... &Dm, where Di = (Bi, F, ⋆i), where b ⋆i f = b ⋆f. Thus, C
's agent can observe V  according to the nonconstructive additive deﬁnition of observables.
Finally, we assume that C's agent can observe V  according to the nonconstructive additive deﬁnition of observables, and we show
that C's agent can observe V  according to the constructive internalizing-externalizing deﬁnition. Let C ≃C1& ... &Cn, where Ci ◃⊥Si
. Let Ci = (Ai, Ei, ⋅i), and without loss of generality, let C = C1& ... &Cn = (A, E, ⋅), where A = A1 × ⋯× An and E = E1 ⊔⋯⊔En.
First, we show that InternalV (C) ≃C1 ⊕⋯⊕Cn. Let C1 ⊕⋯⊕Cn = (A1 ⊔⋯⊔An, E1 × ⋯× En, ⋆). Observe that (since A is
nonempty), InternalV (C) ≅(A × F, B/F, ⋆′), where F = {E1, ... , En}, where (a, f) ⋆q = a ⋅q(f). 
We construct
( g 0 , h 0 ) : ( A 1 ⊔ ⋯ ⊔ A n , E 1 × ⋯ × E n , ⋆ ) → ( A × F , B / F , ⋆ ′ ) 
and
( g 1 , h 1 ) : ( A × F , B / F , ⋆ ′ ) → ( A 1 ⊔ ⋯ ⊔ A n , E 1 × ⋯ × E n , ⋆ ) 
as follows. Let g1((a1, ... , an), Ei) = ai. Let g0(ai) = ((a1, ... , ai, ... , an), Ei), where ai ∈Ai, and aj ∈Aj is chosen arbitrarily for j ≠i. Let 
h0(q) = (q(E1), ... , q(En)), and h1(e1, ... , en) = q, where q(Ei) = ei. Clearly, h0 and h1 are inverses.
To see that (g0, h0) is a morphism, observe that for all ai ∈A1 ⊔⋯⊔An and q ∈B/F, we have

g 0 ( a i ) ⋆ ′ q  = ( ( a 1 , ... , a i , ... , a n ) , E i ) ⋆ ′ q 
 = ( a 1 , ... , a i , ... , a n ) ⋅ q ( E i ) 
 = a i ⋅ i q ( E i ) 
 = a i ⋆ ( q ( E 1 ) , ... , q ( E n ) ) 
 = a i ⋆ h 0 ( q ) , 
where ai ∈Ai.
To see that (g1, h1) is a morphism, observe that for all ((a1, ... , an), Ei) ∈A × F, and for all (e1, ... en) ∈E1 × ⋯× En, we have
g 1 ( ( a 1 , ... , a n ) , E i ) ⋆ ( e 1 , ... , e n )  = a i ⋆ ( e 1 ... , e n ) 
 = a i ⋅ i e i 
 = ( a 1 , ... , a n ) ⋅ e i 
 = ( a 1 , ... , a n ) ⋅ h 1 ( e 1 , ... , e n ) ( E i ) 
 = ( ( a 1 , ... , a n ) , E i ) ⋆ h 1 ( e 1 , ... , e n ) . 
It is clear that (g0, h0) ∘(g1, h1) and (g1, h1) ∘(g0, h0) are both homotopic to the identity, since h0 ∘h1 and h1 ∘h0 are both the
identity.
Now, we have that InternalV (C1& ... &Cn) ≃C1 ⊕⋯⊕Cn, and so we also have dually that ExternalV (C1 ⊕⋯⊕Cn) ≃C1& ... &Cn.
Thus, C ≃ExternalV (InternalV (C)). □
The thing that is going on here is that when C internalizes V , the agent of C then has the full ability to choose how V  goes (among
ways of V  going that were possible in C). InternalV (C) might have other choices than just choosing how V  goes. If it does, then it
can freely entangle those other choices with the choice of V  however it wants.
When C then externalizes V , it loses all control over V . However, it preserves the ability to entangle all of its other choices with
the way that V  goes. This ability for the agent to entangle its choices with V  is exactly what it means to say "V  is observable."
 
5.1. Example
Let C0 be deﬁned as in the previous examples, with V = {{ur, nr}, {us, ns}}. By the internalizing-externalizing deﬁnitions, there
exists a frame
InternalV (C0) ≅   
(u, r)
(u, s)
(n, r)
(n, s)
(u ↔r, r)
(u ↔r, s)
(u ↔s, r)
(u ↔s, s)
⎛
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜
⎝
ur
us
nr
ns
ur
ns
nr
us
⎞
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟
⎠
,
which is biextensionally equivalent to

C1 =    
ur
nr
us
ns
⎛
⎜ 
⎜ 
⎜
⎝
ur
nr
us
ns
⎞
⎟ 
⎟ 
⎟
⎠
.
We then have that
ExternalV (C1) ≅   
r
s
(r →ur, s →us)
(r →nr, s →ns)
(r →ur, s →ns)
(r →nr, s →ur)
⎛
⎜ 
⎜ 
⎜
⎝
ur
us
nr
ns
ur
ns
nr
us
⎞
⎟ 
⎟ 
⎟
⎠
,
which is isomorphic to C0.
This example illustrates both internalizing-externalizing deﬁnitions, and also shows the construction used in the constructive
deﬁnition.
 
In our next post, we'll conclude the sequence by showing how to formalize agents that learn and act over time using Cartesian
frames.

Time in Cartesian Frames
Crossposted from the AI Alignment Forum. May contain more technical jargon than
usual.
This is the twelfth and ﬁnal post in the Cartesian Frames sequence. Read the ﬁrst post
here.
Up until now, we have (in the examples) mostly considered agents making a single
choice, rather than acting repeatedly over time.
The actions, environments, and worlds we've considered might be extended over
time. For example, imagine a prisoner's dilemma where "cooperating" requires
pushing a button every day for ﬁve years.
However, our way of discussing Cartesian frames so far would treat "push the button
every day for ﬁve years" as an atomic action, a single element a ∈A. 
Now, will begin discussing how to use Cartesian frames to explicitly represent agents
passing through time. Let us start with a basic example.
 
1. Partial Observability
Consider a process where two players, Yosef and Zoe, collaboratively choose a three-
digit binary number. Yosef ﬁrst chooses the ﬁrst digit, then Zoe chooses the second
digit, then Yosef chooses the third digit. The world will be represented by the three-
digit number. The Cartesian frame from the perspective of Yosef looks like this:
C0 =
⎛
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜
⎝
000
010
000
010
001
011
001
011
000
011
000
011
001
010
001
010
100
110
110
100
101
111
111
101
100
111
111
100
101
110
110
101
⎞
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟
⎠
.

Here, C0 = (A0, E0, ⋅0) is a Cartesian frame over 
W0 = {000,  001,  010,  011,  100,  101,  110,  111}.
The four possible environments from left to right represent Zoe choosing 0, Zoe
choosing 1, Zoe copying the ﬁrst digit, and Zoe negating the ﬁrst digit.
The eight possible agents can be broken up into two groups of four. In the top four
possible agents, Yosef chooses 0 for the ﬁrst digit, while in the bottom four, he
chooses 1. Within each group, the four possible agents represent Yosef choosing 0 for
the third digit, choosing 1 for the third digit, copying the second digit, and negating
the second digit.
Consider the three partitions W1, W2, and W3 of W0 representing the ﬁrst, second and
third digits respectively. Wi = {w
0
i , w
1
i }, where w
0
1 = {000,  001,  010,  011}, 
w
1
1 = {100,  101,  110,  111}, w
0
2 = {000,  001,  100,  101}, w
1
2 = {010,  011,  110,  111}
, w
0
3 = {000,  010,  100,  110}, and w
1
3 = {001,  011,  101,  111}.
Clearly, by the deﬁnition of observables, W2 is not observable in C0. But there is still a
sense in which this does not tell the whole story. Yosef can observe W2 for the purpose
of deciding the third digit, but can't observe W2 for the purpose of deciding the ﬁrst
digit.
There are actually many ways to express this fact, but I want to draw attention to one
speciﬁc way to express this partial observability: ExternalW1(C0) can observe W2.
Indeed, we have 

ExternalW1(C0) ≃C1 =
⎛
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜
⎝
000
010
100
110
000
010
100
111
000
010
101
110
000
010
101
111
000
011
100
110
000
011
100
111
000
011
101
110
000
011
101
111
001
010
100
110
001
010
100
111
001
010
101
110
001
010
101
111
001
011
100
110
001
011
100
111
001
011
101
110
001
011
101
111
⎞
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟
⎠
.
It may seem counter-intuitive that when you externalize W1, and thus take some
control out of the hands of the agent, you actually end up with more possible agents.
This is because the agent now has to specify what the third digit is, not only as a
function of the second digit, but also as a function of the ﬁrst digit. The agent could
have speciﬁed the third digit as a function of the ﬁrst digit before, but some of the
policies would have been identical to each other.
The four possible environments of C1 specify the ﬁrst two digits, while the 16 possible
agents represent all of the ways to have the third digit be a function of those ﬁrst two
digits. It is clear that W2 is observable in C1.
This gives us a generic way to deﬁne a type of partial observability:

Deﬁnition: Given a Cartesian frame C over W, and partitions V  and T of W, we say V
 is observable in C after time T if V  is observable in ExternalT(C).
 
2. Partitions as Time
Built into the above deﬁnition is the fact that we are thinking of (at least some)
partitions of W as representing time. This makes a lot of sense when we think of W as
a set of possible complete world histories. For any given time, this gives a partition
where world histories are in the same subset if they agree on the world history up to
that point in time.
For example, the above partition W1 was the partition that we got by considering a
time after Yosef chooses the ﬁrst digit, but before Zoe chooses the second digit.
Further, this gives us a sequence of nested partitions, since the partition associated
with one time is always a reﬁnement of the partition associated with an earlier time.
Note that this is a multiplicative/updateless view of time. There is also an
additive/updateful view of time, in which time is a nested sequence of subsets. In the
additive view, possible worlds are eliminated as you pass through time. In the
multiplicative view, possible worlds are distinguished from each other as you pass
through time. We will focus on the multiplicative view, which I consider better-
motivated.
 
3. Nested Subagents
Let C = (A, E, ⋅) be a ﬁxed Cartesian frame over a world W. Let T0, ⋯, Tn be a sequence
of nested partitions of W, with T0 = {W}, Tn = {{w} | w ∈W}, and Ti+1 a reﬁnement
of Ti.
This gives a nested sequence of multiplicative superagents CTn ◃× ⋯◃× CT0, where 
CTi = ExternalTi(C), which follows from the lemma below. 
Lemma: Given a Cartesian frame C over W, if U and V  are partitions of W and U is a
reﬁnement of V , then ExternalU(C) ◃× ExternalV (C).

Proof: Let C = (A, E, ⋅), and let u : W →U and v : W →V  send each element of W to
their part in U and V  respectively. Let ExternalU(C) = (A/BU, BU × E, ⋅U), where 
BU = {{a′ ∈A | ∀e ∈E, u(a′ ⋅e) = u(a ⋅e)} | a ∈A}. Similarly, let
ExternalV (C) = (A/BV , BV × E, ⋅V ), where 
BV = {{a′ ∈A | ∀e ∈E, v(a′ ⋅e) = v(a ⋅e)} | a ∈A}. Let bU : A →BU and bV : A →BV
 send each element of A to its part in BU and BV  respectively. 
Since U is a reﬁnement of V , there exists a v′ : U →V , such that v′ ∘u = v. Further, we
have that BU is a reﬁnement of BV , so there exists a b
′
V : BU →BV  such that 
b
′
V ∘bU = bV .
It suﬃces to show there exist three sets X, Y , and Z, and a function f : X × Y × Z →W
 such that ExternalU(C) ≃(X, Y × Z, ⋄) and ExternalV (C) ≃(X × Y , Z, ∙), where ⋄ and ∙
 are given by x ⋄(y, z) = f(x, y, z) and (x, y) ∙z = f(x, y, z).
We will take X to be A/BU and Z to be BV × E. We deﬁne Y  to be the set of all right
inverses to b
′
V , Y = {y : BV →BU | ∀b ∈BU,  b
′
V (y(b)) = b}. We will let 
f(x, y, (b, e)) = x(y(b)) ⋅e.
First, we show
External U ( C )  = ( A / B U , B U × E , ⋅ U ) 
 ≃ ( X , Y  × Z , ⋄ ) . 
We deﬁne
( g 0 , h 0 ) : ( A / B U , B U × E , ⋅ U ) → ( X , Y  × Z , ⋄ ) 
and
( g 1 , h 1 ) : ( X , Y  × Z , ⋄ ) → ( A / B U , B U × E , ⋅ U ) 

as follows. Let g0 and g1 be the identity on X = A/BU, and let h0 : Y × Z →BU × E be
given by h0(y, (b, e)) = (y(b), e). Finally, let h1 : BU × E →Y × Z be chosen to satisfy 
h1(b, e) = (y, (b
′
V (b), e)), where y is such that y(b
′
V (b)) = b, and for b′ ≠b
′
V (b), y(b′) is
chosen arbitrarily to be any preimage of b′ under b
′
V .
We have that (g0, h0) is a morphism, because for all x ∈A/BU and (y, (b, e)) ∈Y × Z,
g 0 ( x ) ⋄ ( y , ( b , e ) )  = f ( x , y , ( b , e ) ) 
 = x ( y ( b ) ) ⋅ e 
 = x ⋅ U ( y ( b ) , e ) 
 = x ⋅ U h 0 ( y , ( b , e ) ) . 
Similarly, (g1, h1) is a morphism, because for all x ∈X and (b, e) ∈BU × E, we have
g 1 ( x ) ⋅ U ( b , e )  = x ⋅ U ( b , e ) 
 = x ( b ) ⋅ e 
 = x ( y ( b 
′
V  ( b ) ) ) ⋅ e 
 = f ( x , y , ( b 
′
V  ( b ) , e ) ) 
 = x ⋄ ( y , ( b 
′
V  ( b ) , e ) ) 
 = x ⋄ h 1 ( b , e ) , 
where y is as given in the deﬁnition of h1. Since g0 ∘g1 and g1 ∘g0 are both the
identity, we have that (g0, h0) ∘(g1, h1) and (g1, h1) ∘(g0, h0) are both homotopic to
the identity, so ExternalU(C) ≃(X, Y × Z, ⋄).
Next, we show
External V  ( C )  = ( A / B V  , B V  × E , ⋅ V  ) 
 ≃ ( X × Y  , Z , ∙ ) . 
We deﬁne

( g 2 , h 2 ) : ( A / B V  , B V  × E , ⋅ V  ) → ( X × Y  , Z , ∙ ) 
and
( g 3 , h 3 ) : ( X × Y  , Z , ∙ ) → ( A / B V  , B V  × E , ⋅ V  ) 
as follows. Let h2 and h3 be the identity on Z = BV × E, and let g3 : X × Y →A/BV  be
given by g3(x, y) = x ∘y. To see that x ∘y is in A/BV , we need to verify that bV ∘x ∘y is
the identity on BV . Indeed,
b V  ∘ x ∘ y  = b 
′
V  ∘ b U ∘ x ∘ y 
 = b 
′
V  ∘ y , 
which is the identity on BV . Let g2 : A/BV →X × Y  be given by g2(q) = (q′, bU ∘q),
where q′ ∈A/BU is chosen such that for all b ∈BV , q′(bU(q(b))) = q(b), and for b′ not in
the image of bU ∘q, q′(b′) ∈b′. We can do this simultaneously for all inputs of the
form bU(q(b)), since bU ∘q is injective, since it has a left inverse, b
′
V .
We have that (g2, h2) is a morphism, because for all q ∈A/BV  and (b, e) ∈Z, we have
g 2 ( q ) ∙ ( b , e )  = ( q ′ , b U ∘ q ) ∙ ( b , e ) 
 = f ( q ′ , b U ∘ q , ( b , e ) ) 
 = q ′ ( b U ( q ( b ) ) ) ⋅ e 
 = q ( b ) ⋅ e 
 = q ⋅ V  ( b , e ) 
 = h 2 ( q ) ⋅ V  ( b , e ) , 
where q′ is as in the deﬁnition of g2. Similarly, (g3, h3) is a morphism, because for all 
(x, y) ∈X × Y  and (b, e) ∈BV × E, we have

g 3 ( x , y ) ⋅ V  ( b , e )  = x ∘ y ⋅ V  ( b , e ) 
 = x ( y ( b ) ) ⋅ e 
 = f ( x , y , ( b , e ) ) 
 = ( x , y ) ∙ ( b , e ) 
 = ( x , y ) ∙ h 3 ( b , e ) . 
Since h3 ∘h2 and h2 ∘h3 are both the identity, we have that (g2, h2) ∘(g3, h3) and 
(g3, h3) ∘(g2, h2) are both homotopic to the identity, so ExternalV (C) ≃(X × Y , Z, ∙),
completing the proof. □
The sequence CT0, ... , CTn represents the agent persisting across time, but each
subagent CTi does not really represent a single time-slice of the agent. Instead, CTi
 represents an agent persisting across time starting at the time Ti.
I think that this is actually the more natural notion. However, if we want to think about
an agent persisting across times as a sequence of single times-slices of the agent, we
could also do that. Since CTi+1 is a multiplicative subagent of CTi, CTi+1 must have a
sister DTi+1 in CTi, so we could consider the sequence DT1, ... , DTn.
 
4. Controllables Decrease and Observables
Increase Over Time
An interesting fact about these sequences CT0, ... , CTn is that controllables decrease
and observables increase over time, so for i ≤j we have Obs(CTi) ⊆Obs(CTj) and 
Ctrl(CTi) ⊇Ctrl(CTj) (and Ensure(CTi) ⊇Ensure(CTj) and Prevent(CTi) ⊇Prevent(CTj)),
which follows directly from the following two lemmas.
Lemma: Given a Cartesian frame C over W, if U and V  are partitions of W and U is a
reﬁnement of V , then Ctrl(ExternalV (C)) ⊇Ctrl(ExternalU(C)).

Proof: Let CV = ExternalV (C), and let CU = ExternalV (C). We will actually only need to
use the fact that CU ◃× CV , and that both CU and CV  have nonempty agents. CU and 
CV  do in fact have nonempty agent, because, as we have shown, externalizing a
partition of W always produces nonempty agents.
It suﬃces to establish that Ensure(CTi) ⊇Ensure(CTj), and the result for Ctrl follows
trivially.
Since CU ◃× CV , there exist X, Y , Z, and f : X × Y × Z →W such that CU ≃(X, Y × Z, ⋄)
 and CV ≃(X × Y , Z, ∙), where ⋄ and ∙ are given by x ⋄(y, z) = f(x, y, z) and 
(x, y) ∙z = f(x, y, z). Let C
′
U = (X, Y × Z, ⋄), and let C
′
V ≃(X × Y , Z, ∙). Observe that X
 and Y  are nonempty.
Since Ensure is preserved by biextensional equivalence, it suﬃces to show that 
Ensure(C
′
V ) ⊇Ensure(C
′
U). Let S ∈Ensure(C
′
U). Thus, there exists some x0 ∈X, such
that for all (y, z) ∈Y × Z, x0 ⋄(y, z) = f(x0, y, z) ∈S. Since Y  is nonempty, we can take
an arbitrary y0 ∈Y , and observe that for all z ∈S, (x0, y0) ∙z = f(x0, y0, z) ∈S. Thus,  
S ∈Ensure(C
′
V ). □
Lemma: Given a Cartesian frame C over W, if U and V  are partitions of W and U is a
reﬁnement of V , then Obs(ExternalV (C)) ⊆Obs(ExternalU(C)).
Proof: Let C = (A, E, ⋅), and let u : W →U and v : W →V  send each element of W to
their part in U and V  respectively. Let ExternalU(C) = (A/BU, BU × E, ⋅U), where 
BU = {{a′ ∈A | ∀e ∈E, u(a′ ⋅e) = u(a ⋅e)} | a ∈A}. Similarly, let
ExternalU(C) = (A/BV , BV × E, ⋅V ), where 
BV = {{a′ ∈A | ∀e ∈E, v(a′ ⋅e) = v(a ⋅e)} | a ∈A}. Let bU : A →BU and bV : A →BV
 send each element of A to its part in BU and BV  respectively. 

Since U is a reﬁnement of V , there exists a v′ : U →V , such that v′ ∘u = v. Further, we
have that BU is a reﬁnement of BV , so there exists a b
′
V : BU →BV  such that 
b
′
V ∘bU = bV .
Let S ∈Obs(ExternalV (C)). Thus, for every pair q0, q1 ∈A/BV , there exists a q2 ∈A/BV
 such that q2 ∈if(S, q0, q1). Thus, we can deﬁne an f : A/BV × A/BV →A/BV   such that
for all q0, q1 ∈A/BV , f(q0, q1) ∈if(S, q0, q1). 
Our goal is to show that S ∈Obs(ExternalU(C)). For this, it suﬃces to show that for
any q0, q1 ∈A/BU, there exists a q2 ∈A/BU such that q2 ∈if(S, q0, q1). 
Let q0, q1 ∈A/BU be arbitrary. Given an arbitrary b ∈BU, let q
b
i ∈A/BV  be any element
that satisﬁes q
b
i (b
′
V (b)) = qi(b). This is possible because qi(b) ∈b ⊆b
′
V (b). It does not
matter what q
b
i  does on other inputs. Let q2 : BU →A be such that for all b ∈BU, 
q2(b) = f(q
b
0, q
b
1)(b
′
V (b)).
To complete the proof, we need to show that q2 ∈A/BU and q2 ∈if(S, q0, q1). 
To show that q2 ∈A/BU, we need that for all b ∈BU, q2(b) ∈b. Let b ∈BU be arbitrary.
Since q0(b) ∈b, by the deﬁnition of BU, it suﬃces to show that for all e ∈E, 
u(q2(b) ⋅e) = u(q0(b) ⋅e). Further, since q1(b) ∈b, we already have that for all e ∈E, 
u(q1(b) ⋅e) = u(q0(b) ⋅e). Thus, it suﬃces to show that for all e ∈E, either 
q2(b) ⋅e = q0(b) ⋅e or q2(b) ⋅e = q1(b) ⋅e. Indeed, if q2(b) ⋅e ∈S, then
q 2 ( b ) ⋅ e  = f ( q 
b
0 , q 
b
1 ) ( b 
′
V  ( b ) ) ⋅ e 
 = q 
b
0 ( b 
′
V  ( b ) ) ⋅ e 
 = q 0 ( b ) ⋅ e , 

and similarly, if q2(b) ⋅e ∉S, then q2(b) ⋅e = q1(b) ⋅e. Thus, we have that for all e ∈E
, u(q2(b) ⋅e) = u(q0(b) ⋅e), so for our arbitrary b ∈BU, q0(b) ∈b, so q2 ∈A/BU.
Let (b, e) ∈BU × E  be such that q2 ⋅U (b, e) ∈S. We want to show that 
q2 ⋅U (b, e) = q0 ⋅U (b, e). Indeed,
q 2 ⋅ U ( b , e )  = q 2 ( b ) ⋅ e 
 = f ( q 
b
0 , q 
b
1 ) ( b 
′
V  ( b ) ) ⋅ e 
 = f ( q 
b
0 , q 
b
1 ) ⋅ V  ( b 
′
V  ( b ) , e ) 
 = q 
b
0 ⋅ V  ( b 
′
V  ( b ) , e ) 
 = q 
b
0 ( b 
′
V  ( b ) ) ⋅ e 
 = q 0 ( b ) ⋅ e 
 = q 0 ⋅ U ( b , e ) . 
Symmetrically, if (b, e) ∈BU × E is such that q2 ⋅U (b, e) ∉S, we have 
q2 ⋅U (b, e) = q1 ⋅U (b, e). Thus q2 ∈if(S, q0, q1).
Thus, since q0 and q1 were arbitrary, we have that S ∈Obs(ExternalU(C)), completing
the proof. □
This result allows us to think of time as a sort of ritual in which control of the world is
sacriﬁced in exchange for ability to condition on the world.
 
5. Directions for Future Work
As I noted at the start of this sequence, Cartesian frames take their motivation from
Hutter, attempting to improve on the cybernetic agent model; they take their angle of
attack from Pearl, using combinatorics to infer functional structure from relational
structure; and they take their structure from game theory, working with base objects
that look similar to normal-form games.
Building up from very simple foundations, we have found that Cartesian frames yield
elegant notions of agents making choices and observations, of agents acting over

time, and of subagent relations. At the same time, Cartesian frames allow us to switch
between diﬀerent levels of description of the world and consider many diﬀerent ways
of factorizing the world into variables.
I suspect that this is the last post I will write on Cartesian frames for a while, but I am
excited about the framework, and would really like to get more people working on it.
To help with that, I've commented below with various directions for future work: ways
that I think the framework could be extended, made better, or applied.
frames that are partitions into rectangles
generalizing observability
preferences and goals
subagents
logical time
logical uncertainty
formalizing time
computational complexity
time and coarse world models
category-theory-ﬁrst approaches
I've erred on the side of inclusion in these comments: some may point to dead ends,
or may be based on false assumptions.
If you have questions or want to discuss Cartesian frames, I'll be hosting a fourth and
ﬁnal oﬃce hours / discussion section this Sunday at 2pm PT on GatherTown.

Cartesian Frames and Factored Sets
on ArXiv
Crossposted from the AI Alignment Forum. May contain more technical jargon than
usual.
Papers on Cartesian frames and factored sets are now on arXiv. 
Cartesian Frames: https://arxiv.org/abs/2109.10996
Factored Sets: https://arxiv.org/abs/2109.11513
The factored set paper is approximately identical to the sequence here, while the
Cartesian frame paper is rewritten by Daniel Hermann and Josiah Lopez-Wild,
optimized for an audience of philosophers.

